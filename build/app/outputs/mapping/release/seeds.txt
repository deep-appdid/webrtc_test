org.webrtc.VideoDecoder
com.cloudwebrtc.webrtc.DataChannelObserver$1
com.cloudwebrtc.webrtc.utils.Callback
org.webrtc.audio.JavaAudioDeviceModule
org.webrtc.DynamicBitrateAdjuster
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback$AnimationCallback
org.webrtc.VideoEncoderWrapper
com.google.android.gms.common.GooglePlayServicesMissingManifestValueException
com.cloudwebrtc.webrtc.GetUserMediaImpl$VideoCapturerInfo
androidx.activity.ImmLeaksCleaner
org.webrtc.VideoFrame$I420Buffer
kotlin.internal.jdk8.JDK8PlatformImplementations
org.webrtc.CameraCapturer$7
org.webrtc.SurfaceViewRenderer
com.cloudwebrtc.webrtc.R$attr
org.webrtc.PeerConnection$BundlePolicy
org.webrtc.CameraVideoCapturer$CameraStatistics
androidx.window.embedding.ExtensionEmbeddingBackend$EmbeddingCallbackImpl
org.webrtc.Logging
org.webrtc.audio.WebRtcAudioManager
org.webrtc.VideoDecoderWrapper
androidx.window.layout.WindowMetricsCalculatorDecorator
androidx.lifecycle.ReflectiveGenericLifecycleObserver
androidx.window.embedding.EmbeddingRule
org.webrtc.VideoEncoder$CodecSpecificInfoAV1
org.webrtc.TextureBufferImpl$2
org.webrtc.SSLCertificateVerifier
androidx.activity.ComponentActivity$3
androidx.window.layout.FoldingFeature$OcclusionType$Companion
kotlin.coroutines.jvm.internal.BaseContinuationImpl
com.cloudwebrtc.webrtc.audio.AudioDeviceKind
androidx.window.embedding.EmbeddingTranslatingCallback
org.webrtc.Logging$TraceLevel
org.webrtc.RtpParameters$Codec
org.webrtc.Camera2Session$CameraStateCallback
com.cloudwebrtc.webrtc.R$layout
org.webrtc.Camera1Session$SessionState
org.webrtc.CalledByNativeUnchecked
org.webrtc.R
io.flutter.plugins.firebase.core.FlutterFirebaseCoreRegistrar
org.webrtc.ThreadUtils$4
androidx.lifecycle.FullLifecycleObserverAdapter
org.webrtc.MediaStreamTrack$State
androidx.window.embedding.SplitPairRule
androidx.activity.OnBackPressedDispatcher$LifecycleOnBackPressedCancellable
org.webrtc.AndroidVideoDecoder
androidx.window.layout.FoldingFeature
org.webrtc.CameraEnumerationAndroid$2
org.webrtc.BaseBitrateAdjuster
org.webrtc.VideoFrameBufferType
org.webrtc.StatsObserver
com.cloudwebrtc.webrtc.GetUserMediaImpl$4
androidx.window.layout.WindowInfoTracker
org.webrtc.RtpTransceiver
org.webrtc.VideoEncoderFactory
kotlinx.coroutines.internal.MainDispatcherFactory
org.webrtc.NV12Buffer
org.webrtc.VideoDecoder$Callback
org.webrtc.NativeCapturerObserver
com.cloudwebrtc.webrtc.record.FrameCapturer
org.webrtc.MediaConstraints$KeyValuePair
androidx.window.embedding.ActivityStack
org.webrtc.DataChannel$Init
org.webrtc.JniHelper
org.webrtc.PeerConnection$SignalingState
org.webrtc.audio.JavaAudioDeviceModule$AudioTrackErrorCallback
org.webrtc.NetworkMonitorAutoDetect$ConnectivityManagerDelegate
org.webrtc.EglRenderer$2
com.google.android.gms.dynamite.DynamiteModule$DynamiteLoaderClassLoader
org.webrtc.SessionDescription
org.webrtc.CryptoOptions
org.webrtc.MediaCodecWrapperFactoryImpl$MediaCodecWrapperImpl
org.webrtc.NetworkChangeDetector
com.cloudwebrtc.webrtc.GetUserMediaImpl$IsCameraEnabled
org.webrtc.DtmfSender
org.webrtc.LibvpxVp9Decoder
org.webrtc.LibvpxVp9Encoder
androidx.window.layout.WindowMetricsCalculator
org.webrtc.MediaStream
org.webrtc.Histogram
org.webrtc.voiceengine.WebRtcAudioManager$VolumeLogger
org.webrtc.VideoCodecInfo
org.webrtc.ThreadUtils$1CaughtException
org.webrtc.NetworkMonitorAutoDetect
org.webrtc.NetworkMonitorAutoDetect$WifiManagerDelegate
org.webrtc.VideoDecoder$Settings
androidx.window.layout.FoldingFeature$State
androidx.window.embedding.SplitInfo
org.webrtc.RtpParameters
org.webrtc.VideoSink
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$5
org.webrtc.Logging$1
org.webrtc.VideoEncoder$CodecSpecificInfo
com.cloudwebrtc.webrtc.utils.ConstraintsMap
org.webrtc.StatsReport$Value
org.webrtc.ScreenCapturerAndroid$1
org.webrtc.audio.AudioDeviceModule
org.webrtc.FrameCryptor
org.webrtc.CameraCapturer$3
org.webrtc.AndroidVideoDecoder$DecodedTextureMetadata
org.webrtc.VideoEncoder$Capabilities
android.support.v4.app.RemoteActionCompatParcelizer
org.webrtc.RtpCapabilities$HeaderExtensionCapability
org.webrtc.MediaStreamTrack
org.webrtc.PeerConnection$IceServer
org.webrtc.VideoFrameDrawer$YuvUploader
org.webrtc.StatsReport
com.cloudwebrtc.webrtc.DataChannelObserver
org.webrtc.WrappedVideoDecoderFactory
com.cloudwebrtc.webrtc.StateProvider
org.webrtc.AudioEncoderFactoryFactory
org.webrtc.CameraEnumerationAndroid$ClosestComparator
androidx.window.layout.ExtensionInterfaceCompat$ExtensionCallbackInterface
org.webrtc.FrameCryptor$FrameCryptionState
androidx.window.layout.ExtensionWindowLayoutInfoBackend$MulticastConsumer
io.flutter.embedding.engine.renderer.SurfaceTextureWrapper
androidx.savedstate.Recreator
kotlinx.coroutines.CoroutineExceptionHandler
org.webrtc.PeerConnection$Observer
org.webrtc.voiceengine.WebRtcAudioRecord$AudioRecordThread
org.webrtc.FrameCryptor$Observer
androidx.window.layout.HardwareFoldingFeature
androidx.lifecycle.LiveData$LifecycleBoundObserver
org.webrtc.EglBase10Impl$1FakeSurfaceHolder
com.cloudwebrtc.webrtc.R$dimen
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapperFactory
org.webrtc.RtcCertificatePem
org.webrtc.voiceengine.WebRtcAudioRecord$AudioRecordStartErrorCode
org.webrtc.CameraSession$CreateSessionCallback
com.google.android.gms.common.GooglePlayServicesManifestException
com.google.android.gms.common.api.Scope
org.webrtc.GlTextureFrameBuffer
androidx.window.core.Version
org.webrtc.GlUtil$GlOutOfMemoryException
io.flutter.plugins.firebase.core.FlutterFirebasePlugin
org.webrtc.PeerConnectionFactory$Options
org.webrtc.RendererCommon$GlDrawer
org.webrtc.NetworkMonitor
org.webrtc.RtpParameters$Rtcp
org.webrtc.CameraEnumerationAndroid$CaptureFormat$FramerateRange
com.cloudwebrtc.webrtc.record.AudioTrackInterceptor
org.webrtc.NetworkMonitorAutoDetect$NetworkState
org.webrtc.HardwareVideoDecoderFactory
org.webrtc.VideoEncoder$Callback
org.webrtc.PeerConnection$PortPrunePolicy
com.cloudwebrtc.webrtc.utils.PermissionUtils
com.cloudwebrtc.webrtc.GetUserMediaImpl$2
org.webrtc.audio.JavaAudioDeviceModule$Builder
androidx.window.java.layout.WindowInfoTrackerCallbackAdapter$addListener$1$1
org.webrtc.NetworkMonitor$2
kotlin.internal.jdk7.JDK7PlatformImplementations
org.webrtc.VideoFileRenderer
io.grpc.util.SecretRoundRobinLoadBalancerProvider$Provider
org.webrtc.EglBase10
com.cloudwebrtc.webrtc.SurfaceTextureRenderer
org.webrtc.PlatformSoftwareVideoDecoderFactory
org.webrtc.VideoEncoder$ResolutionBitrateLimits
org.webrtc.GlShader
org.webrtc.voiceengine.WebRtcAudioTrack$WebRtcAudioTrackErrorCallback
org.webrtc.voiceengine.WebRtcAudioManager
org.webrtc.CryptoOptions$Builder
org.webrtc.PeerConnectionDependencies$Builder
com.google.firebase.firestore.FirestoreRegistrar
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$FallbackFactory
androidx.window.layout.SidecarCompat$DistinctElementCallback
org.webrtc.NetworkStatePredictorFactoryFactory
org.webrtc.LibvpxVp8Decoder
org.webrtc.Size
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin
org.webrtc.RefCounted
org.webrtc.audio.JavaAudioDeviceModule$AudioTrackStateCallback
com.cloudwebrtc.webrtc.PeerConnectionObserver
androidx.window.java.R
com.cloudwebrtc.webrtc.GetUserMediaImpl$1
org.webrtc.MediaCodecWrapperFactoryImpl
org.webrtc.audio.JavaAudioDeviceModule$AudioSamples
org.webrtc.NetworkMonitorAutoDetect$WifiDirectManagerDelegate
org.webrtc.NetworkControllerFactoryFactory
org.webrtc.SimulcastVideoEncoder
androidx.window.layout.WindowInfoTrackerDecorator
org.webrtc.RefCountDelegate
org.webrtc.ScreenCapturerAndroid$2
org.webrtc.VideoEncoder$CodecSpecificInfoVP8
androidx.window.layout.SidecarCompat$TranslatingCallback
org.webrtc.voiceengine.BuildInfo
org.webrtc.DataChannel$Buffer
org.webrtc.MediaCodecVideoDecoderFactory
org.webrtc.RtpTransceiver$RtpTransceiverInit
androidx.window.layout.SidecarCompat$DistinctSidecarElementCallback
org.webrtc.CameraVideoCapturer$CameraEventsHandler
org.webrtc.GlRectDrawer
io.flutter.plugin.platform.SingleViewPresentation
androidx.window.embedding.SplitPlaceholderRule
org.webrtc.CryptoOptions$Srtp
org.webrtc.RtpSender
com.cloudwebrtc.webrtc.PeerConnectionObserver$1
androidx.window.embedding.EmbeddingCompat
org.webrtc.NetEqFactoryFactory
org.webrtc.BuiltinAudioDecoderFactoryFactory
kotlinx.coroutines.android.AndroidDispatcherFactory
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$6
org.webrtc.audio.JavaAudioDeviceModule$SamplesReadyCallback
org.webrtc.VideoFrame$TextureBuffer
androidx.window.layout.SidecarAdapter$Companion
org.webrtc.TurnCustomizer
org.webrtc.Predicate$2
org.webrtc.VideoEncoder$EncodeInfo
androidx.core.graphics.drawable.IconCompat
org.webrtc.FileVideoCapturer$1
androidx.window.java.layout.WindowInfoTrackerCallbackAdapter
androidx.window.layout.ActivityCompatHelperApi30
com.cloudwebrtc.webrtc.utils.ConstraintsArray
org.webrtc.NetworkChangeDetectorFactory
org.webrtc.CameraCapturer$9
org.webrtc.MediaConstraints
org.webrtc.VideoSource
org.webrtc.FileVideoCapturer
org.webrtc.RtpTransceiver$RtpTransceiverDirection
org.webrtc.PeerConnection$TlsCertPolicy
org.webrtc.VideoEncoder$ScalingSettings
org.webrtc.GlUtil
org.webrtc.PeerConnection$RtcpMuxPolicy
androidx.window.layout.ExtensionWindowLayoutInfoBackend
androidx.window.embedding.ExtensionEmbeddingBackend
org.webrtc.FrameDecryptor
org.webrtc.MediaStreamTrack$MediaType
com.cloudwebrtc.webrtc.R$string
androidx.window.core.Version$bigInteger$2
org.webrtc.VideoFrameDrawer
io.flutter.view.AccessibilityViewEmbedder
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor$FrameCryptorStateObserver
org.webrtc.CameraVideoCapturer
org.webrtc.voiceengine.WebRtcAudioRecord$AudioSamples
androidx.window.layout.FoldingFeature$State$Companion
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor$1
com.cloudwebrtc.webrtc.audio.AudioSwitchManager
org.webrtc.Logging$Severity
org.webrtc.ScreenCapturerAndroid
androidx.window.layout.WindowInfoTrackerImpl
android.support.v4.graphics.drawable.IconCompatParcelizer
org.webrtc.EncodedImage$FrameType
androidx.window.core.ExperimentalWindowApi
androidx.annotation.Keep
androidx.versionedparcelable.ParcelImpl
org.webrtc.Metrics$HistogramInfo
org.webrtc.MediaSource$State
org.webrtc.PeerConnection$CandidateNetworkPolicy
org.webrtc.VideoFrame$TextureBuffer$Type
org.webrtc.VideoDecoder$DecodeInfo
org.webrtc.RendererCommon$RendererEvents
org.webrtc.CandidatePairChangeEvent
org.webrtc.Camera2Session
androidx.window.layout.DisplayCompatHelperApi17
androidx.window.layout.WindowBackend
org.webrtc.VideoProcessor$FrameAdaptationParameters
org.webrtc.PeerConnection$KeyType
org.webrtc.AndroidVideoDecoder$FrameInfo
org.webrtc.FramerateBitrateAdjuster
androidx.window.embedding.SplitRuleParser
org.webrtc.NetworkMonitor$NetworkObserver
androidx.window.layout.ExtensionsWindowLayoutInfoAdapter
org.webrtc.NativeLibrary$DefaultLoader
org.webrtc.AudioTrack
org.webrtc.RtpCapabilities$CodecCapability
org.webrtc.NetworkChangeDetector$IPAddress
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$2
org.webrtc.VideoSource$AspectRatio
org.webrtc.NetworkPreference
org.webrtc.RendererCommon$1
org.webrtc.voiceengine.WebRtcAudioTrack
org.webrtc.SoftwareVideoDecoderFactory
org.webrtc.VideoCodecStatus
org.webrtc.YuvConverter
org.webrtc.EglBase14Impl
io.flutter.plugins.firebase.firestore.FlutterFirebaseFirestoreRegistrar
androidx.window.embedding.EmbeddingAdapter
androidx.savedstate.SavedStateRegistry$1
org.webrtc.ThreadUtils$1
com.cloudwebrtc.webrtc.record.VideoFileRenderer
androidx.window.layout.WindowMetrics
org.webrtc.audio.WebRtcAudioRecord$AudioRecordThread
com.google.firebase.components.ComponentDiscoveryService
org.webrtc.RtpParameters$HeaderExtension
org.webrtc.VideoEncoderFactory$VideoEncoderSelector
org.webrtc.EglBase14$Context
org.webrtc.DataChannel$State
org.webrtc.AudioDecoderFactoryFactory
androidx.window.layout.EmptyDecorator
org.webrtc.audio.WebRtcAudioTrack$AudioTrackThread
androidx.window.layout.SidecarCompat$registerConfigurationChangeListener$configChangeObserver$1
org.webrtc.MediaCodecWrapperFactory
org.webrtc.CameraCapturer$4
com.cloudwebrtc.webrtc.CameraEventsHandler
org.webrtc.RtpParameters$Encoding
org.webrtc.EglBase$ConfigBuilder
androidx.window.embedding.ExtensionEmbeddingBackend$Companion
org.webrtc.NetworkMonitorAutoDetect$SimpleNetworkCallback
org.webrtc.SdpObserver
org.webrtc.RTCStats
org.webrtc.H264Utils
io.flutter.embedding.engine.FlutterJNI
org.webrtc.EglBase10Impl$Context
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$4
androidx.window.layout.WindowInfoTrackerImpl$Companion
org.webrtc.audio.WebRtcAudioEffects
org.webrtc.AudioSource
org.webrtc.PeerConnection$ContinualGatheringPolicy
org.webrtc.NetworkChangeDetector$ConnectionType
org.webrtc.PeerConnection$IceGatheringState
androidx.lifecycle.SingleGeneratedAdapterObserver
org.webrtc.EglRenderer$EglSurfaceCreation
org.webrtc.VideoDecoderFallback
com.cloudwebrtc.webrtc.GetUserMediaImpl$NoSuchFieldWithNameException
io.flutter.embedding.engine.mutatorsstack.FlutterMutatorsStack
org.webrtc.Camera1Session$2
org.webrtc.HardwareVideoEncoder
androidx.window.layout.ActivityCompatHelperApi24
androidx.window.layout.FoldingFeature$Orientation
org.webrtc.AndroidVideoDecoder$1
androidx.window.embedding.ActivityRule
com.cloudwebrtc.webrtc.record.MediaRecorderImpl
org.webrtc.CameraEnumerationAndroid
org.webrtc.SurfaceTextureHelper$FrameRefMonitor
org.webrtc.RtpReceiver$Observer
com.cloudwebrtc.webrtc.utils.EglUtils
org.webrtc.FrameCryptorKeyProvider
org.webrtc.audio.JavaAudioDeviceModule$AudioRecordErrorCallback
org.webrtc.MediaCodecWrapper
com.cloudwebrtc.webrtc.GetUserMediaImpl$3
org.webrtc.TextureBufferImpl$1
org.webrtc.EglRenderer$HandlerWithExceptionCallback
androidx.window.layout.WindowMetricsCalculator$Companion$decorator$1
org.webrtc.RTCStatsReport
org.webrtc.IceCandidate
com.google.android.gms.common.api.internal.LifecycleCallback
androidx.window.embedding.EmbeddingInterfaceCompat$EmbeddingCallbackInterface
androidx.window.layout.SidecarCompat$Companion
org.webrtc.VideoProcessor
org.webrtc.VideoFrame$Buffer
org.webrtc.Predicate$1
org.webrtc.SoftwareVideoDecoderFactory$1
org.webrtc.VideoEncoder$RateControlParameters
org.webrtc.GlRectDrawer$ShaderCallbacks
org.webrtc.EglRenderer
androidx.window.embedding.EmbeddingInterfaceCompat
org.webrtc.WrappedNativeVideoEncoder
com.cloudwebrtc.webrtc.record.AudioChannel
org.webrtc.voiceengine.WebRtcAudioUtils
org.webrtc.RtpReceiver
org.webrtc.FileVideoCapturer$VideoReaderY4M
com.cloudwebrtc.webrtc.utils.PermissionUtils$RequestPermissionsFragment
io.flutter.embedding.engine.plugins.lifecycle.HiddenLifecycleReference
org.webrtc.RtpParameters$DegradationPreference
org.webrtc.HardwareVideoEncoder$1
org.webrtc.Camera2Session$CaptureSessionCallback
io.flutter.embedding.engine.FlutterOverlaySurface
org.webrtc.ThreadUtils$ThreadChecker
com.google.android.gms.common.util.DynamiteApi
org.webrtc.audio.WebRtcAudioTrack
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback
org.webrtc.NativeAndroidVideoTrackSource
org.webrtc.CameraEnumerationAndroid$CaptureFormat
androidx.window.layout.WindowMetricsCalculator$Companion$overrideDecorator$1
androidx.window.R$styleable
org.webrtc.CapturerObserver
androidx.lifecycle.Lifecycling$1
org.webrtc.VideoFrameDrawer$1
org.webrtc.SoftwareVideoEncoderFactory$1
org.webrtc.CameraCapturer$SwitchState
org.webrtc.MediaSource
com.google.firebase.concurrent.ExecutorsRegistrar
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin$LifeCycleObserver
com.cloudwebrtc.webrtc.record.OutputAudioSamplesInterceptor
org.webrtc.NetworkMonitor$InstanceHolder
kotlinx.coroutines.internal.StackTraceRecoveryKt
io.flutter.plugins.GeneratedPluginRegistrant
androidx.window.layout.WindowMetricsCalculatorCompat
androidx.window.embedding.EmbeddingCompat$Companion
org.webrtc.SimulcastVideoEncoderFactory
org.webrtc.audio.VolumeLogger
com.google.android.gms.common.api.GoogleApiActivity
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor$FrameCryptorStateObserver$1
org.webrtc.VideoCodecMimeType
org.webrtc.EncodedImage
org.webrtc.Camera1Session$1
org.webrtc.GlGenericDrawer$ShaderCallbacks
org.webrtc.VideoDecoderFactory
org.webrtc.CameraSession$Events
org.webrtc.Camera2Session$CameraCaptureCallback
org.webrtc.Metrics
org.webrtc.audio.JavaAudioDeviceModule$AudioRecordStartErrorCode
androidx.window.layout.SidecarWindowBackend$ExtensionListenerImpl
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin$1
com.cloudwebrtc.webrtc.R$id
org.webrtc.EglBase$Context
org.webrtc.CameraCapturer$6
com.cloudwebrtc.webrtc.R$style
org.webrtc.PeerConnection$AdapterType
org.webrtc.voiceengine.WebRtcAudioRecord$WebRtcAudioRecordSamplesReadyCallback
androidx.window.layout.SidecarWindowBackend$Companion
org.webrtc.PeerConnectionFactory$InitializationOptions
org.webrtc.Empty
androidx.window.embedding.SplitController$Companion
androidx.activity.ComponentActivity$2
org.webrtc.GlGenericDrawer$ShaderType
org.webrtc.AddIceObserver
org.webrtc.SurfaceEglRenderer
androidx.window.layout.WindowMetricsCalculator$Companion$reset$1
org.webrtc.RtpCapabilities
androidx.window.java.layout.WindowInfoTrackerCallbackAdapter$addListener$1$1$invokeSuspend$$inlined$collect$1
org.webrtc.PeerConnectionFactory$Builder
org.webrtc.EglRenderer$1
org.webrtc.BuiltinAudioEncoderFactoryFactory
org.webrtc.FileVideoCapturer$VideoReader
org.webrtc.EglBase14
org.webrtc.NativeLibrary
org.webrtc.HardwareVideoEncoderFactory$1
com.google.android.gms.common.GooglePlayServicesIncorrectManifestValueException
io.grpc.okhttp.OkHttpChannelProvider
androidx.window.layout.FoldingFeature$Orientation$Companion
org.webrtc.PeerConnection
androidx.versionedparcelable.CustomVersionedParcelable
androidx.window.R
org.webrtc.WebRtcClassLoader
org.webrtc.PeerConnectionDependencies
org.webrtc.EglRenderer$ErrorCallback
org.webrtc.voiceengine.WebRtcAudioEffects
org.webrtc.EglRenderer$FrameListener
androidx.core.app.RemoteActionCompatParcelizer
org.webrtc.Camera1Enumerator
com.cloudwebrtc.webrtc.utils.MediaConstraintsUtils
androidx.window.core.Bounds
androidx.window.embedding.SplitController
androidx.window.layout.SidecarAdapter
org.webrtc.TimestampAligner
org.webrtc.CameraVideoCapturer$MediaRecorderHandler
org.webrtc.CalledByNative
com.google.firebase.firestore.FirebaseFirestore
org.webrtc.DataChannel
org.webrtc.VideoCapturer
androidx.window.embedding.MatcherUtils
org.webrtc.Camera1Session
org.webrtc.FecControllerFactoryFactoryInterface
org.webrtc.Loggable
org.webrtc.CameraSession
org.webrtc.VideoEncoder$CodecSpecificInfoVP9
androidx.window.layout.HardwareFoldingFeature$Type
com.google.android.gms.common.api.Status
org.webrtc.CameraCapturer
org.webrtc.CameraCapturer$5
org.webrtc.PeerConnection$TcpCandidatePolicy
org.webrtc.EncodedImage$Builder
androidx.lifecycle.CompositeGeneratedAdaptersObserver
org.webrtc.audio.VolumeLogger$LogVolumeTask
org.webrtc.PeerConnectionFactory
org.webrtc.FrameEncryptor
org.webrtc.voiceengine.WebRtcAudioRecord$WebRtcAudioRecordErrorCallback
com.google.firebase.components.ComponentRegistrar
androidx.window.R$attr
org.webrtc.PeerConnection$SdpSemantics
androidx.window.layout.HardwareFoldingFeature$Companion
org.webrtc.Predicate$3
org.webrtc.ContextUtils
org.webrtc.HardwareVideoDecoderFactory$1
org.webrtc.WrappedNativeVideoDecoder
org.webrtc.WrappedNativeI420Buffer
com.cloudwebrtc.webrtc.MethodCallHandlerImpl
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$1
androidx.window.embedding.SplitPairFilter
org.webrtc.audio.WebRtcAudioRecord$1
com.cloudwebrtc.webrtc.OrientationAwareScreenCapturer
org.webrtc.GlGenericDrawer
org.webrtc.CameraEnumerationAndroid$1
org.webrtc.MediaCodecUtils$1
org.webrtc.audio.WebRtcAudioTrackUtils
org.webrtc.PlatformSoftwareVideoDecoderFactory$1
org.webrtc.PeerConnection$PeerConnectionState
org.webrtc.TextureBufferImpl$RefCountMonitor
androidx.window.layout.DisplayCompatHelperApi28
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor
androidx.core.graphics.drawable.IconCompatParcelizer
com.cloudwebrtc.webrtc.utils.AnyThreadSink
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer
org.webrtc.PeerConnection$IceTransportsType
org.webrtc.RTCStatsCollectorCallback
org.webrtc.DefaultVideoDecoderFactory
com.cloudwebrtc.webrtc.GetUserMediaImpl$5
androidx.window.layout.DisplayFeature
kotlinx.coroutines.android.AndroidExceptionPreHandler
org.webrtc.SessionDescription$Type
org.webrtc.ThreadUtils$2
io.flutter.embedding.android.FlutterSplashView$SavedState
com.cloudwebrtc.webrtc.utils.AnyThreadResult
com.google.android.gms.common.annotation.KeepName
org.webrtc.JavaI420Buffer
com.google.firebase.provider.FirebaseInitProvider
org.webrtc.CameraSession$FailureType
org.webrtc.Camera2Capturer
org.webrtc.CameraVideoCapturer$CameraSwitchHandler
com.cloudwebrtc.webrtc.BuildConfig
androidx.core.app.CoreComponentFactory
androidx.fragment.app.Fragment$2
org.webrtc.LibvpxVp8Encoder
org.webrtc.voiceengine.WebRtcAudioTrack$AudioTrackStartErrorCode
org.webrtc.Camera1Capturer
io.grpc.internal.DnsNameResolverProvider
org.webrtc.DataChannel$Observer
androidx.window.layout.WindowLayoutInfo
androidx.window.layout.ExtensionInterfaceCompat
org.webrtc.NetworkMonitor$1
org.webrtc.ThreadUtils$BlockingOperation
org.webrtc.SoftwareVideoEncoderFactory
androidx.window.embedding.EmptyEmbeddingComponent
com.cloudwebrtc.webrtc.utils.MediaConstraintsUtils$1
com.google.android.gms.common.api.internal.BasePendingResult
org.webrtc.audio.JavaAudioDeviceModule$AudioRecordStateCallback
org.webrtc.audio.WebRtcAudioUtils
org.webrtc.NV21Buffer
com.cloudwebrtc.webrtc.record.AudioSamplesInterceptor
org.webrtc.VideoTrack
org.webrtc.TextureBufferImpl
org.webrtc.HardwareVideoEncoderFactory
org.webrtc.VideoSource$1
org.webrtc.FrameCryptorFactory
org.webrtc.EglRenderer$FrameListenerAndParams
io.flutter.plugins.firebase.core.FlutterFirebasePluginRegistry
com.cloudwebrtc.webrtc.R
org.webrtc.RendererCommon$ScalingType
org.webrtc.VideoEncoderFallback
org.webrtc.EglBase10Impl
org.webrtc.JNILogging
org.webrtc.YuvConverter$ShaderCallbacks
androidx.window.embedding.SplitRule$LayoutDir
org.webrtc.VideoEncoder
org.webrtc.NativePeerConnectionFactory
com.google.firebase.FirebaseCommonRegistrar
org.webrtc.voiceengine.WebRtcAudioRecord
androidx.window.layout.SidecarCompat$FirstAttachAdapter
org.webrtc.CameraEnumerator
com.cloudwebrtc.webrtc.R$styleable
org.webrtc.SurfaceTextureHelper$3
org.webrtc.CameraCapturer$1
org.webrtc.JniCommon
androidx.window.embedding.SplitRule
org.webrtc.PeerConnectionFactory$ThreadInfo
org.webrtc.ThreadUtils$1Result
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper
org.webrtc.Camera2Enumerator
org.webrtc.EglBase10$Context
org.webrtc.VideoEncoder$BitrateAllocation
org.webrtc.CallSessionFileRotatingLogSink
androidx.window.layout.FoldingFeature$OcclusionType
org.webrtc.VideoEncoder$Settings
org.webrtc.voiceengine.WebRtcAudioManager$VolumeLogger$LogVolumeTask
org.webrtc.VideoEncoder$EncoderInfo
org.webrtc.NativeLibraryLoader
org.webrtc.VideoFrame
androidx.core.app.RemoteActionCompat
androidx.window.layout.WindowMetricsCalculator$Companion
org.webrtc.VideoEncoder$CodecSpecificInfoH264
com.google.android.gms.common.internal.ReflectedParcelable
com.cloudwebrtc.webrtc.R$integer
org.webrtc.EglBase
io.flutter.view.FlutterCallbackInformation
org.webrtc.ThreadUtils$3
androidx.window.embedding.ActivityFilter
androidx.window.layout.SidecarWindowBackend
org.webrtc.PeerConnection$IceServer$Builder
org.webrtc.Camera2Session$SessionState
org.webrtc.CryptoOptions$SFrame
org.webrtc.Predicate
org.webrtc.RendererCommon$VideoLayoutMeasure
androidx.window.embedding.ExtensionEmbeddingBackend$SplitListenerWrapper
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$3
io.grpc.internal.PickFirstLoadBalancerProvider
io.grpc.internal.JndiResourceResolverFactory
org.webrtc.BitrateAdjuster
org.webrtc.CameraCapturer$2
org.webrtc.voiceengine.WebRtcAudioTrack$AudioTrackThread
org.webrtc.IceCandidateErrorEvent
androidx.window.R$id
com.cloudwebrtc.webrtc.utils.PermissionUtils$Callback
org.webrtc.AudioProcessingFactory
org.webrtc.LibaomAv1Encoder
androidx.window.layout.SidecarCompat
com.cloudwebrtc.webrtc.R$drawable
org.webrtc.SurfaceTextureHelper
org.webrtc.YuvHelper
org.webrtc.voiceengine.WebRtcAudioTrack$ErrorCallback
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper
com.cloudwebrtc.webrtc.utils.ObjectType
org.webrtc.VideoFileRenderer$1
org.webrtc.SurfaceTextureHelper$2
com.cloudwebrtc.webrtc.GetUserMediaImpl
androidx.window.embedding.EmbeddingBackend
org.webrtc.PeerConnection$IceConnectionState
androidx.window.embedding.SplitRule$Api30Impl
org.webrtc.FrameCryptorAlgorithm
org.webrtc.audio.LowLatencyAudioBufferManager
org.webrtc.Priority
org.webrtc.MediaCodecUtils
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer$1
com.google.android.gms.auth.api.signin.GoogleSignInAccount
org.webrtc.HardwareVideoEncoder$BusyCount
com.example.demo_agora.MainActivity
org.webrtc.EglBase14Impl$Context
androidx.window.core.Version$Companion
org.webrtc.PeerConnection$RTCConfiguration
org.webrtc.NetworkChangeDetector$Observer
org.webrtc.PeerConnectionFactory$InitializationOptions$Builder
androidx.window.layout.HardwareFoldingFeature$Type$Companion
org.webrtc.ThreadUtils
org.webrtc.RendererCommon
androidx.window.layout.WindowInfoTrackerImpl$windowLayoutInfo$1
org.webrtc.audio.JavaAudioDeviceModule$AudioTrackStartErrorCode
com.cloudwebrtc.webrtc.GetUserMediaImpl$ScreenRequestPermissionsFragment
com.cloudwebrtc.webrtc.R$color
org.webrtc.CameraVideoCapturer$CameraStatistics$1
org.webrtc.NetworkChangeDetector$NetworkInformation
org.webrtc.DefaultVideoEncoderFactory
org.webrtc.CameraCapturer$8
androidx.window.layout.WindowInfoTracker$Companion
androidx.window.layout.SidecarWindowBackend$WindowLayoutChangeCallbackWrapper
org.webrtc.SurfaceTextureHelper$1
org.webrtc.audio.WebRtcAudioRecord
com.cloudwebrtc.webrtc.utils.PermissionUtils$1
com.cloudwebrtc.webrtc.GetUserMediaImpl$3$1
org.webrtc.EncodedImage$FrameType: org.webrtc.EncodedImage$FrameType EmptyFrame
org.webrtc.NetworkMonitorAutoDetect$NetworkState: boolean connected
org.webrtc.CameraCapturer$8: java.lang.String val$cameraName
com.cloudwebrtc.webrtc.R$id: int tag_accessibility_heading
com.google.firestore.v1.Target$DocumentsTarget: com.google.protobuf.Parser PARSER
com.google.firestore.v1.AggregationResult: int AGGREGATE_FIELDS_FIELD_NUMBER
com.google.firestore.v1.ExistenceFilter: int UNCHANGED_NAMES_FIELD_NUMBER
org.webrtc.VideoEncoder$RateControlParameters: double framerateFps
org.webrtc.FileVideoCapturer$VideoReaderY4M: int frameHeight
org.webrtc.EglRenderer: boolean mirrorVertically
org.webrtc.GlTextureFrameBuffer: int pixelFormat
org.webrtc.SurfaceTextureHelper: org.webrtc.YuvConverter yuvConverter
com.cloudwebrtc.webrtc.R$styleable: int SplitPlaceholderRule_splitMinWidth
kotlin.jvm.internal.CallableReference: java.lang.Object NO_RECEIVER
com.google.firestore.v1.Document: java.lang.String name_
org.webrtc.PeerConnection$IceServer: org.webrtc.PeerConnection$TlsCertPolicy tlsCertPolicy
org.webrtc.RtpParameters: java.util.List encodings
com.cloudwebrtc.webrtc.audio.AudioSwitchManager: com.cloudwebrtc.webrtc.audio.AudioSwitchManager instance
androidx.window.embedding.ExtensionEmbeddingBackend$EmbeddingCallbackImpl: java.util.List lastInfo
org.webrtc.HardwareVideoEncoder: org.webrtc.BitrateAdjuster bitrateAdjuster
org.webrtc.HardwareVideoEncoder$BusyCount: java.lang.Object countLock
io.flutter.plugin.platform.SingleViewPresentation: io.flutter.plugin.platform.SingleViewPresentation$PresentationState state
com.google.firestore.v1.DocumentChange: com.google.protobuf.Internal$IntList removedTargetIds_
androidx.window.R$attr: int activityName
org.webrtc.EglRenderer: java.lang.String name
com.google.firestore.v1.Target$QueryTarget: java.lang.Object queryType_
org.webrtc.CameraEnumerationAndroid$1: int val$requestedFps
androidx.window.embedding.SplitPairFilter: android.content.ComponentName primaryActivityName
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper: org.webrtc.VideoEncoder$Settings streamSettings
org.webrtc.FileVideoCapturer$VideoReaderY4M: int frameWidth
androidx.window.layout.SidecarCompat$registerConfigurationChangeListener$configChangeObserver$1: android.app.Activity $activity
org.webrtc.MediaStreamTrack$MediaType: org.webrtc.MediaStreamTrack$MediaType MEDIA_TYPE_VIDEO
org.webrtc.audio.WebRtcAudioTrack: long AUDIO_TRACK_THREAD_JOIN_TIMEOUT_MS
org.webrtc.RTCStatsReport: java.util.Map stats
com.cloudwebrtc.webrtc.utils.ObjectType: com.cloudwebrtc.webrtc.utils.ObjectType Byte
com.google.firestore.v1.WriteResult: int TRANSFORM_RESULTS_FIELD_NUMBER
org.webrtc.PeerConnection$RTCConfiguration: org.webrtc.PeerConnection$IceTransportsType iceTransportsType
org.webrtc.CameraEnumerationAndroid$CaptureFormat$FramerateRange: int max
org.webrtc.Logging$Severity: org.webrtc.Logging$Severity LS_ERROR
org.webrtc.voiceengine.WebRtcAudioRecord: int audioSource
com.google.firestore.v1.Target: int EXPECTED_COUNT_FIELD_NUMBER
androidx.window.embedding.ActivityFilter: java.lang.String intentAction
androidx.window.layout.SidecarCompat: java.util.Map windowListenerRegisteredContexts
com.google.firebase.firestore.proto.NoDocument: java.lang.String name_
org.webrtc.RtpSender: long nativeRtpSender
org.webrtc.voiceengine.WebRtcAudioManager$VolumeLogger$LogVolumeTask: org.webrtc.voiceengine.WebRtcAudioManager$VolumeLogger this$0
org.webrtc.SurfaceTextureHelper: org.webrtc.TextureBufferImpl$RefCountMonitor textureRefCountMonitor
org.webrtc.MediaCodecVideoDecoderFactory: java.lang.String TAG
org.webrtc.AndroidVideoDecoder: java.lang.String TAG
androidx.window.layout.SidecarCompat$DistinctSidecarElementCallback: java.util.WeakHashMap mActivityWindowLayoutInfo
org.webrtc.SurfaceTextureHelper: org.webrtc.VideoSink listener
kotlin.coroutines.jvm.internal.SuspendLambda: int arity
com.google.firestore.v1.RunAggregationQueryResponse: com.google.firestore.v1.RunAggregationQueryResponse DEFAULT_INSTANCE
io.flutter.embedding.engine.FlutterJNI: java.lang.String TAG
androidx.window.embedding.EmbeddingTranslatingCallback: androidx.window.embedding.EmbeddingAdapter adapter
com.cloudwebrtc.webrtc.audio.AudioDeviceKind: java.lang.Class audioDeviceClass
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: android.app.Activity activity
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin: java.lang.String TAG
com.google.firestore.v1.DocumentTransform$FieldTransform: int MAXIMUM_FIELD_NUMBER
org.webrtc.VideoFileRenderer: java.lang.String outputFileName
org.webrtc.VideoEncoderFallback: org.webrtc.VideoEncoder primary
org.webrtc.VideoCodecStatus: org.webrtc.VideoCodecStatus ERR_REQUEST_SLI
org.webrtc.Logging$TraceLevel: org.webrtc.Logging$TraceLevel TRACE_STATEINFO
org.webrtc.AndroidVideoDecoder: org.webrtc.VideoDecoder$Callback callback
org.webrtc.SimulcastVideoEncoder: org.webrtc.VideoEncoderFactory primary
androidx.window.layout.SidecarWindowBackend$WindowLayoutChangeCallbackWrapper: androidx.window.layout.WindowLayoutInfo lastInfo
org.webrtc.HardwareVideoEncoder: int frameSizeBytes
com.google.firestore.v1.WriteResponse: java.lang.String streamId_
org.webrtc.VideoEncoder$EncoderInfo: int requestedResolutionAlignment
androidx.window.embedding.ExtensionEmbeddingBackend$EmbeddingCallbackImpl: androidx.window.embedding.ExtensionEmbeddingBackend this$0
androidx.window.java.layout.WindowInfoTrackerCallbackAdapter$addListener$1$1: int label
org.webrtc.PeerConnectionFactory: java.lang.String VIDEO_FRAME_EMIT_TRIAL
kotlinx.coroutines.internal.LockFreeTaskQueueCore: long _state
com.cloudwebrtc.webrtc.GetUserMediaImpl$4: com.cloudwebrtc.webrtc.GetUserMediaImpl this$0
org.webrtc.CameraCapturer$SwitchState: org.webrtc.CameraCapturer$SwitchState IDLE
androidx.window.layout.FoldingFeature$OcclusionType: androidx.window.layout.FoldingFeature$OcclusionType FULL
org.webrtc.voiceengine.WebRtcAudioRecord$AudioRecordThread: org.webrtc.voiceengine.WebRtcAudioRecord this$0
org.webrtc.AndroidVideoDecoder$FrameInfo: int rotation
com.google.firestore.admin.v1.Index$IndexField: com.google.firestore.admin.v1.Index$IndexField DEFAULT_INSTANCE
com.google.firestore.bundle.BundledQuery: com.google.protobuf.Parser PARSER
com.cloudwebrtc.webrtc.PeerConnectionObserver$1: int[] $SwitchMap$org$webrtc$PeerConnection$IceGatheringState
org.webrtc.audio.WebRtcAudioRecord: org.webrtc.audio.WebRtcAudioRecord$AudioRecordThread audioThread
org.webrtc.SurfaceTextureHelper: int frameRotation
com.cloudwebrtc.webrtc.R$id: int actions
org.webrtc.IceCandidate: int sdpMLineIndex
com.google.firestore.v1.StructuredAggregationQuery$Aggregation$Avg: int FIELD_FIELD_NUMBER
org.webrtc.audio.JavaAudioDeviceModule$Builder: org.webrtc.audio.JavaAudioDeviceModule$SamplesReadyCallback samplesReadyCallback
org.webrtc.VideoProcessor$FrameAdaptationParameters: boolean drop
com.cloudwebrtc.webrtc.record.VideoFileRenderer: android.os.Handler audioThreadHandler
com.cloudwebrtc.webrtc.GetUserMediaImpl: java.lang.String PERMISSION_AUDIO
org.webrtc.CryptoOptions$SFrame: org.webrtc.CryptoOptions this$0
com.google.firestore.v1.Target$QueryTarget: int STRUCTURED_QUERY_FIELD_NUMBER
org.webrtc.PeerConnection$IceServer$Builder: java.util.List tlsAlpnProtocols
org.webrtc.audio.JavaAudioDeviceModule$AudioTrackStartErrorCode: org.webrtc.audio.JavaAudioDeviceModule$AudioTrackStartErrorCode AUDIO_TRACK_START_STATE_MISMATCH
com.cloudwebrtc.webrtc.PeerConnectionObserver: io.flutter.plugin.common.BinaryMessenger messenger
org.webrtc.CameraCapturer$3: org.webrtc.CameraCapturer this$0
com.google.firestore.v1.ListenResponse: com.google.firestore.v1.ListenResponse DEFAULT_INSTANCE
com.google.firebase.firestore.proto.UnknownDocument: com.google.protobuf.Timestamp version_
org.webrtc.TextureBufferImpl$1: java.lang.Runnable val$releaseCallback
org.webrtc.VideoCodecInfo: int payload
org.webrtc.VideoFileRenderer: java.nio.ByteBuffer outputFrameBuffer
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor$FrameCryptorStateObserver: java.lang.String frameCryptorId
org.webrtc.AndroidVideoDecoder: boolean keyFrameRequired
org.webrtc.audio.JavaAudioDeviceModule: int inputSampleRate
com.google.firestore.v1.AggregationResult: com.google.firestore.v1.AggregationResult DEFAULT_INSTANCE
org.webrtc.PeerConnection$KeyType: org.webrtc.PeerConnection$KeyType[] $VALUES
org.webrtc.voiceengine.WebRtcAudioManager: java.lang.String TAG
org.webrtc.VideoEncoder$ResolutionBitrateLimits: int minStartBitrateBps
org.webrtc.audio.WebRtcAudioRecord: int DEFAULT_AUDIO_FORMAT
com.google.firestore.v1.TransactionOptions$ReadWrite: int RETRY_TRANSACTION_FIELD_NUMBER
com.cloudwebrtc.webrtc.R$styleable: int Capability_shortcutMatchRequired
org.webrtc.CameraCapturer$1: org.webrtc.CameraCapturer this$0
org.webrtc.HardwareVideoEncoder: int MAX_ENCODER_Q_SIZE
org.webrtc.voiceengine.WebRtcAudioRecord$AudioSamples: int sampleRate
org.webrtc.PeerConnection$RTCConfiguration: boolean suspendBelowMinBitrate
org.webrtc.audio.WebRtcAudioRecord: java.lang.String TAG
com.cloudwebrtc.webrtc.R$id: int async
org.webrtc.EglRenderer$FrameListenerAndParams: org.webrtc.EglRenderer$FrameListener listener
org.webrtc.PeerConnection$RTCConfiguration: java.lang.String turnLoggingId
com.google.firestore.v1.WriteRequest: int LABELS_FIELD_NUMBER
org.webrtc.audio.WebRtcAudioTrack: int BUFFERS_PER_SECOND
com.cloudwebrtc.webrtc.R$id: int tag_unhandled_key_listeners
com.cloudwebrtc.webrtc.GetUserMediaImpl: org.webrtc.audio.JavaAudioDeviceModule audioDeviceModule
org.webrtc.PeerConnectionFactory: java.lang.String VIDEO_CAPTURER_THREAD_NAME
com.google.firestore.v1.StructuredQuery$Order: com.google.protobuf.Parser PARSER
com.google.firestore.v1.BatchGetDocumentsResponse: int TRANSACTION_FIELD_NUMBER
org.webrtc.NativeLibrary: boolean libraryLoaded
org.webrtc.EglBase10Impl$1FakeSurfaceHolder: org.webrtc.EglBase10Impl this$0
com.google.firestore.v1.StructuredQuery$Filter: com.google.firestore.v1.StructuredQuery$Filter DEFAULT_INSTANCE
com.google.firestore.v1.ExistenceFilter: com.google.protobuf.Parser PARSER
org.webrtc.PeerConnectionFactory$Builder: org.webrtc.VideoDecoderFactory videoDecoderFactory
androidx.concurrent.futures.AbstractResolvableFuture: java.lang.Object value
com.cloudwebrtc.webrtc.R$id: int accessibility_action_clickable_span
org.webrtc.WrappedVideoDecoderFactory: org.webrtc.VideoDecoderFactory softwareVideoDecoderFactory
org.webrtc.AndroidVideoDecoder: org.webrtc.SurfaceTextureHelper surfaceTextureHelper
com.google.firestore.v1.DocumentChange: com.google.protobuf.Parser PARSER
org.webrtc.FramerateBitrateAdjuster: int DEFAULT_FRAMERATE_FPS
org.webrtc.MediaCodecUtils: int COLOR_QCOM_FORMATYVU420PackedSemiPlanar16m4ka
org.webrtc.NetworkMonitorAutoDetect: org.webrtc.NetworkMonitorAutoDetect$WifiManagerDelegate wifiManagerDelegate
org.webrtc.audio.WebRtcAudioRecord: android.media.AudioManager audioManager
org.webrtc.EglRenderer$FrameListenerAndParams: org.webrtc.RendererCommon$GlDrawer drawer
com.cloudwebrtc.webrtc.GetUserMediaImpl$1: org.webrtc.MediaStream val$mediaStream
com.cloudwebrtc.webrtc.R$styleable: int FontFamily_fontProviderPackage
org.webrtc.MediaStream: java.util.List videoTracks
com.cloudwebrtc.webrtc.record.VideoFileRenderer: java.lang.String TAG
com.google.firestore.v1.Write: com.google.firestore.v1.Precondition currentDocument_
com.google.protobuf.Timestamp: long seconds_
org.webrtc.EglRenderer: java.lang.Runnable logStatisticsRunnable
androidx.window.layout.HardwareFoldingFeature$Type: androidx.window.layout.HardwareFoldingFeature$Type$Companion Companion
org.webrtc.Size: int height
com.google.firestore.v1.DocumentTransform$FieldTransform: int APPEND_MISSING_ELEMENTS_FIELD_NUMBER
org.webrtc.PeerConnection$BundlePolicy: org.webrtc.PeerConnection$BundlePolicy BALANCED
org.webrtc.PeerConnection$AdapterType: org.webrtc.PeerConnection$AdapterType[] $VALUES
org.webrtc.PeerConnectionFactory$Options: int ADAPTER_TYPE_WIFI
com.google.firebase.firestore.proto.WriteBatch: int WRITES_FIELD_NUMBER
org.webrtc.CryptoOptions$Srtp: boolean enableAes128Sha1_32CryptoCipher
org.webrtc.VideoCodecMimeType: org.webrtc.VideoCodecMimeType H265
com.cloudwebrtc.webrtc.R$dimen: int notification_right_icon_size
org.webrtc.EglRenderer: boolean usePresentationTimeStamp
io.flutter.plugin.platform.SingleViewPresentation: int viewId
org.webrtc.HardwareVideoEncoder: int adjustedBitrate
org.webrtc.voiceengine.WebRtcAudioTrack: int DEFAULT_USAGE
androidx.window.layout.SidecarWindowBackend: androidx.window.layout.SidecarWindowBackend$Companion Companion
org.webrtc.Logging$Severity: org.webrtc.Logging$Severity LS_INFO
org.webrtc.MediaCodecUtils: int COLOR_QCOM_FORMATYVU420PackedSemiPlanar32m4ka
org.webrtc.audio.JavaAudioDeviceModule: java.lang.String TAG
org.webrtc.VideoCodecMimeType: java.lang.String mimeType
org.webrtc.RtpCapabilities$HeaderExtensionCapability: java.lang.String uri
com.google.firestore.v1.StructuredAggregationQuery: int AGGREGATIONS_FIELD_NUMBER
org.webrtc.VideoFrameDrawer: java.lang.String TAG
org.webrtc.PeerConnection$IceServer$Builder: java.lang.String hostname
org.webrtc.Camera2Enumerator: double NANO_SECONDS_PER_SECOND
org.webrtc.NetworkMonitorAutoDetect$NetworkState: int underlyingNetworkTypeForVpn
androidx.fragment.app.FragmentManagerState: android.os.Parcelable$Creator CREATOR
org.webrtc.AndroidVideoDecoder: boolean running
com.cloudwebrtc.webrtc.R$id: int tag_accessibility_actions
androidx.window.layout.SidecarWindowBackend: androidx.window.layout.SidecarWindowBackend globalInstance
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_3
org.webrtc.PeerConnection$AdapterType: org.webrtc.PeerConnection$AdapterType UNKNOWN
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor$FrameCryptorStateObserver: java.util.ArrayList eventQueue
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin: io.flutter.plugin.common.EventChannel eventChannel
com.cloudwebrtc.webrtc.utils.PermissionUtils: java.lang.String PERMISSIONS
org.webrtc.EglRenderer: long renderSwapBufferTimeNs
org.webrtc.Logging$Severity: org.webrtc.Logging$Severity LS_NONE
org.webrtc.VideoEncoder$EncodeInfo: org.webrtc.EncodedImage$FrameType[] frameTypes
org.webrtc.CryptoOptions$Builder: boolean enableAes128Sha1_32CryptoCipher
org.webrtc.EncodedImage: org.webrtc.EncodedImage$FrameType frameType
org.webrtc.EglRenderer: java.lang.Object frameLock
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$4: com.cloudwebrtc.webrtc.MethodCallHandlerImpl this$0
org.webrtc.DefaultVideoDecoderFactory: org.webrtc.VideoDecoderFactory softwareVideoDecoderFactory
com.google.firestore.v1.CommitRequest: com.google.protobuf.Internal$ProtobufList writes_
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin: io.flutter.plugin.common.MethodChannel methodChannel
org.webrtc.audio.WebRtcAudioTrack$AudioTrackThread: org.webrtc.audio.WebRtcAudioTrack this$0
org.webrtc.ScreenCapturerAndroid: android.media.projection.MediaProjectionManager mediaProjectionManager
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor$1: int[] $SwitchMap$org$webrtc$FrameCryptor$FrameCryptionState
org.webrtc.voiceengine.WebRtcAudioRecord: long nativeAudioRecord
org.webrtc.YuvConverter$ShaderCallbacks: float[] coeffs
androidx.window.layout.SidecarAdapter: java.lang.String TAG
kotlinx.coroutines.CancelledContinuation: int _resumed
org.webrtc.CameraCapturer: org.webrtc.CameraVideoCapturer$CameraSwitchHandler switchEventsHandler
org.webrtc.SurfaceViewRenderer: org.webrtc.RendererCommon$RendererEvents rendererEvents
com.cloudwebrtc.webrtc.GetUserMediaImpl$ScreenRequestPermissionsFragment: int resultCode
org.webrtc.voiceengine.WebRtcAudioManager: int outputChannels
kotlinx.coroutines.scheduling.CoroutineScheduler$Worker: int workerCtl
org.webrtc.PeerConnectionFactory$Builder: org.webrtc.NetworkStatePredictorFactoryFactory networkStatePredictorFactoryFactory
org.webrtc.VideoCodecStatus: org.webrtc.VideoCodecStatus TARGET_BITRATE_OVERSHOOT
com.google.firestore.v1.RunAggregationQueryRequest: int PARENT_FIELD_NUMBER
com.google.android.gms.common.api.Scope: android.os.Parcelable$Creator CREATOR
org.webrtc.VideoFrameDrawer: int renderHeight
org.webrtc.VideoDecoder$Settings: int numberOfCores
org.webrtc.Camera2Session: android.hardware.camera2.CameraManager cameraManager
com.google.firestore.v1.StructuredQuery$CompositeFilter: com.google.firestore.v1.StructuredQuery$CompositeFilter DEFAULT_INSTANCE
org.webrtc.NetworkChangeDetector$ConnectionType: org.webrtc.NetworkChangeDetector$ConnectionType CONNECTION_BLUETOOTH
org.webrtc.CameraEnumerationAndroid: java.lang.String TAG
org.webrtc.YuvConverter$ShaderCallbacks: float[] vCoeffs
androidx.window.R$attr: int splitMinSmallestWidth
com.cloudwebrtc.webrtc.R$styleable: int GradientColor_android_startColor
org.webrtc.SessionDescription: org.webrtc.SessionDescription$Type type
org.webrtc.audio.WebRtcAudioRecord: android.content.Context context
org.webrtc.VideoCodecStatus: org.webrtc.VideoCodecStatus REQUEST_SLI
org.webrtc.PeerConnectionFactory$InitializationOptions$Builder: boolean enableInternalTracer
androidx.window.core.Version: java.lang.String description
androidx.window.embedding.ActivityStack: java.util.List activities
com.google.firestore.v1.MapValue: com.google.firestore.v1.MapValue DEFAULT_INSTANCE
org.webrtc.RtpReceiver: long nativeRtpReceiver
org.webrtc.RtpTransceiver$RtpTransceiverInit: java.util.List sendEncodings
com.cloudwebrtc.webrtc.R$id: int text2
com.google.firestore.v1.Precondition: int EXISTS_FIELD_NUMBER
org.webrtc.GlTextureFrameBuffer: int height
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer: io.flutter.view.TextureRegistry$SurfaceTextureEntry entry
com.cloudwebrtc.webrtc.R$drawable: int notification_bg_normal_pressed
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer: java.lang.String TAG
kotlinx.coroutines.JobSupport$Finishing: java.lang.Object _exceptionsHolder
org.webrtc.AndroidVideoDecoder: int colorFormat
com.google.firestore.v1.DocumentTransform: java.lang.String document_
org.webrtc.AndroidVideoDecoder$1: org.webrtc.AndroidVideoDecoder this$0
org.webrtc.AndroidVideoDecoder: org.webrtc.VideoCodecMimeType codecType
org.webrtc.voiceengine.WebRtcAudioRecord: java.lang.String TAG
org.webrtc.VideoEncoder$Settings: boolean automaticResizeOn
org.webrtc.voiceengine.WebRtcAudioRecord$AudioRecordStartErrorCode: org.webrtc.voiceengine.WebRtcAudioRecord$AudioRecordStartErrorCode AUDIO_RECORD_START_EXCEPTION
androidx.window.embedding.ActivityFilter: android.content.ComponentName componentName
org.webrtc.HardwareVideoEncoder: int sliceHeight
com.cloudwebrtc.webrtc.R$id: int tag_accessibility_pane_title
org.webrtc.PeerConnectionDependencies: org.webrtc.SSLCertificateVerifier sslCertificateVerifier
com.google.firestore.v1.BloomFilter: int hashCount_
com.google.firestore.v1.RunAggregationQueryResponse: com.google.protobuf.ByteString transaction_
com.cloudwebrtc.webrtc.audio.AudioDeviceKind: com.cloudwebrtc.webrtc.audio.AudioDeviceKind BLUETOOTH
com.google.firestore.v1.TargetChange: com.google.protobuf.ByteString resumeToken_
org.webrtc.audio.WebRtcAudioTrack: org.webrtc.audio.JavaAudioDeviceModule$AudioTrackErrorCallback errorCallback
org.webrtc.CameraCapturer$2: org.webrtc.CameraCapturer this$0
org.webrtc.CameraCapturer: boolean firstFrameObserved
androidx.window.core.Version: java.lang.String VERSION_PATTERN_STRING
org.webrtc.FileVideoCapturer: java.util.TimerTask tickTask
com.google.firestore.v1.StructuredQuery$FieldFilter: com.google.firestore.v1.StructuredQuery$FieldFilter DEFAULT_INSTANCE
com.google.firestore.v1.BitSequence: com.google.protobuf.ByteString bitmap_
androidx.window.layout.ExtensionWindowLayoutInfoBackend: java.util.Map activityToListeners
org.webrtc.SimulcastVideoEncoder: org.webrtc.VideoCodecInfo info
androidx.window.layout.WindowMetricsCalculator$Companion: androidx.window.layout.WindowMetricsCalculator$Companion $$INSTANCE
com.cloudwebrtc.webrtc.R$id: int chronometer
io.flutter.embedding.android.FlutterSplashView$SavedState: android.os.Parcelable$Creator CREATOR
org.webrtc.SessionDescription: java.lang.String description
androidx.lifecycle.Lifecycle$Event: androidx.lifecycle.Lifecycle$Event ON_STOP
com.google.firestore.v1.StructuredAggregationQuery$Aggregation$Count: com.google.protobuf.Int64Value upTo_
androidx.window.layout.ExtensionWindowLayoutInfoBackend$MulticastConsumer: java.util.concurrent.locks.ReentrantLock multicastConsumerLock
org.webrtc.CameraCapturer: int framerate
com.google.firestore.v1.BatchGetDocumentsRequest: com.google.protobuf.Internal$ProtobufList documents_
org.webrtc.VideoSource: org.webrtc.NativeAndroidVideoTrackSource nativeAndroidVideoTrackSource
com.google.firestore.v1.ArrayValue: com.google.firestore.v1.ArrayValue DEFAULT_INSTANCE
org.webrtc.NetworkMonitor$1: org.webrtc.NetworkMonitor this$0
org.webrtc.CameraCapturer$6: org.webrtc.CameraSession val$oldSession
com.cloudwebrtc.webrtc.record.VideoFileRenderer: android.media.MediaCodec$BufferInfo bufferInfo
androidx.window.embedding.SplitPairRule: boolean finishSecondaryWithPrimary
androidx.window.embedding.SplitPairRule: java.util.Set filters
org.webrtc.audio.WebRtcAudioTrack: org.webrtc.audio.VolumeLogger volumeLogger
org.webrtc.Camera1Session$SessionState: org.webrtc.Camera1Session$SessionState RUNNING
androidx.window.layout.SidecarCompat$DistinctSidecarElementCallback: androidx.window.layout.SidecarAdapter sidecarAdapter
org.webrtc.MediaStreamTrack$MediaType: org.webrtc.MediaStreamTrack$MediaType MEDIA_TYPE_AUDIO
org.webrtc.Histogram: long handle
org.webrtc.HardwareVideoEncoder: long forcedKeyFrameNs
org.webrtc.NetworkMonitor$2: java.lang.String val$fieldTrialsString
org.webrtc.WrappedNativeI420Buffer: int strideU
com.google.firestore.v1.BatchGetDocumentsRequest: int consistencySelectorCase_
com.google.firestore.admin.v1.Index: int STATE_FIELD_NUMBER
org.webrtc.voiceengine.WebRtcAudioManager: int BITS_PER_SAMPLE
org.webrtc.PeerConnection$IceGatheringState: org.webrtc.PeerConnection$IceGatheringState COMPLETE
org.webrtc.EglRenderer: org.webrtc.VideoFrame pendingFrame
org.webrtc.Logging: org.webrtc.Loggable loggable
org.webrtc.H264Utils: java.lang.String H264_FMTP_PROFILE_LEVEL_ID
com.cloudwebrtc.webrtc.utils.PermissionUtils: java.lang.String GRANT_RESULTS
androidx.window.layout.HardwareFoldingFeature: androidx.window.layout.FoldingFeature$State state
com.cloudwebrtc.webrtc.R$attr: int alwaysExpand
org.webrtc.RtpReceiver: long nativeObserver
org.webrtc.voiceengine.WebRtcAudioTrack: org.webrtc.ThreadUtils$ThreadChecker threadChecker
org.webrtc.audio.JavaAudioDeviceModule$AudioTrackStartErrorCode: org.webrtc.audio.JavaAudioDeviceModule$AudioTrackStartErrorCode AUDIO_TRACK_START_EXCEPTION
org.webrtc.voiceengine.WebRtcAudioManager: boolean blacklistDeviceForOpenSLESUsageIsOverridden
org.webrtc.ContextUtils: android.content.Context applicationContext
com.cloudwebrtc.webrtc.R$styleable: int ColorStateListItem_android_alpha
org.webrtc.Camera2Session: int height
org.webrtc.Camera2Session: org.webrtc.Camera2Session$SessionState state
org.webrtc.PeerConnection$PeerConnectionState: org.webrtc.PeerConnection$PeerConnectionState CONNECTING
com.cloudwebrtc.webrtc.R$styleable: int GradientColor_android_centerY
androidx.window.embedding.SplitRule: int minSmallestWidth
org.webrtc.AndroidVideoDecoder: boolean hasDecodedFirstFrame
kotlin.jvm.internal.Lambda: int arity
com.google.firestore.v1.StructuredQuery: int OFFSET_FIELD_NUMBER
com.cloudwebrtc.webrtc.R$id: int tag_on_apply_window_listener
com.cloudwebrtc.webrtc.utils.PermissionUtils: java.lang.String REQUEST_CODE
com.google.firestore.v1.WriteResult: com.google.protobuf.Internal$ProtobufList transformResults_
org.webrtc.VideoEncoder$ScalingSettings: org.webrtc.VideoEncoder$ScalingSettings OFF
org.webrtc.StatsReport: org.webrtc.StatsReport$Value[] values
kotlin.coroutines.jvm.internal.ContinuationImpl: kotlin.coroutines.CoroutineContext _context
org.webrtc.MediaStreamTrack$State: org.webrtc.MediaStreamTrack$State[] $VALUES
com.cloudwebrtc.webrtc.R$styleable: int SplitPairRule_finishPrimaryWithSecondary
androidx.lifecycle.Lifecycle$Event: androidx.lifecycle.Lifecycle$Event ON_RESUME
androidx.window.R$styleable: int SplitPlaceholderRule_splitRatio
org.webrtc.GlGenericDrawer$ShaderType: org.webrtc.GlGenericDrawer$ShaderType YUV
org.webrtc.audio.WebRtcAudioTrack: android.media.AudioTrack audioTrack
org.webrtc.audio.JavaAudioDeviceModule$Builder: int audioSource
com.google.firestore.v1.StructuredQuery$FieldFilter: com.google.protobuf.Parser PARSER
org.webrtc.VideoEncoder$ResolutionBitrateLimits: int minBitrateBps
com.google.firestore.v1.Target$QueryTarget: int PARENT_FIELD_NUMBER
com.google.firestore.v1.Value: int BOOLEAN_VALUE_FIELD_NUMBER
org.webrtc.TextureBufferImpl: int id
org.webrtc.TextureBufferImpl: org.webrtc.VideoFrame$TextureBuffer$Type type
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_31
androidx.window.embedding.SplitController: boolean sDebug
com.cloudwebrtc.webrtc.GetUserMediaImpl: int minAPILevel
androidx.window.embedding.SplitPairRule: boolean clearTop
com.cloudwebrtc.webrtc.record.AudioTrackInterceptor: org.webrtc.audio.JavaAudioDeviceModule$SamplesReadyCallback callback
com.cloudwebrtc.webrtc.GetUserMediaImpl$1: io.flutter.plugin.common.MethodChannel$Result val$result
org.webrtc.EglBase$Context: long NO_CONTEXT
org.webrtc.audio.JavaAudioDeviceModule: boolean useStereoInput
androidx.fragment.app.FragmentState: android.os.Parcelable$Creator CREATOR
com.google.protobuf.Any: com.google.protobuf.ByteString value_
org.webrtc.CameraVideoCapturer$CameraStatistics: int freezePeriodCount
org.webrtc.PeerConnection$IceServer: java.util.List tlsEllipticCurves
org.webrtc.NetworkChangeDetector$NetworkInformation: java.lang.String name
org.webrtc.GlGenericDrawer$ShaderType: org.webrtc.GlGenericDrawer$ShaderType RGB
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_6
org.webrtc.PeerConnectionFactory$InitializationOptions: org.webrtc.Loggable loggable
com.google.android.gms.common.internal.RootTelemetryConfiguration: android.os.Parcelable$Creator CREATOR
org.webrtc.Priority: int MEDIUM
org.webrtc.audio.WebRtcAudioRecord: org.webrtc.audio.JavaAudioDeviceModule$AudioRecordStateCallback stateCallback
org.webrtc.audio.WebRtcAudioRecord$AudioRecordThread: org.webrtc.audio.WebRtcAudioRecord this$0
com.google.firestore.v1.Target$QueryTarget: int queryTypeCase_
com.cloudwebrtc.webrtc.R$attr: int activityAction
org.webrtc.VideoDecoder$Settings: int height
com.cloudwebrtc.webrtc.R$dimen: int notification_media_narrow_margin
com.cloudwebrtc.webrtc.GetUserMediaImpl$4: java.lang.String val$id
com.cloudwebrtc.webrtc.R$styleable: int FontFamilyFont_android_ttcIndex
org.webrtc.EglRenderer: org.webrtc.VideoFrameDrawer frameDrawer
org.webrtc.PeerConnection: java.util.List receivers
org.webrtc.FrameCryptor$FrameCryptionState: org.webrtc.FrameCryptor$FrameCryptionState DECRYPTIONFAILED
com.google.firestore.v1.Precondition: com.google.protobuf.Parser PARSER
com.cloudwebrtc.webrtc.record.MediaRecorderImpl: org.webrtc.VideoTrack videoTrack
com.google.firestore.v1.BatchGetDocumentsRequest: int DATABASE_FIELD_NUMBER
org.webrtc.audio.JavaAudioDeviceModule$AudioSamples: int channelCount
org.webrtc.SoftwareVideoEncoderFactory: long nativeFactory
kotlinx.coroutines.JobSupport$Finishing: int _isCompleting
org.webrtc.EglBase14Impl: android.opengl.EGLContext eglContext
org.webrtc.EncodedImage: long captureTimeNs
kotlinx.coroutines.internal.LockFreeTaskQueue: java.lang.Object _cur
com.google.firestore.v1.MapValue: com.google.protobuf.MapFieldLite fields_
org.webrtc.GlGenericDrawer: java.nio.FloatBuffer FULL_RECTANGLE_TEXTURE_BUFFER
org.webrtc.voiceengine.WebRtcAudioTrack: org.webrtc.voiceengine.WebRtcAudioTrack$WebRtcAudioTrackErrorCallback errorCallbackOld
com.google.firestore.bundle.BundledQuery: java.lang.String parent_
com.google.android.gms.signin.internal.zak: android.os.Parcelable$Creator CREATOR
org.webrtc.PeerConnectionFactory: boolean internalTracerInitialized
androidx.window.R$styleable: int SplitPairRule_clearTop
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_12
org.webrtc.voiceengine.WebRtcAudioRecord: int BITS_PER_SAMPLE
org.webrtc.RTCStats: java.lang.String type
org.webrtc.Camera1Session: org.webrtc.CameraSession$Events events
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_7
com.google.firestore.v1.StructuredQuery$UnaryFilter: com.google.protobuf.Parser PARSER
io.flutter.plugin.platform.SingleViewPresentation: boolean startFocused
kotlinx.coroutines.EventLoopImplBase: int _isCompleted
org.webrtc.voiceengine.WebRtcAudioEffects: boolean DEBUG
androidx.window.layout.WindowMetricsCalculatorCompat: java.lang.String TAG
com.google.firestore.v1.DocumentRemove: int DOCUMENT_FIELD_NUMBER
com.cloudwebrtc.webrtc.R$attr: int fontProviderQuery
org.webrtc.audio.WebRtcAudioTrack: int CALLBACK_BUFFER_SIZE_MS
org.webrtc.DefaultVideoDecoderFactory: org.webrtc.VideoDecoderFactory platformSoftwareVideoDecoderFactory
org.webrtc.CameraSession$FailureType: org.webrtc.CameraSession$FailureType ERROR
com.google.firebase.firestore.proto.UnknownDocument: com.google.firebase.firestore.proto.UnknownDocument DEFAULT_INSTANCE
org.webrtc.audio.WebRtcAudioTrack: int BITS_PER_SAMPLE
org.webrtc.voiceengine.WebRtcAudioManager: int nativeChannels
com.google.firestore.v1.MapValue: int FIELDS_FIELD_NUMBER
com.google.firestore.v1.StructuredQuery: int offset_
org.webrtc.CallSessionFileRotatingLogSink: long nativeSink
org.webrtc.NetworkChangeDetector$ConnectionType: org.webrtc.NetworkChangeDetector$ConnectionType CONNECTION_5G
org.webrtc.HardwareVideoEncoder: int REQUIRED_RESOLUTION_ALIGNMENT
org.webrtc.MediaSource$State: org.webrtc.MediaSource$State LIVE
androidx.window.layout.WindowInfoTracker$Companion: boolean DEBUG
com.google.firebase.firestore.proto.WriteBatch: int BATCH_ID_FIELD_NUMBER
com.google.firestore.v1.Document: com.google.protobuf.Timestamp updateTime_
com.google.firestore.admin.v1.Index$IndexField: int ORDER_FIELD_NUMBER
com.google.firebase.firestore.proto.MaybeDocument: int DOCUMENT_FIELD_NUMBER
io.flutter.embedding.engine.mutatorsstack.FlutterMutatorsStack: java.util.List finalClippingPaths
org.webrtc.SoftwareVideoEncoderFactory$1: long val$nativeEncoder
org.webrtc.audio.LowLatencyAudioBufferManager: boolean keepLoweringBufferSize
org.webrtc.MediaStreamTrack$State: org.webrtc.MediaStreamTrack$State LIVE
com.cloudwebrtc.webrtc.R$layout: int notification_action_tombstone
org.webrtc.HardwareVideoEncoder: org.webrtc.VideoEncoder$Callback callback
org.webrtc.voiceengine.WebRtcAudioRecord: org.webrtc.voiceengine.WebRtcAudioEffects effects
org.webrtc.CameraCapturer: boolean sessionOpening
com.google.firestore.v1.BatchGetDocumentsRequest: int NEW_TRANSACTION_FIELD_NUMBER
org.webrtc.CameraVideoCapturer$CameraStatistics: int CAMERA_FREEZE_REPORT_TIMOUT_MS
com.google.firestore.v1.StructuredAggregationQuery$Aggregation: com.google.protobuf.Parser PARSER
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback: int deferredInsetTypes
com.cloudwebrtc.webrtc.record.MediaRecorderImpl: java.io.File recordFile
org.webrtc.PeerConnectionFactory$Builder: org.webrtc.audio.AudioDeviceModule audioDeviceModule
org.webrtc.audio.WebRtcAudioRecord: int CHECK_REC_STATUS_DELAY_MS
org.webrtc.PeerConnection$PortPrunePolicy: org.webrtc.PeerConnection$PortPrunePolicy PRUNE_BASED_ON_PRIORITY
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin$LifeCycleObserver: com.cloudwebrtc.webrtc.FlutterWebRTCPlugin this$0
kotlinx.coroutines.scheduling.CoroutineScheduler: int _isTerminated
org.webrtc.RendererCommon$ScalingType: org.webrtc.RendererCommon$ScalingType SCALE_ASPECT_BALANCED
org.webrtc.PeerConnection$RTCConfiguration: org.webrtc.TurnCustomizer turnCustomizer
org.webrtc.EglRenderer: int framesReceived
androidx.window.layout.SidecarCompat$FirstAttachAdapter: java.lang.ref.WeakReference activityWeakReference
com.cloudwebrtc.webrtc.R$dimen: int compat_notification_large_icon_max_width
com.cloudwebrtc.webrtc.R$id: int title
org.webrtc.GlGenericDrawer: java.lang.String INPUT_VERTEX_COORDINATE_NAME
com.google.firestore.v1.Document: int UPDATE_TIME_FIELD_NUMBER
com.google.firestore.v1.TransactionOptions$ReadOnly: com.google.firestore.v1.TransactionOptions$ReadOnly DEFAULT_INSTANCE
org.webrtc.HardwareVideoEncoder: org.webrtc.ThreadUtils$ThreadChecker encodeThreadChecker
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapperFactory: org.webrtc.VideoEncoderFactory factory
org.webrtc.RtpSender: boolean ownsTrack
org.webrtc.Camera1Enumerator: boolean captureToTexture
org.webrtc.voiceengine.WebRtcAudioRecord: org.webrtc.voiceengine.WebRtcAudioRecord$WebRtcAudioRecordErrorCallback errorCallback
org.webrtc.SurfaceTextureHelper$1: java.lang.String val$threadName
io.flutter.view.AccessibilityViewEmbedder: android.util.SparseArray flutterIdToOrigin
com.google.firebase.firestore.proto.Target: int QUERY_FIELD_NUMBER
org.webrtc.ThreadUtils$3: java.util.concurrent.Callable val$callable
org.webrtc.audio.VolumeLogger: java.util.Timer timer
org.webrtc.NetworkMonitorAutoDetect$WifiDirectManagerDelegate: org.webrtc.NetworkChangeDetector$Observer observer
com.cloudwebrtc.webrtc.record.VideoFileRenderer: int outputFileWidth
com.google.firestore.v1.StructuredQuery: com.google.firestore.v1.StructuredQuery$Projection select_
com.google.firestore.v1.ExistenceFilter: int TARGET_ID_FIELD_NUMBER
org.webrtc.NetworkPreference: int NOT_PREFERRED
com.cloudwebrtc.webrtc.GetUserMediaImpl: int CAPTURE_PERMISSION_REQUEST_CODE
org.webrtc.Camera1Session$1: org.webrtc.Camera1Session this$0
com.cloudwebrtc.webrtc.R$id: int line3
com.google.firestore.v1.Value: int BYTES_VALUE_FIELD_NUMBER
org.webrtc.NV12Buffer: int height
org.webrtc.HardwareVideoEncoder: int MAX_VIDEO_FRAMERATE
org.webrtc.PeerConnection$TlsCertPolicy: org.webrtc.PeerConnection$TlsCertPolicy TLS_CERT_POLICY_SECURE
org.webrtc.voiceengine.WebRtcAudioTrack: int usageAttribute
com.cloudwebrtc.webrtc.record.VideoFileRenderer: android.media.MediaCodec audioEncoder
org.webrtc.MediaCodecUtils: java.lang.String INTEL_PREFIX
org.webrtc.MediaCodecUtils: java.lang.String EXYNOS_PREFIX
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer$1: int _width
org.webrtc.Logging: org.webrtc.Logging$Severity loggableSeverity
org.webrtc.JavaI420Buffer: int height
org.webrtc.IceCandidate: java.lang.String serverUrl
com.google.firestore.bundle.BundledQuery: java.lang.Object queryType_
org.webrtc.RendererCommon$ScalingType: org.webrtc.RendererCommon$ScalingType[] $VALUES
com.cloudwebrtc.webrtc.R$attr: int fontProviderCerts
com.cloudwebrtc.webrtc.utils.PermissionUtils: java.lang.String RESULT_RECEIVER
org.webrtc.FrameCryptor$FrameCryptionState: org.webrtc.FrameCryptor$FrameCryptionState ENCRYPTIONFAILED
org.webrtc.TextureBufferImpl$2: org.webrtc.TextureBufferImpl this$0
org.webrtc.Camera2Session$CaptureSessionCallback: org.webrtc.Camera2Session this$0
com.google.protobuf.AbstractMessageLite: int memoizedHashCode
org.webrtc.CameraCapturer: int OPEN_CAMERA_TIMEOUT
org.webrtc.VideoSource$1: org.webrtc.VideoSource this$0
org.webrtc.CameraCapturer$7: org.webrtc.CameraCapturer this$0
org.webrtc.PeerConnection$AdapterType: org.webrtc.PeerConnection$AdapterType CELLULAR_3G
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_23
org.webrtc.VideoDecoder$DecodeInfo: boolean isMissingFrames
org.webrtc.RtcCertificatePem: java.lang.String privateKey
org.webrtc.PeerConnection$IceConnectionState: org.webrtc.PeerConnection$IceConnectionState FAILED
org.webrtc.Logging$TraceLevel: org.webrtc.Logging$TraceLevel TRACE_APICALL
org.webrtc.NetworkChangeDetector$ConnectionType: org.webrtc.NetworkChangeDetector$ConnectionType[] $VALUES
com.google.firestore.v1.StructuredQuery$Order: int DIRECTION_FIELD_NUMBER
com.google.firestore.v1.StructuredQuery$Order: com.google.firestore.v1.StructuredQuery$Order DEFAULT_INSTANCE
org.webrtc.ScreenCapturerAndroid: boolean isDisposed
org.webrtc.SurfaceTextureHelper: boolean hasPendingTexture
kotlinx.coroutines.internal.LockFreeLinkedListNode: java.lang.Object _removedRef
org.webrtc.PeerConnectionFactory$Builder: org.webrtc.VideoEncoderFactory videoEncoderFactory
org.webrtc.PeerConnectionFactory$Options: int ADAPTER_TYPE_UNKNOWN
org.webrtc.VideoSource$AspectRatio: int height
com.cloudwebrtc.webrtc.utils.ConstraintsMap: java.util.Map mMap
org.webrtc.PeerConnectionFactory$Options: int ADAPTER_TYPE_ANY
org.webrtc.VideoFileRenderer: org.webrtc.EglBase eglBase
com.google.firestore.v1.StructuredAggregationQuery: int STRUCTURED_QUERY_FIELD_NUMBER
androidx.window.layout.SidecarCompat: java.util.Map componentCallbackMap
io.flutter.embedding.engine.FlutterJNI: java.lang.String vmServiceUri
com.cloudwebrtc.webrtc.PeerConnectionObserver: java.lang.String TAG
androidx.window.core.Version: androidx.window.core.Version VERSION_0_1
androidx.window.layout.SidecarWindowBackend$WindowLayoutChangeCallbackWrapper: java.util.concurrent.Executor executor
org.webrtc.VideoCodecStatus: org.webrtc.VideoCodecStatus OK
org.webrtc.VideoCodecStatus: int number
org.webrtc.MediaConstraints: java.util.List mandatory
com.google.firestore.v1.Value: int valueTypeCase_
org.webrtc.IceCandidate: java.lang.String sdp
com.google.firestore.v1.StructuredQuery: com.google.protobuf.Internal$ProtobufList orderBy_
kotlinx.coroutines.channels.ArrayChannel: int size
com.cloudwebrtc.webrtc.R$styleable: int GradientColor_android_centerColor
com.cloudwebrtc.webrtc.R$styleable: int GradientColorItem_android_offset
org.webrtc.PeerConnection$AdapterType: java.util.Map BY_BITMASK
com.cloudwebrtc.webrtc.PeerConnectionObserver: com.cloudwebrtc.webrtc.StateProvider stateProvider
org.webrtc.VideoEncoderFallback: org.webrtc.VideoEncoder fallback
org.webrtc.CameraCapturer: org.webrtc.CameraEnumerator cameraEnumerator
org.webrtc.audio.WebRtcAudioRecord: int AUDIO_RECORD_STOP
org.webrtc.CameraEnumerationAndroid$1: int MAX_FPS_HIGH_DIFF_WEIGHT
org.webrtc.EglBase10Impl: javax.microedition.khronos.egl.EGLDisplay eglDisplay
org.webrtc.Predicate$3: org.webrtc.Predicate this$0
com.google.firestore.v1.BitSequence: int padding_
androidx.window.R$attr: int splitMinWidth
org.webrtc.PeerConnection$SignalingState: org.webrtc.PeerConnection$SignalingState CLOSED
com.google.firestore.v1.StructuredQuery$CollectionSelector: int COLLECTION_ID_FIELD_NUMBER
com.google.firebase.firestore.proto.UnknownDocument: com.google.protobuf.Parser PARSER
org.webrtc.PeerConnection$IceConnectionState: org.webrtc.PeerConnection$IceConnectionState[] $VALUES
org.webrtc.VideoFileRenderer$1: org.webrtc.EglBase$Context val$sharedContext
org.webrtc.EglBase10Impl$Context: javax.microedition.khronos.egl.EGLContext eglContext
com.google.firestore.v1.Cursor: com.google.firestore.v1.Cursor DEFAULT_INSTANCE
org.webrtc.audio.WebRtcAudioRecord$AudioRecordThread: boolean keepAlive
androidx.window.embedding.ExtensionEmbeddingBackend$SplitListenerWrapper: android.app.Activity activity
org.webrtc.RtpParameters$Encoding: java.lang.Integer maxFramerate
org.webrtc.voiceengine.WebRtcAudioManager: boolean blacklistDeviceForAAudioUsage
org.webrtc.audio.WebRtcAudioEffects: boolean shouldEnableNs
com.cloudwebrtc.webrtc.GetUserMediaImpl$3$1: com.cloudwebrtc.webrtc.GetUserMediaImpl$3 this$1
org.webrtc.PeerConnection: java.util.List transceivers
org.webrtc.Logging$1: int[] $SwitchMap$org$webrtc$Logging$Severity
com.google.firestore.v1.Target: int ONCE_FIELD_NUMBER
org.webrtc.VideoFrameDrawer$1: int[] $SwitchMap$org$webrtc$VideoFrame$TextureBuffer$Type
org.webrtc.NV21Buffer: int width
com.google.firestore.v1.DocumentDelete: java.lang.String document_
com.google.firebase.firestore.proto.UnknownDocument: java.lang.String name_
kotlinx.coroutines.scheduling.WorkQueue: int producerIndex
com.cloudwebrtc.webrtc.record.VideoFileRenderer: android.view.Surface surface
org.webrtc.Logging$TraceLevel: int level
com.google.firestore.v1.Target: int targetId_
org.webrtc.RtpParameters: java.util.List headerExtensions
com.cloudwebrtc.webrtc.record.FrameCapturer: org.webrtc.VideoTrack videoTrack
org.webrtc.MediaCodecVideoDecoderFactory: org.webrtc.Predicate codecAllowedPredicate
com.google.firestore.v1.BatchGetDocumentsRequest: java.lang.Object consistencySelector_
org.webrtc.PeerConnectionFactory$Options: int ADAPTER_TYPE_VPN
org.webrtc.voiceengine.WebRtcAudioEffects: java.lang.String TAG
org.webrtc.audio.WebRtcAudioRecord$1: java.util.concurrent.atomic.AtomicInteger val$nextThreadId
org.webrtc.MediaCodecUtils$1: int[] $SwitchMap$org$webrtc$VideoCodecMimeType
com.cloudwebrtc.webrtc.R$styleable: int[] FontFamilyFont
com.cloudwebrtc.webrtc.R$style: int TextAppearance_Compat_Notification
com.google.firestore.v1.StructuredQuery: int END_AT_FIELD_NUMBER
com.google.firestore.v1.WriteRequest: int STREAM_ID_FIELD_NUMBER
org.webrtc.Camera2Capturer: android.hardware.camera2.CameraManager cameraManager
androidx.window.core.Version: androidx.window.core.Version UNKNOWN
org.webrtc.PeerConnectionFactory$InitializationOptions$Builder: java.lang.String fieldTrials
org.webrtc.EglBase: java.lang.Object lock
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper: java.util.concurrent.ExecutorService executor
com.google.firestore.v1.ListenResponse: int DOCUMENT_CHANGE_FIELD_NUMBER
com.cloudwebrtc.webrtc.BuildConfig: boolean DEBUG
com.google.firestore.v1.ExistenceFilter: int targetId_
org.webrtc.YuvConverter$ShaderCallbacks: float[] yCoeffs
org.webrtc.AndroidVideoDecoder$DecodedTextureMetadata: java.lang.Integer decodeTimeMs
com.google.protobuf.Timestamp: int nanos_
org.webrtc.StatsReport: double timestamp
org.webrtc.MediaStream: long nativeStream
com.cloudwebrtc.webrtc.audio.AudioSwitchManager: com.twilio.audioswitch.AudioSwitch audioSwitch
com.google.firestore.v1.Target: int targetTypeCase_
com.cloudwebrtc.webrtc.GetUserMediaImpl: java.lang.String PERMISSION_SCREEN
org.webrtc.voiceengine.WebRtcAudioManager: boolean initialized
kotlinx.coroutines.internal.DispatchedContinuation: java.lang.Object _reusableCancellableContinuation
com.cloudwebrtc.webrtc.GetUserMediaImpl$ScreenRequestPermissionsFragment: android.os.ResultReceiver resultReceiver
com.cloudwebrtc.webrtc.utils.AnyThreadSink: android.os.Handler handler
com.google.firestore.v1.ExistenceFilter: int COUNT_FIELD_NUMBER
com.cloudwebrtc.webrtc.R$styleable: int[] SplitPairFilter
com.cloudwebrtc.webrtc.R$styleable: int GradientColor_android_startX
androidx.window.embedding.ActivityRule: java.util.Set filters
org.webrtc.DataChannel$Init: boolean ordered
com.cloudwebrtc.webrtc.DataChannelObserver: io.flutter.plugin.common.EventChannel$EventSink eventSink
org.webrtc.SessionDescription$Type: org.webrtc.SessionDescription$Type ROLLBACK
org.webrtc.audio.WebRtcAudioRecord: int audioFormat
com.google.firestore.admin.v1.Index: com.google.protobuf.Internal$ProtobufList fields_
org.webrtc.H264Utils: org.webrtc.VideoCodecInfo DEFAULT_H264_HIGH_PROFILE_CODEC
org.webrtc.PeerConnection$RTCConfiguration: java.lang.Integer iceCheckMinInterval
com.cloudwebrtc.webrtc.R$attr: int finishPrimaryWithSecondary
com.google.firestore.v1.WriteRequest: com.google.protobuf.Internal$ProtobufList writes_
com.cloudwebrtc.webrtc.R$attr: int fontProviderSystemFontFamily
org.webrtc.RtpParameters$HeaderExtension: int id
com.google.firestore.v1.ArrayValue: int VALUES_FIELD_NUMBER
com.google.firestore.v1.StructuredQuery: com.google.protobuf.Int32Value limit_
org.webrtc.VideoCodecStatus: org.webrtc.VideoCodecStatus ERR_SIZE
org.webrtc.Camera2Session$SessionState: org.webrtc.Camera2Session$SessionState STOPPED
org.webrtc.PeerConnection$RTCConfiguration: int iceCandidatePoolSize
com.google.firestore.v1.Document: com.google.firestore.v1.Document DEFAULT_INSTANCE
org.webrtc.CameraCapturer: org.webrtc.CameraVideoCapturer$CameraStatistics cameraStatistics
androidx.window.embedding.ExtensionEmbeddingBackend: androidx.window.embedding.EmbeddingInterfaceCompat embeddingExtension
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$3: io.flutter.plugin.common.MethodChannel$Result val$result
org.webrtc.audio.JavaAudioDeviceModule$Builder: org.webrtc.audio.JavaAudioDeviceModule$AudioTrackErrorCallback audioTrackErrorCallback
com.google.android.gms.common.api.internal.BasePendingResult: com.google.android.gms.common.api.internal.zas mResultGuardian
com.cloudwebrtc.webrtc.CameraEventsHandler: java.lang.String TAG
org.webrtc.voiceengine.WebRtcAudioTrack: boolean speakerMute
com.cloudwebrtc.webrtc.R$drawable: int notification_template_icon_bg
com.google.firestore.v1.ListenResponse: int responseTypeCase_
kotlin.coroutines.AbstractCoroutineContextElement: kotlin.coroutines.CoroutineContext$Key key
com.cloudwebrtc.webrtc.R$attr: int font
org.webrtc.DataChannel$State: org.webrtc.DataChannel$State OPEN
com.cloudwebrtc.webrtc.GetUserMediaImpl$VideoCapturerInfo: int height
org.webrtc.PeerConnectionFactory$Builder: org.webrtc.AudioProcessingFactory audioProcessingFactory
com.google.firebase.firestore.proto.Target: int targetId_
androidx.window.layout.FoldingFeature$State: androidx.window.layout.FoldingFeature$State FLAT
org.webrtc.VideoDecoderFallback: org.webrtc.VideoDecoder fallback
androidx.window.layout.SidecarWindowBackend$WindowLayoutChangeCallbackWrapper: androidx.core.util.Consumer callback
org.webrtc.Logging$TraceLevel: org.webrtc.Logging$TraceLevel TRACE_CRITICAL
org.webrtc.Logging$TraceLevel: org.webrtc.Logging$TraceLevel TRACE_MEMORY
androidx.concurrent.futures.AbstractResolvableFuture: androidx.concurrent.futures.AbstractResolvableFuture$Listener listeners
org.webrtc.Camera2Session: android.hardware.camera2.CameraCharacteristics cameraCharacteristics
org.webrtc.MediaConstraints$KeyValuePair: java.lang.String value
com.google.firestore.v1.Write: com.google.firestore.v1.DocumentMask updateMask_
org.webrtc.voiceengine.WebRtcAudioTrack: android.media.AudioTrack audioTrack
org.webrtc.voiceengine.WebRtcAudioEffects: java.util.UUID AOSP_NOISE_SUPPRESSOR
com.google.rpc.Status: com.google.protobuf.Internal$ProtobufList details_
androidx.window.layout.WindowInfoTrackerImpl: androidx.window.layout.WindowBackend windowBackend
org.webrtc.audio.WebRtcAudioTrack: android.content.Context context
org.webrtc.HardwareVideoEncoderFactory: boolean enableH264HighProfile
com.cloudwebrtc.webrtc.record.FrameCapturer: boolean gotFrame
org.webrtc.PeerConnection$AdapterType: org.webrtc.PeerConnection$AdapterType ADAPTER_TYPE_ANY
org.webrtc.PeerConnection$SignalingState: org.webrtc.PeerConnection$SignalingState STABLE
org.webrtc.PeerConnection$TcpCandidatePolicy: org.webrtc.PeerConnection$TcpCandidatePolicy ENABLED
org.webrtc.EglRenderer: long LOG_INTERVAL_SEC
com.google.android.gms.common.api.Status: android.os.Parcelable$Creator CREATOR
com.google.firestore.v1.TargetChange: int RESUME_TOKEN_FIELD_NUMBER
org.webrtc.EglRenderer: long renderTimeNs
org.webrtc.DynamicBitrateAdjuster: double BITRATE_ADJUSTMENT_SEC
org.webrtc.VideoEncoder$ResolutionBitrateLimits: int maxBitrateBps
com.cloudwebrtc.webrtc.audio.AudioSwitchManager: android.media.AudioManager$OnAudioFocusChangeListener audioFocusChangeListener
org.webrtc.HardwareVideoEncoder: boolean automaticResizeOn
org.webrtc.NV12Buffer: org.webrtc.RefCountDelegate refCountDelegate
androidx.window.layout.FoldingFeature$Orientation: androidx.window.layout.FoldingFeature$Orientation HORIZONTAL
com.google.firestore.v1.StructuredQuery$UnaryFilter: int FIELD_FIELD_NUMBER
org.webrtc.SurfaceEglRenderer: int frameRotation
org.webrtc.HardwareVideoEncoderFactory: boolean enableIntelVp8Encoder
org.webrtc.NetworkMonitorAutoDetect: org.webrtc.NetworkChangeDetector$Observer observer
org.webrtc.VideoFileRenderer$1: org.webrtc.VideoFileRenderer this$0
androidx.window.R$attr: int finishSecondaryWithPrimary
com.cloudwebrtc.webrtc.audio.AudioDeviceKind: java.lang.String typeName
com.google.protobuf.GeneratedMessageLite: int MEMOIZED_SERIALIZED_SIZE_MASK
org.webrtc.Logging: java.util.logging.Logger fallbackLogger
io.flutter.view.FlutterCallbackInformation: java.lang.String callbackLibraryPath
org.webrtc.StatsReport$Value: java.lang.String name
org.webrtc.audio.WebRtcAudioTrack: java.nio.ByteBuffer byteBuffer
com.google.firestore.v1.Precondition: com.google.firestore.v1.Precondition DEFAULT_INSTANCE
org.webrtc.EglRenderer: org.webrtc.EglBase eglBase
org.webrtc.ScreenCapturerAndroid: android.hardware.display.VirtualDisplay virtualDisplay
org.webrtc.MediaStreamTrack: long nativeTrack
com.cloudwebrtc.webrtc.GetUserMediaImpl$VideoCapturerInfo: com.cloudwebrtc.webrtc.GetUserMediaImpl this$0
com.google.firestore.v1.ListenRequest: int LABELS_FIELD_NUMBER
com.google.firestore.v1.StructuredQuery: int WHERE_FIELD_NUMBER
org.webrtc.PeerConnection$RTCConfiguration: org.webrtc.PeerConnection$SdpSemantics sdpSemantics
org.webrtc.DataChannel$Init: int maxRetransmits
com.google.firestore.v1.StructuredAggregationQuery$Aggregation: int COUNT_FIELD_NUMBER
androidx.fragment.app.BackStackState: android.os.Parcelable$Creator CREATOR
com.cloudwebrtc.webrtc.GetUserMediaImpl$4: io.flutter.plugin.common.MethodChannel$Result val$result
com.cloudwebrtc.webrtc.R$dimen: int notification_large_icon_width
io.flutter.embedding.engine.plugins.lifecycle.HiddenLifecycleReference: androidx.lifecycle.Lifecycle lifecycle
org.webrtc.VideoCodecMimeType: org.webrtc.VideoCodecMimeType VP8
androidx.window.layout.FoldingFeature$State: androidx.window.layout.FoldingFeature$State$Companion Companion
org.webrtc.HardwareVideoEncoder: boolean isEncodingStatisticsEnabled
org.webrtc.NetworkChangeDetector$ConnectionType: org.webrtc.NetworkChangeDetector$ConnectionType CONNECTION_VPN
org.webrtc.WrappedNativeI420Buffer: java.nio.ByteBuffer dataU
org.webrtc.EglRenderer: android.graphics.Matrix drawMatrix
androidx.window.layout.SidecarAdapter: androidx.window.layout.SidecarAdapter$Companion Companion
com.google.rpc.Status: com.google.protobuf.Parser PARSER
com.cloudwebrtc.webrtc.R$attr: int shortcutMatchRequired
com.google.firestore.v1.StructuredQuery$UnaryFilter: com.google.firestore.v1.StructuredQuery$UnaryFilter DEFAULT_INSTANCE
org.webrtc.audio.WebRtcAudioRecord: java.nio.ByteBuffer byteBuffer
org.webrtc.Camera2Session: org.webrtc.Histogram camera2StopTimeMsHistogram
org.webrtc.voiceengine.WebRtcAudioRecord: boolean microphoneMute
androidx.window.R$attr: int activityAction
org.webrtc.PeerConnectionFactory$Builder: org.webrtc.NetworkControllerFactoryFactory networkControllerFactoryFactory
org.webrtc.RtpParameters$Encoding: java.lang.Integer maxBitrateBps
com.cloudwebrtc.webrtc.R$style: int Widget_Compat_NotificationActionContainer
org.webrtc.Logging$TraceLevel: org.webrtc.Logging$TraceLevel TRACE_NONE
com.cloudwebrtc.webrtc.R$drawable: int notification_icon_background
com.google.firestore.v1.Value: int DOUBLE_VALUE_FIELD_NUMBER
org.webrtc.PeerConnection$SignalingState: org.webrtc.PeerConnection$SignalingState HAVE_REMOTE_OFFER
com.google.firestore.v1.TargetChange: com.google.protobuf.Parser PARSER
com.cloudwebrtc.webrtc.R$id: int tag_window_insets_animation_callback
com.cloudwebrtc.webrtc.R$drawable: int notify_panel_notification_icon_bg
com.google.firestore.v1.DocumentChange: int REMOVED_TARGET_IDS_FIELD_NUMBER
org.webrtc.DtmfSender: long nativeDtmfSender
androidx.window.embedding.SplitPlaceholderRule: android.content.Intent placeholderIntent
com.cloudwebrtc.webrtc.record.VideoFileRenderer: android.media.MediaCodec$BufferInfo audioBufferInfo
org.webrtc.RtpTransceiver: org.webrtc.RtpSender cachedSender
com.cloudwebrtc.webrtc.BuildConfig: java.lang.String BUILD_TYPE
com.cloudwebrtc.webrtc.R$drawable: int notification_bg
org.webrtc.WrappedNativeI420Buffer: int height
org.webrtc.AndroidVideoDecoder: org.webrtc.AndroidVideoDecoder$DecodedTextureMetadata renderedTextureMetadata
org.webrtc.EncodedImage: int rotation
org.webrtc.NativeCapturerObserver: org.webrtc.NativeAndroidVideoTrackSource nativeAndroidVideoTrackSource
androidx.window.R$styleable: int SplitPairRule_splitMinWidth
org.webrtc.WrappedNativeI420Buffer: int width
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_29
org.webrtc.RtpParameters$Encoding: int networkPriority
org.webrtc.HardwareVideoEncoder: java.util.concurrent.BlockingDeque outputBuilders
com.cloudwebrtc.webrtc.R$color: int notification_icon_bg_color
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_16
org.webrtc.audio.WebRtcAudioEffects: java.lang.String TAG
org.webrtc.SoftwareVideoDecoderFactory: java.lang.String TAG
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$2: io.flutter.plugin.common.MethodChannel$Result val$result
com.google.firestore.v1.BatchGetDocumentsResponse: com.google.protobuf.Timestamp readTime_
org.webrtc.audio.WebRtcAudioRecord: int DEFAULT_AUDIO_SOURCE
com.google.firestore.v1.Value: int NULL_VALUE_FIELD_NUMBER
com.google.firestore.v1.WriteResponse: int STREAM_ID_FIELD_NUMBER
com.google.firestore.v1.BitSequence: int PADDING_FIELD_NUMBER
com.google.firestore.admin.v1.Index: int state_
org.webrtc.PeerConnectionFactory$ThreadInfo: java.lang.Thread thread
org.webrtc.audio.JavaAudioDeviceModule$AudioRecordStartErrorCode: org.webrtc.audio.JavaAudioDeviceModule$AudioRecordStartErrorCode AUDIO_RECORD_START_EXCEPTION
com.google.firebase.firestore.proto.Target: com.google.firebase.firestore.proto.Target DEFAULT_INSTANCE
org.webrtc.IceCandidate: org.webrtc.PeerConnection$AdapterType adapterType
org.webrtc.VideoFrameDrawer: android.graphics.Point renderSize
org.webrtc.PeerConnection$RTCConfiguration: org.webrtc.PeerConnection$ContinualGatheringPolicy continualGatheringPolicy
org.webrtc.NetworkMonitor: int numObservers
org.webrtc.Metrics: java.util.Map map
org.webrtc.FrameCryptor$FrameCryptionState: org.webrtc.FrameCryptor$FrameCryptionState KEYRATCHETED
org.webrtc.audio.WebRtcAudioTrack$AudioTrackThread: boolean keepAlive
com.google.firebase.firestore.proto.WriteBatch: com.google.firebase.firestore.proto.WriteBatch DEFAULT_INSTANCE
com.cloudwebrtc.webrtc.R$dimen: int notification_action_icon_size
com.google.firestore.v1.RunAggregationQueryResponse: int READ_TIME_FIELD_NUMBER
org.webrtc.SurfaceTextureHelper$1: org.webrtc.SurfaceTextureHelper$FrameRefMonitor val$frameRefMonitor
com.cloudwebrtc.webrtc.GetUserMediaImpl: java.lang.String REQUEST_CODE
com.google.firestore.v1.DocumentChange: int removedTargetIdsMemoizedSerializedSize
org.webrtc.ScreenCapturerAndroid: android.media.projection.MediaProjection$Callback mediaProjectionCallback
com.google.firestore.v1.DocumentTransform: int FIELD_TRANSFORMS_FIELD_NUMBER
org.webrtc.VideoFrameBufferType: int I420A
com.google.rpc.Status: int CODE_FIELD_NUMBER
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer: android.graphics.SurfaceTexture texture
androidx.window.layout.FoldingFeature$State: androidx.window.layout.FoldingFeature$State HALF_OPENED
org.webrtc.DataChannel$Buffer: boolean binary
com.cloudwebrtc.webrtc.GetUserMediaImpl: java.util.Map mSurfaceTextureHelpers
org.webrtc.CryptoOptions$Srtp: boolean enableGcmCryptoSuites
org.webrtc.TimestampAligner: long nativeTimestampAligner
com.cloudwebrtc.webrtc.SurfaceTextureRenderer: org.webrtc.RendererCommon$RendererEvents rendererEvents
com.google.android.gms.common.ConnectionResult: android.os.Parcelable$Creator CREATOR
org.webrtc.PeerConnection$RTCConfiguration: int iceBackupCandidatePairPingInterval
com.google.protobuf.Any: com.google.protobuf.Any DEFAULT_INSTANCE
com.cloudwebrtc.webrtc.utils.ObjectType: com.cloudwebrtc.webrtc.utils.ObjectType Null
com.cloudwebrtc.webrtc.R$id: int icon
org.webrtc.NetworkMonitorAutoDetect: long INVALID_NET_ID
org.webrtc.DataChannel$Init: int maxRetransmitTimeMs
org.webrtc.FileVideoCapturer: java.util.Timer timer
org.webrtc.audio.WebRtcAudioTrackUtils: java.lang.String TAG
org.webrtc.IceCandidateErrorEvent: java.lang.String address
androidx.window.embedding.EmbeddingCompat: java.lang.String TAG
com.cloudwebrtc.webrtc.R$styleable: int ActivityRule_alwaysExpand
org.webrtc.VideoProcessor$FrameAdaptationParameters: int cropY
androidx.window.java.layout.WindowInfoTrackerCallbackAdapter$addListener$1$1$invokeSuspend$$inlined$collect$1: androidx.core.util.Consumer $consumer$inlined
com.cloudwebrtc.webrtc.R$layout: int notification_template_part_time
org.webrtc.audio.VolumeLogger: java.lang.String THREAD_NAME
org.webrtc.NetworkMonitorAutoDetect$ConnectivityManagerDelegate: android.net.ConnectivityManager connectivityManager
kotlinx.coroutines.scheduling.WorkQueue: int blockingTasksInBuffer
com.google.protobuf.Any: com.google.protobuf.Parser PARSER
org.webrtc.SurfaceTextureHelper: org.webrtc.TimestampAligner timestampAligner
org.webrtc.RtpParameters$Encoding: java.lang.Integer minBitrateBps
org.webrtc.FileVideoCapturer$VideoReaderY4M: long videoStart
com.google.firestore.v1.StructuredQuery$CollectionSelector: boolean allDescendants_
org.webrtc.Camera2Capturer: android.content.Context context
com.cloudwebrtc.webrtc.record.MediaRecorderImpl: boolean isRunning
androidx.window.embedding.ExtensionEmbeddingBackend: java.util.concurrent.locks.ReentrantLock globalLock
com.google.firestore.v1.BatchGetDocumentsRequest: int TRANSACTION_FIELD_NUMBER
com.cloudwebrtc.webrtc.record.VideoFileRenderer: int audioTrackIndex
org.webrtc.VideoSource: org.webrtc.VideoProcessor videoProcessor
com.cloudwebrtc.webrtc.R$id: int line1
org.webrtc.PeerConnectionFactory$ThreadInfo: int tid
com.cloudwebrtc.webrtc.utils.PermissionUtils: int requestCode
org.webrtc.CameraCapturer$6: org.webrtc.CameraCapturer this$0
com.cloudwebrtc.webrtc.audio.AudioSwitchManager: android.os.Handler handler
org.webrtc.TextureBufferImpl: int height
com.google.firestore.v1.Target: int TARGET_ID_FIELD_NUMBER
com.cloudwebrtc.webrtc.R$styleable: int FontFamilyFont_font
org.webrtc.ScreenCapturerAndroid: int width
org.webrtc.CameraCapturer: org.webrtc.CapturerObserver capturerObserver
com.google.firestore.v1.DocumentTransform: com.google.protobuf.Parser PARSER
com.cloudwebrtc.webrtc.R$id: int action_image
org.webrtc.Metrics$HistogramInfo: int max
com.cloudwebrtc.webrtc.PeerConnectionObserver$1: int[] $SwitchMap$org$webrtc$PeerConnection$PeerConnectionState
org.webrtc.AndroidVideoDecoder: org.webrtc.EglBase$Context sharedContext
org.webrtc.CameraSession$FailureType: org.webrtc.CameraSession$FailureType[] $VALUES
org.webrtc.audio.VolumeLogger$LogVolumeTask: int maxRingVolume
org.webrtc.CryptoOptions$SFrame: boolean requireFrameEncryption
androidx.window.R$attr: int secondaryActivityAction
org.webrtc.audio.WebRtcAudioRecord: boolean isAcousticEchoCancelerSupported
com.google.firestore.v1.StructuredAggregationQuery$Aggregation$Sum: com.google.protobuf.Parser PARSER
com.google.firestore.v1.Value: com.google.firestore.v1.Value DEFAULT_INSTANCE
androidx.window.embedding.SplitPairFilter: android.content.ComponentName secondaryActivityName
com.google.firestore.v1.CommitResponse: int WRITE_RESULTS_FIELD_NUMBER
org.webrtc.MediaCodecUtils: int[] TEXTURE_COLOR_FORMATS
com.cloudwebrtc.webrtc.utils.ObjectType: com.cloudwebrtc.webrtc.utils.ObjectType[] $VALUES
com.google.firebase.firestore.proto.MaybeDocument: boolean hasCommittedMutations_
com.cloudwebrtc.webrtc.record.VideoFileRenderer: java.nio.ByteBuffer[] encoderOutputBuffers
org.webrtc.audio.WebRtcAudioEffects: android.media.audiofx.AudioEffect$Descriptor[] cachedEffects
org.webrtc.CameraEnumerationAndroid$CaptureFormat: org.webrtc.CameraEnumerationAndroid$CaptureFormat$FramerateRange framerate
org.webrtc.CameraCapturer$8: org.webrtc.CameraCapturer this$0
com.cloudwebrtc.webrtc.record.MediaRecorderImpl: com.cloudwebrtc.webrtc.record.VideoFileRenderer videoFileRenderer
org.webrtc.Camera2Session: org.webrtc.SurfaceTextureHelper surfaceTextureHelper
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor: java.lang.String TAG
org.webrtc.FileVideoCapturer: org.webrtc.CapturerObserver capturerObserver
org.webrtc.HardwareVideoEncoder: org.webrtc.HardwareVideoEncoder$BusyCount outputBuffersBusyCount
org.webrtc.DataChannel: long nativeDataChannel
com.google.firestore.v1.DocumentTransform$FieldTransform: int INCREMENT_FIELD_NUMBER
org.webrtc.PeerConnectionFactory: org.webrtc.PeerConnectionFactory$ThreadInfo signalingThread
com.cloudwebrtc.webrtc.R$attr: int finishSecondaryWithPrimary
org.webrtc.Metrics$HistogramInfo: int bucketCount
org.webrtc.SimulcastVideoEncoderFactory: org.webrtc.VideoEncoderFactory fallback
org.webrtc.GlGenericDrawer$ShaderType: org.webrtc.GlGenericDrawer$ShaderType OES
com.google.rpc.Status: int DETAILS_FIELD_NUMBER
com.cloudwebrtc.webrtc.record.VideoFileRenderer: boolean muxerStarted
io.flutter.plugin.platform.SingleViewPresentation: android.view.View$OnFocusChangeListener focusChangeListener
org.webrtc.voiceengine.WebRtcAudioRecord: long AUDIO_RECORD_THREAD_JOIN_TIMEOUT_MS
org.webrtc.audio.JavaAudioDeviceModule: org.webrtc.audio.WebRtcAudioRecord audioInput
com.google.firestore.v1.ListenRequest: int REMOVE_TARGET_FIELD_NUMBER
org.webrtc.Camera2Session: java.lang.String TAG
com.cloudwebrtc.webrtc.R$attr: int secondaryActivityName
com.cloudwebrtc.webrtc.R$attr: int splitMinWidth
androidx.window.embedding.SplitInfo: androidx.window.embedding.ActivityStack secondaryActivityStack
com.cloudwebrtc.webrtc.PeerConnectionObserver$1: int[] $SwitchMap$org$webrtc$PeerConnection$SignalingState
org.webrtc.SurfaceTextureHelper: int textureHeight
com.cloudwebrtc.webrtc.R$id: int tag_on_receive_content_listener
org.webrtc.FileVideoCapturer$1: org.webrtc.FileVideoCapturer this$0
androidx.window.R$id: int ltr
com.google.firestore.v1.StructuredAggregationQuery$Aggregation: com.google.firestore.v1.StructuredAggregationQuery$Aggregation DEFAULT_INSTANCE
org.webrtc.NV21Buffer: org.webrtc.RefCountDelegate refCountDelegate
org.webrtc.VideoFrame$TextureBuffer$Type: int glTarget
com.google.firestore.v1.WriteResult: com.google.protobuf.Timestamp updateTime_
org.webrtc.PeerConnection$IceConnectionState: org.webrtc.PeerConnection$IceConnectionState CLOSED
com.cloudwebrtc.webrtc.record.OutputAudioSamplesInterceptor: org.webrtc.audio.JavaAudioDeviceModule audioDeviceModule
com.google.firestore.v1.DocumentDelete: com.google.protobuf.Internal$IntList removedTargetIds_
org.webrtc.SurfaceTextureHelper: java.lang.String TAG
org.webrtc.SoftwareVideoEncoderFactory: java.lang.String TAG
androidx.window.core.Bounds: int left
org.webrtc.VideoProcessor$FrameAdaptationParameters: int cropWidth
org.webrtc.DataChannel$Init: boolean negotiated
org.webrtc.VideoFrameDrawer: org.webrtc.VideoFrameDrawer$YuvUploader yuvUploader
androidx.window.layout.FoldingFeature$OcclusionType: java.lang.String description
org.webrtc.audio.WebRtcAudioRecord: android.media.AudioDeviceInfo preferredDevice
org.webrtc.PeerConnection$TcpCandidatePolicy: org.webrtc.PeerConnection$TcpCandidatePolicy[] $VALUES
androidx.window.layout.SidecarCompat$TranslatingCallback: androidx.window.layout.SidecarCompat this$0
org.webrtc.audio.WebRtcAudioEffects: java.util.UUID AOSP_NOISE_SUPPRESSOR
com.cloudwebrtc.webrtc.R$layout: int notification_action
org.webrtc.NetworkMonitorAutoDetect: android.net.ConnectivityManager$NetworkCallback allNetworkCallback
org.webrtc.CandidatePairChangeEvent: int lastDataReceivedMs
org.webrtc.RtpTransceiver$RtpTransceiverInit: org.webrtc.RtpTransceiver$RtpTransceiverDirection direction
com.google.firestore.v1.BatchGetDocumentsResponse: java.lang.Object result_
com.google.protobuf.GeneratedMessageLite: com.google.protobuf.UnknownFieldSetLite unknownFields
com.google.firestore.v1.Document: int FIELDS_FIELD_NUMBER
org.webrtc.EglBase$ConfigBuilder: int openGlesVersion
org.webrtc.SurfaceTextureHelper: org.webrtc.SurfaceTextureHelper$FrameRefMonitor frameRefMonitor
org.webrtc.NativeAndroidVideoTrackSource: long nativeAndroidVideoTrackSource
org.webrtc.VideoProcessor$FrameAdaptationParameters: int cropHeight
org.webrtc.voiceengine.WebRtcAudioManager: boolean hardwareAGC
org.webrtc.CameraEnumerationAndroid$2: int val$requestedHeight
io.flutter.plugin.platform.SingleViewPresentation: io.flutter.plugin.platform.SingleViewPresentation$AccessibilityDelegatingFrameLayout rootView
org.webrtc.VideoFrameDrawer: org.webrtc.VideoFrame lastI420Frame
org.webrtc.GlGenericDrawer: java.lang.String INPUT_TEXTURE_COORDINATE_NAME
org.webrtc.PeerConnection$IceServer: java.lang.String uri
com.google.firestore.v1.BloomFilter: com.google.protobuf.Parser PARSER
org.webrtc.Priority: int VERY_LOW
androidx.window.R$styleable: int SplitPairFilter_primaryActivityName
com.cloudwebrtc.webrtc.R$styleable: int SplitPairRule_clearTop
com.cloudwebrtc.webrtc.R$id: int tag_transition_group
com.cloudwebrtc.webrtc.OrientationAwareScreenCapturer: android.content.Context applicationContext
org.webrtc.ContextUtils: java.lang.String TAG
org.webrtc.SurfaceViewRenderer: int rotatedFrameHeight
org.webrtc.NetworkMonitor: org.webrtc.NetworkChangeDetectorFactory networkChangeDetectorFactory
org.webrtc.PeerConnection$SignalingState: org.webrtc.PeerConnection$SignalingState[] $VALUES
org.webrtc.RtpParameters$DegradationPreference: org.webrtc.RtpParameters$DegradationPreference MAINTAIN_FRAMERATE
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_5
kotlinx.coroutines.internal.AtomicOp: java.lang.Object _consensus
com.cloudwebrtc.webrtc.R$styleable: int FontFamilyFont_android_fontVariationSettings
org.webrtc.Size: int width
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer: io.flutter.plugin.common.EventChannel$EventSink eventSink
org.webrtc.voiceengine.WebRtcAudioManager: int inputBufferSize
com.google.firestore.v1.StructuredQuery: com.google.protobuf.Internal$ProtobufList from_
org.webrtc.VideoFrameBufferType: int NATIVE
com.google.firestore.v1.StructuredAggregationQuery$Aggregation$Count: com.google.protobuf.Parser PARSER
com.google.firestore.v1.RunAggregationQueryRequest: int queryTypeCase_
kotlinx.coroutines.scheduling.CoroutineScheduler$Worker: java.lang.Object nextParkedWorker
com.cloudwebrtc.webrtc.R$styleable: int FontFamily_fontProviderAuthority
org.webrtc.Predicate$2: org.webrtc.Predicate this$0
org.webrtc.HardwareVideoEncoder: int width
org.webrtc.PeerConnection$RTCConfiguration: java.util.List iceServers
org.webrtc.audio.WebRtcAudioTrack$AudioTrackThread: org.webrtc.audio.LowLatencyAudioBufferManager bufferManager
org.webrtc.GlGenericDrawer$ShaderType: org.webrtc.GlGenericDrawer$ShaderType[] $VALUES
androidx.window.R$id: int locale
org.webrtc.DefaultVideoEncoderFactory: org.webrtc.VideoEncoderFactory hardwareVideoEncoderFactory
org.webrtc.PeerConnectionFactory: java.lang.String TAG
org.webrtc.CameraEnumerationAndroid$CaptureFormat$FramerateRange: int min
org.webrtc.VideoCodecStatus: org.webrtc.VideoCodecStatus UNINITIALIZED
org.webrtc.HardwareVideoEncoder: java.lang.String TAG
com.google.firebase.firestore.proto.Target: int LAST_LIMBO_FREE_SNAPSHOT_VERSION_FIELD_NUMBER
kotlin.jvm.internal.FunctionReference: int arity
org.webrtc.PeerConnection$IceConnectionState: org.webrtc.PeerConnection$IceConnectionState CONNECTED
androidx.window.layout.ExtensionWindowLayoutInfoBackend$MulticastConsumer: androidx.window.layout.WindowLayoutInfo lastKnownValue
org.webrtc.PeerConnection$RTCConfiguration: boolean offerExtmapAllowMixed
org.webrtc.VideoCodecStatus: org.webrtc.VideoCodecStatus NO_OUTPUT
org.webrtc.audio.JavaAudioDeviceModule$Builder: boolean useStereoOutput
com.google.firestore.v1.BatchGetDocumentsRequest: java.lang.String database_
com.google.firestore.v1.DocumentRemove: com.google.protobuf.Timestamp readTime_
androidx.window.R$attr: int finishPrimaryWithSecondary
org.webrtc.GlShader: java.lang.String TAG
org.webrtc.NetworkMonitorAutoDetect$ConnectivityManagerDelegate: boolean getAllNetworksFromCache
org.webrtc.AndroidVideoDecoder: org.webrtc.ThreadUtils$ThreadChecker outputThreadChecker
org.webrtc.VideoProcessor$FrameAdaptationParameters: int scaleWidth
org.webrtc.YuvConverter: org.webrtc.GlGenericDrawer drawer
androidx.window.embedding.ExtensionEmbeddingBackend$SplitListenerWrapper: java.util.concurrent.Executor executor
org.webrtc.NetworkChangeDetector$NetworkInformation: org.webrtc.NetworkChangeDetector$IPAddress[] ipAddresses
org.webrtc.RtpCapabilities$CodecCapability: java.lang.String name
org.webrtc.AndroidVideoDecoder: java.util.concurrent.BlockingDeque frameInfos
androidx.window.core.Version: androidx.window.core.Version$Companion Companion
com.cloudwebrtc.webrtc.R$id: int right_side
org.webrtc.CryptoOptions$Builder: boolean enableEncryptedRtpHeaderExtensions
org.webrtc.PeerConnection$AdapterType: org.webrtc.PeerConnection$AdapterType WIFI
com.google.firestore.v1.TransactionOptions: int modeCase_
org.webrtc.audio.WebRtcAudioTrack: java.lang.String TAG
org.webrtc.audio.JavaAudioDeviceModule$Builder: boolean useHardwareAcousticEchoCanceler
org.webrtc.VideoFrame: int rotation
org.webrtc.PeerConnection$IceServer$Builder: java.lang.String password
org.webrtc.SurfaceTextureHelper$1: org.webrtc.EglBase$Context val$sharedContext
androidx.lifecycle.Lifecycle$Event: androidx.lifecycle.Lifecycle$Event ON_PAUSE
com.google.firestore.v1.Value: int ARRAY_VALUE_FIELD_NUMBER
org.webrtc.PeerConnection$PeerConnectionState: org.webrtc.PeerConnection$PeerConnectionState FAILED
com.google.firestore.v1.Target: int DOCUMENTS_FIELD_NUMBER
com.google.firestore.v1.RunAggregationQueryRequest: com.google.protobuf.Parser PARSER
org.webrtc.PeerConnectionFactory$Builder: org.webrtc.AudioDecoderFactoryFactory audioDecoderFactoryFactory
org.webrtc.PeerConnectionFactory$InitializationOptions$Builder: org.webrtc.Logging$Severity loggableSeverity
org.webrtc.FileVideoCapturer$VideoReaderY4M: java.lang.String TAG
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor frameCryptor
org.webrtc.YuvConverter$ShaderCallbacks: float stepSize
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer: int id
org.webrtc.MediaConstraints: java.util.List optional
org.webrtc.RtpParameters$Rtcp: boolean reducedSize
com.cloudwebrtc.webrtc.utils.ObjectType: com.cloudwebrtc.webrtc.utils.ObjectType Number
org.webrtc.DataChannel$State: org.webrtc.DataChannel$State CONNECTING
org.webrtc.HardwareVideoEncoder: java.lang.String codecName
com.cloudwebrtc.webrtc.GetUserMediaImpl: java.lang.String RESULT_RECEIVER
com.google.firestore.v1.Cursor: int BEFORE_FIELD_NUMBER
com.google.firestore.v1.WriteRequest: int WRITES_FIELD_NUMBER
com.google.protobuf.Int32Value: int value_
org.webrtc.PeerConnection$SdpSemantics: org.webrtc.PeerConnection$SdpSemantics[] $VALUES
com.cloudwebrtc.webrtc.R$attr: int placeholderActivityName
org.webrtc.NetworkMonitorAutoDetect$WifiDirectManagerDelegate: android.content.Context context
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: java.lang.String TAG
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_28
org.webrtc.voiceengine.WebRtcAudioRecord$AudioSamples: byte[] data
com.cloudwebrtc.webrtc.R$attr: int alpha
com.google.firestore.v1.CommitResponse: int COMMIT_TIME_FIELD_NUMBER
androidx.window.layout.FoldingFeature$Orientation: androidx.window.layout.FoldingFeature$Orientation VERTICAL
androidx.window.layout.SidecarCompat$registerConfigurationChangeListener$configChangeObserver$1: androidx.window.layout.SidecarCompat this$0
org.webrtc.Camera2Enumerator: android.content.Context context
com.google.firestore.v1.TransactionOptions$ReadWrite: com.google.firestore.v1.TransactionOptions$ReadWrite DEFAULT_INSTANCE
com.google.firestore.v1.Precondition: java.lang.Object conditionType_
org.webrtc.voiceengine.WebRtcAudioManager: boolean DEBUG
androidx.window.java.layout.WindowInfoTrackerCallbackAdapter: java.util.Map consumerToJobMap
com.google.firestore.v1.DocumentChange: com.google.firestore.v1.Document document_
com.cloudwebrtc.webrtc.R$dimen: int compat_button_inset_horizontal_material
org.webrtc.HardwareVideoEncoderFactory: int QCOM_VP8_KEY_FRAME_INTERVAL_ANDROID_M_MS
org.webrtc.audio.WebRtcAudioManager: int DEFAULT_SAMPLE_RATE_HZ
com.google.android.gms.dynamite.DynamiteModule$DynamiteLoaderClassLoader: java.lang.ClassLoader sClassLoader
com.cloudwebrtc.webrtc.R$attr: int nestedScrollViewStyle
org.webrtc.TurnCustomizer: long nativeTurnCustomizer
androidx.window.layout.SidecarCompat$DistinctSidecarElementCallback: java.util.concurrent.locks.ReentrantLock lock
androidx.concurrent.futures.AbstractResolvableFuture: androidx.concurrent.futures.AbstractResolvableFuture$Waiter waiters
org.webrtc.EglBase14Impl: android.opengl.EGLConfig eglConfig
org.webrtc.CameraCapturer: int OPEN_CAMERA_DELAY_MS
com.cloudwebrtc.webrtc.GetUserMediaImpl: int DEFAULT_WIDTH
com.google.type.LatLng: int LATITUDE_FIELD_NUMBER
org.webrtc.RtpParameters$Encoding: java.lang.String rid
com.google.firestore.v1.StructuredQuery$Filter: int COMPOSITE_FILTER_FIELD_NUMBER
com.google.firestore.v1.StructuredAggregationQuery$Aggregation$Sum: int FIELD_FIELD_NUMBER
androidx.window.embedding.SplitRule$Api30Impl: androidx.window.embedding.SplitRule$Api30Impl INSTANCE
com.cloudwebrtc.webrtc.SurfaceTextureRenderer: boolean isFirstFrameRendered
com.google.firestore.v1.StructuredQuery$Filter: int UNARY_FILTER_FIELD_NUMBER
androidx.window.layout.FoldingFeature$OcclusionType: androidx.window.layout.FoldingFeature$OcclusionType$Companion Companion
org.webrtc.VideoFrameDrawer: android.graphics.Matrix renderMatrix
org.webrtc.audio.WebRtcAudioManager: java.lang.String TAG
com.cloudwebrtc.webrtc.R$dimen: int notification_action_text_size
org.webrtc.NetworkMonitorAutoDetect$WifiDirectManagerDelegate: org.webrtc.NetworkChangeDetector$NetworkInformation wifiP2pNetworkInfo
com.cloudwebrtc.webrtc.PeerConnectionObserver: java.util.Map remoteTracks
org.webrtc.HardwareVideoEncoder: org.webrtc.MediaCodecWrapperFactory mediaCodecWrapperFactory
org.webrtc.VideoCodecInfo: java.lang.String H264_LEVEL_3_1
org.webrtc.PeerConnection$ContinualGatheringPolicy: org.webrtc.PeerConnection$ContinualGatheringPolicy GATHER_ONCE
com.google.firestore.v1.ExistenceFilter: int count_
com.google.firestore.v1.StructuredQuery$FieldFilter: int VALUE_FIELD_NUMBER
io.flutter.embedding.android.FlutterSplashView$SavedState: java.lang.String previousCompletedSplashIsolate
com.google.firestore.v1.StructuredQuery$CollectionSelector: int ALL_DESCENDANTS_FIELD_NUMBER
com.google.firestore.v1.StructuredQuery: com.google.firestore.v1.Cursor startAt_
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: android.util.LongSparseArray renders
org.webrtc.PeerConnection$IceServer: java.lang.String username
com.google.type.LatLng: com.google.protobuf.Parser PARSER
org.webrtc.GlGenericDrawer: org.webrtc.GlShader currentShader
org.webrtc.DataChannel$Init: java.lang.String protocol
androidx.window.layout.HardwareFoldingFeature$Type: androidx.window.layout.HardwareFoldingFeature$Type FOLD
org.webrtc.PeerConnectionFactory$InitializationOptions: java.lang.String nativeLibraryName
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor$FrameCryptorStateObserver: io.flutter.plugin.common.EventChannel eventChannel
com.google.firestore.v1.StructuredQuery$Projection: com.google.protobuf.Parser PARSER
androidx.window.embedding.SplitPairFilter: java.lang.String secondaryActivityIntentAction
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: java.util.Map localStreams
org.webrtc.SessionDescription$Type: org.webrtc.SessionDescription$Type[] $VALUES
org.webrtc.voiceengine.WebRtcAudioManager: int DEFAULT_FRAME_PER_BUFFER
org.webrtc.HardwareVideoEncoderFactory$1: int[] $SwitchMap$org$webrtc$VideoCodecMimeType
com.google.firestore.v1.DocumentRemove: int READ_TIME_FIELD_NUMBER
org.webrtc.SurfaceTextureHelper$1: org.webrtc.YuvConverter val$yuvConverter
io.flutter.embedding.engine.renderer.SurfaceTextureWrapper: boolean released
org.webrtc.RtpParameters$DegradationPreference: org.webrtc.RtpParameters$DegradationPreference DISABLED
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_30
org.webrtc.audio.VolumeLogger: android.media.AudioManager audioManager
org.webrtc.WrappedVideoDecoderFactory: org.webrtc.VideoDecoderFactory platformSoftwareVideoDecoderFactory
org.webrtc.PeerConnection$RTCConfiguration: org.webrtc.RtcCertificatePem certificate
com.google.firestore.v1.WriteRequest: com.google.protobuf.MapFieldLite labels_
com.google.firestore.v1.BatchGetDocumentsResponse: int FOUND_FIELD_NUMBER
com.google.firebase.firestore.proto.Target: com.google.protobuf.ByteString resumeToken_
androidx.window.layout.SidecarCompat$DistinctSidecarElementCallback: androidx.window.sidecar.SidecarInterface$SidecarCallback callbackInterface
org.webrtc.PeerConnection$BundlePolicy: org.webrtc.PeerConnection$BundlePolicy MAXBUNDLE
com.cloudwebrtc.webrtc.record.VideoFileRenderer: org.webrtc.EglBase eglBase
com.google.firestore.v1.StructuredQuery$FieldFilter: com.google.firestore.v1.Value value_
com.google.firestore.v1.StructuredAggregationQuery: int queryTypeCase_
org.webrtc.RtpParameters$Rtcp: java.lang.String cname
org.webrtc.MediaCodecUtils: java.lang.String NVIDIA_PREFIX
com.cloudwebrtc.webrtc.R$layout: int notification_template_custom_big
org.webrtc.audio.WebRtcAudioTrack: int AUDIO_TRACK_START
com.cloudwebrtc.webrtc.OrientationAwareScreenCapturer: boolean isPortrait
org.webrtc.VideoFrameDrawer: int renderWidth
com.google.firestore.v1.WriteResponse: com.google.firestore.v1.WriteResponse DEFAULT_INSTANCE
com.cloudwebrtc.webrtc.R$id: int locale
com.google.firestore.bundle.BundledQuery: com.google.firestore.bundle.BundledQuery DEFAULT_INSTANCE
org.webrtc.EncodedImage: int encodedWidth
org.webrtc.Logging$TraceLevel: org.webrtc.Logging$TraceLevel TRACE_MODULECALL
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_20
org.webrtc.audio.JavaAudioDeviceModule$Builder: org.webrtc.audio.JavaAudioDeviceModule$AudioRecordStateCallback audioRecordStateCallback
org.webrtc.HardwareVideoEncoder: org.webrtc.GlRectDrawer textureDrawer
com.cloudwebrtc.webrtc.R$styleable: int ColorStateListItem_alpha
kotlin.jvm.internal.CallableReference: java.lang.String name
org.webrtc.audio.WebRtcAudioTrack: boolean useLowLatency
com.cloudwebrtc.webrtc.record.VideoFileRenderer: boolean encoderStarted
com.cloudwebrtc.webrtc.R$style: int TextAppearance_Compat_Notification_Time
io.flutter.embedding.engine.FlutterJNI: io.flutter.embedding.engine.deferredcomponents.DeferredComponentManager deferredComponentManager
org.webrtc.SurfaceTextureHelper$1: boolean val$alignTimestamps
org.webrtc.TextureBufferImpl: org.webrtc.TextureBufferImpl$RefCountMonitor refCountMonitor
com.google.firestore.v1.ListenRequest: com.google.protobuf.Parser PARSER
org.webrtc.MediaStream: java.lang.String TAG
org.webrtc.AndroidVideoDecoder: int DEQUEUE_OUTPUT_BUFFER_TIMEOUT_US
org.webrtc.FrameCryptor$FrameCryptionState: org.webrtc.FrameCryptor$FrameCryptionState NEW
org.webrtc.audio.WebRtcAudioRecord: org.webrtc.audio.JavaAudioDeviceModule$SamplesReadyCallback audioSamplesReadyCallback
com.google.firestore.v1.BatchGetDocumentsResponse: int READ_TIME_FIELD_NUMBER
org.webrtc.NetworkChangeDetector$ConnectionType: org.webrtc.NetworkChangeDetector$ConnectionType CONNECTION_WIFI
com.cloudwebrtc.webrtc.audio.AudioDeviceKind: com.cloudwebrtc.webrtc.audio.AudioDeviceKind EARPIECE
org.webrtc.VideoFrameDrawer: float[] dstPoints
org.webrtc.PeerConnection$RTCConfiguration: boolean pruneTurnPorts
org.webrtc.VideoCodecInfo: java.lang.String H264_FMTP_PROFILE_LEVEL_ID
org.webrtc.PeerConnectionFactory$InitializationOptions$Builder: android.content.Context applicationContext
io.flutter.embedding.engine.FlutterJNI: io.flutter.embedding.engine.dart.PlatformMessageHandler platformMessageHandler
com.google.firestore.v1.StructuredQuery$Filter: int FIELD_FILTER_FIELD_NUMBER
com.google.firestore.v1.DocumentTransform: com.google.firestore.v1.DocumentTransform DEFAULT_INSTANCE
com.google.firestore.v1.DocumentTransform$FieldTransform: java.lang.String fieldPath_
com.cloudwebrtc.webrtc.R$styleable: int SplitPairFilter_secondaryActivityName
org.webrtc.NetworkMonitorAutoDetect: org.webrtc.NetworkMonitorAutoDetect$WifiDirectManagerDelegate wifiDirectManagerDelegate
io.flutter.embedding.engine.FlutterJNI: io.flutter.plugin.localization.LocalizationPlugin localizationPlugin
com.google.firestore.v1.WriteResponse: int COMMIT_TIME_FIELD_NUMBER
org.webrtc.SessionDescription$Type: org.webrtc.SessionDescription$Type OFFER
com.cloudwebrtc.webrtc.R$styleable: int SplitPairRule_finishSecondaryWithPrimary
com.google.android.gms.common.internal.TelemetryData: android.os.Parcelable$Creator CREATOR
org.webrtc.H264Utils: java.lang.String H264_PROFILE_CONSTRAINED_BASELINE
org.webrtc.FrameCryptor$FrameCryptionState: org.webrtc.FrameCryptor$FrameCryptionState[] $VALUES
org.webrtc.ScreenCapturerAndroid$1: org.webrtc.ScreenCapturerAndroid this$0
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback: android.view.WindowInsets lastWindowInsets
org.webrtc.NetworkMonitorAutoDetect: boolean includeWifiDirect
org.webrtc.SurfaceTextureHelper: int oesTextureId
org.webrtc.CameraCapturer: java.lang.String pendingCameraName
org.webrtc.HardwareVideoEncoder: int MEDIA_CODEC_RELEASE_TIMEOUT_MS
org.webrtc.voiceengine.WebRtcAudioRecord: boolean DEBUG
com.cloudwebrtc.webrtc.R$dimen: int notification_right_side_padding_top
org.webrtc.audio.WebRtcAudioRecord: long nativeAudioRecord
com.cloudwebrtc.webrtc.R$styleable: int SplitPairRule_splitMinSmallestWidth
org.webrtc.voiceengine.WebRtcAudioManager$VolumeLogger: android.media.AudioManager audioManager
org.webrtc.SurfaceTextureHelper$3: org.webrtc.SurfaceTextureHelper this$0
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_27
com.google.protobuf.Any: java.lang.String typeUrl_
org.webrtc.PeerConnection$RTCConfiguration: org.webrtc.PeerConnection$TcpCandidatePolicy tcpCandidatePolicy
com.cloudwebrtc.webrtc.R$styleable: int[] GradientColor
com.cloudwebrtc.webrtc.GetUserMediaImpl: android.content.Context applicationContext
io.flutter.embedding.engine.renderer.SurfaceTextureWrapper: boolean attached
org.webrtc.EglRenderer: org.webrtc.RendererCommon$GlDrawer drawer
org.webrtc.SurfaceTextureHelper$2: org.webrtc.SurfaceTextureHelper this$0
com.cloudwebrtc.webrtc.audio.AudioSwitchManager: java.util.List preferredDeviceList
org.webrtc.RTCStatsReport: long timestampUs
org.webrtc.VideoFrameDrawer: float[] srcPoints
com.cloudwebrtc.webrtc.R$styleable: int FontFamilyFont_android_fontStyle
org.webrtc.CameraCapturer: int width
org.webrtc.AndroidVideoDecoder: java.lang.Thread outputThread
org.webrtc.NetworkMonitor: org.webrtc.NetworkChangeDetector$ConnectionType currentConnectionType
org.webrtc.voiceengine.WebRtcAudioManager: int nativeSampleRate
org.webrtc.PeerConnection$RTCConfiguration: int maxIPv6Networks
com.google.firestore.v1.ListenRequest: int ADD_TARGET_FIELD_NUMBER
org.webrtc.audio.WebRtcAudioRecord: java.util.concurrent.atomic.AtomicInteger nextSchedulerId
org.webrtc.JavaI420Buffer: org.webrtc.RefCountDelegate refCountDelegate
org.webrtc.GlTextureFrameBuffer: int width
com.google.rpc.Status: com.google.rpc.Status DEFAULT_INSTANCE
org.webrtc.FileVideoCapturer$VideoReaderY4M: java.nio.channels.FileChannel mediaFileChannel
com.google.firestore.v1.BatchGetDocumentsRequest: int MASK_FIELD_NUMBER
org.webrtc.VideoEncoder$RateControlParameters: org.webrtc.VideoEncoder$BitrateAllocation bitrate
org.webrtc.StatsReport$Value: java.lang.String value
org.webrtc.voiceengine.WebRtcAudioTrack: org.webrtc.voiceengine.WebRtcAudioTrack$ErrorCallback errorCallback
org.webrtc.CameraCapturer: android.content.Context applicationContext
com.cloudwebrtc.webrtc.R$attr: int splitLayoutDirection
org.webrtc.VideoFrame$TextureBuffer$Type: org.webrtc.VideoFrame$TextureBuffer$Type OES
org.webrtc.RtpParameters$Encoding: boolean adaptiveAudioPacketTime
org.webrtc.Camera2Session: long constructionTimeNs
org.webrtc.PeerConnectionFactory: org.webrtc.PeerConnectionFactory$ThreadInfo workerThread
org.webrtc.EglRenderer$1: org.webrtc.EglRenderer this$0
com.cloudwebrtc.webrtc.record.MediaRecorderImpl: java.lang.String TAG
org.webrtc.JavaI420Buffer: int strideU
org.webrtc.voiceengine.WebRtcAudioManager: boolean proAudio
com.google.firestore.v1.WriteResponse: com.google.protobuf.ByteString streamToken_
org.webrtc.VideoFrameBufferType: int I422
org.webrtc.NetworkMonitorAutoDetect: java.lang.String wifiSSID
com.google.firestore.v1.DocumentTransform$FieldTransform: int REMOVE_ALL_FROM_ARRAY_FIELD_NUMBER
org.webrtc.H264Utils: org.webrtc.VideoCodecInfo DEFAULT_H264_BASELINE_PROFILE_CODEC
org.webrtc.NetworkMonitorAutoDetect: org.webrtc.NetworkChangeDetector$ConnectionType connectionType
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_0
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor$FrameCryptorStateObserver$1: com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor val$this$0
com.google.firestore.v1.BatchGetDocumentsResponse: int resultCase_
org.webrtc.CameraEnumerationAndroid$2: int val$requestedWidth
org.webrtc.NetworkChangeDetector$NetworkInformation: org.webrtc.NetworkChangeDetector$ConnectionType type
com.cloudwebrtc.webrtc.utils.AnyThreadSink: io.flutter.plugin.common.EventChannel$EventSink eventSink
com.google.firestore.v1.ListenRequest: com.google.protobuf.MapFieldLite labels_
io.flutter.embedding.engine.FlutterOverlaySurface: android.view.Surface surface
com.google.firestore.v1.Write: int VERIFY_FIELD_NUMBER
com.cloudwebrtc.webrtc.R$styleable: int[] GradientColorItem
org.webrtc.CandidatePairChangeEvent: org.webrtc.IceCandidate local
org.webrtc.voiceengine.WebRtcAudioManager$VolumeLogger: int TIMER_PERIOD_IN_SECONDS
com.google.firestore.v1.DocumentChange: com.google.protobuf.Internal$IntList targetIds_
org.webrtc.voiceengine.WebRtcAudioEffects: android.media.audiofx.AcousticEchoCanceler aec
com.google.firestore.v1.DocumentDelete: int REMOVED_TARGET_IDS_FIELD_NUMBER
org.webrtc.DataChannel$State: org.webrtc.DataChannel$State CLOSING
com.google.firestore.v1.BloomFilter: com.google.firestore.v1.BloomFilter DEFAULT_INSTANCE
com.google.firestore.v1.Value: int TIMESTAMP_VALUE_FIELD_NUMBER
com.google.android.gms.signin.internal.zag: android.os.Parcelable$Creator CREATOR
org.webrtc.PeerConnection$PeerConnectionState: org.webrtc.PeerConnection$PeerConnectionState DISCONNECTED
org.webrtc.PeerConnection$RTCConfiguration: boolean surfaceIceCandidatesOnIceTransportTypeChanged
org.webrtc.H264Utils: java.lang.String H264_LEVEL_3_1
com.cloudwebrtc.webrtc.R$styleable: int SplitPairFilter_primaryActivityName
com.cloudwebrtc.webrtc.DataChannelObserver: java.lang.String flutterId
org.webrtc.audio.WebRtcAudioRecord: boolean isNoiseSuppressorSupported
org.webrtc.DefaultVideoDecoderFactory: org.webrtc.VideoDecoderFactory hardwareVideoDecoderFactory
org.webrtc.EglRenderer: org.webrtc.EglRenderer$ErrorCallback errorCallback
org.webrtc.ScreenCapturerAndroid: org.webrtc.CapturerObserver capturerObserver
com.cloudwebrtc.webrtc.record.VideoFileRenderer: android.media.MediaMuxer mediaMuxer
io.flutter.embedding.engine.FlutterJNI: io.flutter.embedding.engine.FlutterJNI$AccessibilityDelegate accessibilityDelegate
kotlinx.coroutines.JobSupport$Finishing: java.lang.Object _rootCause
org.webrtc.VideoCodecMimeType: org.webrtc.VideoCodecMimeType[] $VALUES
androidx.window.embedding.ActivityStack: boolean isEmpty
com.google.firestore.v1.CommitRequest: com.google.firestore.v1.CommitRequest DEFAULT_INSTANCE
com.cloudwebrtc.webrtc.record.FrameCapturer: io.flutter.plugin.common.MethodChannel$Result callback
com.cloudwebrtc.webrtc.R$styleable: int FontFamilyFont_ttcIndex
com.cloudwebrtc.webrtc.GetUserMediaImpl$3: io.flutter.plugin.common.MethodChannel$Result val$result
com.google.firestore.v1.StructuredAggregationQuery$Aggregation: int ALIAS_FIELD_NUMBER
org.webrtc.PeerConnectionFactory$Options: boolean disableNetworkMonitor
com.google.firestore.v1.StructuredAggregationQuery: java.lang.Object queryType_
com.cloudwebrtc.webrtc.R$styleable: int GradientColorItem_android_color
org.webrtc.RtpParameters: java.lang.String transactionId
org.webrtc.EncodedImage: org.webrtc.RefCountDelegate refCountDelegate
org.webrtc.audio.JavaAudioDeviceModule$AudioTrackStartErrorCode: org.webrtc.audio.JavaAudioDeviceModule$AudioTrackStartErrorCode[] $VALUES
org.webrtc.SoftwareVideoDecoderFactory: long nativeFactory
org.webrtc.Camera2Enumerator: java.util.Map cachedSupportedFormats
com.google.android.gms.common.internal.ConnectionTelemetryConfiguration: android.os.Parcelable$Creator CREATOR
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: java.util.Map localTracks
org.webrtc.CameraCapturer: java.lang.String cameraName
org.webrtc.NetworkMonitorAutoDetect: org.webrtc.NetworkMonitorAutoDetect$ConnectivityManagerDelegate connectivityManagerDelegate
org.webrtc.NV12Buffer: int sliceHeight
org.webrtc.PeerConnection$IceConnectionState: org.webrtc.PeerConnection$IceConnectionState CHECKING
org.webrtc.VideoFrame$TextureBuffer$Type: org.webrtc.VideoFrame$TextureBuffer$Type[] $VALUES
org.webrtc.PeerConnection$PeerConnectionState: org.webrtc.PeerConnection$PeerConnectionState CONNECTED
org.webrtc.voiceengine.WebRtcAudioRecord: org.webrtc.voiceengine.WebRtcAudioRecord$WebRtcAudioRecordSamplesReadyCallback audioSamplesReadyCallback
com.google.firestore.v1.StructuredAggregationQuery: com.google.firestore.v1.StructuredAggregationQuery DEFAULT_INSTANCE
org.webrtc.DataChannel$State: org.webrtc.DataChannel$State[] $VALUES
com.cloudwebrtc.webrtc.GetUserMediaImpl: android.util.SparseArray mediaRecorders
org.webrtc.AndroidVideoDecoder: int stride
org.webrtc.voiceengine.WebRtcAudioManager$VolumeLogger$LogVolumeTask: int maxVoiceCallVolume
org.webrtc.EncodedImage$Builder: int encodedWidth
com.google.android.gms.common.internal.GetServiceRequest: android.os.Parcelable$Creator CREATOR
org.webrtc.PeerConnection$IceTransportsType: org.webrtc.PeerConnection$IceTransportsType NOHOST
org.webrtc.RtpParameters$Encoding: java.lang.Double scaleResolutionDownBy
org.webrtc.voiceengine.WebRtcAudioRecord$AudioRecordStartErrorCode: org.webrtc.voiceengine.WebRtcAudioRecord$AudioRecordStartErrorCode AUDIO_RECORD_START_STATE_MISMATCH
org.webrtc.audio.WebRtcAudioEffects: boolean DEBUG
com.google.firestore.v1.BitSequence: com.google.firestore.v1.BitSequence DEFAULT_INSTANCE
org.webrtc.CameraCapturer$SwitchState: org.webrtc.CameraCapturer$SwitchState PENDING
com.cloudwebrtc.webrtc.R$styleable: int FontFamily_fontProviderFetchTimeout
com.cloudwebrtc.webrtc.R$styleable: int GradientColor_android_endY
org.webrtc.PeerConnection$PeerConnectionState: org.webrtc.PeerConnection$PeerConnectionState CLOSED
org.webrtc.RtpTransceiver$RtpTransceiverDirection: org.webrtc.RtpTransceiver$RtpTransceiverDirection INACTIVE
com.google.firebase.firestore.proto.MaybeDocument: com.google.firebase.firestore.proto.MaybeDocument DEFAULT_INSTANCE
com.google.firestore.v1.StructuredQuery$CompositeFilter: com.google.protobuf.Internal$ProtobufList filters_
org.webrtc.RtpCapabilities$CodecCapability: org.webrtc.MediaStreamTrack$MediaType kind
org.webrtc.PeerConnectionFactory$InitializationOptions: android.content.Context applicationContext
org.webrtc.VideoCodecInfo: java.util.Map params
org.webrtc.EglBase$ConfigBuilder: boolean isRecordable
org.webrtc.PeerConnection$SdpSemantics: org.webrtc.PeerConnection$SdpSemantics UNIFIED_PLAN
org.webrtc.audio.WebRtcAudioRecord: boolean microphoneMute
com.cloudwebrtc.webrtc.record.VideoFileRenderer: org.webrtc.GlRectDrawer drawer
org.webrtc.RtpCapabilities$CodecCapability: java.lang.String mimeType
androidx.window.layout.HardwareFoldingFeature$Type: java.lang.String description
com.cloudwebrtc.webrtc.utils.ObjectType: com.cloudwebrtc.webrtc.utils.ObjectType Map
com.cloudwebrtc.webrtc.utils.MediaConstraintsUtils$1: int[] $SwitchMap$com$cloudwebrtc$webrtc$utils$ObjectType
org.webrtc.VideoFileRenderer: android.os.HandlerThread fileThread
org.webrtc.VideoSource: org.webrtc.CapturerObserver capturerObserver
org.webrtc.MediaSource: long nativeSource
com.cloudwebrtc.webrtc.record.VideoFileRenderer: java.nio.ByteBuffer[] audioInputBuffers
com.google.firestore.v1.Write: int TRANSFORM_FIELD_NUMBER
com.google.firestore.v1.CommitResponse: com.google.protobuf.Internal$ProtobufList writeResults_
com.google.firestore.v1.ListenResponse: com.google.protobuf.Parser PARSER
org.webrtc.PeerConnection$PortPrunePolicy: org.webrtc.PeerConnection$PortPrunePolicy NO_PRUNE
androidx.window.R$styleable: int SplitPlaceholderRule_splitMinWidth
kotlin.jvm.internal.CallableReference: java.lang.String signature
com.cloudwebrtc.webrtc.R$styleable: int GradientColor_android_endColor
org.webrtc.NetworkMonitorAutoDetect$SimpleNetworkCallback: org.webrtc.NetworkMonitorAutoDetect this$0
org.webrtc.HardwareVideoEncoderFactory: int QCOM_VP8_KEY_FRAME_INTERVAL_ANDROID_L_MS
com.cloudwebrtc.webrtc.R$string: int status_bar_notification_info_overflow
org.webrtc.PeerConnectionFactory$Options: int networkIgnoreMask
org.webrtc.SurfaceViewRenderer: int rotatedFrameWidth
com.google.firestore.v1.StructuredQuery$FieldReference: com.google.firestore.v1.StructuredQuery$FieldReference DEFAULT_INSTANCE
org.webrtc.FrameCryptorAlgorithm: org.webrtc.FrameCryptorAlgorithm AES_CBC
org.webrtc.audio.JavaAudioDeviceModule: android.media.AudioManager audioManager
com.google.rpc.Status: java.lang.String message_
com.cloudwebrtc.webrtc.GetUserMediaImpl$VideoCapturerInfo: int width
com.google.firestore.v1.DocumentRemove: com.google.firestore.v1.DocumentRemove DEFAULT_INSTANCE
org.webrtc.VideoProcessor$FrameAdaptationParameters: long timestampNs
org.webrtc.VideoFrameBufferType: int I010
androidx.window.R$styleable: int SplitPairRule_splitLayoutDirection
org.webrtc.RTCStats: java.util.Map members
org.webrtc.NetworkMonitor: java.util.ArrayList networkObservers
org.webrtc.RtpParameters$Encoding: double bitratePriority
org.webrtc.RtpParameters: org.webrtc.RtpParameters$Rtcp rtcp
com.google.firestore.v1.ListenResponse: int DOCUMENT_REMOVE_FIELD_NUMBER
androidx.window.embedding.SplitPlaceholderRule: java.util.Set filters
org.webrtc.RtpTransceiver$RtpTransceiverDirection: int nativeIndex
org.webrtc.voiceengine.WebRtcAudioManager: int outputBufferSize
androidx.window.core.Bounds: int top
org.webrtc.voiceengine.WebRtcAudioRecord: int CALLBACK_BUFFER_SIZE_MS
org.webrtc.MediaCodecUtils: java.lang.String TAG
org.webrtc.EglBase10Impl$1FakeSurfaceHolder: android.view.Surface surface
org.webrtc.GlGenericDrawer: org.webrtc.GlGenericDrawer$ShaderCallbacks shaderCallbacks
androidx.window.embedding.SplitController: androidx.window.embedding.SplitController globalInstance
org.webrtc.PeerConnection$CandidateNetworkPolicy: org.webrtc.PeerConnection$CandidateNetworkPolicy[] $VALUES
org.webrtc.PeerConnection$IceGatheringState: org.webrtc.PeerConnection$IceGatheringState[] $VALUES
org.webrtc.audio.JavaAudioDeviceModule$Builder: org.webrtc.audio.JavaAudioDeviceModule$AudioRecordErrorCallback audioRecordErrorCallback
kotlin.coroutines.jvm.internal.BaseContinuationImpl: kotlin.coroutines.Continuation completion
org.webrtc.voiceengine.WebRtcAudioRecord: java.nio.ByteBuffer byteBuffer
org.webrtc.EglBase: int[] CONFIG_RECORDABLE
com.google.firestore.v1.WriteResponse: com.google.protobuf.Parser PARSER
org.webrtc.DefaultVideoEncoderFactory: org.webrtc.VideoEncoderFactory softwareVideoEncoderFactory
com.google.firestore.v1.DocumentTransform: com.google.protobuf.Internal$ProtobufList fieldTransforms_
io.flutter.embedding.engine.FlutterJNI: boolean prefetchDefaultFontManagerCalled
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_10
com.cloudwebrtc.webrtc.PeerConnectionObserver: io.flutter.plugin.common.EventChannel eventChannel
org.webrtc.VideoFrameBufferType: int I420
androidx.window.R$id: int androidx_window_activity_scope
kotlinx.coroutines.internal.ThreadSafeHeap: int _size
org.webrtc.EglBase10Impl$Context: javax.microedition.khronos.egl.EGLConfig eglContextConfig
androidx.window.layout.SidecarWindowBackend$ExtensionListenerImpl: androidx.window.layout.SidecarWindowBackend this$0
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_18
org.webrtc.HardwareVideoEncoderFactory: java.util.List H264_HW_EXCEPTION_MODELS
org.webrtc.Camera1Session: android.hardware.Camera$CameraInfo info
androidx.window.layout.SidecarCompat: androidx.window.layout.SidecarAdapter sidecarAdapter
com.google.firestore.v1.Cursor: boolean before_
io.flutter.embedding.engine.mutatorsstack.FlutterMutatorsStack: android.graphics.Matrix finalMatrix
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin: androidx.lifecycle.Lifecycle lifecycle
org.webrtc.MediaSource$State: org.webrtc.MediaSource$State INITIALIZING
org.webrtc.SurfaceTextureHelper: boolean isTextureInUse
com.cloudwebrtc.webrtc.DataChannelObserver$1: int[] $SwitchMap$org$webrtc$DataChannel$State
com.google.firestore.v1.StructuredQuery$CompositeFilter: int OP_FIELD_NUMBER
org.webrtc.voiceengine.WebRtcAudioUtils: boolean isDefaultSampleRateOverridden
org.webrtc.HardwareVideoEncoder: android.view.Surface textureInputSurface
org.webrtc.RtpTransceiver$RtpTransceiverDirection: org.webrtc.RtpTransceiver$RtpTransceiverDirection STOPPED
org.webrtc.SurfaceEglRenderer: boolean isFirstFrameRendered
com.google.firebase.firestore.proto.NoDocument: com.google.protobuf.Timestamp readTime_
org.webrtc.audio.JavaAudioDeviceModule$AudioSamples: int sampleRate
androidx.window.R$attr: int clearTop
org.webrtc.Logging$TraceLevel: org.webrtc.Logging$TraceLevel TRACE_ALL
org.webrtc.PeerConnectionFactory$InitializationOptions$Builder: java.lang.String nativeLibraryName
com.google.firestore.v1.Target: com.google.protobuf.Parser PARSER
org.webrtc.PeerConnection$RTCConfiguration: int iceConnectionReceivingTimeout
org.webrtc.AndroidVideoDecoder: java.lang.Object dimensionLock
com.google.firestore.v1.Target: com.google.protobuf.Int32Value expectedCount_
org.webrtc.HardwareVideoDecoderFactory: org.webrtc.Predicate defaultAllowedPredicate
io.flutter.embedding.engine.FlutterJNI: boolean initCalled
com.google.firestore.v1.DocumentRemove: int REMOVED_TARGET_IDS_FIELD_NUMBER
org.webrtc.PeerConnection$PeerConnectionState: org.webrtc.PeerConnection$PeerConnectionState[] $VALUES
androidx.window.layout.WindowInfoTrackerImpl$windowLayoutInfo$1: java.lang.Object L$2
com.google.firestore.v1.DocumentTransform$FieldTransform: com.google.protobuf.Parser PARSER
org.webrtc.audio.WebRtcAudioTrack: long nativeAudioTrack
org.webrtc.TextureBufferImpl: int width
com.cloudwebrtc.webrtc.GetUserMediaImpl: java.lang.String PERMISSIONS
org.webrtc.HardwareVideoEncoder: boolean useSurfaceMode
androidx.window.embedding.SplitController: androidx.window.embedding.EmbeddingBackend embeddingBackend
org.webrtc.VideoFileRenderer: android.os.HandlerThread renderThread
org.webrtc.PeerConnection$IceTransportsType: org.webrtc.PeerConnection$IceTransportsType RELAY
com.google.firestore.v1.RunAggregationQueryRequest: int STRUCTURED_AGGREGATION_QUERY_FIELD_NUMBER
com.cloudwebrtc.webrtc.utils.AnyThreadResult: io.flutter.plugin.common.MethodChannel$Result result
org.webrtc.FrameCryptorAlgorithm: org.webrtc.FrameCryptorAlgorithm AES_GCM
org.webrtc.MediaSource$State: org.webrtc.MediaSource$State[] $VALUES
androidx.window.layout.SidecarWindowBackend: java.lang.String TAG
org.webrtc.CameraEnumerationAndroid$CaptureFormat: int height
com.google.firestore.v1.Write: int UPDATE_FIELD_NUMBER
kotlinx.coroutines.android.HandlerDispatcherKt: android.view.Choreographer choreographer
com.google.firestore.v1.RunAggregationQueryResponse: int TRANSACTION_FIELD_NUMBER
org.webrtc.SurfaceTextureHelper: android.graphics.SurfaceTexture surfaceTexture
org.webrtc.voiceengine.WebRtcAudioTrack: long AUDIO_TRACK_THREAD_JOIN_TIMEOUT_MS
org.webrtc.PeerConnection$IceConnectionState: org.webrtc.PeerConnection$IceConnectionState COMPLETED
androidx.window.core.Bounds: int right
org.webrtc.voiceengine.WebRtcAudioTrack: java.lang.String TAG
com.google.firestore.admin.v1.Index: java.lang.String name_
org.webrtc.AndroidVideoDecoder: org.webrtc.ThreadUtils$ThreadChecker decoderThreadChecker
org.webrtc.CandidatePairChangeEvent: int estimatedDisconnectedTimeMs
com.cloudwebrtc.webrtc.R$drawable: int notification_bg_low
org.webrtc.MediaStreamTrack$MediaType: int nativeIndex
com.cloudwebrtc.webrtc.utils.ConstraintsArray: java.util.ArrayList mArray
com.google.firestore.v1.DocumentTransform$FieldTransform: java.lang.Object transformType_
org.webrtc.audio.JavaAudioDeviceModule: org.webrtc.audio.WebRtcAudioTrack audioOutput
com.cloudwebrtc.webrtc.R$color: int androidx_core_ripple_material_light
org.webrtc.SurfaceEglRenderer: int rotatedFrameWidth
org.webrtc.CameraCapturer: org.webrtc.CameraCapturer$SwitchState switchState
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: java.util.Map mPeerConnectionObservers
com.google.firestore.v1.Cursor: com.google.protobuf.Parser PARSER
com.google.firestore.v1.StructuredQuery$Order: int FIELD_FIELD_NUMBER
org.webrtc.PeerConnection$RTCConfiguration: org.webrtc.PeerConnection$RtcpMuxPolicy rtcpMuxPolicy
io.flutter.embedding.engine.FlutterJNI: android.os.Looper mainLooper
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$FallbackFactory: org.webrtc.VideoEncoderFactory hardwareVideoEncoderFactory
org.webrtc.voiceengine.WebRtcAudioManager: int sampleRate
androidx.window.R$styleable: int SplitPairFilter_secondaryActivityName
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_22
org.webrtc.VideoFrameBufferType: int I210
androidx.window.java.layout.WindowInfoTrackerCallbackAdapter: androidx.window.layout.WindowInfoTracker tracker
org.webrtc.SurfaceViewRenderer: int surfaceWidth
com.google.firestore.v1.ListenResponse: int DOCUMENT_DELETE_FIELD_NUMBER
org.webrtc.MediaCodecUtils: int COLOR_QCOM_FORMATYUV420PackedSemiPlanar32m
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback: boolean needsSave
org.webrtc.CameraCapturer: java.lang.Object stateLock
org.webrtc.VideoCodecMimeType: org.webrtc.VideoCodecMimeType H264
com.cloudwebrtc.webrtc.BuildConfig: java.lang.String LIBRARY_PACKAGE_NAME
androidx.window.embedding.EmbeddingCompat: boolean DEBUG
com.cloudwebrtc.webrtc.R$dimen: int compat_button_padding_horizontal_material
org.webrtc.VideoEncoder$BitrateAllocation: int[][] bitratesBbs
org.webrtc.Camera2Session: org.webrtc.Histogram camera2StartTimeMsHistogram
org.webrtc.FileVideoCapturer$VideoReaderY4M: int FRAME_DELIMETER_LENGTH
androidx.lifecycle.Lifecycle$Event: androidx.lifecycle.Lifecycle$Event[] $VALUES
com.google.firebase.firestore.proto.Target: int LAST_LISTEN_SEQUENCE_NUMBER_FIELD_NUMBER
org.webrtc.WrappedVideoDecoderFactory: org.webrtc.VideoDecoderFactory hardwareVideoDecoderFactory
androidx.window.layout.WindowMetricsCalculator$Companion$decorator$1: androidx.window.layout.WindowMetricsCalculator$Companion$decorator$1 INSTANCE
org.webrtc.SurfaceViewRenderer: org.webrtc.RendererCommon$VideoLayoutMeasure videoLayoutMeasure
com.cloudwebrtc.webrtc.R$styleable: int Capability_queryPatterns
com.google.firestore.v1.Precondition: int conditionTypeCase_
org.webrtc.EglRenderer: org.webrtc.GlTextureFrameBuffer bitmapTextureFramebuffer
org.webrtc.voiceengine.WebRtcAudioTrack: int BUFFERS_PER_SECOND
org.webrtc.IceCandidateErrorEvent: int port
org.webrtc.EglBase14Impl$Context: android.opengl.EGLContext egl14Context
org.webrtc.Camera2Session: org.webrtc.CameraSession$Events events
org.webrtc.Metrics: java.lang.String TAG
org.webrtc.CandidatePairChangeEvent: java.lang.String reason
org.webrtc.VideoDecoder$Settings: int width
com.google.firestore.bundle.BundledQuery: int limitType_
org.webrtc.PeerConnection$RTCConfiguration: java.lang.Integer iceUnwritableTimeMs
org.webrtc.audio.WebRtcAudioRecord: org.webrtc.audio.JavaAudioDeviceModule$AudioRecordErrorCallback errorCallback
org.webrtc.audio.LowLatencyAudioBufferManager: int prevUnderrunCount
com.google.firestore.v1.RunAggregationQueryResponse: com.google.protobuf.Timestamp readTime_
androidx.window.layout.WindowInfoTracker$Companion: java.lang.String TAG
org.webrtc.VideoEncoder$Settings: org.webrtc.VideoEncoder$Capabilities capabilities
org.webrtc.audio.WebRtcAudioRecord: java.util.concurrent.ScheduledExecutorService executor
org.webrtc.H264Utils: java.lang.String H264_FMTP_LEVEL_ASYMMETRY_ALLOWED
org.webrtc.ScreenCapturerAndroid: android.content.Intent mediaProjectionPermissionResultData
com.google.firestore.bundle.BundledQuery: int queryTypeCase_
com.cloudwebrtc.webrtc.GetUserMediaImpl$VideoCapturerInfo: boolean isScreenCapture
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor: java.util.Map frameCryptos
org.webrtc.EglRenderer: java.lang.Object layoutLock
com.cloudwebrtc.webrtc.R$styleable: int[] SplitPairRule
com.cloudwebrtc.webrtc.R$styleable: int[] ActivityFilter
com.cloudwebrtc.webrtc.SurfaceTextureRenderer: java.lang.Object layoutLock
org.webrtc.NetworkMonitorAutoDetect: java.util.Set availableNetworks
com.google.firestore.v1.DocumentTransform$FieldTransform: int SET_TO_SERVER_VALUE_FIELD_NUMBER
com.google.firestore.v1.DocumentTransform$FieldTransform: com.google.firestore.v1.DocumentTransform$FieldTransform DEFAULT_INSTANCE
org.webrtc.PeerConnection$AdapterType: org.webrtc.PeerConnection$AdapterType CELLULAR_5G
org.webrtc.audio.JavaAudioDeviceModule$Builder: android.content.Context context
com.google.firestore.v1.BatchGetDocumentsRequest: com.google.firestore.v1.DocumentMask mask_
org.webrtc.audio.WebRtcAudioTrack: int AUDIO_TRACK_STOP
org.webrtc.HardwareVideoEncoder$BusyCount: int count
org.webrtc.RtpTransceiver$RtpTransceiverDirection: org.webrtc.RtpTransceiver$RtpTransceiverDirection[] $VALUES
org.webrtc.NV12Buffer: int width
com.google.firestore.v1.Value: int REFERENCE_VALUE_FIELD_NUMBER
com.google.firestore.v1.Value: int GEO_POINT_VALUE_FIELD_NUMBER
org.webrtc.AndroidVideoDecoder: org.webrtc.MediaCodecWrapperFactory mediaCodecWrapperFactory
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor$FrameCryptorStateObserver: com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor this$0
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_19
com.google.android.gms.common.internal.zav: android.os.Parcelable$Creator CREATOR
com.google.firestore.v1.RunAggregationQueryRequest: int READ_TIME_FIELD_NUMBER
com.cloudwebrtc.webrtc.record.VideoFileRenderer: int trackIndex
com.cloudwebrtc.webrtc.PeerConnectionObserver$1: int[] $SwitchMap$org$webrtc$PeerConnection$IceConnectionState
com.cloudwebrtc.webrtc.record.VideoFileRenderer: android.os.HandlerThread audioThread
org.webrtc.CameraCapturer: java.lang.Runnable openCameraTimeoutRunnable
androidx.window.layout.DisplayCompatHelperApi17: androidx.window.layout.DisplayCompatHelperApi17 INSTANCE
androidx.window.layout.ExtensionWindowLayoutInfoBackend: java.util.Map listenerToActivity
org.webrtc.AndroidVideoDecoder: int height
com.cloudwebrtc.webrtc.R$styleable: int ColorStateListItem_android_color
kotlinx.coroutines.EventLoopImplBase: java.lang.Object _queue
org.webrtc.AndroidVideoDecoder: int sliceHeight
com.google.firestore.v1.Write: com.google.protobuf.Parser PARSER
androidx.window.embedding.SplitRule: int minWidth
com.google.protobuf.Any: int VALUE_FIELD_NUMBER
org.webrtc.EglBase: int[] CONFIG_PLAIN
org.webrtc.AndroidVideoDecoder: int MEDIA_CODEC_RELEASE_TIMEOUT_MS
org.webrtc.audio.WebRtcAudioRecord: java.util.concurrent.ScheduledFuture future
org.webrtc.VideoCodecMimeType: org.webrtc.VideoCodecMimeType VP9
org.webrtc.JavaI420Buffer: java.nio.ByteBuffer dataV
com.google.firestore.v1.BitSequence: com.google.protobuf.Parser PARSER
org.webrtc.VideoCodecInfo: java.lang.String H264_PROFILE_CONSTRAINED_HIGH
androidx.window.R$attr: int secondaryActivityName
org.webrtc.voiceengine.WebRtcAudioManager: boolean hardwareAEC
androidx.window.R$attr: int primaryActivityName
com.google.firestore.v1.StructuredAggregationQuery$Aggregation$Count: int UP_TO_FIELD_NUMBER
org.webrtc.voiceengine.WebRtcAudioTrack: boolean DEBUG
org.webrtc.EglRenderer: java.util.ArrayList frameListeners
org.webrtc.NV12Buffer: java.nio.ByteBuffer buffer
com.cloudwebrtc.webrtc.R$styleable: int SplitPairRule_splitRatio
org.webrtc.Predicate$1: org.webrtc.Predicate val$other
com.cloudwebrtc.webrtc.DataChannelObserver: org.webrtc.DataChannel dataChannel
org.webrtc.CryptoOptions$Srtp: boolean enableEncryptedRtpHeaderExtensions
com.google.firestore.v1.ListenResponse: int FILTER_FIELD_NUMBER
androidx.window.layout.ExtensionWindowLayoutInfoBackend: java.util.concurrent.locks.ReentrantLock extensionWindowBackendLock
com.cloudwebrtc.webrtc.audio.AudioSwitchManager: kotlin.jvm.functions.Function2 audioDeviceChangeListener
org.webrtc.SurfaceEglRenderer: org.webrtc.RendererCommon$RendererEvents rendererEvents
org.webrtc.CameraVideoCapturer$CameraStatistics: org.webrtc.SurfaceTextureHelper surfaceTextureHelper
org.webrtc.PeerConnectionFactory$Builder: org.webrtc.NetEqFactoryFactory neteqFactoryFactory
com.google.firestore.v1.WriteRequest: com.google.firestore.v1.WriteRequest DEFAULT_INSTANCE
org.webrtc.voiceengine.WebRtcAudioManager: org.webrtc.voiceengine.WebRtcAudioManager$VolumeLogger volumeLogger
com.google.firebase.firestore.proto.Target: int targetTypeCase_
org.webrtc.audio.JavaAudioDeviceModule$AudioSamples: int audioFormat
org.webrtc.RtpParameters$Codec: java.lang.Integer numChannels
com.cloudwebrtc.webrtc.GetUserMediaImpl$NoSuchFieldWithNameException: java.lang.String className
com.google.firestore.v1.Target: int READ_TIME_FIELD_NUMBER
com.cloudwebrtc.webrtc.OrientationAwareScreenCapturer: android.view.WindowManager windowManager
androidx.window.layout.SidecarCompat: java.lang.String TAG
com.cloudwebrtc.webrtc.R$attr: int splitRatio
org.webrtc.GlGenericDrawer: int inPosLocation
org.webrtc.voiceengine.WebRtcAudioUtils: boolean useWebRtcBasedNoiseSuppressor
com.google.firestore.v1.BatchGetDocumentsRequest: int DOCUMENTS_FIELD_NUMBER
com.cloudwebrtc.webrtc.GetUserMediaImpl$VideoCapturerInfo: org.webrtc.VideoCapturer capturer
org.webrtc.SurfaceEglRenderer: java.lang.String TAG
com.google.firestore.v1.Cursor: int VALUES_FIELD_NUMBER
com.google.firestore.v1.StructuredAggregationQuery: com.google.protobuf.Parser PARSER
com.cloudwebrtc.webrtc.R$styleable: int FontFamily_fontProviderSystemFontFamily
com.google.firebase.firestore.proto.WriteBatch: com.google.protobuf.Timestamp localWriteTime_
com.google.firestore.v1.DocumentMask: com.google.protobuf.Parser PARSER
org.webrtc.RtpParameters$Codec: java.util.Map parameters
com.google.firestore.v1.TransactionOptions$ReadOnly: int consistencySelectorCase_
kotlinx.coroutines.scheduling.WorkQueue: int consumerIndex
org.webrtc.VideoFileRenderer: int outputFrameSize
org.webrtc.GlGenericDrawer: java.lang.String TEXTURE_MATRIX_NAME
com.google.firestore.v1.ExistenceFilter: com.google.firestore.v1.ExistenceFilter DEFAULT_INSTANCE
kotlinx.coroutines.JobSupport: java.lang.Object _parentHandle
io.flutter.view.FlutterCallbackInformation: java.lang.String callbackName
com.google.firestore.v1.Target$QueryTarget: com.google.firestore.v1.Target$QueryTarget DEFAULT_INSTANCE
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_13
org.webrtc.CryptoOptions$Builder: boolean requireFrameEncryption
org.webrtc.voiceengine.WebRtcAudioRecord$AudioRecordStartErrorCode: org.webrtc.voiceengine.WebRtcAudioRecord$AudioRecordStartErrorCode[] $VALUES
com.cloudwebrtc.webrtc.R$id: int tag_screen_reader_focusable
org.webrtc.voiceengine.WebRtcAudioUtils: boolean useWebRtcBasedAcousticEchoCanceler
com.cloudwebrtc.webrtc.record.VideoFileRenderer: android.os.HandlerThread renderThread
org.webrtc.RtpCapabilities: java.util.List headerExtensions
org.webrtc.Logging$TraceLevel: org.webrtc.Logging$TraceLevel TRACE_INFO
org.webrtc.Camera1Session: boolean captureToTexture
org.webrtc.Camera2Session$CameraStateCallback: org.webrtc.Camera2Session this$0
org.webrtc.GlTextureFrameBuffer: int textureId
com.google.rpc.Status: int MESSAGE_FIELD_NUMBER
org.webrtc.VideoCodecInfo: java.lang.String H264_FMTP_LEVEL_ASYMMETRY_ALLOWED
org.webrtc.NativeLibrary: java.lang.String TAG
org.webrtc.NV21Buffer: int height
org.webrtc.WrappedNativeI420Buffer: int strideV
org.webrtc.voiceengine.WebRtcAudioRecord$AudioSamples: int audioFormat
org.webrtc.voiceengine.WebRtcAudioUtils: int DEFAULT_SAMPLE_RATE_HZ
com.google.firebase.firestore.proto.Target: int DOCUMENTS_FIELD_NUMBER
org.webrtc.EglRenderer$EglSurfaceCreation: java.lang.Object surface
org.webrtc.PeerConnection$IceServer: java.lang.String password
kotlinx.coroutines.internal.LockFreeLinkedListNode: java.lang.Object _prev
org.webrtc.PeerConnection$RTCConfiguration: java.lang.Integer iceCheckIntervalWeakConnectivityMs
org.webrtc.VideoEncoder$Settings: int maxFramerate
org.webrtc.audio.WebRtcAudioRecord: org.webrtc.audio.WebRtcAudioEffects effects
com.cloudwebrtc.webrtc.audio.AudioDeviceKind: com.cloudwebrtc.webrtc.audio.AudioDeviceKind WIRED_HEADSET
org.webrtc.CameraEnumerationAndroid$CaptureFormat: int width
com.cloudwebrtc.webrtc.R$id: int rtl
com.cloudwebrtc.webrtc.R$dimen: int compat_button_inset_vertical_material
org.webrtc.RtpTransceiver$RtpTransceiverInit: java.util.List streamIds
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: android.content.Context context
org.webrtc.CameraEnumerationAndroid$1: int MAX_FPS_LOW_DIFF_WEIGHT
org.webrtc.PeerConnection$RTCConfiguration: boolean presumeWritableWhenFullyRelayed
org.webrtc.PeerConnection$RtcpMuxPolicy: org.webrtc.PeerConnection$RtcpMuxPolicy NEGOTIATE
com.google.firestore.v1.StructuredQuery$Order: int direction_
org.webrtc.VideoFrameDrawer$YuvUploader: java.nio.ByteBuffer copyBuffer
androidx.window.java.layout.WindowInfoTrackerCallbackAdapter$addListener$1$1: kotlinx.coroutines.flow.Flow $flow
com.cloudwebrtc.webrtc.GetUserMediaImpl$2: io.flutter.plugin.common.MethodChannel$Result val$result
com.cloudwebrtc.webrtc.R$layout: int notification_template_icon_group
org.webrtc.RtpTransceiver$RtpTransceiverDirection: org.webrtc.RtpTransceiver$RtpTransceiverDirection SEND_RECV
com.google.firestore.v1.DocumentDelete: int DOCUMENT_FIELD_NUMBER
org.webrtc.RtpTransceiver$RtpTransceiverDirection: org.webrtc.RtpTransceiver$RtpTransceiverDirection SEND_ONLY
com.google.firestore.v1.CommitRequest: com.google.protobuf.Parser PARSER
androidx.window.R$id: int rtl
org.webrtc.VideoCodecStatus: org.webrtc.VideoCodecStatus TIMEOUT
com.cloudwebrtc.webrtc.R$color: int notification_action_color_filter
com.google.firebase.firestore.proto.Target: java.lang.Object targetType_
com.google.firebase.firestore.proto.Target: int RESUME_TOKEN_FIELD_NUMBER
org.webrtc.audio.WebRtcAudioTrack: org.webrtc.audio.WebRtcAudioTrack$AudioTrackThread audioThread
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer: com.cloudwebrtc.webrtc.SurfaceTextureRenderer surfaceTextureRenderer
io.flutter.embedding.engine.FlutterJNI: io.flutter.embedding.engine.FlutterJNI$AsyncWaitForVsyncDelegate asyncWaitForVsyncDelegate
org.webrtc.RtpCapabilities$CodecCapability: java.lang.Integer numChannels
org.webrtc.EglBase10Impl: javax.microedition.khronos.egl.EGLConfig eglConfig
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin: com.cloudwebrtc.webrtc.FlutterWebRTCPlugin$LifeCycleObserver observer
com.google.firestore.v1.RunAggregationQueryRequest: int consistencySelectorCase_
org.webrtc.YuvConverter: java.lang.String TAG
org.webrtc.MediaCodecUtils: java.lang.String QCOM_PREFIX
com.google.firestore.v1.CommitRequest: java.lang.String database_
org.webrtc.voiceengine.WebRtcAudioTrack$AudioTrackStartErrorCode: org.webrtc.voiceengine.WebRtcAudioTrack$AudioTrackStartErrorCode AUDIO_TRACK_START_EXCEPTION
org.webrtc.VideoFileRenderer: java.lang.String TAG
org.webrtc.H264Utils: java.lang.String H264_CONSTRAINED_HIGH_3_1
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer$1: int _height
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_14
com.cloudwebrtc.webrtc.R$id: int right_icon
com.cloudwebrtc.webrtc.PeerConnectionObserver: java.util.Map transceivers
org.webrtc.GlGenericDrawer: java.lang.String vertexShader
org.webrtc.VideoEncoder$ScalingSettings: java.lang.Integer low
org.webrtc.EglBase10Impl: javax.microedition.khronos.egl.EGLSurface eglSurface
com.cloudwebrtc.webrtc.record.VideoFileRenderer: int IFRAME_INTERVAL
org.webrtc.EglRenderer: java.lang.Object statisticsLock
com.cloudwebrtc.webrtc.R$styleable: int FontFamilyFont_fontWeight
androidx.window.embedding.SplitInfo: androidx.window.embedding.ActivityStack primaryActivityStack
org.webrtc.CameraEnumerationAndroid: java.util.ArrayList COMMON_RESOLUTIONS
com.google.firestore.v1.TargetChange: int targetChangeType_
com.cloudwebrtc.webrtc.R$styleable: int[] Capability
org.webrtc.Camera1Session: android.os.Handler cameraThreadHandler
org.webrtc.Camera1Session: org.webrtc.Histogram camera1StartTimeMsHistogram
com.google.firestore.v1.StructuredQuery$Filter: java.lang.Object filterType_
com.cloudwebrtc.webrtc.R$dimen: int notification_top_pad_large_text
org.webrtc.HardwareVideoEncoder: java.lang.Integer surfaceColorFormat
androidx.window.layout.WindowInfoTrackerImpl$windowLayoutInfo$1: int label
org.webrtc.Logging$TraceLevel: org.webrtc.Logging$TraceLevel TRACE_TIMER
org.webrtc.Logging$TraceLevel: org.webrtc.Logging$TraceLevel TRACE_DEFAULT
com.cloudwebrtc.webrtc.record.AudioChannel: com.cloudwebrtc.webrtc.record.AudioChannel INPUT
com.cloudwebrtc.webrtc.R$attr: int fontWeight
org.webrtc.Predicate$2: org.webrtc.Predicate val$other
org.webrtc.Camera1Session$2: org.webrtc.Camera1Session this$0
com.cloudwebrtc.webrtc.SurfaceTextureRenderer: android.graphics.SurfaceTexture texture
com.google.firestore.v1.ListenResponse: java.lang.Object responseType_
org.webrtc.Camera2Session: int fpsUnitFactor
com.google.rpc.Status: int code_
androidx.window.core.Version: kotlin.Lazy bigInteger$delegate
org.webrtc.CameraEnumerationAndroid$1: int MIN_FPS_LOW_VALUE_WEIGHT
org.webrtc.Camera2Enumerator: java.lang.String TAG
androidx.window.java.layout.WindowInfoTrackerCallbackAdapter$addListener$1$1: androidx.core.util.Consumer $consumer
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback: io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback$InsetsListener insetsListener
org.webrtc.EglRenderer: org.webrtc.EglRenderer$EglSurfaceCreation eglSurfaceCreationRunnable
androidx.window.layout.SidecarCompat: androidx.window.layout.ExtensionInterfaceCompat$ExtensionCallbackInterface extensionCallback
org.webrtc.voiceengine.WebRtcAudioRecord: int DEFAULT_AUDIO_SOURCE
org.webrtc.NetworkChangeDetector$ConnectionType: org.webrtc.NetworkChangeDetector$ConnectionType CONNECTION_UNKNOWN
org.webrtc.NetworkMonitorAutoDetect: android.content.Context context
org.webrtc.RefCountDelegate: java.util.concurrent.atomic.AtomicInteger refCount
kotlin.jvm.internal.CallableReference: java.lang.Class owner
com.google.android.gms.common.internal.MethodInvocation: android.os.Parcelable$Creator CREATOR
androidx.window.R$attr: int splitRatio
androidx.window.core.Bounds: int bottom
com.cloudwebrtc.webrtc.record.VideoFileRenderer: android.os.Handler renderThreadHandler
org.webrtc.VideoSource: java.lang.Object videoProcessorLock
org.webrtc.NetworkChangeDetector$NetworkInformation: long handle
org.webrtc.PeerConnectionDependencies$Builder: org.webrtc.PeerConnection$Observer observer
org.webrtc.MediaCodecUtils: int COLOR_QCOM_FORMATYVU420PackedSemiPlanar64x32Tile2m8ka
androidx.window.embedding.SplitController: androidx.window.embedding.SplitController$Companion Companion
org.webrtc.VideoCodecMimeType: org.webrtc.VideoCodecMimeType AV1
org.webrtc.PeerConnection$PeerConnectionState: org.webrtc.PeerConnection$PeerConnectionState NEW
org.webrtc.audio.VolumeLogger$LogVolumeTask: int maxVoiceCallVolume
com.cloudwebrtc.webrtc.GetUserMediaImpl: java.lang.String TAG
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor: com.cloudwebrtc.webrtc.StateProvider stateProvider
org.webrtc.YuvConverter: java.lang.String FRAGMENT_SHADER
org.webrtc.audio.WebRtcAudioUtils: java.lang.String TAG
androidx.window.layout.ExtensionsWindowLayoutInfoAdapter: androidx.window.layout.ExtensionsWindowLayoutInfoAdapter INSTANCE
com.google.firestore.v1.RunAggregationQueryRequest: int NEW_TRANSACTION_FIELD_NUMBER
org.webrtc.RtpParameters$DegradationPreference: org.webrtc.RtpParameters$DegradationPreference MAINTAIN_RESOLUTION
com.google.firestore.v1.StructuredAggregationQuery$Aggregation$Avg: com.google.firestore.v1.StructuredAggregationQuery$Aggregation$Avg DEFAULT_INSTANCE
androidx.window.layout.WindowInfoTracker$Companion: androidx.window.layout.WindowInfoTracker$Companion $$INSTANCE
androidx.window.layout.SidecarWindowBackend: androidx.window.layout.ExtensionInterfaceCompat windowExtension
org.webrtc.EncodedImage: int encodedHeight
org.webrtc.FrameCryptor: long observerPtr
org.webrtc.VideoEncoder$Capabilities: boolean lossNotification
androidx.window.layout.FoldingFeature$Orientation: java.lang.String description
com.google.firestore.v1.Target$QueryTarget: com.google.protobuf.Parser PARSER
org.webrtc.EncodedImage$Builder: long captureTimeNs
org.webrtc.Camera1Session: org.webrtc.CameraEnumerationAndroid$CaptureFormat captureFormat
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$4: io.flutter.plugin.common.MethodChannel$Result val$result
com.cloudwebrtc.webrtc.R$layout: int custom_dialog
org.webrtc.ScreenCapturerAndroid: long numCapturedFrames
org.webrtc.MediaStreamTrack$State: org.webrtc.MediaStreamTrack$State ENDED
androidx.window.layout.SidecarWindowBackend: java.util.concurrent.CopyOnWriteArrayList windowLayoutChangeCallbacks
kotlin.jvm.internal.CallableReference: kotlin.reflect.KCallable reflected
org.webrtc.voiceengine.WebRtcAudioTrack: java.nio.ByteBuffer byteBuffer
org.webrtc.HardwareVideoEncoder: org.webrtc.VideoCodecMimeType codecType
com.cloudwebrtc.webrtc.record.VideoFileRenderer: boolean isRunning
org.webrtc.EglBase: int[] CONFIG_RGBA
com.google.protobuf.Timestamp: int NANOS_FIELD_NUMBER
org.webrtc.audio.WebRtcAudioRecord: android.media.AudioRecord audioRecord
androidx.window.core.Version: int major
io.flutter.embedding.engine.FlutterJNI: java.util.concurrent.locks.ReentrantReadWriteLock shellHolderLock
org.webrtc.PeerConnection$KeyType: org.webrtc.PeerConnection$KeyType RSA
org.webrtc.voiceengine.WebRtcAudioManager: boolean lowLatencyInput
org.webrtc.Camera2Session: boolean isCameraFrontFacing
com.google.firestore.v1.Write: int DELETE_FIELD_NUMBER
org.webrtc.Metrics$HistogramInfo: java.util.Map samples
org.webrtc.audio.WebRtcAudioEffects: java.util.UUID AOSP_ACOUSTIC_ECHO_CANCELER
com.google.firestore.v1.TransactionOptions: int READ_ONLY_FIELD_NUMBER
org.webrtc.PeerConnection$RTCConfiguration: boolean disableIPv6OnWifi
org.webrtc.Logging$TraceLevel: org.webrtc.Logging$TraceLevel TRACE_DEBUG
org.webrtc.VideoCodecStatus: org.webrtc.VideoCodecStatus LEVEL_EXCEEDED
androidx.window.embedding.EmbeddingCompat: androidx.window.extensions.embedding.ActivityEmbeddingComponent embeddingExtension
org.webrtc.GlGenericDrawer: java.lang.String genericFragmentSource
org.webrtc.CameraCapturer: android.os.Handler uiThreadHandler
org.webrtc.MediaConstraints$KeyValuePair: java.lang.String key
org.webrtc.voiceengine.WebRtcAudioTrack$AudioTrackStartErrorCode: org.webrtc.voiceengine.WebRtcAudioTrack$AudioTrackStartErrorCode AUDIO_TRACK_START_STATE_MISMATCH
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_1
org.webrtc.PeerConnection$RTCConfiguration: java.lang.Boolean combinedAudioVideoBwe
org.webrtc.RtpParameters$Encoding: boolean active
com.cloudwebrtc.webrtc.R$id: int normal
com.google.protobuf.Any: int TYPE_URL_FIELD_NUMBER
org.webrtc.MediaStreamTrack$MediaType: org.webrtc.MediaStreamTrack$MediaType[] $VALUES
org.webrtc.FrameCryptorKeyProvider: long nativeKeyProvider
io.flutter.embedding.engine.renderer.SurfaceTextureWrapper: java.lang.Runnable onFrameConsumed
org.webrtc.EncodedImage: long captureTimeMs
com.google.firebase.firestore.proto.WriteBatch: int LOCAL_WRITE_TIME_FIELD_NUMBER
org.webrtc.NetworkMonitorAutoDetect$ConnectivityManagerDelegate: boolean requestVPN
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$6: int[] $SwitchMap$com$cloudwebrtc$webrtc$utils$ObjectType
com.google.firestore.v1.StructuredQuery$Order: com.google.firestore.v1.StructuredQuery$FieldReference field_
org.webrtc.voiceengine.WebRtcAudioUtils: java.lang.String[] BLACKLISTED_NS_MODELS
org.webrtc.VideoFrameBufferType: int I444
org.webrtc.PeerConnection$IceServer$Builder: org.webrtc.PeerConnection$TlsCertPolicy tlsCertPolicy
org.webrtc.Camera2Session: org.webrtc.CameraEnumerationAndroid$CaptureFormat captureFormat
com.google.type.LatLng: int LONGITUDE_FIELD_NUMBER
com.google.firestore.v1.TargetChange: int READ_TIME_FIELD_NUMBER
com.google.firebase.firestore.proto.MaybeDocument: int documentTypeCase_
com.google.firestore.v1.StructuredQuery$Projection: com.google.protobuf.Internal$ProtobufList fields_
com.google.firebase.firestore.proto.MaybeDocument: int HAS_COMMITTED_MUTATIONS_FIELD_NUMBER
androidx.window.layout.SidecarCompat$DistinctElementCallback: java.util.WeakHashMap activityWindowLayoutInfo
org.webrtc.NetworkChangeDetector$ConnectionType: org.webrtc.NetworkChangeDetector$ConnectionType CONNECTION_ETHERNET
com.cloudwebrtc.webrtc.audio.AudioSwitchManager: boolean loggingEnabled
org.webrtc.voiceengine.WebRtcAudioManager: android.media.AudioManager audioManager
androidx.window.layout.WindowInfoTrackerImpl$windowLayoutInfo$1: androidx.window.layout.WindowInfoTrackerImpl this$0
com.google.firestore.v1.StructuredQuery$FieldFilter: com.google.firestore.v1.StructuredQuery$FieldReference field_
com.google.firestore.v1.StructuredAggregationQuery$Aggregation$Sum: com.google.firestore.v1.StructuredAggregationQuery$Aggregation$Sum DEFAULT_INSTANCE
com.google.firestore.v1.ListenRequest: int DATABASE_FIELD_NUMBER
androidx.window.layout.HardwareFoldingFeature$Type: androidx.window.layout.HardwareFoldingFeature$Type HINGE
com.google.firebase.Timestamp: android.os.Parcelable$Creator CREATOR
androidx.window.layout.FoldingFeature$OcclusionType: androidx.window.layout.FoldingFeature$OcclusionType NONE
org.webrtc.PeerConnection$AdapterType: org.webrtc.PeerConnection$AdapterType CELLULAR
com.google.firestore.v1.StructuredQuery$UnaryFilter: int op_
org.webrtc.SurfaceViewRenderer: int surfaceHeight
com.cloudwebrtc.webrtc.audio.AudioDeviceKind: com.cloudwebrtc.webrtc.audio.AudioDeviceKind[] $VALUES
org.webrtc.Camera1Enumerator: java.util.List cachedSupportedFormats
com.google.firestore.v1.TransactionOptions: com.google.firestore.v1.TransactionOptions DEFAULT_INSTANCE
org.webrtc.voiceengine.WebRtcAudioManager$VolumeLogger: java.util.Timer timer
com.google.firestore.v1.StructuredQuery$CompositeFilter: int op_
org.webrtc.PeerConnection$AdapterType: org.webrtc.PeerConnection$AdapterType CELLULAR_2G
org.webrtc.DataChannel$Buffer: java.nio.ByteBuffer data
org.webrtc.PeerConnection$ContinualGatheringPolicy: org.webrtc.PeerConnection$ContinualGatheringPolicy GATHER_CONTINUALLY
org.webrtc.RtpTransceiver: long nativeRtpTransceiver
org.webrtc.HardwareVideoEncoderFactory: int QCOM_VP8_KEY_FRAME_INTERVAL_ANDROID_N_MS
kotlinx.coroutines.CancellableContinuationImpl: int _decision
com.google.firestore.v1.DocumentChange: int targetIdsMemoizedSerializedSize
io.flutter.view.FlutterCallbackInformation: java.lang.String callbackClassName
org.webrtc.RtcCertificatePem: long DEFAULT_EXPIRY
org.webrtc.BaseBitrateAdjuster: double targetFramerateFps
org.webrtc.SurfaceTextureHelper: java.lang.Runnable setListenerRunnable
com.google.firestore.v1.StructuredAggregationQuery$Aggregation$Avg: com.google.protobuf.Parser PARSER
org.webrtc.PeerConnection$SignalingState: org.webrtc.PeerConnection$SignalingState HAVE_LOCAL_PRANSWER
androidx.window.embedding.EmbeddingTranslatingCallback: androidx.window.embedding.EmbeddingInterfaceCompat$EmbeddingCallbackInterface callback
org.webrtc.PeerConnection$IceTransportsType: org.webrtc.PeerConnection$IceTransportsType ALL
org.webrtc.YuvConverter: org.webrtc.VideoFrameDrawer videoFrameDrawer
androidx.window.embedding.ExtensionEmbeddingBackend$SplitListenerWrapper: java.util.List lastValue
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin: io.flutter.plugin.common.EventChannel$EventSink eventSink
org.webrtc.HardwareVideoEncoder: int keyFrameIntervalSec
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor$FrameCryptorStateObserver$1: com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor$FrameCryptorStateObserver this$1
io.flutter.embedding.engine.renderer.SurfaceTextureWrapper: android.graphics.SurfaceTexture surfaceTexture
org.webrtc.audio.WebRtcAudioTrack: boolean speakerMute
org.webrtc.RTCStats: long timestampUs
com.cloudwebrtc.webrtc.GetUserMediaImpl: com.cloudwebrtc.webrtc.record.OutputAudioSamplesInterceptor outputSamplesInterceptor
com.google.firestore.v1.ListenRequest: java.lang.String database_
org.webrtc.Logging$TraceLevel: org.webrtc.Logging$TraceLevel TRACE_STREAM
androidx.window.layout.ExtensionWindowLayoutInfoBackend$MulticastConsumer: java.util.Set registeredListeners
com.cloudwebrtc.webrtc.R$id: int ltr
org.webrtc.NetworkChangeDetector$ConnectionType: org.webrtc.NetworkChangeDetector$ConnectionType CONNECTION_UNKNOWN_CELLULAR
com.cloudwebrtc.webrtc.R$attr: int clearTop
com.cloudwebrtc.webrtc.OrientationAwareScreenCapturer: int height
io.flutter.plugin.platform.SingleViewPresentation: io.flutter.plugin.platform.AccessibilityEventsDelegate accessibilityEventsDelegate
org.webrtc.YuvConverter: org.webrtc.YuvConverter$ShaderCallbacks shaderCallbacks
org.webrtc.IceCandidateErrorEvent: java.lang.String url
com.cloudwebrtc.webrtc.audio.AudioSwitchManager: android.media.AudioManager audioManager
com.google.firestore.v1.TransactionOptions: java.lang.Object mode_
org.webrtc.voiceengine.WebRtcAudioRecord: org.webrtc.voiceengine.WebRtcAudioRecord$AudioRecordThread audioThread
com.google.firestore.v1.Write: com.google.firestore.v1.Write DEFAULT_INSTANCE
com.cloudwebrtc.webrtc.record.MediaRecorderImpl: com.cloudwebrtc.webrtc.record.AudioSamplesInterceptor audioInterceptor
org.webrtc.YuvConverter: org.webrtc.ThreadUtils$ThreadChecker threadChecker
org.webrtc.EglRenderer: boolean mirrorHorizontally
com.cloudwebrtc.webrtc.record.MediaRecorderImpl: java.lang.Integer id
com.google.protobuf.Timestamp: int SECONDS_FIELD_NUMBER
com.cloudwebrtc.webrtc.audio.AudioSwitchManager: android.content.Context context
com.google.firestore.v1.Target: java.lang.Object targetType_
org.webrtc.voiceengine.WebRtcAudioManager: int inputChannels
org.webrtc.EglBase: int EGL_OPENGL_ES3_BIT
org.webrtc.ThreadUtils$3: org.webrtc.ThreadUtils$1Result val$result
androidx.window.layout.HardwareFoldingFeature: androidx.window.core.Bounds featureBounds
com.google.firestore.v1.Value: java.lang.Object valueType_
org.webrtc.Camera1Session: android.content.Context applicationContext
com.google.firestore.v1.Value: com.google.protobuf.Parser PARSER
org.webrtc.audio.WebRtcAudioRecord: int audioSource
com.google.protobuf.GeneratedMessageLite$ExtendableMessage: com.google.protobuf.FieldSet extensions
org.webrtc.GlRectDrawer: java.lang.String FRAGMENT_SHADER
com.cloudwebrtc.webrtc.SurfaceTextureRenderer: int frameRotation
org.webrtc.VideoFrame: org.webrtc.VideoFrame$Buffer buffer
org.webrtc.EglRenderer$HandlerWithExceptionCallback: java.lang.Runnable exceptionCallback
com.cloudwebrtc.webrtc.R$layout: int notification_template_part_chronometer
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$FallbackFactory: org.webrtc.VideoEncoderFactory softwareVideoEncoderFactory
com.cloudwebrtc.webrtc.record.AudioSamplesInterceptor: java.util.HashMap callbacks
com.google.firestore.v1.Precondition: int UPDATE_TIME_FIELD_NUMBER
org.webrtc.HardwareVideoEncoder: java.nio.ByteBuffer configBuffer
org.webrtc.TextureBufferImpl: int unscaledWidth
org.webrtc.audio.WebRtcAudioRecord: byte[] emptyBytes
org.webrtc.DynamicBitrateAdjuster: double BITS_PER_BYTE
org.webrtc.Logging$Severity: org.webrtc.Logging$Severity LS_WARNING
org.webrtc.CameraCapturer$5: org.webrtc.CameraCapturer this$0
org.webrtc.EglRenderer$FrameListenerAndParams: boolean applyFpsReduction
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback: io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback$AnimationCallback animationCallback
androidx.window.layout.WindowMetricsCalculator$Companion$reset$1: androidx.window.layout.WindowMetricsCalculator$Companion$reset$1 INSTANCE
com.cloudwebrtc.webrtc.R$drawable: int notification_bg_low_normal
androidx.window.embedding.EmbeddingCompat: androidx.window.embedding.EmbeddingAdapter adapter
org.webrtc.RtpCapabilities$HeaderExtensionCapability: boolean preferredEncrypted
org.webrtc.SurfaceTextureHelper: org.webrtc.EglBase eglBase
org.webrtc.GlGenericDrawer: java.lang.String DEFAULT_VERTEX_SHADER_STRING
org.webrtc.RtpParameters$Codec: org.webrtc.MediaStreamTrack$MediaType kind
org.webrtc.audio.JavaAudioDeviceModule: long nativeAudioDeviceModule
com.google.firestore.v1.DocumentTransform$FieldTransform: int transformTypeCase_
com.google.firestore.v1.DocumentDelete: com.google.firestore.v1.DocumentDelete DEFAULT_INSTANCE
com.google.firestore.admin.v1.Index: int queryScope_
com.cloudwebrtc.webrtc.R$id: int info
com.google.firestore.v1.TargetChange: com.google.firestore.v1.TargetChange DEFAULT_INSTANCE
org.webrtc.FrameCryptor$FrameCryptionState: org.webrtc.FrameCryptor$FrameCryptionState MISSINGKEY
org.webrtc.audio.WebRtcAudioManager: int BITS_PER_SAMPLE
org.webrtc.AndroidVideoDecoder$FrameInfo: long decodeStartTimeMs
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: io.flutter.view.TextureRegistry textures
com.cloudwebrtc.webrtc.R$id: int action_text
com.cloudwebrtc.webrtc.R$id: int blocking
org.webrtc.MediaSource$State: org.webrtc.MediaSource$State MUTED
org.webrtc.voiceengine.WebRtcAudioTrack$AudioTrackThread: org.webrtc.voiceengine.WebRtcAudioTrack this$0
org.webrtc.NetworkMonitorAutoDetect: java.lang.String TAG
org.webrtc.audio.JavaAudioDeviceModule$Builder: org.webrtc.audio.JavaAudioDeviceModule$AudioTrackStateCallback audioTrackStateCallback
androidx.window.R$styleable: int SplitPlaceholderRule_splitMinSmallestWidth
org.webrtc.RtpTransceiver$RtpTransceiverDirection: org.webrtc.RtpTransceiver$RtpTransceiverDirection RECV_ONLY
org.webrtc.IceCandidate: java.lang.String sdpMid
com.cloudwebrtc.webrtc.R$attr: int fontProviderAuthority
org.webrtc.PeerConnection$ContinualGatheringPolicy: org.webrtc.PeerConnection$ContinualGatheringPolicy[] $VALUES
org.webrtc.VideoCodecStatus: org.webrtc.VideoCodecStatus FALLBACK_SOFTWARE
org.webrtc.voiceengine.WebRtcAudioTrack: byte[] emptyBytes
org.webrtc.audio.LowLatencyAudioBufferManager: int bufferIncreaseCounter
org.webrtc.StatsReport: java.lang.String id
org.webrtc.RtpParameters$Encoding: java.lang.Long ssrc
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback: android.view.View view
com.google.firebase.firestore.proto.MaybeDocument: java.lang.Object documentType_
io.grpc.internal.SerializingExecutor: int runState
com.cloudwebrtc.webrtc.R$styleable: int GradientColor_android_endX
org.webrtc.RendererCommon$ScalingType: org.webrtc.RendererCommon$ScalingType SCALE_ASPECT_FIT
org.webrtc.VideoSource$AspectRatio: int width
io.flutter.plugins.GeneratedPluginRegistrant: java.lang.String TAG
org.webrtc.EglBase$ConfigBuilder: boolean hasAlphaChannel
androidx.window.R$styleable: int[] ActivityFilter
com.google.firestore.admin.v1.Index: int QUERY_SCOPE_FIELD_NUMBER
com.google.firebase.firestore.proto.Target: com.google.protobuf.Parser PARSER
org.webrtc.EglRenderer: java.lang.Object fpsReductionLock
io.flutter.embedding.engine.FlutterJNI: java.lang.Long nativeShellHolderId
org.webrtc.PeerConnection$RTCConfiguration: org.webrtc.PeerConnection$KeyType keyType
com.cloudwebrtc.webrtc.R$style: int TextAppearance_Compat_Notification_Title
androidx.window.layout.DisplayCompatHelperApi28: androidx.window.layout.DisplayCompatHelperApi28 INSTANCE
com.cloudwebrtc.webrtc.R$dimen: int compat_notification_large_icon_max_height
org.webrtc.Camera2Session: int framerate
org.webrtc.RtpParameters$Encoding: java.lang.Integer numTemporalLayers
com.google.firestore.v1.StructuredQuery$Projection: com.google.firestore.v1.StructuredQuery$Projection DEFAULT_INSTANCE
com.google.firestore.v1.Write: int CURRENT_DOCUMENT_FIELD_NUMBER
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_9
org.webrtc.RtpTransceiver: org.webrtc.RtpReceiver cachedReceiver
org.webrtc.voiceengine.WebRtcAudioTrack: org.webrtc.voiceengine.WebRtcAudioTrack$AudioTrackThread audioThread
org.webrtc.SurfaceViewRenderer: boolean enableFixedSize
com.cloudwebrtc.webrtc.R$attr: int queryPatterns
org.webrtc.EncodedImage: java.lang.Integer qp
com.google.firestore.v1.TransactionOptions$ReadWrite: com.google.protobuf.ByteString retryTransaction_
org.webrtc.audio.LowLatencyAudioBufferManager: int ticksUntilNextDecrease
androidx.window.layout.WindowMetrics: androidx.window.core.Bounds _bounds
com.cloudwebrtc.webrtc.R$styleable: int[] SplitPlaceholderRule
com.cloudwebrtc.webrtc.PeerConnectionObserver: java.util.Map remoteStreams
org.webrtc.PeerConnectionDependencies: org.webrtc.PeerConnection$Observer observer
com.cloudwebrtc.webrtc.R$drawable: int notification_tile_bg
com.google.firestore.v1.DocumentMask: int FIELD_PATHS_FIELD_NUMBER
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: io.flutter.plugin.common.BinaryMessenger messenger
com.cloudwebrtc.webrtc.audio.AudioSwitchManager: boolean _speakerphoneOn
com.google.firestore.admin.v1.Index$IndexField: int FIELD_PATH_FIELD_NUMBER
com.cloudwebrtc.webrtc.R$styleable: int FontFamilyFont_android_fontWeight
com.google.firestore.v1.DocumentTransform$FieldTransform: int FIELD_PATH_FIELD_NUMBER
com.cloudwebrtc.webrtc.audio.AudioSwitchManager: boolean isActive
com.cloudwebrtc.webrtc.utils.ObjectType: com.cloudwebrtc.webrtc.utils.ObjectType Boolean
org.webrtc.EglRenderer: float layoutAspectRatio
androidx.window.embedding.ExtensionEmbeddingBackend: androidx.window.embedding.ExtensionEmbeddingBackend$EmbeddingCallbackImpl splitInfoEmbeddingCallback
org.webrtc.VideoSource$AspectRatio: org.webrtc.VideoSource$AspectRatio UNDEFINED
com.google.firestore.v1.StructuredQuery: int LIMIT_FIELD_NUMBER
com.cloudwebrtc.webrtc.SurfaceTextureRenderer: int rotatedFrameHeight
org.webrtc.audio.JavaAudioDeviceModule$Builder: java.util.concurrent.ScheduledExecutorService scheduler
com.google.firebase.firestore.proto.NoDocument: com.google.firebase.firestore.proto.NoDocument DEFAULT_INSTANCE
org.webrtc.CameraEnumerationAndroid$CaptureFormat: int imageFormat
org.webrtc.CameraVideoCapturer$CameraStatistics: int CAMERA_OBSERVER_PERIOD_MS
com.google.firestore.v1.StructuredQuery: int START_AT_FIELD_NUMBER
com.google.firestore.v1.DocumentChange: int TARGET_IDS_FIELD_NUMBER
com.google.protobuf.GeneratedMessageLite: int memoizedSerializedSize
org.webrtc.PeerConnection$RTCConfiguration: boolean activeResetSrtpParams
org.webrtc.VideoEncoder$ResolutionBitrateLimits: int frameSizePixels
org.webrtc.EglBase14Impl: java.lang.String TAG
org.webrtc.audio.JavaAudioDeviceModule$Builder: boolean enableVolumeLogger
com.google.android.gms.auth.api.signin.GoogleSignInAccount: android.os.Parcelable$Creator CREATOR
org.webrtc.Camera1Capturer: boolean captureToTexture
org.webrtc.MediaCodecWrapperFactoryImpl$MediaCodecWrapperImpl: android.media.MediaCodec mediaCodec
org.webrtc.SurfaceEglRenderer: int rotatedFrameHeight
kotlinx.coroutines.internal.LockFreeLinkedListNode: java.lang.Object _next
com.cloudwebrtc.webrtc.R$dimen: int notification_small_icon_size_as_large
com.google.firestore.v1.CommitRequest: com.google.protobuf.ByteString transaction_
com.google.firebase.firestore.proto.NoDocument: int READ_TIME_FIELD_NUMBER
com.google.firestore.v1.CommitResponse: com.google.protobuf.Parser PARSER
kotlinx.coroutines.scheduling.CoroutineScheduler: long parkedWorkersStack
org.webrtc.PeerConnectionFactory$InitializationOptions: boolean enableInternalTracer
org.webrtc.AndroidVideoDecoder$DecodedTextureMetadata: long presentationTimestampUs
org.webrtc.RtpSender: org.webrtc.DtmfSender dtmfSender
org.webrtc.PeerConnection$IceConnectionState: org.webrtc.PeerConnection$IceConnectionState NEW
com.google.protobuf.Int64Value: long value_
com.cloudwebrtc.webrtc.R$styleable: int FontFamily_fontProviderQuery
org.webrtc.PeerConnection$PortPrunePolicy: org.webrtc.PeerConnection$PortPrunePolicy[] $VALUES
org.webrtc.PeerConnectionFactory$Builder: org.webrtc.AudioEncoderFactoryFactory audioEncoderFactoryFactory
com.google.firestore.v1.ListenRequest: java.lang.Object targetChange_
org.webrtc.CameraCapturer: org.webrtc.CameraSession$CreateSessionCallback createSessionCallback
com.google.firestore.v1.TargetChange: com.google.protobuf.Internal$IntList targetIds_
org.webrtc.DynamicBitrateAdjuster: double BITRATE_ADJUSTMENT_MAX_SCALE
com.google.firestore.v1.Write: int UPDATE_MASK_FIELD_NUMBER
org.webrtc.ThreadUtils$1: java.lang.Thread val$thread
com.cloudwebrtc.webrtc.GetUserMediaImpl$NoSuchFieldWithNameException: java.lang.String fieldName
org.webrtc.SurfaceTextureHelper: android.os.Handler handler
org.webrtc.PeerConnection$RTCConfiguration: org.webrtc.PeerConnection$AdapterType networkPreference
org.webrtc.CameraCapturer: int openAttemptsRemaining
com.google.firestore.v1.ListenResponse: int TARGET_CHANGE_FIELD_NUMBER
androidx.window.layout.SidecarCompat$DistinctSidecarElementCallback: androidx.window.sidecar.SidecarDeviceState lastDeviceState
com.google.firestore.bundle.BundledQuery: int PARENT_FIELD_NUMBER
com.google.firestore.v1.StructuredAggregationQuery$Aggregation: java.lang.Object operator_
org.webrtc.SessionDescription$Type: org.webrtc.SessionDescription$Type ANSWER
org.webrtc.Camera2Session: int cameraOrientation
androidx.window.layout.WindowLayoutInfo: java.util.List displayFeatures
org.webrtc.CameraCapturer$8: org.webrtc.CameraVideoCapturer$CameraSwitchHandler val$switchEventsHandler
com.google.firestore.v1.TransactionOptions: com.google.protobuf.Parser PARSER
com.cloudwebrtc.webrtc.R$styleable: int FontFamily_fontProviderCerts
org.webrtc.voiceengine.WebRtcAudioRecord$AudioRecordThread: boolean keepAlive
org.webrtc.audio.VolumeLogger: int TIMER_PERIOD_IN_SECONDS
org.webrtc.EglBase10Impl: java.lang.String TAG
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin: android.app.Application application
androidx.window.core.Version: int minor
org.webrtc.ThreadUtils$1CaughtException: java.lang.Exception e
org.webrtc.PeerConnectionFactory$InitializationOptions: org.webrtc.NativeLibraryLoader nativeLibraryLoader
org.webrtc.HardwareVideoEncoderFactory: java.lang.String TAG
org.webrtc.voiceengine.WebRtcAudioEffects: boolean shouldEnableNs
com.google.firestore.v1.DocumentRemove: java.lang.String document_
com.cloudwebrtc.webrtc.record.VideoFileRenderer: org.webrtc.VideoFrameDrawer frameDrawer
org.webrtc.Predicate$1: org.webrtc.Predicate this$0
com.google.firestore.v1.CommitResponse: com.google.protobuf.Timestamp commitTime_
com.cloudwebrtc.webrtc.R$attr: int fontVariationSettings
com.cloudwebrtc.webrtc.record.VideoFileRenderer: long videoFrameStart
io.flutter.view.AccessibilityViewEmbedder: io.flutter.view.AccessibilityViewEmbedder$ReflectionAccessors reflectionAccessors
com.cloudwebrtc.webrtc.R$styleable: int SplitPlaceholderRule_splitRatio
com.google.firestore.admin.v1.Index$IndexField: com.google.protobuf.Parser PARSER
org.webrtc.Camera2Session: org.webrtc.Histogram camera2ResolutionHistogram
com.google.firebase.firestore.proto.Target: com.google.protobuf.Timestamp snapshotVersion_
androidx.window.R$styleable: int[] SplitPlaceholderRule
org.webrtc.VideoEncoder$ScalingSettings: java.lang.Integer high
org.webrtc.PeerConnection$AdapterType: org.webrtc.PeerConnection$AdapterType ETHERNET
com.cloudwebrtc.webrtc.GetUserMediaImpl$1: com.cloudwebrtc.webrtc.GetUserMediaImpl this$0
com.google.firestore.v1.WriteRequest: com.google.protobuf.ByteString streamToken_
com.google.protobuf.Int32Value: com.google.protobuf.Parser PARSER
org.webrtc.voiceengine.WebRtcAudioRecord$AudioSamples: int channelCount
com.cloudwebrtc.webrtc.R$styleable: int SplitPlaceholderRule_splitLayoutDirection
com.google.firestore.v1.TargetChange: com.google.rpc.Status cause_
org.webrtc.PeerConnection$RTCConfiguration: boolean enableDscp
org.webrtc.YuvConverter$ShaderCallbacks: int xUnitLoc
com.google.firestore.admin.v1.Index$IndexField: int valueModeCase_
androidx.window.core.Version: androidx.window.core.Version CURRENT
org.webrtc.PeerConnection$KeyType: org.webrtc.PeerConnection$KeyType ECDSA
org.webrtc.Logging$TraceLevel: org.webrtc.Logging$TraceLevel TRACE_ERROR
org.webrtc.RendererCommon$ScalingType: org.webrtc.RendererCommon$ScalingType SCALE_ASPECT_FILL
org.webrtc.SoftwareVideoDecoderFactory$1: long val$nativeDecoder
org.webrtc.JavaI420Buffer: int width
org.webrtc.HardwareVideoEncoder: org.webrtc.ThreadUtils$ThreadChecker outputThreadChecker
com.google.firestore.v1.StructuredQuery$CollectionSelector: com.google.firestore.v1.StructuredQuery$CollectionSelector DEFAULT_INSTANCE
org.webrtc.VideoSource: boolean isCapturerRunning
com.cloudwebrtc.webrtc.R$id: int tag_accessibility_clickable_spans
androidx.window.embedding.MatcherUtils: androidx.window.embedding.MatcherUtils INSTANCE
org.webrtc.PeerConnectionFactory: long nativeFactory
org.webrtc.EglRenderer: long nextFrameTimeNs
org.webrtc.SessionDescription$Type: org.webrtc.SessionDescription$Type PRANSWER
org.webrtc.JavaI420Buffer: java.nio.ByteBuffer dataU
com.google.protobuf.Int64Value: int VALUE_FIELD_NUMBER
org.webrtc.PeerConnectionFactory: java.lang.String TRIAL_ENABLED
com.cloudwebrtc.webrtc.GetUserMediaImpl: com.cloudwebrtc.webrtc.record.AudioSamplesInterceptor inputSamplesInterceptor
com.google.firestore.v1.CommitRequest: int DATABASE_FIELD_NUMBER
org.webrtc.PeerConnection$RTCConfiguration: org.webrtc.PeerConnection$BundlePolicy bundlePolicy
com.google.firestore.v1.TargetChange: int TARGET_IDS_FIELD_NUMBER
org.webrtc.CryptoOptions: org.webrtc.CryptoOptions$SFrame sframe
org.webrtc.NetworkChangeDetector$ConnectionType: org.webrtc.NetworkChangeDetector$ConnectionType CONNECTION_NONE
org.webrtc.VideoCodecInfo: java.lang.String H264_CONSTRAINED_HIGH_3_1
org.webrtc.audio.JavaAudioDeviceModule: int outputSampleRate
org.webrtc.VideoProcessor$FrameAdaptationParameters: int cropX
com.google.firestore.v1.TransactionOptions$ReadOnly: com.google.protobuf.Parser PARSER
org.webrtc.GlGenericDrawer: org.webrtc.GlGenericDrawer$ShaderType currentShaderType
com.cloudwebrtc.webrtc.R$id: int forever
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: org.webrtc.PeerConnectionFactory mFactory
com.cloudwebrtc.webrtc.utils.ObjectType: com.cloudwebrtc.webrtc.utils.ObjectType Array
org.webrtc.NetworkMonitor$InstanceHolder: org.webrtc.NetworkMonitor instance
com.google.firestore.v1.ListenRequest: int targetChangeCase_
org.webrtc.SimulcastVideoEncoder: org.webrtc.VideoEncoderFactory fallback
androidx.window.layout.SidecarWindowBackend: java.util.concurrent.locks.ReentrantLock globalLock
com.google.firestore.v1.WriteRequest: int DATABASE_FIELD_NUMBER
com.google.protobuf.GeneratedMessageLite: int MUTABLE_FLAG_MASK
com.google.firebase.firestore.proto.NoDocument: int NAME_FIELD_NUMBER
com.cloudwebrtc.webrtc.record.VideoFileRenderer: android.media.MediaCodec encoder
org.webrtc.RtpCapabilities$CodecCapability: java.util.Map parameters
org.webrtc.MediaStreamTrack: java.lang.String AUDIO_TRACK_KIND
org.webrtc.audio.WebRtcAudioTrack: byte[] emptyBytes
org.webrtc.NetworkChangeDetector$NetworkInformation: org.webrtc.NetworkChangeDetector$ConnectionType underlyingTypeForVpn
org.webrtc.audio.WebRtcAudioEffects: android.media.audiofx.AcousticEchoCanceler aec
androidx.lifecycle.Lifecycle$Event: androidx.lifecycle.Lifecycle$Event ON_ANY
com.cloudwebrtc.webrtc.R$id: int italic
com.google.firestore.v1.BatchGetDocumentsRequest: int READ_TIME_FIELD_NUMBER
io.flutter.plugin.platform.SingleViewPresentation: android.widget.FrameLayout container
org.webrtc.CameraCapturer$SwitchState: org.webrtc.CameraCapturer$SwitchState[] $VALUES
com.cloudwebrtc.webrtc.audio.AudioDeviceKind: com.cloudwebrtc.webrtc.audio.AudioDeviceKind SPEAKER
org.webrtc.GlGenericDrawer: int texMatrixLocation
com.google.firestore.v1.TransactionOptions$ReadOnly: java.lang.Object consistencySelector_
org.webrtc.MediaStreamTrack: java.lang.String VIDEO_TRACK_KIND
com.google.firestore.v1.StructuredQuery$CompositeFilter: int FILTERS_FIELD_NUMBER
org.webrtc.EglBase: int[] CONFIG_PIXEL_BUFFER
org.webrtc.ThreadUtils$3: java.util.concurrent.CountDownLatch val$barrier
org.webrtc.WrappedNativeI420Buffer: java.nio.ByteBuffer dataY
org.webrtc.GlGenericDrawer: int inTcLocation
com.google.firestore.v1.DocumentDelete: com.google.protobuf.Timestamp readTime_
org.webrtc.VideoCodecStatus: org.webrtc.VideoCodecStatus MEMORY
org.webrtc.audio.JavaAudioDeviceModule$Builder: android.media.AudioManager audioManager
org.webrtc.Camera2Session: android.view.Surface surface
androidx.window.layout.ExtensionWindowLayoutInfoBackend$MulticastConsumer: android.app.Activity activity
org.webrtc.FrameCryptor$FrameCryptionState: org.webrtc.FrameCryptor$FrameCryptionState OK
com.cloudwebrtc.webrtc.R$styleable: int FontFamily_fontProviderFetchStrategy
com.cloudwebrtc.webrtc.R$attr: int activityName
org.webrtc.EglRenderer: java.lang.String TAG
com.cloudwebrtc.webrtc.PeerConnectionObserver: io.flutter.plugin.common.EventChannel$EventSink eventSink
com.google.firestore.v1.StructuredAggregationQuery: com.google.protobuf.Internal$ProtobufList aggregations_
com.cloudwebrtc.webrtc.R$dimen: int compat_button_padding_vertical_material
org.webrtc.PeerConnection$RTCConfiguration: boolean enableImplicitRollback
org.webrtc.voiceengine.WebRtcAudioTrack: long nativeAudioTrack
com.cloudwebrtc.webrtc.GetUserMediaImpl: int DEFAULT_FPS
com.cloudwebrtc.webrtc.R$dimen: int notification_big_circle_margin
org.webrtc.Camera1Session$SessionState: org.webrtc.Camera1Session$SessionState STOPPED
org.webrtc.JavaI420Buffer: int strideV
com.cloudwebrtc.webrtc.R$styleable: int[] FontFamily
org.webrtc.IceCandidateErrorEvent: java.lang.String errorText
org.webrtc.EglRenderer$2: org.webrtc.EglRenderer this$0
org.webrtc.RtpParameters$Codec: int payloadType
org.webrtc.PeerConnection$TlsCertPolicy: org.webrtc.PeerConnection$TlsCertPolicy TLS_CERT_POLICY_INSECURE_NO_CHECK
org.webrtc.VideoFileRenderer: int frameCount
org.webrtc.PeerConnection$RTCConfiguration: boolean audioJitterBufferFastAccelerate
com.google.protobuf.Int64Value: com.google.protobuf.Parser PARSER
com.google.firestore.v1.RunAggregationQueryResponse: int RESULT_FIELD_NUMBER
org.webrtc.audio.JavaAudioDeviceModule$AudioSamples: byte[] data
org.webrtc.MediaSource: org.webrtc.RefCountDelegate refCountDelegate
com.google.firestore.v1.TargetChange: com.google.protobuf.Timestamp readTime_
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: com.cloudwebrtc.webrtc.GetUserMediaImpl getUserMediaImpl
org.webrtc.CameraCapturer: int height
com.cloudwebrtc.webrtc.R$attr: int fontProviderFetchTimeout
com.cloudwebrtc.webrtc.utils.MediaConstraintsUtils: java.lang.String TAG
org.webrtc.MediaCodecUtils: int[] ENCODER_COLOR_FORMATS
org.webrtc.ScreenCapturerAndroid: int DISPLAY_FLAGS
org.webrtc.CameraSession$FailureType: org.webrtc.CameraSession$FailureType DISCONNECTED
com.google.firestore.v1.Value: int INTEGER_VALUE_FIELD_NUMBER
com.google.firebase.firestore.proto.Target: com.google.protobuf.Timestamp lastLimboFreeSnapshotVersion_
com.google.protobuf.Int64Value: com.google.protobuf.Int64Value DEFAULT_INSTANCE
com.cloudwebrtc.webrtc.R$id: int notification_background
org.webrtc.CameraVideoCapturer$CameraStatistics: java.lang.String TAG
androidx.window.embedding.ExtensionEmbeddingBackend: java.lang.String TAG
org.webrtc.audio.WebRtcAudioRecord: int AUDIO_RECORD_START
io.flutter.view.AccessibilityViewEmbedder: java.util.Map embeddedViewToDisplayBounds
org.webrtc.audio.JavaAudioDeviceModule: boolean useStereoOutput
com.google.firestore.v1.StructuredQuery$CollectionSelector: com.google.protobuf.Parser PARSER
org.webrtc.VideoFileRenderer: int outputFileWidth
org.webrtc.EncodedImage$Builder: org.webrtc.EncodedImage$FrameType frameType
androidx.window.layout.WindowInfoTrackerImpl$windowLayoutInfo$1: java.lang.Object L$0
io.grpc.util.RoundRobinLoadBalancer$ReadyPicker: int index
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_17
androidx.window.R$styleable: int SplitPairFilter_secondaryActivityAction
kotlin.coroutines.jvm.internal.ContinuationImpl: kotlin.coroutines.Continuation intercepted
com.google.firestore.v1.StructuredQuery$CollectionSelector: java.lang.String collectionId_
com.cloudwebrtc.webrtc.R$attr: int secondaryActivityAction
org.webrtc.PeerConnection$RTCConfiguration: java.lang.Integer iceCheckIntervalStrongConnectivityMs
org.webrtc.PeerConnection$RTCConfiguration: java.lang.Integer screencastMinBitrate
com.google.firestore.v1.TransactionOptions: int READ_WRITE_FIELD_NUMBER
com.cloudwebrtc.webrtc.R$id: int androidx_window_activity_scope
org.webrtc.audio.WebRtcAudioManager: int DEFAULT_FRAME_PER_BUFFER
org.webrtc.EglBase: int[] CONFIG_PIXEL_RGBA_BUFFER
org.webrtc.VideoCodecInfo: java.lang.String H264_FMTP_PACKETIZATION_MODE
com.google.firestore.v1.RunAggregationQueryResponse: com.google.protobuf.Parser PARSER
com.google.firestore.v1.StructuredQuery$FieldReference: java.lang.String fieldPath_
com.cloudwebrtc.webrtc.R$styleable: int GradientColor_android_gradientRadius
org.webrtc.PeerConnection$IceTransportsType: org.webrtc.PeerConnection$IceTransportsType[] $VALUES
org.webrtc.RtpCapabilities$CodecCapability: int preferredPayloadType
com.google.firestore.v1.StructuredQuery: int SELECT_FIELD_NUMBER
org.webrtc.CameraCapturer: org.webrtc.CameraSession$Events cameraSessionEventsHandler
kotlinx.coroutines.DefaultExecutor: java.lang.Thread _thread
androidx.window.embedding.ExtensionEmbeddingBackend: java.util.concurrent.CopyOnWriteArrayList splitChangeCallbacks
com.google.firebase.firestore.proto.MaybeDocument: com.google.protobuf.Parser PARSER
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback$AnimationCallback: io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback this$0
androidx.window.embedding.EmbeddingCompat: androidx.window.embedding.EmbeddingCompat$Companion Companion
kotlinx.coroutines.scheduling.CoroutineScheduler$Worker: int indexInArray
org.webrtc.voiceengine.WebRtcAudioUtils: java.lang.String[] BLACKLISTED_OPEN_SL_ES_MODELS
io.flutter.embedding.engine.FlutterJNI: boolean loadLibraryCalled
org.webrtc.audio.WebRtcAudioRecord: int BUFFER_SIZE_FACTOR
com.google.type.LatLng: com.google.type.LatLng DEFAULT_INSTANCE
org.webrtc.SurfaceEglRenderer: java.lang.Object layoutLock
com.google.protobuf.GeneratedMessageLite: java.util.Map defaultInstanceMap
org.webrtc.voiceengine.WebRtcAudioTrack: int BITS_PER_SAMPLE
org.webrtc.EncodedImage$FrameType: org.webrtc.EncodedImage$FrameType VideoFrameKey
com.google.firestore.v1.StructuredQuery$CompositeFilter: com.google.protobuf.Parser PARSER
androidx.window.layout.WindowInfoTrackerImpl$windowLayoutInfo$1: android.app.Activity $activity
com.cloudwebrtc.webrtc.R$attr: int fontStyle
org.webrtc.PeerConnection$RTCConfiguration: java.lang.Integer iceUnwritableMinChecks
org.webrtc.RefCountDelegate: java.lang.Runnable releaseCallback
com.google.firestore.v1.WriteRequest: int STREAM_TOKEN_FIELD_NUMBER
com.google.firebase.firestore.proto.MaybeDocument: int UNKNOWN_DOCUMENT_FIELD_NUMBER
com.cloudwebrtc.webrtc.R$styleable: int GradientColor_android_tileMode
org.webrtc.H264Utils: java.lang.String H264_FMTP_PACKETIZATION_MODE
com.google.firestore.v1.Target: int resumeTypeCase_
org.webrtc.Camera1Session: org.webrtc.SurfaceTextureHelper surfaceTextureHelper
androidx.window.layout.SidecarCompat$DistinctElementCallback: androidx.window.layout.ExtensionInterfaceCompat$ExtensionCallbackInterface callbackInterface
com.cloudwebrtc.webrtc.R$styleable: int SplitPairRule_splitMinWidth
com.cloudwebrtc.webrtc.record.VideoFileRenderer: long presTime
com.cloudwebrtc.webrtc.R$drawable: int notification_bg_low_pressed
io.flutter.view.AccessibilityViewEmbedder: java.lang.String TAG
com.google.firestore.v1.WriteResponse: int STREAM_TOKEN_FIELD_NUMBER
org.webrtc.voiceengine.WebRtcAudioTrack: int CALLBACK_BUFFER_SIZE_MS
io.flutter.embedding.engine.FlutterJNI: float refreshRateFPS
com.google.firestore.v1.StructuredQuery$Filter: int filterTypeCase_
org.webrtc.CameraEnumerationAndroid$1: int MAX_FPS_DIFF_THRESHOLD
com.google.firestore.v1.StructuredQuery: com.google.firestore.v1.StructuredQuery DEFAULT_INSTANCE
org.webrtc.audio.LowLatencyAudioBufferManager: java.lang.String TAG
org.webrtc.NetworkChangeDetector$ConnectionType: org.webrtc.NetworkChangeDetector$ConnectionType CONNECTION_3G
org.webrtc.RtpParameters$DegradationPreference: org.webrtc.RtpParameters$DegradationPreference[] $VALUES
org.webrtc.PeerConnectionFactory$Builder: org.webrtc.FecControllerFactoryFactoryInterface fecControllerFactoryFactory
androidx.window.R$styleable: int[] ActivityRule
org.webrtc.FrameCryptorAlgorithm: org.webrtc.FrameCryptorAlgorithm[] $VALUES
com.cloudwebrtc.webrtc.GetUserMediaImpl$1: com.cloudwebrtc.webrtc.utils.ConstraintsMap val$constraints
com.google.firestore.v1.StructuredAggregationQuery$Aggregation: int AVG_FIELD_NUMBER
com.google.firestore.v1.DocumentMask: com.google.protobuf.Internal$ProtobufList fieldPaths_
com.cloudwebrtc.webrtc.PeerConnectionObserver$1: int[] $SwitchMap$org$webrtc$RtpTransceiver$RtpTransceiverDirection
com.google.firestore.v1.StructuredAggregationQuery$Aggregation: int SUM_FIELD_NUMBER
org.webrtc.HardwareVideoEncoder: java.lang.Exception shutdownException
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer: io.flutter.plugin.common.EventChannel eventChannel
com.google.firestore.v1.RunAggregationQueryRequest: java.lang.Object queryType_
org.webrtc.PeerConnection$BundlePolicy: org.webrtc.PeerConnection$BundlePolicy[] $VALUES
org.webrtc.NetworkMonitorAutoDetect$WifiManagerDelegate: android.content.Context context
com.google.firestore.admin.v1.Index: com.google.firestore.admin.v1.Index DEFAULT_INSTANCE
com.google.firestore.v1.RunAggregationQueryResponse: com.google.firestore.v1.AggregationResult result_
org.webrtc.voiceengine.WebRtcAudioManager: boolean lowLatencyOutput
org.webrtc.VideoFrameBufferType: int I410
org.webrtc.VideoEncoder$ScalingSettings: boolean on
org.webrtc.PeerConnectionFactory: org.webrtc.PeerConnectionFactory$ThreadInfo networkThread
org.webrtc.BaseBitrateAdjuster: int targetBitrateBps
kotlin.jvm.internal.FunctionReference: int flags
org.webrtc.TextureBufferImpl: org.webrtc.YuvConverter yuvConverter
org.webrtc.voiceengine.WebRtcAudioManager: boolean useStereoOutput
com.google.firestore.v1.DocumentRemove: com.google.protobuf.Parser PARSER
com.google.firestore.v1.StructuredQuery$UnaryFilter: java.lang.Object operandType_
org.webrtc.PeerConnection$RTCConfiguration: java.lang.Integer stableWritableConnectionPingIntervalMs
org.webrtc.EncodedImage$Builder: java.lang.Runnable releaseCallback
org.webrtc.SurfaceTextureHelper: int textureWidth
org.webrtc.NetworkChangeDetector$ConnectionType: org.webrtc.NetworkChangeDetector$ConnectionType CONNECTION_2G
org.webrtc.PeerConnection$RTCConfiguration: boolean enableCpuOveruseDetection
org.webrtc.MediaCodecVideoDecoderFactory: org.webrtc.EglBase$Context sharedContext
org.webrtc.NV21Buffer: byte[] data
com.cloudwebrtc.webrtc.R$styleable: int ActivityFilter_activityName
com.cloudwebrtc.webrtc.R$dimen: int compat_control_corner_material
org.webrtc.DynamicBitrateAdjuster: double deviationBytes
org.webrtc.JNILogging: org.webrtc.Loggable loggable
com.cloudwebrtc.webrtc.record.VideoFileRenderer: int FRAME_RATE
org.webrtc.NetworkMonitorAutoDetect$ConnectivityManagerDelegate: boolean includeOtherUidNetworks
org.webrtc.audio.JavaAudioDeviceModule: java.lang.Object nativeLock
org.webrtc.audio.WebRtcAudioEffects: android.media.audiofx.NoiseSuppressor ns
com.cloudwebrtc.webrtc.R$style: int TextAppearance_Compat_Notification_Info
com.cloudwebrtc.webrtc.R$drawable: int notification_bg_normal
org.webrtc.audio.JavaAudioDeviceModule: android.content.Context context
kotlin.jvm.internal.CallableReference: java.lang.Object receiver
com.google.firebase.firestore.proto.MaybeDocument: int NO_DOCUMENT_FIELD_NUMBER
org.webrtc.VideoEncoder$Settings: int numberOfSimulcastStreams
com.google.firestore.admin.v1.Index$IndexField: int ARRAY_CONFIG_FIELD_NUMBER
org.webrtc.EncodedImage$Builder: java.lang.Integer qp
com.google.firestore.v1.Target: boolean once_
androidx.window.embedding.ExtensionEmbeddingBackend: java.util.concurrent.CopyOnWriteArraySet splitRules
org.webrtc.PeerConnection$RTCConfiguration: org.webrtc.PeerConnection$CandidateNetworkPolicy candidateNetworkPolicy
org.webrtc.SoftwareVideoDecoderFactory$1: org.webrtc.SoftwareVideoDecoderFactory this$0
com.google.firebase.firestore.proto.WriteBatch: com.google.protobuf.Parser PARSER
com.cloudwebrtc.webrtc.GetUserMediaImpl$2: com.cloudwebrtc.webrtc.GetUserMediaImpl this$0
com.google.protobuf.GeneratedMessageLite: int UNINITIALIZED_HASH_CODE
org.webrtc.Camera2Session: org.webrtc.CameraSession$CreateSessionCallback callback
com.google.firestore.v1.WriteRequest: java.lang.String streamId_
org.webrtc.YuvConverter$ShaderCallbacks: int coeffsLoc
androidx.window.layout.EmptyDecorator: androidx.window.layout.EmptyDecorator INSTANCE
com.google.firestore.v1.BloomFilter: int HASH_COUNT_FIELD_NUMBER
org.webrtc.audio.WebRtcAudioTrack: android.media.AudioManager audioManager
com.google.firestore.admin.v1.Index: com.google.protobuf.Parser PARSER
org.webrtc.Logging$Severity: org.webrtc.Logging$Severity[] $VALUES
org.webrtc.CameraCapturer$9: org.webrtc.CameraSession val$oldSession
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor: java.util.Map frameCryptoObservers
com.cloudwebrtc.webrtc.R$style: int TextAppearance_Compat_Notification_Line2
org.webrtc.voiceengine.WebRtcAudioTrack$AudioTrackStartErrorCode: org.webrtc.voiceengine.WebRtcAudioTrack$AudioTrackStartErrorCode[] $VALUES
org.webrtc.PeerConnectionFactory$Options: boolean disableEncryption
org.webrtc.Camera1Session: boolean firstFrameReported
com.google.firebase.firestore.proto.WriteBatch: com.google.protobuf.Internal$ProtobufList writes_
org.webrtc.CameraCapturer$4: org.webrtc.CameraCapturer this$0
org.webrtc.H264Utils: java.lang.String H264_PROFILE_CONSTRAINED_HIGH
org.webrtc.CryptoOptions: org.webrtc.CryptoOptions$Srtp srtp
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_25
com.google.firestore.v1.StructuredAggregationQuery$Aggregation: java.lang.String alias_
com.google.firestore.admin.v1.Index: int NAME_FIELD_NUMBER
com.cloudwebrtc.webrtc.R$attr: int fontProviderPackage
org.webrtc.RtpParameters: java.util.List codecs
com.cloudwebrtc.webrtc.R$id: int action_container
org.webrtc.EglRenderer: android.os.Handler renderThreadHandler
androidx.window.layout.SidecarCompat$FirstAttachAdapter: androidx.window.layout.SidecarCompat sidecarCompat
org.webrtc.Camera2Session: android.hardware.camera2.CameraCaptureSession captureSession
androidx.window.layout.SidecarCompat: androidx.window.layout.SidecarCompat$Companion Companion
com.google.firestore.v1.WriteRequest: java.lang.String database_
org.webrtc.EncodedImage$FrameType: org.webrtc.EncodedImage$FrameType VideoFrameDelta
com.cloudwebrtc.webrtc.R$id: int time
androidx.window.layout.ActivityCompatHelperApi30: androidx.window.layout.ActivityCompatHelperApi30 INSTANCE
com.google.firestore.v1.StructuredQuery$FieldFilter: int FIELD_FIELD_NUMBER
org.webrtc.NetworkMonitor: java.lang.String TAG
com.google.firestore.v1.RunAggregationQueryRequest: java.lang.String parent_
org.webrtc.VideoFrame: long timestampNs
org.webrtc.NetworkMonitorAutoDetect$ConnectivityManagerDelegate: java.util.Set availableNetworks
androidx.window.embedding.ExtensionEmbeddingBackend$SplitListenerWrapper: androidx.core.util.Consumer callback
androidx.window.R$attr: int alwaysExpand
com.cloudwebrtc.webrtc.utils.PermissionUtils$1: com.cloudwebrtc.webrtc.utils.PermissionUtils$Callback val$callback
org.webrtc.EglRenderer$FrameListenerAndParams: float scale
com.google.firestore.v1.ArrayValue: com.google.protobuf.Internal$ProtobufList values_
org.webrtc.FileVideoCapturer$VideoReaderY4M: java.lang.String Y4M_FRAME_DELIMETER
org.webrtc.PeerConnection$AdapterType: org.webrtc.PeerConnection$AdapterType VPN
org.webrtc.VideoDecoder$DecodeInfo: long renderTimeMs
org.webrtc.FileVideoCapturer: java.lang.String TAG
org.webrtc.SurfaceTextureHelper$1: android.os.Handler val$handler
com.google.firestore.v1.BatchGetDocumentsResponse: com.google.protobuf.ByteString transaction_
androidx.window.layout.SidecarWindowBackend: boolean DEBUG
org.webrtc.voiceengine.WebRtcAudioTrack: android.media.AudioManager audioManager
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback: boolean animating
androidx.window.R$styleable: int ActivityFilter_activityName
org.webrtc.NetworkMonitorAutoDetect$NetworkState: int type
com.cloudwebrtc.webrtc.R$integer: int status_bar_notification_info_maxnum
org.webrtc.PeerConnection$SdpSemantics: org.webrtc.PeerConnection$SdpSemantics PLAN_B
org.webrtc.PeerConnection$AdapterType: org.webrtc.PeerConnection$AdapterType CELLULAR_4G
org.webrtc.EglRenderer: int framesRendered
org.webrtc.EglBase10Impl: javax.microedition.khronos.egl.EGLContext eglContext
com.google.firestore.v1.CommitResponse: com.google.firestore.v1.CommitResponse DEFAULT_INSTANCE
org.webrtc.RendererCommon$1: int[] $SwitchMap$org$webrtc$RendererCommon$ScalingType
com.google.firebase.firestore.proto.WriteBatch: com.google.protobuf.Internal$ProtobufList baseWrites_
org.webrtc.NetworkMonitor: java.util.ArrayList nativeNetworkObservers
androidx.window.layout.WindowInfoTracker: androidx.window.layout.WindowInfoTracker$Companion Companion
com.google.firestore.v1.Target: java.lang.Object resumeType_
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: org.webrtc.audio.AudioDeviceModule audioDeviceModule
kotlinx.coroutines.channels.AbstractSendChannel: java.lang.Object onCloseHandler
androidx.window.layout.SidecarWindowBackend$WindowLayoutChangeCallbackWrapper: android.app.Activity activity
com.cloudwebrtc.webrtc.utils.EglUtils: org.webrtc.EglBase rootEglBase
com.google.firestore.v1.RunAggregationQueryRequest: java.lang.Object consistencySelector_
com.cloudwebrtc.webrtc.R$dimen: int notification_content_margin_start
org.webrtc.Camera1Session: int NUMBER_OF_CAPTURE_BUFFERS
org.webrtc.TextureBufferImpl: int unscaledHeight
org.webrtc.HardwareVideoEncoder: java.lang.Integer yuvColorFormat
org.webrtc.TextureBufferImpl: android.os.Handler toI420Handler
org.webrtc.NetworkChangeDetector$IPAddress: byte[] address
com.google.firestore.v1.CommitRequest: int TRANSACTION_FIELD_NUMBER
kotlinx.coroutines.CommonPool: java.util.concurrent.Executor pool
kotlinx.coroutines.EventLoopImplBase: java.lang.Object _delayed
com.cloudwebrtc.webrtc.GetUserMediaImpl$ScreenRequestPermissionsFragment: int requestCode
androidx.window.layout.ActivityCompatHelperApi24: androidx.window.layout.ActivityCompatHelperApi24 INSTANCE
org.webrtc.PeerConnection$RtcpMuxPolicy: org.webrtc.PeerConnection$RtcpMuxPolicy[] $VALUES
com.google.firestore.v1.TransactionOptions$ReadWrite: com.google.protobuf.Parser PARSER
org.webrtc.PeerConnection$IceConnectionState: org.webrtc.PeerConnection$IceConnectionState DISCONNECTED
com.google.firestore.v1.BitSequence: int BITMAP_FIELD_NUMBER
org.webrtc.PeerConnection$IceServer$Builder: java.util.List urls
org.webrtc.RtpCapabilities$HeaderExtensionCapability: int preferredId
org.webrtc.ScreenCapturerAndroid: android.media.projection.MediaProjection mediaProjection
com.google.firestore.v1.DocumentChange: int DOCUMENT_FIELD_NUMBER
androidx.window.R$styleable: int SplitPlaceholderRule_placeholderActivityName
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_11
org.webrtc.HardwareVideoEncoder: int DEQUEUE_OUTPUT_BUFFER_TIMEOUT_US
com.cloudwebrtc.webrtc.R$id: int tag_on_receive_content_mime_types
org.webrtc.VideoCodecInfo: java.lang.String H264_CONSTRAINED_BASELINE_3_1
org.webrtc.audio.JavaAudioDeviceModule$Builder: boolean useLowLatency
androidx.window.embedding.SplitController: java.util.Set staticSplitRules
com.google.firestore.v1.RunAggregationQueryRequest: int TRANSACTION_FIELD_NUMBER
io.flutter.view.AccessibilityViewEmbedder: android.view.View rootAccessibilityView
androidx.window.embedding.ActivityRule: boolean alwaysExpand
org.webrtc.TextureBufferImpl: android.graphics.Matrix transformMatrix
org.webrtc.AndroidVideoDecoder: org.webrtc.MediaCodecWrapper codec
org.webrtc.SimulcastVideoEncoderFactory: org.webrtc.VideoEncoderFactory primary
org.webrtc.VideoFrameDrawer$YuvUploader: int[] yuvTextures
com.cloudwebrtc.webrtc.R$styleable: int GradientColor_android_startY
org.webrtc.Camera2Session: android.hardware.camera2.CameraDevice cameraDevice
org.webrtc.HardwareVideoEncoder: boolean isSemiPlanar
org.webrtc.audio.VolumeLogger: java.lang.String TAG
com.google.firestore.v1.WriteResponse: int WRITE_RESULTS_FIELD_NUMBER
org.webrtc.Metrics$HistogramInfo: int min
org.webrtc.EglRenderer$EglSurfaceCreation: org.webrtc.EglRenderer this$0
org.webrtc.MediaCodecUtils: java.lang.String[] SOFTWARE_IMPLEMENTATION_PREFIXES
org.webrtc.PeerConnection$TlsCertPolicy: org.webrtc.PeerConnection$TlsCertPolicy[] $VALUES
org.webrtc.VideoDecoderFallback: org.webrtc.VideoDecoder primary
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper: org.webrtc.SimulcastVideoEncoderFactory native
com.google.protobuf.Int32Value: int VALUE_FIELD_NUMBER
com.cloudwebrtc.webrtc.R$attr: int primaryActivityName
org.webrtc.audio.WebRtcAudioTrack: org.webrtc.ThreadUtils$ThreadChecker threadChecker
org.webrtc.audio.WebRtcAudioRecord: long AUDIO_RECORD_THREAD_JOIN_TIMEOUT_MS
com.cloudwebrtc.webrtc.R$dimen: int notification_top_pad
org.webrtc.EncodedImage$FrameType: int nativeIndex
org.webrtc.VideoEncoder$Settings: int width
org.webrtc.VideoCodecInfo: java.lang.String H264_PROFILE_CONSTRAINED_BASELINE
org.webrtc.VideoFileRenderer: android.os.Handler renderThreadHandler
org.webrtc.PeerConnection$IceServer: java.util.List urls
org.webrtc.CameraVideoCapturer$CameraStatistics: org.webrtc.CameraVideoCapturer$CameraEventsHandler eventsHandler
org.webrtc.HardwareVideoEncoder$1: org.webrtc.HardwareVideoEncoder this$0
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper: org.webrtc.VideoEncoderFactory fallback
org.webrtc.PeerConnectionFactory$InitializationOptions: org.webrtc.Logging$Severity loggableSeverity
com.cloudwebrtc.webrtc.PeerConnectionObserver: java.lang.String id
org.webrtc.EncodedImage$Builder: java.nio.ByteBuffer buffer
io.flutter.plugin.platform.SingleViewPresentation: java.lang.String TAG
org.webrtc.PeerConnection: java.util.List localStreams
org.webrtc.RtpSender: org.webrtc.MediaStreamTrack cachedTrack
org.webrtc.NetworkMonitor: org.webrtc.NetworkChangeDetector networkChangeDetector
com.google.firestore.v1.Value: int MAP_VALUE_FIELD_NUMBER
com.google.firebase.firestore.proto.Target: int TARGET_ID_FIELD_NUMBER
org.webrtc.RtpParameters: org.webrtc.RtpParameters$DegradationPreference degradationPreference
org.webrtc.HardwareVideoEncoderFactory: org.webrtc.EglBase14$Context sharedContext
org.webrtc.PeerConnection: java.util.List senders
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer$1: com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer this$0
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$1: io.flutter.plugin.common.MethodChannel$Result val$result
kotlinx.coroutines.scheduling.CoroutineScheduler: long controlState
com.cloudwebrtc.webrtc.R$drawable: int notification_template_icon_low_bg
com.cloudwebrtc.webrtc.utils.AnyThreadResult: android.os.Handler handler
androidx.window.layout.WindowInfoTracker$Companion: androidx.window.layout.WindowInfoTrackerDecorator decorator
org.webrtc.HardwareVideoEncoder: java.lang.Thread outputThread
com.google.firestore.v1.StructuredQuery$FieldFilter: int OP_FIELD_NUMBER
org.webrtc.VideoCodecInfo: java.lang.String name
org.webrtc.voiceengine.WebRtcAudioRecord: int BUFFER_SIZE_FACTOR
org.webrtc.AndroidVideoDecoder: int width
org.webrtc.RtpParameters$Codec: java.lang.Integer clockRate
com.google.firestore.v1.Target$DocumentsTarget: com.google.firestore.v1.Target$DocumentsTarget DEFAULT_INSTANCE
com.cloudwebrtc.webrtc.record.AudioChannel: com.cloudwebrtc.webrtc.record.AudioChannel OUTPUT
org.webrtc.NetworkChangeDetector$ConnectionType: org.webrtc.NetworkChangeDetector$ConnectionType CONNECTION_4G
org.webrtc.voiceengine.WebRtcAudioManager: boolean aAudio
org.webrtc.Camera1Session: long constructionTimeNs
com.google.firestore.v1.WriteRequest: com.google.protobuf.Parser PARSER
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer: org.webrtc.VideoTrack videoTrack
io.flutter.view.AccessibilityViewEmbedder: java.util.Map originToFlutterId
io.flutter.embedding.engine.FlutterJNI: io.flutter.plugin.platform.PlatformViewsController platformViewsController
org.webrtc.HardwareVideoEncoderFactory: org.webrtc.Predicate codecAllowedPredicate
kotlinx.coroutines.internal.LockFreeTaskQueueCore: java.lang.Object _next
androidx.window.R$attr: int placeholderActivityName
org.webrtc.CryptoOptions$Builder: boolean enableGcmCryptoSuites
org.webrtc.VideoFrame$TextureBuffer$Type: org.webrtc.VideoFrame$TextureBuffer$Type RGB
androidx.window.layout.WindowMetricsCalculator$Companion: kotlin.jvm.functions.Function1 decorator
com.google.firestore.v1.Target$QueryTarget: java.lang.String parent_
org.webrtc.RtpCapabilities: java.util.List codecs
io.flutter.view.AccessibilityViewEmbedder: int nextFlutterId
org.webrtc.VideoEncoder$Settings: int height
org.webrtc.PeerConnection$IceServer$Builder: java.util.List tlsEllipticCurves
org.webrtc.Camera1Session: org.webrtc.Camera1Session$SessionState state
org.webrtc.HardwareVideoEncoderFactory: int PERIODIC_KEY_FRAME_INTERVAL_S
org.webrtc.JavaI420Buffer: java.nio.ByteBuffer dataY
com.cloudwebrtc.webrtc.R$drawable: int notification_action_background
org.webrtc.voiceengine.WebRtcAudioRecord: android.media.AudioRecord audioRecord
io.flutter.embedding.engine.FlutterOverlaySurface: int id
org.webrtc.voiceengine.WebRtcAudioEffects: android.media.audiofx.AudioEffect$Descriptor[] cachedEffects
kotlinx.coroutines.JobSupport: java.lang.Object _state
androidx.window.layout.ExtensionWindowLayoutInfoBackend: androidx.window.extensions.layout.WindowLayoutComponent component
androidx.window.layout.WindowInfoTrackerImpl: androidx.window.layout.WindowInfoTrackerImpl$Companion Companion
org.webrtc.PlatformSoftwareVideoDecoderFactory: org.webrtc.Predicate defaultAllowedPredicate
com.cloudwebrtc.webrtc.R$id: int notification_main_column
org.webrtc.SurfaceTextureHelper: boolean isQuitting
com.google.android.gms.common.Feature: android.os.Parcelable$Creator CREATOR
com.cloudwebrtc.webrtc.R$styleable: int GradientColor_android_type
com.google.firestore.v1.DocumentDelete: com.google.protobuf.Parser PARSER
org.webrtc.audio.WebRtcAudioTrack: int initialBufferSizeInFrames
com.google.firestore.v1.Write: int UPDATE_TRANSFORMS_FIELD_NUMBER
com.cloudwebrtc.webrtc.R$styleable: int SplitPairFilter_secondaryActivityAction
io.flutter.embedding.engine.FlutterJNI: java.util.Set flutterUiDisplayListeners
kotlinx.coroutines.CancellableContinuationImpl: java.lang.Object _state
org.webrtc.voiceengine.WebRtcAudioRecord: int BUFFERS_PER_SECOND
com.cloudwebrtc.webrtc.PeerConnectionObserver: org.webrtc.PeerConnection$RTCConfiguration configuration
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer: org.webrtc.RendererCommon$RendererEvents rendererEvents
com.cloudwebrtc.webrtc.R$styleable: int FontFamilyFont_fontVariationSettings
org.webrtc.CameraCapturer: android.os.Handler cameraThreadHandler
org.webrtc.audio.JavaAudioDeviceModule$Builder: int outputSampleRate
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_2
org.webrtc.PeerConnection$IceServer: java.util.List tlsAlpnProtocols
com.cloudwebrtc.webrtc.R$id: int action_divider
com.google.firebase.firestore.proto.WriteBatch: int batchId_
org.webrtc.DataChannel: long nativeObserver
org.webrtc.AndroidVideoDecoder: java.lang.Exception shutdownException
org.webrtc.PeerConnection$SignalingState: org.webrtc.PeerConnection$SignalingState HAVE_LOCAL_OFFER
com.cloudwebrtc.webrtc.R$color: int androidx_core_secondary_text_default_material_light
com.google.firestore.v1.Document: com.google.protobuf.MapFieldLite fields_
org.webrtc.FrameCryptor: long nativeFrameCryptor
org.webrtc.CameraCapturer$7: org.webrtc.CameraVideoCapturer$CameraSwitchHandler val$switchEventsHandler
androidx.lifecycle.Lifecycle$Event: androidx.lifecycle.Lifecycle$Event ON_CREATE
org.webrtc.Camera2Session$SessionState: org.webrtc.Camera2Session$SessionState[] $VALUES
com.cloudwebrtc.webrtc.R$style: int Widget_Compat_NotificationActionText
com.cloudwebrtc.webrtc.R$dimen: int notification_main_column_padding_top
org.webrtc.voiceengine.WebRtcAudioUtils: int defaultSampleRateHz
org.webrtc.PeerConnection$IceGatheringState: org.webrtc.PeerConnection$IceGatheringState NEW
org.webrtc.Camera1Session: java.lang.String TAG
com.google.firestore.v1.DocumentRemove: int removedTargetIdsMemoizedSerializedSize
org.webrtc.HardwareVideoEncoder: java.util.Map params
com.cloudwebrtc.webrtc.GetUserMediaImpl: android.media.AudioDeviceInfo preferredInput
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin: com.cloudwebrtc.webrtc.MethodCallHandlerImpl methodCallHandler
org.webrtc.PeerConnection$IceServer: java.lang.String hostname
com.google.android.gms.signin.internal.zai: android.os.Parcelable$Creator CREATOR
kotlin.jvm.internal.CallableReference: boolean isTopLevel
androidx.window.layout.SidecarCompat$DistinctElementCallback: java.util.concurrent.locks.ReentrantLock lock
com.google.firestore.v1.StructuredQuery: int FROM_FIELD_NUMBER
com.cloudwebrtc.webrtc.R$styleable: int FontFamilyFont_android_font
org.webrtc.RtpParameters$HeaderExtension: boolean encrypted
org.webrtc.voiceengine.WebRtcAudioEffects: boolean shouldEnableAec
androidx.window.embedding.SplitRule: int layoutDirection
org.webrtc.audio.WebRtcAudioRecord: int CALLBACK_BUFFER_SIZE_MS
org.webrtc.HardwareVideoEncoder: int stride
org.webrtc.RtpParameters$HeaderExtension: java.lang.String uri
com.google.firestore.v1.WriteResult: com.google.firestore.v1.WriteResult DEFAULT_INSTANCE
com.cloudwebrtc.webrtc.record.VideoFileRenderer: int outputFileHeight
com.google.firestore.v1.WriteResult: int UPDATE_TIME_FIELD_NUMBER
androidx.window.embedding.ExtensionEmbeddingBackend: androidx.window.embedding.ExtensionEmbeddingBackend$Companion Companion
org.webrtc.audio.JavaAudioDeviceModule$AudioRecordStartErrorCode: org.webrtc.audio.JavaAudioDeviceModule$AudioRecordStartErrorCode AUDIO_RECORD_START_STATE_MISMATCH
org.webrtc.RendererCommon: float BALANCED_VISIBLE_FRACTION
org.webrtc.EglRenderer: long minRenderPeriodNs
org.webrtc.voiceengine.WebRtcAudioUtils: java.lang.String TAG
com.google.firestore.v1.TransactionOptions$ReadOnly: int READ_TIME_FIELD_NUMBER
org.webrtc.EglRenderer: long statisticsStartTimeNs
org.webrtc.PeerConnection$IceServer$Builder: java.lang.String username
org.webrtc.DynamicBitrateAdjuster: double timeSinceLastAdjustmentMs
org.webrtc.PeerConnection$CandidateNetworkPolicy: org.webrtc.PeerConnection$CandidateNetworkPolicy ALL
org.webrtc.voiceengine.WebRtcAudioRecord: byte[] emptyBytes
androidx.window.core.Version: int patch
org.webrtc.voiceengine.WebRtcAudioManager$VolumeLogger: java.lang.String THREAD_NAME
org.webrtc.DataChannel$State: org.webrtc.DataChannel$State CLOSED
androidx.window.R$styleable: int ActivityFilter_activityAction
com.cloudwebrtc.webrtc.R$id: int tag_state_description
org.webrtc.audio.WebRtcAudioRecord: java.util.concurrent.atomic.AtomicReference audioSourceMatchesRecordingSessionRef
kotlinx.coroutines.scheduling.WorkQueue: java.lang.Object lastScheduledTask
org.webrtc.Camera1Enumerator: java.lang.String TAG
com.cloudwebrtc.webrtc.R$styleable: int[] ActivityRule
com.cloudwebrtc.webrtc.R$dimen: int notification_large_icon_height
org.webrtc.voiceengine.WebRtcAudioEffects: java.util.UUID AOSP_ACOUSTIC_ECHO_CANCELER
org.webrtc.VideoCodecStatus: org.webrtc.VideoCodecStatus[] $VALUES
org.webrtc.DataChannel$Init: int id
com.cloudwebrtc.webrtc.GetUserMediaImpl$3: org.webrtc.MediaStream val$mediaStream
org.webrtc.PeerConnectionFactory$InitializationOptions: java.lang.String fieldTrials
org.webrtc.PeerConnection$IceTransportsType: org.webrtc.PeerConnection$IceTransportsType NONE
com.google.firestore.v1.BloomFilter: com.google.firestore.v1.BitSequence bits_
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_26
org.webrtc.audio.VolumeLogger$LogVolumeTask: org.webrtc.audio.VolumeLogger this$0
com.google.firestore.v1.Target: int QUERY_FIELD_NUMBER
org.webrtc.CameraVideoCapturer$CameraStatistics: java.lang.Runnable cameraObserver
org.webrtc.PeerConnection$TcpCandidatePolicy: org.webrtc.PeerConnection$TcpCandidatePolicy DISABLED
androidx.lifecycle.Lifecycle$Event: androidx.lifecycle.Lifecycle$Event ON_DESTROY
org.webrtc.EncodedImage$Builder: int encodedHeight
com.cloudwebrtc.webrtc.GetUserMediaImpl$5: int[] $SwitchMap$com$cloudwebrtc$webrtc$utils$ObjectType
com.google.firestore.v1.BatchGetDocumentsRequest: com.google.protobuf.Parser PARSER
org.webrtc.WrappedVideoDecoderFactory: org.webrtc.VideoDecoderFactory hardwareVideoDecoderFactoryWithoutEglContext
org.webrtc.CameraEnumerationAndroid$1: int MIN_FPS_THRESHOLD
com.google.firestore.v1.Document: int NAME_FIELD_NUMBER
org.webrtc.Logging$TraceLevel: org.webrtc.Logging$TraceLevel[] $VALUES
org.webrtc.VideoFileRenderer: android.os.Handler fileThreadHandler
com.cloudwebrtc.webrtc.R$styleable: int SplitPlaceholderRule_splitMinSmallestWidth
org.webrtc.audio.JavaAudioDeviceModule$Builder: android.media.AudioAttributes audioAttributes
com.google.firestore.v1.DocumentDelete: int READ_TIME_FIELD_NUMBER
kotlinx.coroutines.android.AndroidExceptionPreHandler: java.lang.Object _preHandler
org.webrtc.DynamicBitrateAdjuster: int bitrateAdjustmentScaleExp
org.webrtc.audio.JavaAudioDeviceModule$AudioRecordStartErrorCode: org.webrtc.audio.JavaAudioDeviceModule$AudioRecordStartErrorCode[] $VALUES
com.google.firestore.v1.DocumentTransform$FieldTransform: int MINIMUM_FIELD_NUMBER
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor$FrameCryptorStateObserver: io.flutter.plugin.common.EventChannel$EventSink eventSink
com.google.firestore.v1.DocumentMask: com.google.firestore.v1.DocumentMask DEFAULT_INSTANCE
com.cloudwebrtc.webrtc.record.VideoFileRenderer: java.nio.ByteBuffer[] audioOutputBuffers
org.webrtc.voiceengine.WebRtcAudioManager: boolean hardwareNS
androidx.window.java.layout.WindowInfoTrackerCallbackAdapter: java.util.concurrent.locks.ReentrantLock lock
org.webrtc.NetworkMonitor: java.lang.Object networkChangeDetectorLock
org.webrtc.NetworkMonitorAutoDetect$NetworkState: int subtype
androidx.window.embedding.SplitPairRule: boolean finishPrimaryWithSecondary
org.webrtc.EncodedImage$Builder: int rotation
org.webrtc.EglBase14Impl: android.opengl.EGLDisplay eglDisplay
androidx.window.R$styleable: int SplitPairRule_splitMinSmallestWidth
com.cloudwebrtc.webrtc.record.AudioChannel: com.cloudwebrtc.webrtc.record.AudioChannel[] $VALUES
androidx.window.R$styleable: int SplitPairRule_splitRatio
androidx.window.R$styleable: int ActivityRule_alwaysExpand
org.webrtc.NetworkMonitorAutoDetect: android.net.ConnectivityManager$NetworkCallback mobileNetworkCallback
com.google.firestore.admin.v1.Index$IndexField: java.lang.Object valueMode_
org.webrtc.audio.JavaAudioDeviceModule$Builder: int inputSampleRate
org.webrtc.EglRenderer: int framesDropped
com.google.android.gms.common.internal.zat: android.os.Parcelable$Creator CREATOR
org.webrtc.Camera1Session: android.hardware.Camera camera
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback: int overlayInsetTypes
com.google.firestore.v1.BatchGetDocumentsRequest: com.google.firestore.v1.BatchGetDocumentsRequest DEFAULT_INSTANCE
org.webrtc.voiceengine.WebRtcAudioManager: long nativeAudioManager
org.webrtc.PeerConnection$PortPrunePolicy: org.webrtc.PeerConnection$PortPrunePolicy KEEP_FIRST_READY
com.google.firestore.v1.DocumentRemove: com.google.protobuf.Internal$IntList removedTargetIds_
org.webrtc.NativeLibrary: java.lang.Object lock
androidx.window.layout.WindowInfoTrackerImpl$windowLayoutInfo$1: java.lang.Object L$1
org.webrtc.CameraVideoCapturer$CameraStatistics$1: org.webrtc.CameraVideoCapturer$CameraStatistics this$0
org.webrtc.audio.WebRtcAudioTrack: android.media.AudioAttributes audioAttributes
org.webrtc.NetworkPreference: int NEUTRAL
org.webrtc.audio.JavaAudioDeviceModule$Builder: boolean useStereoInput
com.cloudwebrtc.webrtc.R$dimen: int notification_subtext_size
org.webrtc.ThreadUtils$1Result: java.lang.Object value
org.webrtc.Camera2Session$SessionState: org.webrtc.Camera2Session$SessionState RUNNING
org.webrtc.PeerConnection$AdapterType: java.lang.Integer bitMask
com.google.firestore.v1.Value: int STRING_VALUE_FIELD_NUMBER
org.webrtc.Camera1Session: org.webrtc.Histogram camera1StopTimeMsHistogram
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_4
org.webrtc.WrappedNativeI420Buffer: int strideY
com.cloudwebrtc.webrtc.DataChannelObserver: io.flutter.plugin.common.EventChannel eventChannel
org.webrtc.Camera2Enumerator: android.hardware.camera2.CameraManager cameraManager
org.webrtc.ThreadUtils$2: java.util.concurrent.CountDownLatch val$latch
kotlinx.coroutines.android.HandlerContext: kotlinx.coroutines.android.HandlerContext _immediate
org.webrtc.IceCandidateErrorEvent: int errorCode
org.webrtc.EglBase10Impl: int EGL_CONTEXT_CLIENT_VERSION
org.webrtc.audio.WebRtcAudioEffects: boolean shouldEnableAec
com.google.firestore.v1.DocumentDelete: int removedTargetIdsMemoizedSerializedSize
com.google.firestore.v1.WriteResult: com.google.protobuf.Parser PARSER
org.webrtc.WrappedNativeI420Buffer: java.nio.ByteBuffer dataV
org.webrtc.MediaStream: java.util.List preservedVideoTracks
org.webrtc.audio.JavaAudioDeviceModule$Builder: boolean useHardwareNoiseSuppressor
androidx.window.core.Version: androidx.window.core.Version VERSION_1_0
org.webrtc.VideoEncoder$EncoderInfo: boolean applyAlignmentToAllSimulcastLayers
org.webrtc.Logging$TraceLevel: org.webrtc.Logging$TraceLevel TRACE_TERSEINFO
com.cloudwebrtc.webrtc.R$id: int dialog_button
org.webrtc.Logging$TraceLevel: org.webrtc.Logging$TraceLevel TRACE_WARNING
org.webrtc.ThreadUtils$3: org.webrtc.ThreadUtils$1CaughtException val$caughtException
org.webrtc.ThreadUtils$ThreadChecker: java.lang.Thread thread
org.webrtc.SurfaceEglRenderer: boolean isRenderingPaused
org.webrtc.RtpParameters$Codec: java.lang.String name
org.webrtc.EglBase: int EGL_OPENGL_ES2_BIT
androidx.window.core.Version$bigInteger$2: androidx.window.core.Version this$0
org.webrtc.CryptoOptions$Srtp: org.webrtc.CryptoOptions this$0
com.google.firebase.firestore.FirestoreRegistrar: java.lang.String LIBRARY_NAME
org.webrtc.MediaStream: java.util.List audioTracks
com.cloudwebrtc.webrtc.R$dimen: int notification_small_icon_background_padding
com.google.android.gms.common.internal.zzj: android.os.Parcelable$Creator CREATOR
org.webrtc.EglBase14Impl: android.opengl.EGLSurface eglSurface
org.webrtc.PeerConnection$RTCConfiguration: org.webrtc.CryptoOptions cryptoOptions
org.webrtc.H264Utils: java.lang.String H264_CONSTRAINED_BASELINE_3_1
kotlinx.coroutines.DispatchedCoroutine: int _decision
org.webrtc.VideoFrameBufferType: int NV12
org.webrtc.ThreadUtils$4: java.lang.Runnable val$runner
org.webrtc.NetworkMonitorAutoDetect$WifiDirectManagerDelegate: int WIFI_P2P_NETWORK_HANDLE
com.google.firestore.v1.StructuredAggregationQuery$Aggregation$Count: com.google.firestore.v1.StructuredAggregationQuery$Aggregation$Count DEFAULT_INSTANCE
org.webrtc.VideoFileRenderer: java.io.FileOutputStream videoOutFile
org.webrtc.PeerConnection$RTCConfiguration: int audioJitterBufferMaxPackets
org.webrtc.TextureBufferImpl: org.webrtc.RefCountDelegate refCountDelegate
org.webrtc.FileVideoCapturer: org.webrtc.FileVideoCapturer$VideoReader videoReader
com.cloudwebrtc.webrtc.PeerConnectionObserver: java.util.Map dataChannels
org.webrtc.audio.WebRtcAudioTrack: org.webrtc.audio.JavaAudioDeviceModule$AudioTrackStateCallback stateCallback
org.webrtc.Camera2Session: int width
androidx.window.R$styleable: int[] SplitPairFilter
com.google.type.LatLng: double longitude_
org.webrtc.audio.WebRtcAudioRecord: int BUFFERS_PER_SECOND
com.cloudwebrtc.webrtc.GetUserMediaImpl: java.lang.String PROJECTION_DATA
com.google.firestore.v1.DocumentTransform: int DOCUMENT_FIELD_NUMBER
com.cloudwebrtc.webrtc.record.AudioTrackInterceptor: android.media.AudioTrack originalTrack
org.webrtc.VideoCodecStatus: org.webrtc.VideoCodecStatus ERR_PARAMETER
com.google.firestore.v1.Write: int operationCase_
androidx.window.layout.WindowInfoTrackerImpl: int BUFFER_CAPACITY
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$5: com.cloudwebrtc.webrtc.MethodCallHandlerImpl this$0
com.google.firestore.v1.Document: com.google.protobuf.Parser PARSER
org.webrtc.AndroidVideoDecoder: java.lang.String codecName
org.webrtc.Logging$Severity: org.webrtc.Logging$Severity LS_VERBOSE
org.webrtc.Camera1Session$SessionState: org.webrtc.Camera1Session$SessionState[] $VALUES
org.webrtc.HardwareVideoEncoder: boolean running
org.webrtc.PeerConnection$SignalingState: org.webrtc.PeerConnection$SignalingState HAVE_REMOTE_PRANSWER
org.webrtc.Camera2Session: android.content.Context applicationContext
org.webrtc.Priority: int LOW
org.webrtc.WrappedNativeI420Buffer: long nativeBuffer
org.webrtc.YuvConverter: org.webrtc.GlTextureFrameBuffer i420TextureFrameBuffer
com.google.firestore.admin.v1.Index$IndexField: java.lang.String fieldPath_
com.google.firestore.v1.ArrayValue: com.google.protobuf.Parser PARSER
androidx.window.R$styleable: int SplitPairRule_finishPrimaryWithSecondary
com.google.firestore.v1.RunAggregationQueryRequest: com.google.firestore.v1.RunAggregationQueryRequest DEFAULT_INSTANCE
com.cloudwebrtc.webrtc.R$attr: int splitMinSmallestWidth
com.cloudwebrtc.webrtc.R$id: int tag_unhandled_key_event_manager
com.google.firebase.firestore.proto.UnknownDocument: int NAME_FIELD_NUMBER
org.webrtc.PeerConnectionFactory: org.webrtc.PeerConnectionFactory$ThreadInfo staticWorkerThread
com.cloudwebrtc.webrtc.record.VideoFileRenderer: org.webrtc.EglBase$Context sharedContext
org.webrtc.PeerConnectionDependencies$Builder: org.webrtc.SSLCertificateVerifier sslCertificateVerifier
org.webrtc.PeerConnection$BundlePolicy: org.webrtc.PeerConnection$BundlePolicy MAXCOMPAT
androidx.lifecycle.Lifecycle$Event: androidx.lifecycle.Lifecycle$Event ON_START
org.webrtc.EncodedImage: java.nio.ByteBuffer buffer
com.google.protobuf.Timestamp: com.google.protobuf.Parser PARSER
com.google.firestore.v1.ExistenceFilter: com.google.firestore.v1.BloomFilter unchangedNames_
org.webrtc.EglRenderer: java.lang.Object handlerLock
org.webrtc.DynamicBitrateAdjuster: int BITRATE_ADJUSTMENT_STEPS
org.webrtc.PeerConnection$RTCConfiguration: org.webrtc.PeerConnection$PortPrunePolicy turnPortPrunePolicy
com.cloudwebrtc.webrtc.R$id: int text
org.webrtc.VideoEncoder$Settings: int numberOfCores
org.webrtc.audio.JavaAudioDeviceModule$Builder: int audioFormat
org.webrtc.PeerConnection$RTCConfiguration: java.lang.Integer stunCandidateKeepaliveIntervalMs
org.webrtc.PeerConnectionFactory$Options: int ADAPTER_TYPE_LOOPBACK
com.cloudwebrtc.webrtc.R$attr: int ttcIndex
io.flutter.embedding.engine.mutatorsstack.FlutterMutatorsStack: java.util.List mutators
org.webrtc.AndroidVideoDecoder: java.lang.Object renderedTextureMetadataLock
org.webrtc.AndroidVideoDecoder: android.view.Surface surface
org.webrtc.PeerConnectionFactory$Options: int ADAPTER_TYPE_ETHERNET
com.google.firestore.v1.CommitRequest: int WRITES_FIELD_NUMBER
org.webrtc.SurfaceViewRenderer: java.lang.String TAG
kotlinx.coroutines.CompletedExceptionally: int _handled
org.webrtc.RendererCommon$VideoLayoutMeasure: float visibleFractionMismatchOrientation
org.webrtc.NV12Buffer: int stride
org.webrtc.CameraCapturer: org.webrtc.SurfaceTextureHelper surfaceHelper
org.webrtc.RTCStats: java.lang.String id
com.cloudwebrtc.webrtc.R$id: int notification_main_column_container
androidx.window.embedding.SplitInfo: float splitRatio
com.google.firestore.v1.StructuredQuery: com.google.firestore.v1.Cursor endAt_
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer: java.lang.String ownerTag
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor: java.util.Map keyProviders
org.webrtc.HardwareVideoEncoder: org.webrtc.VideoFrameDrawer videoFrameDrawer
org.webrtc.NetworkMonitor$2: org.webrtc.NetworkMonitor this$0
org.webrtc.FrameCryptor$FrameCryptionState: org.webrtc.FrameCryptor$FrameCryptionState INTERNALERROR
androidx.window.layout.FoldingFeature$State: java.lang.String description
org.webrtc.EncodedImage$FrameType: org.webrtc.EncodedImage$FrameType[] $VALUES
org.webrtc.Priority: int HIGH
com.google.firestore.v1.StructuredQuery: com.google.firestore.v1.StructuredQuery$Filter where_
com.google.firestore.v1.BatchGetDocumentsResponse: int MISSING_FIELD_NUMBER
com.cloudwebrtc.webrtc.GetUserMediaImpl: com.cloudwebrtc.webrtc.StateProvider stateProvider
org.webrtc.ScreenCapturerAndroid: org.webrtc.SurfaceTextureHelper surfaceTextureHelper
com.google.firestore.v1.StructuredQuery$Projection: int FIELDS_FIELD_NUMBER
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$1: com.cloudwebrtc.webrtc.MethodCallHandlerImpl this$0
org.webrtc.CandidatePairChangeEvent: org.webrtc.IceCandidate remote
org.webrtc.HardwareVideoEncoder: int height
com.cloudwebrtc.webrtc.R$styleable: int[] ColorStateListItem
org.webrtc.Camera1Session: int cameraId
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_21
org.webrtc.voiceengine.WebRtcAudioTrack$AudioTrackThread: boolean keepAlive
org.webrtc.voiceengine.WebRtcAudioManager: boolean useStereoInput
com.cloudwebrtc.webrtc.OrientationAwareScreenCapturer: int width
com.google.firestore.v1.WriteResponse: com.google.protobuf.Timestamp commitTime_
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_8
com.google.firestore.bundle.BundledQuery: int STRUCTURED_QUERY_FIELD_NUMBER
org.webrtc.EglBase10Impl$Context: javax.microedition.khronos.egl.EGL10 egl
com.google.firestore.v1.TargetChange: int TARGET_CHANGE_TYPE_FIELD_NUMBER
com.cloudwebrtc.webrtc.SurfaceTextureRenderer: boolean isRenderingPaused
com.cloudwebrtc.webrtc.GetUserMediaImpl$3: com.cloudwebrtc.webrtc.GetUserMediaImpl this$0
org.webrtc.PeerConnection$CandidateNetworkPolicy: org.webrtc.PeerConnection$CandidateNetworkPolicy LOW_COST
com.google.firestore.v1.Write: com.google.protobuf.Internal$ProtobufList updateTransforms_
com.google.firestore.v1.BatchGetDocumentsResponse: com.google.protobuf.Parser PARSER
org.webrtc.CameraVideoCapturer$CameraStatistics: int frameCount
org.webrtc.voiceengine.WebRtcAudioUtils: java.lang.String[] BLACKLISTED_AEC_MODELS
com.google.protobuf.GeneratedMessageLite: int UNINITIALIZED_SERIALIZED_SIZE
org.webrtc.VideoCodecStatus: org.webrtc.VideoCodecStatus ERROR
org.webrtc.VideoProcessor$FrameAdaptationParameters: int scaleHeight
org.webrtc.PeerConnectionFactory$InitializationOptions$Builder: org.webrtc.NativeLibraryLoader nativeLibraryLoader
io.flutter.embedding.engine.FlutterJNI: java.util.Set engineLifecycleListeners
org.webrtc.StatsReport: java.lang.String type
com.cloudwebrtc.webrtc.utils.ObjectType: com.cloudwebrtc.webrtc.utils.ObjectType String
org.webrtc.ScreenCapturerAndroid: int height
org.webrtc.CameraCapturer: org.webrtc.CameraSession currentSession
org.webrtc.YuvConverter$ShaderCallbacks: float[] uCoeffs
com.google.firestore.v1.Write: java.lang.Object operation_
com.google.firestore.v1.StructuredAggregationQuery$Aggregation$Avg: com.google.firestore.v1.StructuredQuery$FieldReference field_
androidx.window.embedding.SplitRule: float splitRatio
org.webrtc.NetworkMonitorAutoDetect: android.content.IntentFilter intentFilter
com.google.firestore.v1.TargetChange: int targetIdsMemoizedSerializedSize
org.webrtc.ScreenCapturerAndroid$2: org.webrtc.ScreenCapturerAndroid this$0
org.webrtc.RendererCommon$VideoLayoutMeasure: float visibleFractionMatchOrientation
org.webrtc.VideoFileRenderer: int outputFileHeight
com.google.firestore.v1.MapValue: com.google.protobuf.Parser PARSER
androidx.window.layout.HardwareFoldingFeature: androidx.window.layout.HardwareFoldingFeature$Companion Companion
org.webrtc.voiceengine.WebRtcAudioManager$VolumeLogger$LogVolumeTask: int maxRingVolume
org.webrtc.AndroidVideoDecoder: int DEQUEUE_INPUT_TIMEOUT_US
org.webrtc.SoftwareVideoEncoderFactory$1: org.webrtc.SoftwareVideoEncoderFactory this$0
androidx.concurrent.futures.AbstractResolvableFuture$Waiter: androidx.concurrent.futures.AbstractResolvableFuture$Waiter next
org.webrtc.VideoTrack: java.util.IdentityHashMap sinks
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer$1: int _rotation
org.webrtc.audio.WebRtcAudioTrack: int DEFAULT_USAGE
org.webrtc.GlShader: int program
com.google.firestore.v1.StructuredQuery: int ORDER_BY_FIELD_NUMBER
com.cloudwebrtc.webrtc.R$styleable: int FontFamilyFont_fontStyle
org.webrtc.HardwareVideoEncoder: org.webrtc.EglBase14 textureEglBase
com.cloudwebrtc.webrtc.R$styleable: int SplitPlaceholderRule_placeholderActivityName
com.google.firestore.v1.ListenRequest: com.google.firestore.v1.ListenRequest DEFAULT_INSTANCE
org.webrtc.CameraCapturer: java.lang.String TAG
com.google.firestore.v1.StructuredQuery$UnaryFilter: int operandTypeCase_
org.webrtc.RtcCertificatePem: java.lang.String certificate
io.flutter.plugin.platform.SingleViewPresentation: android.content.Context outerContext
com.google.protobuf.Int32Value: com.google.protobuf.Int32Value DEFAULT_INSTANCE
io.flutter.embedding.android.FlutterSplashView$SavedState: android.os.Bundle splashScreenState
org.webrtc.PeerConnection$RTCConfiguration: java.lang.Boolean allowCodecSwitching
com.google.firestore.v1.StructuredQuery$Filter: com.google.protobuf.Parser PARSER
androidx.window.layout.FoldingFeature$Orientation: androidx.window.layout.FoldingFeature$Orientation$Companion Companion
com.cloudwebrtc.webrtc.PeerConnectionObserver: org.webrtc.PeerConnection peerConnection
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper: org.webrtc.VideoEncoder encoder
kotlinx.coroutines.scheduling.LimitingDispatcher: int inFlightTasks
org.webrtc.EglBase: int EGL_RECORDABLE_ANDROID
com.google.firebase.firestore.proto.NoDocument: com.google.protobuf.Parser PARSER
com.cloudwebrtc.webrtc.GetUserMediaImpl: int DEFAULT_HEIGHT
com.google.firebase.firestore.proto.UnknownDocument: int VERSION_FIELD_NUMBER
com.google.firestore.v1.BloomFilter: int BITS_FIELD_NUMBER
com.google.firestore.v1.Cursor: com.google.protobuf.Internal$ProtobufList values_
androidx.window.R$attr: int splitLayoutDirection
com.cloudwebrtc.webrtc.GetUserMediaImpl: java.util.Map mVideoCapturers
kotlinx.coroutines.InvokeOnCancelling: int _invoked
org.webrtc.MediaCodecUtils: int[] DECODER_COLOR_FORMATS
com.google.firestore.v1.StructuredQuery$FieldReference: com.google.protobuf.Parser PARSER
androidx.window.embedding.MatcherUtils: java.lang.String sMatchersTag
org.webrtc.PeerConnectionFactory$InitializationOptions$Builder: org.webrtc.Loggable loggable
org.webrtc.PeerConnection: long nativePeerConnection
com.google.firestore.v1.Target$DocumentsTarget: int DOCUMENTS_FIELD_NUMBER
org.webrtc.GlGenericDrawer: java.nio.FloatBuffer FULL_RECTANGLE_BUFFER
org.webrtc.ScreenCapturerAndroid: int VIRTUAL_DISPLAY_DPI
com.cloudwebrtc.webrtc.GetUserMediaImpl: java.lang.String PERMISSION_VIDEO
com.cloudwebrtc.webrtc.GetUserMediaImpl: java.lang.String GRANT_RESULTS
com.cloudwebrtc.webrtc.DataChannelObserver: java.util.ArrayList eventQueue
org.webrtc.RtpReceiver: org.webrtc.MediaStreamTrack cachedTrack
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$2: com.cloudwebrtc.webrtc.MethodCallHandlerImpl this$0
com.cloudwebrtc.webrtc.GetUserMediaImpl$VideoCapturerInfo: int fps
org.webrtc.SurfaceTextureHelper: org.webrtc.VideoSink pendingListener
org.webrtc.SurfaceViewRenderer: org.webrtc.SurfaceEglRenderer eglRenderer
androidx.window.layout.WindowInfoTrackerImpl: androidx.window.layout.WindowMetricsCalculator windowMetricsCalculator
com.google.android.gms.signin.internal.zaa: android.os.Parcelable$Creator CREATOR
org.webrtc.voiceengine.WebRtcAudioManager: boolean blacklistDeviceForOpenSLESUsage
com.google.firestore.v1.StructuredQuery$UnaryFilter: int OP_FIELD_NUMBER
com.google.firestore.bundle.BundledQuery: int LIMIT_TYPE_FIELD_NUMBER
com.google.firestore.v1.StructuredAggregationQuery$Aggregation: int operatorCase_
com.google.firestore.v1.Document: com.google.protobuf.Timestamp createTime_
com.cloudwebrtc.webrtc.R$id: int icon_group
org.webrtc.Camera2Session: boolean firstFrameReported
io.flutter.plugins.firebase.core.FlutterFirebasePluginRegistry: java.util.Map registeredPlugins
com.cloudwebrtc.webrtc.record.FrameCapturer: java.io.File file
com.google.type.LatLng: double latitude_
org.webrtc.NetworkMonitorAutoDetect$NetworkState: int underlyingNetworkSubtypeForVpn
androidx.window.layout.WindowMetricsCalculatorCompat: androidx.window.layout.WindowMetricsCalculatorCompat INSTANCE
org.webrtc.Camera2Session: android.os.Handler cameraThreadHandler
org.webrtc.GlTextureFrameBuffer: int frameBufferId
com.google.firestore.v1.Document: int CREATE_TIME_FIELD_NUMBER
androidx.window.layout.SidecarCompat: androidx.window.sidecar.SidecarInterface sidecar
com.cloudwebrtc.webrtc.SurfaceTextureRenderer: int rotatedFrameWidth
com.cloudwebrtc.webrtc.GetUserMediaImpl: boolean isFacing
com.google.firebase.firestore.proto.Target: long lastListenSequenceNumber_
org.webrtc.CameraEnumerationAndroid$1: int MIN_FPS_HIGH_VALUE_WEIGHT
org.webrtc.CameraCapturer$SwitchState: org.webrtc.CameraCapturer$SwitchState IN_PROGRESS
org.webrtc.CameraCapturer: org.webrtc.CameraVideoCapturer$CameraEventsHandler eventsHandler
org.webrtc.HardwareVideoEncoder: long lastKeyFrameNs
com.google.firestore.v1.BatchGetDocumentsResponse: com.google.firestore.v1.BatchGetDocumentsResponse DEFAULT_INSTANCE
com.cloudwebrtc.webrtc.R$styleable: int SplitPairRule_splitLayoutDirection
com.google.firestore.v1.StructuredQuery: com.google.protobuf.Parser PARSER
org.webrtc.PeerConnectionFactory: org.webrtc.PeerConnectionFactory$ThreadInfo staticNetworkThread
org.webrtc.HardwareVideoEncoder: org.webrtc.EglBase14$Context sharedContext
org.webrtc.HardwareVideoEncoder: long nextPresentationTimestampUs
androidx.concurrent.futures.AbstractResolvableFuture$Waiter: java.lang.Thread thread
org.webrtc.JavaI420Buffer: int strideY
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper: org.webrtc.VideoEncoderFactory primary
kotlinx.coroutines.DefaultExecutor: int debugStatus
androidx.window.embedding.MatcherUtils: boolean sDebugMatchers
com.google.firestore.v1.StructuredAggregationQuery$Aggregation$Sum: com.google.firestore.v1.StructuredQuery$FieldReference field_
com.cloudwebrtc.webrtc.R$attr: int fontProviderFetchStrategy
com.cloudwebrtc.webrtc.GetUserMediaImpl$NoSuchFieldWithNameException: com.cloudwebrtc.webrtc.GetUserMediaImpl this$0
com.google.firebase.firestore.proto.WriteBatch: int BASE_WRITES_FIELD_NUMBER
org.webrtc.PeerConnection$AdapterType: org.webrtc.PeerConnection$AdapterType LOOPBACK
androidx.window.embedding.ExtensionEmbeddingBackend: androidx.window.embedding.ExtensionEmbeddingBackend globalInstance
com.google.firestore.v1.AggregationResult: com.google.protobuf.MapFieldLite aggregateFields_
org.webrtc.EglBase$ConfigBuilder: boolean supportsPixelBuffer
org.webrtc.PeerConnectionFactory$Options: int ADAPTER_TYPE_CELLULAR
org.webrtc.MediaSource$State: org.webrtc.MediaSource$State ENDED
org.webrtc.voiceengine.WebRtcAudioEffects: android.media.audiofx.NoiseSuppressor ns
com.google.firestore.admin.v1.Index: int FIELDS_FIELD_NUMBER
org.webrtc.SurfaceViewRenderer: java.lang.String resourceName
org.webrtc.HardwareVideoEncoder: org.webrtc.MediaCodecWrapper codec
org.webrtc.RtpCapabilities$CodecCapability: java.lang.Integer clockRate
org.webrtc.PeerConnectionFactory: org.webrtc.PeerConnectionFactory$ThreadInfo staticSignalingThread
org.webrtc.FileVideoCapturer$VideoReaderY4M: java.io.RandomAccessFile mediaFile
androidx.window.layout.HardwareFoldingFeature: androidx.window.layout.HardwareFoldingFeature$Type type
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_15
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer: org.webrtc.MediaStream mediaStream
org.webrtc.CameraCapturer: int MAX_OPEN_CAMERA_ATTEMPTS
org.webrtc.PeerConnection$RtcpMuxPolicy: org.webrtc.PeerConnection$RtcpMuxPolicy REQUIRE
androidx.window.embedding.SplitController: java.util.concurrent.locks.ReentrantLock globalLock
com.google.firestore.v1.TargetChange: int CAUSE_FIELD_NUMBER
org.webrtc.RtpParameters$DegradationPreference: org.webrtc.RtpParameters$DegradationPreference BALANCED
org.webrtc.VideoEncoder$Settings: int startBitrate
com.google.firestore.v1.StructuredQuery$FieldReference: int FIELD_PATH_FIELD_NUMBER
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$3: com.cloudwebrtc.webrtc.MethodCallHandlerImpl this$0
androidx.window.R$styleable: int SplitPlaceholderRule_splitLayoutDirection
com.google.firestore.v1.Target: com.google.firestore.v1.Target DEFAULT_INSTANCE
com.google.firestore.v1.Target$DocumentsTarget: com.google.protobuf.Internal$ProtobufList documents_
com.google.firestore.v1.WriteResponse: com.google.protobuf.Internal$ProtobufList writeResults_
androidx.window.layout.WindowMetricsCalculator: androidx.window.layout.WindowMetricsCalculator$Companion Companion
org.webrtc.NetworkMonitorAutoDetect$SimpleNetworkCallback: java.util.Set availableNetworks
org.webrtc.NetworkMonitorAutoDetect: boolean isRegistered
com.cloudwebrtc.webrtc.R$styleable: int GradientColor_android_centerX
androidx.window.R$styleable: int SplitPairRule_finishSecondaryWithPrimary
org.webrtc.Camera1Session: org.webrtc.Histogram camera1ResolutionHistogram
org.webrtc.VideoFileRenderer: org.webrtc.YuvConverter yuvConverter
com.google.firestore.v1.DocumentChange: com.google.firestore.v1.DocumentChange DEFAULT_INSTANCE
org.webrtc.PeerConnectionFactory$Builder: org.webrtc.PeerConnectionFactory$Options options
androidx.window.R$styleable: int[] SplitPairRule
com.cloudwebrtc.webrtc.R$id: int accessibility_custom_action_24
io.flutter.plugins.firebase.core.FlutterFirebasePlugin: java.util.concurrent.ExecutorService cachedThreadPool
org.webrtc.PeerConnection$IceGatheringState: org.webrtc.PeerConnection$IceGatheringState GATHERING
com.google.protobuf.Timestamp: com.google.protobuf.Timestamp DEFAULT_INSTANCE
org.webrtc.EglBase10Impl: javax.microedition.khronos.egl.EGL10 egl
org.webrtc.CameraCapturer$9: org.webrtc.CameraCapturer this$0
com.google.firebase.firestore.proto.Target: int SNAPSHOT_VERSION_FIELD_NUMBER
androidx.versionedparcelable.ParcelImpl: android.os.Parcelable$Creator CREATOR
com.cloudwebrtc.webrtc.R$styleable: int ActivityFilter_activityAction
org.webrtc.Camera2Session: java.lang.String cameraId
com.google.firestore.v1.StructuredQuery$FieldFilter: int op_
com.cloudwebrtc.webrtc.record.VideoFileRenderer: java.lang.String MIME_TYPE
org.webrtc.Logging: boolean loggingEnabled
com.google.firestore.v1.AggregationResult: com.google.protobuf.Parser PARSER
com.google.firestore.v1.Target: int RESUME_TOKEN_FIELD_NUMBER
org.webrtc.RtpSender: void setFrameEncryptor(org.webrtc.FrameEncryptor)
com.cloudwebrtc.webrtc.PeerConnectionObserver: void onIceConnectionChange(org.webrtc.PeerConnection$IceConnectionState)
org.webrtc.voiceengine.WebRtcAudioTrack$WebRtcAudioTrackErrorCallback: void onWebRtcAudioTrackError(java.lang.String)
io.grpc.util.OutlierDetectionLoadBalancerProvider: java.lang.String getPolicyName()
com.cloudwebrtc.webrtc.PeerConnectionObserver: void onStandardizedIceConnectionChange(org.webrtc.PeerConnection$IceConnectionState)
org.webrtc.voiceengine.WebRtcAudioEffects: boolean isNoiseSuppressorExcludedByUUID()
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper: java.util.concurrent.ExecutorService getExecutor()
org.webrtc.voiceengine.WebRtcAudioRecord$AudioSamples: WebRtcAudioRecord$AudioSamples(android.media.AudioRecord,byte[])
org.webrtc.VideoFileRenderer: void lambda$renderFrameOnRenderThread$1(org.webrtc.VideoFrame$I420Buffer,org.webrtc.VideoFrame)
org.webrtc.EglBase10Impl: void release()
org.webrtc.voiceengine.WebRtcAudioRecord: boolean stopRecording()
com.google.firestore.v1.StructuredQuery$UnaryFilter: StructuredQuery$UnaryFilter()
androidx.window.embedding.SplitPairFilter: int hashCode()
org.webrtc.NetworkMonitor: org.webrtc.NetworkMonitor getInstance()
org.webrtc.RendererCommon$ScalingType: org.webrtc.RendererCommon$ScalingType[] values()
io.flutter.plugins.firebase.core.FlutterFirebasePlugin: com.google.android.gms.tasks.Task didReinitializeFirebaseCore()
kotlinx.coroutines.YieldContext: YieldContext()
org.webrtc.VideoEncoder$ScalingSettings: VideoEncoder$ScalingSettings()
org.webrtc.PeerConnection$TcpCandidatePolicy: org.webrtc.PeerConnection$TcpCandidatePolicy[] $values()
org.webrtc.MediaSource$State: org.webrtc.MediaSource$State[] $values()
io.flutter.embedding.engine.FlutterJNI: void onSurfaceWindowChanged(android.view.Surface)
org.webrtc.VideoFileRenderer$1: void run()
org.webrtc.EglBase10Impl: void createSurface(android.graphics.SurfaceTexture)
org.webrtc.audio.WebRtcAudioUtils: java.lang.String audioEncodingToString(int)
org.webrtc.voiceengine.WebRtcAudioManager$VolumeLogger: void stop()
com.cloudwebrtc.webrtc.PeerConnectionObserver: void onRemoveTrack(org.webrtc.RtpReceiver)
org.webrtc.DataChannel$Init: int getMaxRetransmits()
org.webrtc.RtpReceiver: long nativeSetObserver(long,org.webrtc.RtpReceiver$Observer)
com.twilio.audioswitch.AudioDevice: AudioDevice()
com.google.firebase.firestore.core.LimboDocumentChange$Type: com.google.firebase.firestore.core.LimboDocumentChange$Type[] values()
com.google.firebase.firestore.proto.UnknownDocument: UnknownDocument()
org.webrtc.SurfaceViewRenderer: void updateSurfaceSize()
org.webrtc.NetworkMonitorAutoDetect: void unregisterReceiver()
androidx.window.embedding.SplitRule: boolean checkParentMetrics(android.view.WindowMetrics)
org.webrtc.audio.WebRtcAudioRecord: WebRtcAudioRecord(android.content.Context,android.media.AudioManager)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void initialize(int)
org.webrtc.ScreenCapturerAndroid$2: ScreenCapturerAndroid$2(org.webrtc.ScreenCapturerAndroid)
org.webrtc.voiceengine.WebRtcAudioEffects: boolean isNoiseSuppressorEffectAvailable()
org.webrtc.GlGenericDrawer$ShaderType: org.webrtc.GlGenericDrawer$ShaderType[] $values()
org.webrtc.MediaCodecWrapperFactoryImpl$MediaCodecWrapperImpl: void flush()
org.webrtc.audio.WebRtcAudioManager: android.media.AudioManager getAudioManager(android.content.Context)
androidx.window.layout.SidecarWindowBackend: androidx.window.layout.ExtensionInterfaceCompat getWindowExtension()
org.webrtc.NetworkMonitorAutoDetect$ConnectivityManagerDelegate: void requestMobileNetwork(android.net.ConnectivityManager$NetworkCallback)
androidx.window.embedding.ActivityFilter: ActivityFilter(android.content.ComponentName,java.lang.String)
org.webrtc.Logging: void d(java.lang.String,java.lang.String)
com.cloudwebrtc.webrtc.utils.ConstraintsMap: double getDouble(java.lang.String)
com.google.firebase.firestore.core.FieldFilter$Operator: com.google.firebase.firestore.core.FieldFilter$Operator[] values()
org.webrtc.MediaSource: long getNativeMediaSource()
org.webrtc.PeerConnection: void nativeCreateAnswer(org.webrtc.SdpObserver,org.webrtc.MediaConstraints)
org.webrtc.voiceengine.WebRtcAudioManager: boolean isNoiseSuppressorSupported()
org.webrtc.RtpTransceiver: boolean isStopped()
io.flutter.embedding.engine.FlutterJNI: void nativeImageHeaderCallback(long,int,int)
androidx.window.layout.SidecarWindowBackend$WindowLayoutChangeCallbackWrapper: void setLastInfo(androidx.window.layout.WindowLayoutInfo)
io.flutter.view.AccessibilityViewEmbedder: void cacheVirtualIdMappings(android.view.View,int,int)
com.google.firestore.v1.CommitResponse: CommitResponse()
com.cloudwebrtc.webrtc.PeerConnectionObserver: org.webrtc.RtpReceiver getRtpReceiverById(java.lang.String)
com.cloudwebrtc.webrtc.PeerConnectionObserver: void getStatsForTrack(java.lang.String,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.EglRenderer: void notifyCallbacks(org.webrtc.VideoFrame,boolean)
org.webrtc.audio.WebRtcAudioTrack: int getBufferSizeInFrames()
org.webrtc.NetworkMonitorAutoDetect$ConnectivityManagerDelegate: org.webrtc.NetworkChangeDetector$NetworkInformation networkToInfo(android.net.Network)
org.webrtc.NetworkMonitorAutoDetect$SimpleNetworkCallback: void onLost(android.net.Network)
org.webrtc.TurnCustomizer: void dispose()
org.webrtc.MediaStreamTrack: MediaStreamTrack(long)
org.webrtc.MediaStream: void removeVideoTrack(long)
org.webrtc.NativeLibrary: void initialize(org.webrtc.NativeLibraryLoader,java.lang.String)
org.webrtc.SurfaceTextureHelper: void lambda$setTextureSize$2(int,int)
org.webrtc.PeerConnection: org.webrtc.PeerConnection$IceGatheringState iceGatheringState()
androidx.window.layout.WindowMetricsCalculator$Companion$decorator$1: java.lang.Object invoke(java.lang.Object)
org.webrtc.CameraCapturer$3: void run()
org.webrtc.audio.WebRtcAudioUtils: void logAudioDeviceInfo(java.lang.String,android.media.AudioManager)
org.webrtc.voiceengine.WebRtcAudioManager: boolean getStereoInput()
org.webrtc.MediaStream: boolean nativeAddAudioTrackToNativeStream(long,long)
org.webrtc.PeerConnection$RTCConfiguration: boolean getOfferExtmapAllowMixed()
org.webrtc.YuvHelper: void copyPlane(java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,int,int)
org.webrtc.EglRenderer: void resetStatistics(long)
org.webrtc.MediaStreamTrack: org.webrtc.MediaStreamTrack$State nativeGetState(long)
org.webrtc.PeerConnection$AdapterType: org.webrtc.PeerConnection$AdapterType[] $values()
org.webrtc.RtpCapabilities$CodecCapability: org.webrtc.MediaStreamTrack$MediaType getKind()
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper: org.webrtc.VideoEncoder$EncoderInfo getEncoderInfo$lambda-10(com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$5: boolean isEnabled(java.lang.String)
androidx.window.layout.WindowMetricsCalculator$Companion$decorator$1: androidx.window.layout.WindowMetricsCalculator invoke(androidx.window.layout.WindowMetricsCalculator)
com.cloudwebrtc.webrtc.BuildConfig: BuildConfig()
androidx.window.embedding.MatcherUtils: boolean wildcardMatch(java.lang.String,java.lang.String)
io.flutter.plugins.firebase.core.FlutterFirebasePluginRegistry: com.google.android.gms.tasks.Task didReinitializeFirebaseCore()
androidx.window.core.Bounds: int getBottom()
com.cloudwebrtc.webrtc.SurfaceTextureRenderer: SurfaceTextureRenderer(java.lang.String)
org.webrtc.Logging: void nativeEnableLogToDebugOutput(int)
org.webrtc.audio.WebRtcAudioManager: int getLowLatencyFramesPerBuffer(android.media.AudioManager)
io.grpc.LoadBalancerProvider: LoadBalancerProvider()
org.webrtc.MediaCodecWrapper: int dequeueInputBuffer(long)
org.webrtc.EglRenderer: void setErrorCallback(org.webrtc.EglRenderer$ErrorCallback)
org.webrtc.RtpTransceiver$RtpTransceiverInit: RtpTransceiver$RtpTransceiverInit()
org.webrtc.RtpSender: java.lang.String nativeGetMediaType(long)
org.webrtc.JavaI420Buffer: org.webrtc.VideoFrame$I420Buffer toI420()
com.cloudwebrtc.webrtc.PeerConnectionObserver: void getTransceivers(io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.PeerConnection$Observer: void onTrack(org.webrtc.RtpTransceiver)
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper: org.webrtc.VideoEncoder createEncoder(org.webrtc.VideoCodecInfo)
org.webrtc.JavaI420Buffer: void release()
io.flutter.plugins.firebase.firestore.FlutterFirebaseFirestoreTransactionResult: FlutterFirebaseFirestoreTransactionResult()
org.webrtc.VideoEncoder$ScalingSettings: VideoEncoder$ScalingSettings(boolean,int,int)
androidx.window.embedding.ExtensionEmbeddingBackend: java.util.concurrent.locks.ReentrantLock access$getGlobalLock$cp()
androidx.collection.SparseArrayCompat: SparseArrayCompat()
org.webrtc.MediaCodecUtils: boolean isSoftwareOnlyQOrHigher(android.media.MediaCodecInfo)
org.webrtc.SurfaceTextureHelper: org.webrtc.SurfaceTextureHelper create(java.lang.String,org.webrtc.EglBase$Context,boolean)
com.google.firebase.FirebaseCommonRegistrar: FirebaseCommonRegistrar()
com.google.protobuf.AbstractMessageLite: AbstractMessageLite()
io.grpc.okhttp.NegotiationType: io.grpc.okhttp.NegotiationType[] values()
com.google.firebase.firestore.Filter: Filter()
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin: FlutterWebRTCPlugin()
org.webrtc.VideoEncoderWrapper: boolean getScalingSettingsOn(org.webrtc.VideoEncoder$ScalingSettings)
org.webrtc.Camera2Session: void start()
org.webrtc.MediaStreamTrack$MediaType: MediaStreamTrack$MediaType(java.lang.String,int,int)
org.webrtc.CryptoOptions$Srtp: CryptoOptions$Srtp(org.webrtc.CryptoOptions,boolean,boolean,boolean)
org.webrtc.YuvConverter$ShaderCallbacks: void setPlaneU()
com.google.protobuf.LazyFieldLite: LazyFieldLite()
org.webrtc.PeerConnection$SdpSemantics: PeerConnection$SdpSemantics(java.lang.String,int)
org.webrtc.DefaultVideoDecoderFactory: DefaultVideoDecoderFactory(org.webrtc.VideoDecoderFactory)
com.cloudwebrtc.webrtc.utils.MediaConstraintsUtils: org.webrtc.MediaConstraints parseMediaConstraints(com.cloudwebrtc.webrtc.utils.ConstraintsMap)
org.webrtc.NV21Buffer: org.webrtc.VideoFrame$I420Buffer toI420()
org.webrtc.PeerConnection: void stopRtcEventLog()
org.webrtc.MediaStream: long getNativeMediaStream()
androidx.window.embedding.EmbeddingAdapter: java.lang.Object component1(android.util.Pair)
kotlin.jvm.internal.CallableReference: kotlin.reflect.KVisibility getVisibility()
com.cloudwebrtc.webrtc.audio.AudioSwitchManager: void enableSpeakerphone(boolean)
org.webrtc.CallSessionFileRotatingLogSink: long nativeAddSink(java.lang.String,int,int)
org.webrtc.PeerConnection: boolean nativeStartRtcEventLog(int,int)
io.flutter.embedding.engine.FlutterJNI: void notifyLowMemoryWarning()
org.webrtc.VideoCodecStatus: int getNumber()
org.webrtc.CameraCapturer$2: void onCameraError(org.webrtc.CameraSession,java.lang.String)
org.webrtc.VideoEncoder: org.webrtc.VideoCodecStatus setRateAllocation(org.webrtc.VideoEncoder$BitrateAllocation,int)
io.flutter.embedding.engine.mutatorsstack.FlutterMutatorsStack: void pushClipRRect(int,int,int,int,float[])
org.webrtc.voiceengine.WebRtcAudioRecord: void nativeCacheDirectBufferAddress(java.nio.ByteBuffer,long)
androidx.window.embedding.MatcherUtils: MatcherUtils()
org.webrtc.PeerConnection$PortPrunePolicy: PeerConnection$PortPrunePolicy(java.lang.String,int)
org.webrtc.voiceengine.WebRtcAudioRecord: void setOnAudioSamplesReady(org.webrtc.voiceengine.WebRtcAudioRecord$WebRtcAudioRecordSamplesReadyCallback)
com.cloudwebrtc.webrtc.utils.ConstraintsMap: void putByte(java.lang.String,byte[])
org.webrtc.PeerConnection: long getNativePeerConnection()
com.cloudwebrtc.webrtc.R$style: R$style()
com.google.firestore.v1.StructuredQuery$Filter$FilterTypeCase: com.google.firestore.v1.StructuredQuery$Filter$FilterTypeCase valueOf(java.lang.String)
org.webrtc.NetworkMonitor: org.webrtc.NetworkChangeDetector getNetworkChangeDetector()
org.webrtc.audio.WebRtcAudioManager: int getMinInputFrameSize(int,int)
org.webrtc.voiceengine.WebRtcAudioRecord: void setMicrophoneMute(boolean)
com.cloudwebrtc.webrtc.utils.PermissionUtils: void requestPermissions(android.content.Context,android.app.Activity,java.lang.String[],android.os.ResultReceiver)
androidx.window.layout.WindowInfoTracker$-CC: void overrideDecorator(androidx.window.layout.WindowInfoTrackerDecorator)
io.flutter.embedding.engine.renderer.SurfaceTextureWrapper: android.graphics.SurfaceTexture surfaceTexture()
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback: boolean access$200(io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback)
io.flutter.view.AccessibilityBridge$AccessibilityFeature: io.flutter.view.AccessibilityBridge$AccessibilityFeature[] values()
org.webrtc.EglRenderer: void createEglSurface(android.view.Surface)
org.webrtc.NetworkMonitor: void setNetworkChangeDetectorFactory(org.webrtc.NetworkChangeDetectorFactory)
kotlin.coroutines.jvm.internal.BaseContinuationImpl: kotlin.coroutines.Continuation create(java.lang.Object,kotlin.coroutines.Continuation)
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper: org.webrtc.VideoCodecStatus release()
org.webrtc.CameraSession$FailureType: CameraSession$FailureType(java.lang.String,int)
com.cloudwebrtc.webrtc.record.AudioTrackInterceptor: int getBufferSizeInFrames()
org.webrtc.PeerConnection$RTCConfiguration: boolean getActiveResetSrtpParams()
com.google.android.gms.common.api.internal.zzb: zzb()
androidx.window.layout.ExtensionsWindowLayoutInfoAdapter: ExtensionsWindowLayoutInfoAdapter()
kotlin.coroutines.jvm.internal.BaseContinuationImpl: BaseContinuationImpl(kotlin.coroutines.Continuation)
org.webrtc.MediaCodecWrapperFactoryImpl$MediaCodecWrapperImpl: int dequeueInputBuffer(long)
com.cloudwebrtc.webrtc.utils.ConstraintsArray: ConstraintsArray()
org.webrtc.GlShader: void setVertexAttribArray(java.lang.String,int,java.nio.FloatBuffer)
org.webrtc.audio.AudioDeviceModule: void setMicrophoneMute(boolean)
com.cloudwebrtc.webrtc.GetUserMediaImpl$4: void onCameraSwitchDone(boolean)
io.flutter.embedding.engine.FlutterJNI: void setAccessibilityFeatures(int)
org.webrtc.NetworkMonitor$2: void onConnectionTypeChanged(org.webrtc.NetworkChangeDetector$ConnectionType)
io.flutter.embedding.engine.FlutterJNI: void nativeSetViewportMetrics(long,float,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int[],int[],int[])
org.webrtc.PeerConnection$SignalingState: org.webrtc.PeerConnection$SignalingState[] values()
org.webrtc.EglBase10Impl: org.webrtc.EglBase$Context getEglBaseContext()
kotlinx.coroutines.CompletionHandlerBase: CompletionHandlerBase()
io.flutter.view.AccessibilityBridge$LocaleStringAttribute: AccessibilityBridge$LocaleStringAttribute()
org.webrtc.PeerConnectionFactory$Builder: org.webrtc.PeerConnectionFactory$Builder setAudioEncoderFactoryFactory(org.webrtc.AudioEncoderFactoryFactory)
org.webrtc.JavaI420Buffer: java.nio.ByteBuffer getDataU()
io.flutter.embedding.engine.FlutterJNI: void handlePlatformMessage(java.lang.String,java.nio.ByteBuffer,int,long)
com.cloudwebrtc.webrtc.utils.PermissionUtils: void requestPermissions(android.content.Context,android.app.Activity,java.lang.String[],com.cloudwebrtc.webrtc.utils.PermissionUtils$Callback)
org.webrtc.NetworkMonitorAutoDetect$ConnectivityManagerDelegate: org.webrtc.NetworkMonitorAutoDetect$NetworkState getNetworkState()
androidx.window.embedding.ExtensionEmbeddingBackend: void registerRule(androidx.window.embedding.EmbeddingRule)
com.google.firestore.v1.ListenResponse$ResponseTypeCase: com.google.firestore.v1.ListenResponse$ResponseTypeCase[] values()
org.webrtc.VideoCodecInfo: boolean equals(java.lang.Object)
org.webrtc.audio.WebRtcAudioRecord: void setPreferredDevice(android.media.AudioDeviceInfo)
org.webrtc.voiceengine.WebRtcAudioManager: int getMinInputFrameSize(int,int)
com.google.firestore.v1.StructuredQuery$Filter: StructuredQuery$Filter()
org.webrtc.EglBase$-CC: int getOpenGlesVersionFromConfig(int[])
org.webrtc.RtpCapabilities$CodecCapability: int getPreferredPayloadType()
io.flutter.embedding.engine.FlutterOverlaySurface: int getId()
org.webrtc.RtpTransceiver: void dispose()
kotlin.coroutines.jvm.internal.ContinuationImpl: kotlin.coroutines.CoroutineContext getContext()
io.flutter.plugins.pathprovider.Messages$StorageDirectory: io.flutter.plugins.pathprovider.Messages$StorageDirectory[] values()
com.cloudwebrtc.webrtc.utils.MediaConstraintsUtils: void parseConstraints(com.cloudwebrtc.webrtc.utils.ConstraintsMap,java.util.List)
org.webrtc.Camera1Session: int getFrameOrientation()
com.google.gson.stream.JsonToken: com.google.gson.stream.JsonToken valueOf(java.lang.String)
androidx.core.content.ContextCompat$Api24Impl: java.io.File getDataDir(android.content.Context)
kotlin.jvm.internal.Lambda: java.lang.String toString()
org.webrtc.PeerConnectionFactory: void printStackTraces()
androidx.window.layout.WindowMetrics: int hashCode()
org.webrtc.VideoTrack: long getNativeVideoTrack()
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin: void onAttachedToEngine(io.flutter.embedding.engine.plugins.FlutterPlugin$FlutterPluginBinding)
org.webrtc.voiceengine.WebRtcAudioManager: void assertTrue(boolean)
org.webrtc.MediaSource$State: org.webrtc.MediaSource$State[] values()
androidx.window.core.Version: int compareTo(java.lang.Object)
org.webrtc.MediaCodecWrapper: void flush()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$3: void onSetSuccess()
org.webrtc.VideoFrame$I420Buffer$-CC: int $default$getBufferType(org.webrtc.VideoFrame$I420Buffer)
com.cloudwebrtc.webrtc.utils.AnyThreadSink: void lambda$error$1(java.lang.String,java.lang.String,java.lang.Object)
org.webrtc.PeerConnection$RTCConfiguration: org.webrtc.PeerConnection$PortPrunePolicy getTurnPortPrunePolicy()
org.webrtc.CameraEnumerator: org.webrtc.CameraVideoCapturer createCapturer(java.lang.String,org.webrtc.CameraVideoCapturer$CameraEventsHandler)
org.webrtc.SimulcastVideoEncoderFactory: org.webrtc.VideoEncoder createEncoder(org.webrtc.VideoCodecInfo)
io.grpc.util.OutlierDetectionLoadBalancerProvider: io.grpc.NameResolver$ConfigOrError parseLoadBalancingPolicyConfig(java.util.Map)
com.cloudwebrtc.webrtc.utils.AnyThreadResult: AnyThreadResult(io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.voiceengine.WebRtcAudioTrack$AudioTrackStartErrorCode: org.webrtc.voiceengine.WebRtcAudioTrack$AudioTrackStartErrorCode valueOf(java.lang.String)
org.webrtc.Camera2Session: void create(org.webrtc.CameraSession$CreateSessionCallback,org.webrtc.CameraSession$Events,android.content.Context,android.hardware.camera2.CameraManager,org.webrtc.SurfaceTextureHelper,java.lang.String,int,int,int)
org.webrtc.audio.WebRtcAudioTrack: void reportWebRtcAudioTrackError(java.lang.String)
kotlin.jvm.internal.CallableReference: boolean isOpen()
org.webrtc.EglBase10Impl: void detachCurrent()
io.flutter.embedding.engine.FlutterJNI: void nativeOnVsync(long,long,long)
org.webrtc.FileVideoCapturer$VideoReaderY4M: void close()
org.webrtc.HardwareVideoEncoder: org.webrtc.VideoCodecStatus encodeTextureBuffer(org.webrtc.VideoFrame,long)
org.webrtc.PeerConnection$Observer: void onIceConnectionChange(org.webrtc.PeerConnection$IceConnectionState)
io.grpc.ConnectivityState: io.grpc.ConnectivityState valueOf(java.lang.String)
org.webrtc.CameraCapturer$1: void onFailure(org.webrtc.CameraSession$FailureType,java.lang.String)
org.webrtc.Camera2Capturer: void printStackTrace()
org.webrtc.GlRectDrawer: GlRectDrawer()
org.webrtc.HardwareVideoEncoder: org.webrtc.VideoCodecStatus setRateAllocation(org.webrtc.VideoEncoder$BitrateAllocation,int)
org.webrtc.LibvpxVp8Decoder: LibvpxVp8Decoder()
org.webrtc.audio.WebRtcAudioTrack$AudioTrackThread: WebRtcAudioTrack$AudioTrackThread(org.webrtc.audio.WebRtcAudioTrack,java.lang.String)
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin$LifeCycleObserver: void onActivityCreated(android.app.Activity,android.os.Bundle)
com.google.firebase.firestore.remote.TestingHooks$ExistenceFilterBloomFilterInfo: TestingHooks$ExistenceFilterBloomFilterInfo()
org.webrtc.EglRenderer$FrameListenerAndParams: EglRenderer$FrameListenerAndParams(org.webrtc.EglRenderer$FrameListener,float,org.webrtc.RendererCommon$GlDrawer,boolean)
org.webrtc.EglBase14Impl: int surfaceWidth()
com.google.firebase.firestore.DocumentChange$Type: com.google.firebase.firestore.DocumentChange$Type valueOf(java.lang.String)
androidx.core.app.CoreComponentFactory: CoreComponentFactory()
com.cloudwebrtc.webrtc.utils.PermissionUtils$RequestPermissionsFragment: void onResume()
org.webrtc.NativeAndroidVideoTrackSource: NativeAndroidVideoTrackSource(long)
com.cloudwebrtc.webrtc.utils.PermissionUtils$RequestPermissionsFragment: PermissionUtils$RequestPermissionsFragment()
com.google.protobuf.UnknownFieldSetLite: UnknownFieldSetLite()
com.google.firestore.v1.StructuredQuery$Builder: StructuredQuery$Builder()
org.webrtc.voiceengine.WebRtcAudioTrack$AudioTrackStartErrorCode: WebRtcAudioTrack$AudioTrackStartErrorCode(java.lang.String,int)
androidx.window.embedding.SplitPlaceholderRule: int hashCode()
io.grpc.okhttp.OkHttpChannelBuilder: io.grpc.okhttp.OkHttpChannelBuilder transportExecutor(java.util.concurrent.Executor)
org.webrtc.RTCStats: RTCStats(long,java.lang.String,java.lang.String,java.util.Map)
org.webrtc.PeerConnectionFactory$Builder: org.webrtc.PeerConnectionFactory$Builder setVideoDecoderFactory(org.webrtc.VideoDecoderFactory)
com.cloudwebrtc.webrtc.utils.PermissionUtils$Callback: void invoke(java.lang.String[],int[])
org.webrtc.CallSessionFileRotatingLogSink: void nativeDeleteSink(long)
org.webrtc.PeerConnectionFactory$InitializationOptions$Builder: org.webrtc.PeerConnectionFactory$InitializationOptions createInitializationOptions()
org.webrtc.WrappedNativeVideoDecoder: org.webrtc.VideoCodecStatus initDecode(org.webrtc.VideoDecoder$Settings,org.webrtc.VideoDecoder$Callback)
androidx.core.graphics.drawable.IconCompatParcelizer: void write(androidx.core.graphics.drawable.IconCompat,androidx.versionedparcelable.VersionedParcel)
io.flutter.embedding.engine.FlutterJNI: void addEngineLifecycleListener(io.flutter.embedding.engine.FlutterEngine$EngineLifecycleListener)
org.webrtc.audio.WebRtcAudioTrack: void logMainParameters()
org.webrtc.NetworkMonitor: void notifyObserversOfConnectionTypeChange(org.webrtc.NetworkChangeDetector$ConnectionType)
org.webrtc.CameraSession$Events: void onCameraClosed(org.webrtc.CameraSession)
com.cloudwebrtc.webrtc.GetUserMediaImpl$ScreenRequestPermissionsFragment: void checkSelfPermissions(boolean)
androidx.window.embedding.MatcherUtils: boolean areActivityOrIntentComponentsMatching$window_release(android.app.Activity,android.content.ComponentName)
io.flutter.embedding.android.FlutterActivity: FlutterActivity()
org.webrtc.VideoFrame$TextureBuffer: int getTextureId()
org.webrtc.PeerConnectionFactory: void onNetworkThreadReady()
com.google.firebase.firestore.local.Persistence: Persistence()
com.cloudwebrtc.webrtc.utils.EglUtils: EglUtils()
org.webrtc.voiceengine.WebRtcAudioUtils: boolean useWebRtcBasedAutomaticGainControl()
com.cloudwebrtc.webrtc.GetUserMediaImpl: void lambda$requestPermissions$1(java.util.ArrayList,com.cloudwebrtc.webrtc.utils.Callback,com.cloudwebrtc.webrtc.utils.Callback,java.lang.String[],int[])
androidx.concurrent.futures.AbstractResolvableFuture$Waiter: AbstractResolvableFuture$Waiter()
com.cloudwebrtc.webrtc.PeerConnectionObserver: void restartIce()
org.webrtc.Logging$TraceLevel: org.webrtc.Logging$TraceLevel valueOf(java.lang.String)
org.webrtc.ThreadUtils$1CaughtException: ThreadUtils$1CaughtException()
org.webrtc.EglRenderer: void setFpsReduction(float)
com.google.common.base.Optional: Optional()
org.webrtc.LibvpxVp9Encoder: LibvpxVp9Encoder()
androidx.window.embedding.SplitPairRule: androidx.window.embedding.SplitPairRule plus$window_release(androidx.window.embedding.SplitPairFilter)
io.flutter.plugins.firebase.core.FlutterFirebaseCoreRegistrar: java.util.List getComponents()
org.webrtc.CameraCapturer$4: void onCameraFreezed(java.lang.String)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void rtpTransceiverGetCurrentDirection(java.lang.String,java.lang.String,io.flutter.plugin.common.MethodChannel$Result)
kotlinx.coroutines.scheduling.WorkQueue: WorkQueue()
com.google.firestore.v1.BloomFilter: BloomFilter()
org.webrtc.voiceengine.BuildInfo: int getSdkVersion()
org.webrtc.SurfaceViewRenderer: void addFrameListener(org.webrtc.EglRenderer$FrameListener,float)
org.webrtc.NetworkMonitorAutoDetect$ConnectivityManagerDelegate: boolean checkFieldTrial(java.lang.String,java.lang.String,boolean)
io.grpc.okhttp.internal.Platform$TlsExtensionType: io.grpc.okhttp.internal.Platform$TlsExtensionType valueOf(java.lang.String)
org.webrtc.ThreadUtils$ThreadChecker: ThreadUtils$ThreadChecker()
org.webrtc.PeerConnection$RTCConfiguration: org.webrtc.PeerConnection$ContinualGatheringPolicy getContinualGatheringPolicy()
com.google.firebase.firestore.proto.Target$TargetTypeCase: com.google.firebase.firestore.proto.Target$TargetTypeCase[] values()
org.webrtc.PeerConnection$RTCConfiguration: boolean getEnableCpuOveruseDetection()
org.webrtc.CryptoOptions: org.webrtc.CryptoOptions$Builder builder()
org.webrtc.audio.JavaAudioDeviceModule$Builder: org.webrtc.audio.JavaAudioDeviceModule$Builder setUseStereoOutput(boolean)
org.webrtc.audio.JavaAudioDeviceModule$AudioRecordErrorCallback: void onWebRtcAudioRecordError(java.lang.String)
io.flutter.embedding.engine.FlutterJNI: void updateCustomAccessibilityActions(java.nio.ByteBuffer,java.lang.String[])
com.google.firestore.v1.WriteResult: WriteResult()
org.webrtc.RtcCertificatePem: org.webrtc.RtcCertificatePem generateCertificate(long)
org.webrtc.EglRenderer: void setLayoutAspectRatio(float)
org.webrtc.SurfaceTextureHelper$1: org.webrtc.SurfaceTextureHelper call()
org.webrtc.PeerConnection$TlsCertPolicy: org.webrtc.PeerConnection$TlsCertPolicy valueOf(java.lang.String)
org.webrtc.DtmfSender: boolean canInsertDtmf()
io.flutter.plugins.firebase.core.FlutterFirebasePluginRegistry: void lambda$didReinitializeFirebaseCore$1(com.google.android.gms.tasks.TaskCompletionSource)
org.webrtc.RTCStatsCollectorCallback: void onStatsDelivered(org.webrtc.RTCStatsReport)
org.webrtc.HardwareVideoDecoderFactory$1: boolean test(java.lang.Object)
io.grpc.util.SecretRoundRobinLoadBalancerProvider$Provider: java.lang.String getPolicyName()
com.google.firebase.database.collection.LLRBNode$Color: com.google.firebase.database.collection.LLRBNode$Color[] values()
org.webrtc.Size: boolean equals(java.lang.Object)
com.google.protobuf.Int32Value: Int32Value()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$3: void onSetFailure(java.lang.String)
org.webrtc.CameraEnumerator: java.lang.String[] getDeviceNames()
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin: void startListening(android.content.Context,io.flutter.plugin.common.BinaryMessenger,io.flutter.view.TextureRegistry)
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin$LifeCycleObserver: void onDestroy(androidx.lifecycle.LifecycleOwner)
org.webrtc.MediaCodecVideoDecoderFactory: org.webrtc.VideoDecoder createDecoder(org.webrtc.VideoCodecInfo)
com.cloudwebrtc.webrtc.utils.ConstraintsArray: int getInt(int)
org.webrtc.DataChannel: void close()
org.webrtc.TextureBufferImpl: void lambda$new$0(org.webrtc.TextureBufferImpl$RefCountMonitor)
org.webrtc.VideoEncoderWrapper: java.lang.Integer getScalingSettingsLow(org.webrtc.VideoEncoder$ScalingSettings)
org.webrtc.CameraEnumerationAndroid$CaptureFormat$FramerateRange: CameraEnumerationAndroid$CaptureFormat$FramerateRange(int,int)
org.webrtc.VideoFrame$TextureBuffer$Type: int getGlTarget()
org.webrtc.NetworkChangeDetector$ConnectionType: org.webrtc.NetworkChangeDetector$ConnectionType[] values()
org.webrtc.SSLCertificateVerifier: boolean verify(byte[])
com.cloudwebrtc.webrtc.OrientationAwareScreenCapturer: OrientationAwareScreenCapturer(android.content.Intent,android.media.projection.MediaProjection$Callback)
com.cloudwebrtc.webrtc.R$color: R$color()
org.webrtc.RendererCommon$VideoLayoutMeasure: void setVisibleFraction(float,float)
com.google.firestore.v1.AggregationResult: AggregationResult()
org.webrtc.VideoFrameDrawer: int distance(float,float,float,float)
org.webrtc.audio.WebRtcAudioTrack: void nativeCacheDirectBufferAddress(long,java.nio.ByteBuffer)
org.webrtc.PeerConnection: void dispose()
org.webrtc.Camera2Session: void checkIsOnCameraThread()
org.webrtc.TimestampAligner: long nativeCreateTimestampAligner()
org.webrtc.voiceengine.WebRtcAudioManager: int getLowLatencyInputFramesPerBuffer()
org.webrtc.TextureBufferImpl: org.webrtc.TextureBufferImpl applyTransformMatrix(android.graphics.Matrix,int,int,int,int)
org.webrtc.VideoFrameDrawer: void drawFrame(org.webrtc.VideoFrame,org.webrtc.RendererCommon$GlDrawer)
io.flutter.embedding.engine.FlutterJNI: android.graphics.Bitmap getBitmap()
org.webrtc.VideoDecoder: java.lang.String getImplementationName()
kotlin.jvm.internal.FunctionReference: kotlin.reflect.KCallable getReflected()
org.webrtc.audio.JavaAudioDeviceModule$AudioTrackErrorCallback: void onWebRtcAudioTrackError(java.lang.String)
androidx.window.core.Version$Companion: androidx.window.core.Version getUNKNOWN()
org.webrtc.EglRenderer: void addFrameListener(org.webrtc.EglRenderer$FrameListener,float)
androidx.window.layout.SidecarWindowBackend$WindowLayoutChangeCallbackWrapper: androidx.window.layout.WindowLayoutInfo getLastInfo()
org.webrtc.Predicate$2: boolean test(java.lang.Object)
com.cloudwebrtc.webrtc.SurfaceTextureRenderer: void updateFrameDimensionsAndReportEvents(org.webrtc.VideoFrame)
androidx.window.embedding.ActivityStack: boolean isEmpty()
org.webrtc.EncodedImage$FrameType: org.webrtc.EncodedImage$FrameType[] values()
org.webrtc.NetworkMonitorAutoDetect$ConnectivityManagerDelegate: void releaseCallback(android.net.ConnectivityManager$NetworkCallback)
org.webrtc.CryptoOptions$Srtp: boolean getEnableAes128Sha1_32CryptoCipher()
com.cloudwebrtc.webrtc.utils.ObjectType: com.cloudwebrtc.webrtc.utils.ObjectType valueOf(java.lang.String)
org.webrtc.NetworkMonitorAutoDetect$ConnectivityManagerDelegate: java.util.List getActiveNetworkList()
com.google.firebase.firestore.util.AsyncQueue: AsyncQueue()
androidx.window.layout.SidecarWindowBackend: java.util.concurrent.CopyOnWriteArrayList getWindowLayoutChangeCallbacks()
org.webrtc.VideoDecoder: org.webrtc.VideoCodecStatus release()
androidx.window.embedding.SplitPairFilter: java.lang.String getSecondaryActivityIntentAction()
org.webrtc.CameraCapturer$3: CameraCapturer$3(org.webrtc.CameraCapturer)
org.webrtc.JavaI420Buffer: java.nio.ByteBuffer getDataV()
org.webrtc.audio.WebRtcAudioEffects: boolean effectTypeIsVoIP(java.util.UUID)
androidx.window.embedding.SplitController: androidx.window.embedding.SplitController access$getGlobalInstance$cp()
org.webrtc.SoftwareVideoEncoderFactory$1: SoftwareVideoEncoderFactory$1(org.webrtc.SoftwareVideoEncoderFactory,long)
org.webrtc.Predicate$3: Predicate$3(org.webrtc.Predicate)
org.webrtc.EglRenderer: void clearImage()
org.webrtc.MediaStream: boolean nativeAddVideoTrackToNativeStream(long,long)
org.webrtc.voiceengine.BuildInfo: java.lang.String getDeviceManufacturer()
org.webrtc.BaseBitrateAdjuster: void reportEncodedFrame(int)
org.webrtc.VideoFrame$Buffer: org.webrtc.VideoFrame$I420Buffer toI420()
com.google.firebase.firestore.model.FieldIndex$Segment: FieldIndex$Segment()
kotlin.coroutines.AbstractCoroutineContextElement: AbstractCoroutineContextElement(kotlin.coroutines.CoroutineContext$Key)
org.webrtc.ThreadUtils$3: void run()
org.webrtc.NetworkMonitorAutoDetect: java.util.List getActiveNetworkList()
org.webrtc.audio.JavaAudioDeviceModule$Builder: org.webrtc.audio.JavaAudioDeviceModule$Builder setAudioTrackErrorCallback(org.webrtc.audio.JavaAudioDeviceModule$AudioTrackErrorCallback)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void mediaStreamRemoveTrack(java.lang.String,java.lang.String,io.flutter.plugin.common.MethodChannel$Result)
io.flutter.embedding.engine.FlutterJNI: void onRenderingStopped()
org.webrtc.MediaCodecVideoDecoderFactory: boolean isCodecAllowed(android.media.MediaCodecInfo)
org.webrtc.AndroidVideoDecoder: AndroidVideoDecoder(org.webrtc.MediaCodecWrapperFactory,java.lang.String,org.webrtc.VideoCodecMimeType,int,org.webrtc.EglBase$Context)
org.webrtc.PeerConnection: org.webrtc.DataChannel nativeCreateDataChannel(java.lang.String,org.webrtc.DataChannel$Init)
org.webrtc.MediaStream: boolean addTrack(org.webrtc.VideoTrack)
org.webrtc.VideoCapturer: void stopCapture()
org.webrtc.MediaConstraints: java.lang.String stringifyKeyValuePairList(java.util.List)
org.webrtc.MediaCodecWrapperFactoryImpl$MediaCodecWrapperImpl: android.media.MediaFormat getOutputFormat()
org.webrtc.EglBase10Impl: void swapBuffers()
com.cloudwebrtc.webrtc.utils.PermissionUtils: void access$000(android.os.ResultReceiver,int,java.lang.String[],int[])
androidx.window.core.Version: androidx.window.core.Version access$getCURRENT$cp()
org.webrtc.audio.JavaAudioDeviceModule: JavaAudioDeviceModule(android.content.Context,android.media.AudioManager,org.webrtc.audio.WebRtcAudioRecord,org.webrtc.audio.WebRtcAudioTrack,int,int,boolean,boolean)
org.webrtc.MediaCodecWrapperFactoryImpl$MediaCodecWrapperImpl: void queueInputBuffer(int,int,int,long,int)
io.grpc.okhttp.internal.framed.HeadersMode: io.grpc.okhttp.internal.framed.HeadersMode valueOf(java.lang.String)
androidx.window.embedding.ExtensionEmbeddingBackend$Companion: androidx.window.embedding.EmbeddingInterfaceCompat initAndVerifyEmbeddingExtension()
org.webrtc.CameraEnumerator: boolean isFrontFacing(java.lang.String)
kotlin.jvm.internal.CallableReference: java.lang.Object callBy(java.util.Map)
org.webrtc.PeerConnection: boolean nativeRemoveTrack(long)
org.webrtc.voiceengine.WebRtcAudioTrack: int channelCountToConfiguration(int)
org.webrtc.PeerConnectionFactory$Builder: org.webrtc.PeerConnectionFactory$Builder setFecControllerFactoryFactoryInterface(org.webrtc.FecControllerFactoryFactoryInterface)
org.webrtc.PeerConnection: void nativeSetRemoteDescription(org.webrtc.SdpObserver,org.webrtc.SessionDescription)
androidx.window.layout.FoldingFeature: androidx.window.layout.FoldingFeature$Orientation getOrientation()
org.webrtc.voiceengine.WebRtcAudioEffects: boolean isAcousticEchoCancelerSupported()
org.webrtc.TurnCustomizer: void checkTurnCustomizerExists()
org.webrtc.PeerConnection: org.webrtc.RtcCertificatePem nativeGetCertificate()
io.flutter.embedding.android.FlutterTextureView: void setRenderSurface(android.view.Surface)
org.webrtc.CameraEnumerationAndroid$CaptureFormat: int frameSize(int,int,int)
org.webrtc.RtpTransceiver: boolean nativeStopped(long)
org.webrtc.NativeAndroidVideoTrackSource: void nativeSetIsScreencast(long,boolean)
androidx.window.layout.SidecarWindowBackend: void registerLayoutChangeCallback(android.app.Activity,java.util.concurrent.Executor,androidx.core.util.Consumer)
com.cloudwebrtc.webrtc.audio.AudioDeviceKind: AudioDeviceKind(java.lang.String,int,java.lang.String,java.lang.Class)
com.cloudwebrtc.webrtc.PeerConnectionObserver: java.lang.String iceGatheringStateString(org.webrtc.PeerConnection$IceGatheringState)
org.webrtc.CameraVideoCapturer: void addMediaRecorderToCamera(android.media.MediaRecorder,org.webrtc.CameraVideoCapturer$MediaRecorderHandler)
androidx.window.embedding.SplitController: void access$setStaticSplitRules(androidx.window.embedding.SplitController,java.util.Set)
androidx.window.layout.ExtensionsWindowLayoutInfoAdapter: boolean validBounds(android.app.Activity,androidx.window.core.Bounds)
org.webrtc.PeerConnectionDependencies$Builder: PeerConnectionDependencies$Builder(org.webrtc.PeerConnection$Observer)
com.cloudwebrtc.webrtc.PeerConnectionObserver: void handleStatsReport(org.webrtc.RTCStatsReport,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.Camera1Enumerator: java.util.List convertSizes(java.util.List)
org.webrtc.RtpParameters$HeaderExtension: boolean getEncrypted()
io.flutter.view.AccessibilityViewEmbedder: void addChildrenToFlutterNode(android.view.accessibility.AccessibilityNodeInfo,android.view.View,android.view.accessibility.AccessibilityNodeInfo)
com.google.firestore.v1.TransactionOptions$ReadOnly: TransactionOptions$ReadOnly()
androidx.window.layout.SidecarCompat$DistinctSidecarElementCallback: void onWindowLayoutChanged(android.os.IBinder,androidx.window.sidecar.SidecarWindowLayoutInfo)
org.webrtc.PeerConnectionFactory: org.webrtc.RtpCapabilities getRtpReceiverCapabilities(org.webrtc.MediaStreamTrack$MediaType)
org.webrtc.GlGenericDrawer: GlGenericDrawer(java.lang.String,org.webrtc.GlGenericDrawer$ShaderCallbacks)
org.webrtc.MediaCodecWrapper: void configure(android.media.MediaFormat,android.view.Surface,android.media.MediaCrypto,int)
org.webrtc.voiceengine.WebRtcAudioTrack: int getStreamVolume()
org.webrtc.PeerConnection$IceServer: PeerConnection$IceServer(java.lang.String,java.lang.String,java.lang.String,org.webrtc.PeerConnection$TlsCertPolicy)
kotlin.reflect.KVisibility: kotlin.reflect.KVisibility[] values()
org.webrtc.PeerConnection$RTCConfiguration: boolean getSuspendBelowMinBitrate()
com.cloudwebrtc.webrtc.PeerConnectionObserver: void dataChannelSend(java.lang.String,java.nio.ByteBuffer,java.lang.Boolean)
com.cloudwebrtc.webrtc.GetUserMediaImpl: void requestPermissions(java.util.ArrayList,com.cloudwebrtc.webrtc.utils.Callback,com.cloudwebrtc.webrtc.utils.Callback)
org.webrtc.Predicate$1: boolean test(java.lang.Object)
androidx.window.embedding.ActivityStack: int hashCode()
org.webrtc.audio.WebRtcAudioRecord: void reportWebRtcAudioRecordError(java.lang.String)
io.flutter.embedding.engine.FlutterJNI: void setPlatformViewsController(io.flutter.plugin.platform.PlatformViewsController)
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper: java.lang.String getImplementationName$lambda-5(com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper)
org.webrtc.Camera2Session$SessionState: org.webrtc.Camera2Session$SessionState[] values()
org.webrtc.NV12Buffer: org.webrtc.VideoFrame$I420Buffer toI420()
org.webrtc.HardwareVideoEncoder: org.webrtc.VideoCodecStatus updateBitrate()
org.webrtc.VideoEncoder$-CC: boolean $default$isHardwareEncoder(org.webrtc.VideoEncoder)
androidx.window.layout.SidecarAdapter: boolean isEqualSidecarDisplayFeatures(java.util.List,java.util.List)
org.webrtc.WrappedNativeVideoDecoder: long createNativeVideoDecoder()
org.webrtc.ContextUtils: void initialize(android.content.Context)
org.webrtc.GlUtil: int generateTexture(int)
io.flutter.embedding.engine.mutatorsstack.FlutterMutatorView: void setOnDescendantFocusChangeListener(android.view.View$OnFocusChangeListener)
org.webrtc.voiceengine.WebRtcAudioRecord: void reportWebRtcAudioRecordInitError(java.lang.String)
io.grpc.ClientCall$Listener: ClientCall$Listener()
org.webrtc.EglBase10Impl: void swapBuffers(long)
com.cloudwebrtc.webrtc.GetUserMediaImpl: void screenRequestPermissions(android.os.ResultReceiver)
org.webrtc.CameraSession$Events: void onCameraOpening()
androidx.core.app.RemoteActionCompatParcelizer: androidx.core.app.RemoteActionCompat read(androidx.versionedparcelable.VersionedParcel)
io.grpc.Channel: Channel()
io.flutter.embedding.engine.FlutterJNI: void nativeDispatchPlatformMessage(long,java.lang.String,java.nio.ByteBuffer,int,int)
androidx.window.layout.WindowInfoTrackerImpl$windowLayoutInfo$1: java.lang.Object invokeSuspend(java.lang.Object)
kotlinx.coroutines.CoroutineStart: kotlinx.coroutines.CoroutineStart[] values()
io.flutter.embedding.engine.FlutterJNI: long nativeAttach(io.flutter.embedding.engine.FlutterJNI)
org.webrtc.Logging$TraceLevel: org.webrtc.Logging$TraceLevel[] values()
org.webrtc.MediaSource: void dispose()
org.webrtc.PeerConnection: boolean addStream(org.webrtc.MediaStream)
com.cloudwebrtc.webrtc.utils.AnyThreadSink: void lambda$success$0(java.lang.Object)
org.webrtc.Empty: Empty()
org.webrtc.EglBase10Impl: void releaseSurface()
org.webrtc.audio.JavaAudioDeviceModule: boolean isBuiltInNoiseSuppressorSupported()
org.webrtc.VideoFrame$Buffer: void release()
androidx.window.layout.WindowMetricsCalculator$Companion$overrideDecorator$1: java.lang.Object invoke(java.lang.Object)
androidx.window.layout.HardwareFoldingFeature$Companion: void validateFeatureBounds$window_release(androidx.window.core.Bounds)
com.cloudwebrtc.webrtc.PeerConnectionObserver: org.webrtc.MediaStreamTrack getTransceiversTrack(java.lang.String)
org.webrtc.WrappedVideoDecoderFactory: org.webrtc.VideoCodecInfo[] getSupportedCodecs()
com.google.firebase.heartbeatinfo.HeartBeatInfo$HeartBeat: com.google.firebase.heartbeatinfo.HeartBeatInfo$HeartBeat[] values()
com.cloudwebrtc.webrtc.CameraEventsHandler: void onFirstFrameAvailable()
io.flutter.embedding.engine.systemchannels.TextInputChannel$TextInputType: io.flutter.embedding.engine.systemchannels.TextInputChannel$TextInputType[] values()
androidx.window.embedding.ActivityFilter: int hashCode()
org.webrtc.audio.WebRtcAudioUtils: void logAudioState(java.lang.String,android.content.Context,android.media.AudioManager)
com.google.protobuf.JavaType: com.google.protobuf.JavaType valueOf(java.lang.String)
io.flutter.embedding.engine.systemchannels.PlatformChannel$DeviceOrientation: io.flutter.embedding.engine.systemchannels.PlatformChannel$DeviceOrientation[] values()
org.webrtc.CameraCapturer$2: void onCameraClosed(org.webrtc.CameraSession)
org.webrtc.ThreadUtils: java.lang.Object invokeAtFrontUninterruptibly(android.os.Handler,java.util.concurrent.Callable)
org.webrtc.SurfaceTextureHelper: void lambda$returnTextureFrame$5()
org.webrtc.JavaI420Buffer: void nativeCropAndScaleI420(java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,int,int,int,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,int,int)
org.webrtc.FrameCryptor$FrameCryptionState: org.webrtc.FrameCryptor$FrameCryptionState[] $values()
org.webrtc.VideoCodecMimeType: java.lang.String mimeType()
com.cloudwebrtc.webrtc.GetUserMediaImpl: void getUserMedia(com.cloudwebrtc.webrtc.utils.ConstraintsMap,io.flutter.plugin.common.MethodChannel$Result,org.webrtc.MediaStream)
kotlinx.coroutines.android.AndroidDispatcherFactory: kotlinx.coroutines.android.HandlerContext createDispatcher(java.util.List)
io.flutter.embedding.engine.renderer.FlutterRenderer$DisplayFeatureType: io.flutter.embedding.engine.renderer.FlutterRenderer$DisplayFeatureType[] values()
org.webrtc.PeerConnection: void createOffer(org.webrtc.SdpObserver,org.webrtc.MediaConstraints)
org.webrtc.audio.WebRtcAudioRecord: boolean isAudioSourceMatchingRecordingSession()
org.webrtc.SurfaceTextureHelper: void returnTextureFrame()
org.webrtc.voiceengine.WebRtcAudioUtils: boolean runningOnEmulator()
org.webrtc.EglBase14Impl: void release()
org.webrtc.PeerConnection$Observer: void onDataChannel(org.webrtc.DataChannel)
io.flutter.embedding.engine.renderer.FlutterRenderer$DisplayFeatureState: io.flutter.embedding.engine.renderer.FlutterRenderer$DisplayFeatureState valueOf(java.lang.String)
com.cloudwebrtc.webrtc.GetUserMediaImpl: void getUserMedia(com.cloudwebrtc.webrtc.utils.ConstraintsMap,io.flutter.plugin.common.MethodChannel$Result,org.webrtc.MediaStream,java.util.List)
org.webrtc.RtpParameters: java.util.List getCodecs()
androidx.window.core.Bounds: int getTop()
org.webrtc.RtpCapabilities$CodecCapability: java.lang.Integer getClockRate()
androidx.window.layout.DisplayCompatHelperApi17: void getRealSize(android.view.Display,android.graphics.Point)
io.grpc.okhttp.internal.framed.HeadersMode: io.grpc.okhttp.internal.framed.HeadersMode[] values()
org.webrtc.SurfaceEglRenderer: void pauseVideo()
org.webrtc.GlUtil: GlUtil()
com.google.firebase.firestore.core.CompositeFilter$Operator: com.google.firebase.firestore.core.CompositeFilter$Operator valueOf(java.lang.String)
com.google.firestore.admin.v1.Index$IndexField$Builder: Index$IndexField$Builder()
org.webrtc.VideoEncoder$EncoderInfo: VideoEncoder$EncoderInfo(int,boolean)
org.webrtc.VideoFrameDrawer: void calculateTransformedRenderSize(int,int,android.graphics.Matrix)
org.webrtc.RTCStatsReport: java.util.Map getStatsMap()
io.flutter.embedding.engine.FlutterJNI: void init(android.content.Context,java.lang.String[],java.lang.String,java.lang.String,java.lang.String,long)
org.webrtc.EglBase14Impl: void createSurface(android.graphics.SurfaceTexture)
androidx.window.java.layout.WindowInfoTrackerCallbackAdapter$addListener$1$1: java.lang.Object invokeSuspend(java.lang.Object)
org.webrtc.VideoSource$1: void onFrameCaptured(org.webrtc.VideoFrame)
androidx.window.embedding.ExtensionEmbeddingBackend$Companion: boolean isExtensionVersionSupported(java.lang.Integer)
org.webrtc.EglRenderer$FrameListener: void onFrame(android.graphics.Bitmap)
androidx.window.core.Bounds: int getLeft()
com.cloudwebrtc.webrtc.PeerConnectionObserver: void rtpTransceiverStop(java.lang.String,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.voiceengine.WebRtcAudioManager$VolumeLogger$LogVolumeTask: void run()
org.webrtc.CameraVideoCapturer$CameraEventsHandler: void onFirstFrameAvailable()
org.webrtc.VideoEncoder$ScalingSettings: VideoEncoder$ScalingSettings(boolean)
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper: java.lang.Long createNativeVideoEncoder$lambda-6(com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper)
org.webrtc.RtpSender: boolean nativeSetTrack(long,long)
com.google.firestore.admin.v1.Index$Builder: Index$Builder()
com.google.firestore.v1.StructuredQuery$Order$Builder: StructuredQuery$Order$Builder()
org.webrtc.RtpTransceiver$RtpTransceiverDirection: int getNativeIndex()
org.webrtc.PeerConnection$SdpSemantics: org.webrtc.PeerConnection$SdpSemantics valueOf(java.lang.String)
org.webrtc.EglBase: void createSurface(android.view.Surface)
org.webrtc.EglBase14Impl: void createSurface(android.view.Surface)
com.google.firestore.v1.ListenRequest$Builder: ListenRequest$Builder()
org.webrtc.GlShader: GlShader(java.lang.String,java.lang.String)
org.webrtc.PeerConnection$RTCConfiguration: int getIceCandidatePoolSize()
org.webrtc.ScreenCapturerAndroid: void stopCapture()
com.cloudwebrtc.webrtc.audio.AudioSwitchManager: void stop()
org.webrtc.EglBase14Impl: void createSurfaceInternal(java.lang.Object)
org.webrtc.audio.WebRtcAudioRecord: java.lang.String audioStateToString(int)
com.cloudwebrtc.webrtc.PeerConnectionObserver: void onTrack(org.webrtc.RtpTransceiver)
org.webrtc.NetworkMonitor: void updateObserverActiveNetworkList(long)
io.flutter.embedding.engine.FlutterJNI: void onBeginFrame()
androidx.window.embedding.ExtensionEmbeddingBackend: void registerSplitListenerForActivity(android.app.Activity,java.util.concurrent.Executor,androidx.core.util.Consumer)
androidx.window.core.Version: int getPatch()
com.google.firebase.firestore.proto.MaybeDocument$DocumentTypeCase: com.google.firebase.firestore.proto.MaybeDocument$DocumentTypeCase[] values()
org.webrtc.PeerConnection$Observer: void onConnectionChange(org.webrtc.PeerConnection$PeerConnectionState)
io.flutter.embedding.engine.FlutterJNI: void loadLibrary()
org.webrtc.voiceengine.WebRtcAudioTrack$ErrorCallback: void onWebRtcAudioTrackError(java.lang.String)
org.webrtc.SoftwareVideoEncoderFactory$1: long createNativeVideoEncoder()
org.webrtc.audio.WebRtcAudioTrack: void logNativeOutputSampleRate(int)
com.cloudwebrtc.webrtc.utils.ConstraintsMap: void putNull(java.lang.String)
org.webrtc.NetworkMonitorAutoDetect$SimpleNetworkCallback: void onLosing(android.net.Network,int)
org.webrtc.PeerConnection$RTCConfiguration: org.webrtc.PeerConnection$CandidateNetworkPolicy getCandidateNetworkPolicy()
io.grpc.util.OutlierDetectionLoadBalancerProvider: int getPriority()
com.google.firebase.firestore.proto.Target$Builder: Target$Builder()
org.webrtc.audio.JavaAudioDeviceModule$AudioTrackStartErrorCode: org.webrtc.audio.JavaAudioDeviceModule$AudioTrackStartErrorCode[] $values()
org.webrtc.Camera2Capturer: void switchCamera(org.webrtc.CameraVideoCapturer$CameraSwitchHandler,java.lang.String)
androidx.window.layout.ExtensionWindowLayoutInfoBackend: void registerLayoutChangeCallback(android.app.Activity,java.util.concurrent.Executor,androidx.core.util.Consumer)
com.cloudwebrtc.webrtc.PeerConnectionObserver: java.util.Map candidateToMap(org.webrtc.IceCandidate)
io.grpc.util.SecretRoundRobinLoadBalancerProvider$Provider: int getPriority()
org.webrtc.CameraEnumerationAndroid$2: int diff(org.webrtc.Size)
androidx.window.layout.ExtensionInterfaceCompat: void onWindowLayoutChangeListenerAdded(android.app.Activity)
org.webrtc.FramerateBitrateAdjuster: void setTargets(int,double)
org.webrtc.audio.WebRtcAudioRecord: boolean isAcousticEchoCancelerSupported()
org.webrtc.WrappedNativeVideoEncoder: long createNativeVideoEncoder()
kotlinx.coroutines.CancelHandlerBase: CancelHandlerBase()
org.webrtc.GlTextureFrameBuffer: void setSize(int,int)
org.webrtc.DataChannel: long getNativeDataChannel()
org.webrtc.RtpParameters$Encoding: double getBitratePriority()
org.webrtc.Logging: void w(java.lang.String,java.lang.String,java.lang.Throwable)
io.grpc.ManagedChannelRegistry: ManagedChannelRegistry()
org.webrtc.NetworkMonitorAutoDetect: void onReceive(android.content.Context,android.content.Intent)
org.webrtc.RtpTransceiver: java.lang.String getMid()
org.webrtc.voiceengine.WebRtcAudioTrack: void logBufferCapacityInFrames()
io.flutter.embedding.engine.FlutterJNI: void invokePlatformMessageResponseCallback(int,java.nio.ByteBuffer,int)
org.webrtc.CameraCapturer$5: CameraCapturer$5(org.webrtc.CameraCapturer)
org.webrtc.GlUtil: void checkNoGLES2Error(java.lang.String)
org.webrtc.EglBase10Impl$1FakeSurfaceHolder: android.view.Surface getSurface()
org.webrtc.EglRenderer: void lambda$release$2(android.os.Looper)
org.webrtc.PeerConnectionFactory$InitializationOptions$Builder: PeerConnectionFactory$InitializationOptions$Builder(android.content.Context)
org.webrtc.PeerConnectionFactory$Options: PeerConnectionFactory$Options()
org.webrtc.voiceengine.WebRtcAudioUtils: boolean useWebRtcBasedNoiseSuppressor()
org.webrtc.DataChannel: long bufferedAmount()
org.webrtc.PeerConnection$AdapterType: org.webrtc.PeerConnection$AdapterType[] values()
com.google.firestore.v1.StructuredQuery$CompositeFilter$Builder: StructuredQuery$CompositeFilter$Builder()
org.webrtc.DataChannel$Observer: void onStateChange()
androidx.window.embedding.SplitController: void access$setGlobalInstance$cp(androidx.window.embedding.SplitController)
androidx.window.embedding.SplitController$Companion: SplitController$Companion()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$2: void onCreateSuccess(org.webrtc.SessionDescription)
org.webrtc.FrameCryptor: void nativeSetEnabled(long,boolean)
org.webrtc.CameraSession$Events: void onFrameCaptured(org.webrtc.CameraSession,org.webrtc.VideoFrame)
org.webrtc.NetworkMonitor: void removeNetworkObserver(org.webrtc.NetworkMonitor$NetworkObserver)
androidx.window.layout.SidecarCompat$registerConfigurationChangeListener$configChangeObserver$1: void onLowMemory()
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$FallbackFactory: SimulcastVideoEncoderFactoryWrapper$FallbackFactory(org.webrtc.VideoEncoderFactory)
com.google.firebase.firestore.Query$Direction: com.google.firebase.firestore.Query$Direction valueOf(java.lang.String)
androidx.concurrent.futures.AbstractResolvableFuture: AbstractResolvableFuture()
org.webrtc.PeerConnectionFactory: org.webrtc.AudioTrack createAudioTrack(java.lang.String,org.webrtc.AudioSource)
org.webrtc.DataChannel: long nativeBufferedAmount()
org.webrtc.voiceengine.WebRtcAudioTrack: void nativeCacheDirectBufferAddress(java.nio.ByteBuffer,long)
org.webrtc.PeerConnection: void nativeNewGetStatsReceiver(long,org.webrtc.RTCStatsCollectorCallback)
androidx.window.embedding.SplitRuleParser: android.content.ComponentName buildClassName(java.lang.String,java.lang.CharSequence)
org.webrtc.NetworkMonitorAutoDetect$NetworkState: boolean isConnected()
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback$AnimationCallback: void onEnd(android.view.WindowInsetsAnimation)
org.webrtc.audio.WebRtcAudioTrack: void logUnderrunCount()
org.webrtc.EncodedImage: void retain()
org.webrtc.TextureBufferImpl$1: void onRelease(org.webrtc.TextureBufferImpl)
org.webrtc.PeerConnection$RTCConfiguration: java.lang.Integer getIceCheckIntervalStrongConnectivity()
org.webrtc.audio.AudioDeviceModule: void setSpeakerMute(boolean)
org.webrtc.PeerConnection$CandidateNetworkPolicy: org.webrtc.PeerConnection$CandidateNetworkPolicy valueOf(java.lang.String)
org.webrtc.audio.WebRtcAudioRecord$1: java.lang.Thread newThread(java.lang.Runnable)
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin$LifeCycleObserver: void onCreate(androidx.lifecycle.LifecycleOwner)
org.webrtc.HardwareVideoEncoderFactory: boolean isHardwareSupportedInCurrentSdkH264(android.media.MediaCodecInfo)
org.webrtc.PeerConnection$Observer: void onIceGatheringChange(org.webrtc.PeerConnection$IceGatheringState)
com.google.firestore.v1.TargetChange$TargetChangeType: com.google.firestore.v1.TargetChange$TargetChangeType valueOf(java.lang.String)
androidx.window.embedding.EmbeddingAdapter: java.util.List translate(java.util.List)
org.webrtc.VideoEncoder$ResolutionBitrateLimits: int getMaxBitrateBps()
org.webrtc.PeerConnection$RTCConfiguration: boolean getPresumeWritableWhenFullyRelayed()
androidx.window.embedding.EmbeddingAdapter: boolean translateActivityPairPredicates$lambda-1(androidx.window.embedding.EmbeddingAdapter,java.util.Set,android.util.Pair)
org.webrtc.PeerConnectionFactory: void printInternalStackTraces(boolean)
org.webrtc.Camera1Capturer: void printStackTrace()
androidx.window.embedding.SplitPairRule: int hashCode()
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor$FrameCryptorStateObserver: java.util.ArrayList access$100(com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor$FrameCryptorStateObserver)
org.webrtc.EncodedImage$Builder: org.webrtc.EncodedImage createEncodedImage()
org.webrtc.CryptoOptions$Builder: org.webrtc.CryptoOptions$Builder setEnableGcmCryptoSuites(boolean)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$1: void onSetFailure(java.lang.String)
org.webrtc.PeerConnection$RTCConfiguration: boolean getAudioJitterBufferFastAccelerate()
org.webrtc.MediaCodecWrapperFactoryImpl$MediaCodecWrapperImpl: void releaseOutputBuffer(int,boolean)
androidx.lifecycle.Lifecycle$State: androidx.lifecycle.Lifecycle$State[] values()
io.flutter.embedding.engine.FlutterJNI: boolean nativeFlutterTextUtilsIsEmoji(int)
org.webrtc.RtpTransceiver: void stopStandard()
androidx.window.core.Bounds: int getRight()
org.webrtc.audio.JavaAudioDeviceModule$AudioSamples: byte[] getData()
org.webrtc.VideoEncoderFactory$VideoEncoderSelector: org.webrtc.VideoCodecInfo onEncoderBroken()
org.webrtc.Logging$Severity: org.webrtc.Logging$Severity valueOf(java.lang.String)
org.webrtc.CameraSession$Events: void onCameraDisconnected(org.webrtc.CameraSession)
org.webrtc.HardwareVideoEncoder: org.webrtc.VideoCodecStatus initEncodeInternal()
org.webrtc.IceCandidateErrorEvent: IceCandidateErrorEvent(java.lang.String,int,java.lang.String,int,java.lang.String)
org.webrtc.SurfaceTextureHelper$3: void run()
com.google.firestore.v1.RunAggregationQueryRequest: RunAggregationQueryRequest()
org.webrtc.PeerConnection$IceServer$Builder: org.webrtc.PeerConnection$IceServer$Builder setUsername(java.lang.String)
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin: void onDetachedFromActivity()
com.google.firebase.firestore.DocumentChange$Type: com.google.firebase.firestore.DocumentChange$Type[] values()
com.cloudwebrtc.webrtc.utils.AnyThreadResult: void post(java.lang.Runnable)
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper: java.lang.Boolean isHardwareEncoder$lambda-7(com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper)
androidx.window.embedding.ExtensionEmbeddingBackend: ExtensionEmbeddingBackend(androidx.window.embedding.EmbeddingInterfaceCompat)
kotlinx.coroutines.channels.BufferOverflow: kotlinx.coroutines.channels.BufferOverflow[] values()
org.webrtc.VideoTrack: void removeSink(org.webrtc.VideoSink)
org.webrtc.audio.JavaAudioDeviceModule$AudioRecordStartErrorCode: JavaAudioDeviceModule$AudioRecordStartErrorCode(java.lang.String,int)
com.google.firestore.v1.CommitRequest$Builder: CommitRequest$Builder()
org.webrtc.VideoFrame$TextureBuffer$Type: VideoFrame$TextureBuffer$Type(java.lang.String,int,int)
org.webrtc.NetworkMonitor: int getNumObservers()
kotlin.jvm.internal.CallableReference: java.util.List getParameters()
org.webrtc.VideoSource: void adaptOutputFormat(org.webrtc.VideoSource$AspectRatio,java.lang.Integer,org.webrtc.VideoSource$AspectRatio,java.lang.Integer,java.lang.Integer)
org.webrtc.EglBase10Impl$Context: EglBase10Impl$Context(javax.microedition.khronos.egl.EGL10,javax.microedition.khronos.egl.EGLContext,javax.microedition.khronos.egl.EGLConfig)
org.webrtc.SurfaceTextureHelper$FrameRefMonitor: void onDestroyBuffer(org.webrtc.VideoFrame$TextureBuffer)
androidx.window.layout.WindowMetricsCalculator$Companion$reset$1: androidx.window.layout.WindowMetricsCalculator invoke(androidx.window.layout.WindowMetricsCalculator)
org.webrtc.RefCounted: void release()
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer: void Dispose()
kotlin.internal.jdk8.JDK8PlatformImplementations: JDK8PlatformImplementations()
org.webrtc.voiceengine.WebRtcAudioRecord$AudioSamples: int getChannelCount()
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper: org.webrtc.VideoCodecStatus initEncode$lambda-0(com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper,org.webrtc.VideoEncoder$Settings,org.webrtc.VideoEncoder$Callback)
org.webrtc.PeerConnection$Observer: void onSelectedCandidatePairChanged(org.webrtc.CandidatePairChangeEvent)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: org.webrtc.PeerConnection$RTCConfiguration parseRTCConfiguration(com.cloudwebrtc.webrtc.utils.ConstraintsMap)
org.webrtc.VideoFrameDrawer$YuvUploader: int[] uploadFromBuffer(org.webrtc.VideoFrame$I420Buffer)
org.webrtc.CapturerObserver: void onFrameCaptured(org.webrtc.VideoFrame)
com.google.firestore.v1.DocumentMask: DocumentMask()
org.webrtc.voiceengine.WebRtcAudioTrack$AudioTrackStartErrorCode: org.webrtc.voiceengine.WebRtcAudioTrack$AudioTrackStartErrorCode[] values()
com.cloudwebrtc.webrtc.GetUserMediaImpl: GetUserMediaImpl(com.cloudwebrtc.webrtc.StateProvider,android.content.Context)
org.webrtc.PeerConnection$IceServer: java.util.List getUrls()
org.webrtc.RefCounted: void retain()
org.webrtc.audio.WebRtcAudioTrack: android.media.AudioTrack createAudioTrackOnOreoOrHigher(int,int,int,android.media.AudioAttributes)
org.webrtc.EglBase: int surfaceHeight()
org.webrtc.voiceengine.WebRtcAudioManager: void setStereoOutput(boolean)
org.webrtc.NetworkChangeDetector$NetworkInformation: java.lang.String getName()
org.webrtc.voiceengine.WebRtcAudioTrack: void logMainParameters()
io.flutter.embedding.engine.FlutterJNI: void nativeSurfaceWindowChanged(long,android.view.Surface)
androidx.window.layout.SidecarWindowBackend$Companion: SidecarWindowBackend$Companion()
androidx.window.core.Bounds: java.lang.String toString()
io.flutter.embedding.engine.FlutterJNI: void nativeSetAccessibilityFeatures(long,int)
org.webrtc.Camera1Session$SessionState: org.webrtc.Camera1Session$SessionState[] values()
com.google.firebase.firestore.FirebaseFirestoreException$Code: com.google.firebase.firestore.FirebaseFirestoreException$Code valueOf(java.lang.String)
com.cloudwebrtc.webrtc.GetUserMediaImpl$2: GetUserMediaImpl$2(com.cloudwebrtc.webrtc.GetUserMediaImpl,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.VideoFrame$I420Buffer: int getStrideV()
org.webrtc.SurfaceViewRenderer: void setEnableHardwareScaler(boolean)
org.webrtc.PeerConnection$IceConnectionState: org.webrtc.PeerConnection$IceConnectionState fromNativeIndex(int)
org.webrtc.VideoEncoderFactory: org.webrtc.VideoEncoder createEncoder(org.webrtc.VideoCodecInfo)
org.webrtc.Camera1Enumerator: org.webrtc.CameraVideoCapturer createCapturer(java.lang.String,org.webrtc.CameraVideoCapturer$CameraEventsHandler)
com.google.firestore.admin.v1.Index$QueryScope: com.google.firestore.admin.v1.Index$QueryScope valueOf(java.lang.String)
org.webrtc.VideoEncoderWrapper: org.webrtc.VideoEncoder$Callback createEncoderCallback(long)
org.webrtc.Camera1Capturer: void createCameraSession(org.webrtc.CameraSession$CreateSessionCallback,org.webrtc.CameraSession$Events,android.content.Context,org.webrtc.SurfaceTextureHelper,java.lang.String,int,int,int)
io.grpc.okhttp.internal.CipherSuite: io.grpc.okhttp.internal.CipherSuite valueOf(java.lang.String)
io.flutter.embedding.engine.FlutterJNI: void unregisterTexture(long)
org.webrtc.CapturerObserver: void onCapturerStarted(boolean)
org.webrtc.PeerConnection: java.util.List getReceivers()
io.flutter.view.AccessibilityBridge$Action: io.flutter.view.AccessibilityBridge$Action valueOf(java.lang.String)
org.webrtc.HardwareVideoEncoderFactory: org.webrtc.VideoCodecInfo[] getSupportedCodecs()
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback: android.view.WindowInsets access$402(io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback,android.view.WindowInsets)
kotlin.coroutines.AbstractCoroutineContextElement: kotlin.coroutines.CoroutineContext minusKey(kotlin.coroutines.CoroutineContext$Key)
org.webrtc.Camera1Capturer: Camera1Capturer(java.lang.String,org.webrtc.CameraVideoCapturer$CameraEventsHandler,boolean)
org.webrtc.PeerConnection: long nativeCreatePeerConnectionObserver(org.webrtc.PeerConnection$Observer)
org.webrtc.FramerateBitrateAdjuster: FramerateBitrateAdjuster()
org.webrtc.Metrics: org.webrtc.Metrics nativeGetAndReset()
org.webrtc.VideoProcessor$FrameAdaptationParameters: VideoProcessor$FrameAdaptationParameters(int,int,int,int,int,int,long,boolean)
kotlinx.coroutines.channels.Send: Send()
org.webrtc.RtpReceiver: RtpReceiver(long)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$4: void onCreateSuccess(org.webrtc.SessionDescription)
org.webrtc.VideoEncoder$-CC: org.webrtc.VideoEncoder$ResolutionBitrateLimits[] $default$getResolutionBitrateLimits(org.webrtc.VideoEncoder)
org.webrtc.PeerConnectionFactory: boolean nativeStartInternalTracingCapture(java.lang.String)
org.webrtc.PeerConnection$RTCConfiguration: org.webrtc.PeerConnection$KeyType getKeyType()
kotlin.coroutines.jvm.internal.SuspendLambda: SuspendLambda(int,kotlin.coroutines.Continuation)
org.webrtc.TextureBufferImpl: TextureBufferImpl(int,int,int,int,org.webrtc.VideoFrame$TextureBuffer$Type,int,android.graphics.Matrix,android.os.Handler,org.webrtc.YuvConverter,org.webrtc.TextureBufferImpl$RefCountMonitor)
org.webrtc.voiceengine.WebRtcAudioTrack$ErrorCallback: void onWebRtcAudioTrackStartError(org.webrtc.voiceengine.WebRtcAudioTrack$AudioTrackStartErrorCode,java.lang.String)
com.cloudwebrtc.webrtc.PeerConnectionObserver: org.webrtc.RtpSender getRtpSenderById(java.lang.String)
kotlin.coroutines.intrinsics.CoroutineSingletons: kotlin.coroutines.intrinsics.CoroutineSingletons[] values()
org.webrtc.voiceengine.WebRtcAudioRecord: void releaseAudioResources()
com.google.protobuf.FieldType: com.google.protobuf.FieldType[] values()
org.webrtc.PeerConnection$RTCConfiguration: java.lang.Boolean getAllowCodecSwitching()
org.webrtc.DynamicBitrateAdjuster: DynamicBitrateAdjuster()
com.cloudwebrtc.webrtc.DataChannelObserver: DataChannelObserver(io.flutter.plugin.common.BinaryMessenger,java.lang.String,java.lang.String,org.webrtc.DataChannel)
com.cloudwebrtc.webrtc.GetUserMediaImpl$4: GetUserMediaImpl$4(com.cloudwebrtc.webrtc.GetUserMediaImpl,io.flutter.plugin.common.MethodChannel$Result,java.lang.String)
org.webrtc.MediaConstraints: java.util.List getOptional()
org.webrtc.MediaCodecWrapperFactoryImpl$MediaCodecWrapperImpl: MediaCodecWrapperFactoryImpl$MediaCodecWrapperImpl(android.media.MediaCodec)
org.webrtc.NV12Buffer: void retain()
com.google.firestore.v1.StructuredAggregationQuery$Aggregation$Sum: StructuredAggregationQuery$Aggregation$Sum()
org.webrtc.VideoCodecStatus: VideoCodecStatus(java.lang.String,int,int)
org.webrtc.GlGenericDrawer$ShaderType: org.webrtc.GlGenericDrawer$ShaderType[] values()
androidx.window.layout.SidecarAdapter$Companion: void setSidecarDevicePosture(androidx.window.sidecar.SidecarDeviceState,int)
org.webrtc.YuvHelper: void nativeABGRToI420(java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,int,int)
org.webrtc.PeerConnection: org.webrtc.RtpTransceiver addTransceiver(org.webrtc.MediaStreamTrack$MediaType,org.webrtc.RtpTransceiver$RtpTransceiverInit)
org.webrtc.YuvHelper: void ABGRToI420(java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,int,int)
io.flutter.embedding.android.RenderMode: io.flutter.embedding.android.RenderMode[] values()
com.cloudwebrtc.webrtc.PeerConnectionObserver: java.lang.String getNextDataChannelUUID()
com.google.firebase.firestore.core.OrderBy$Direction: com.google.firebase.firestore.core.OrderBy$Direction valueOf(java.lang.String)
com.google.firebase.firestore.proto.Target$TargetTypeCase: com.google.firebase.firestore.proto.Target$TargetTypeCase valueOf(java.lang.String)
org.webrtc.audio.WebRtcAudioUtils: void logDeviceInfo(java.lang.String)
org.webrtc.DataChannel: DataChannel(long)
org.webrtc.FileVideoCapturer: void startCapture(int,int,int)
org.webrtc.VideoFrameDrawer$YuvUploader: void release()
org.webrtc.VideoEncoder: org.webrtc.VideoEncoder$ScalingSettings getScalingSettings()
org.webrtc.LibaomAv1Encoder: LibaomAv1Encoder()
org.webrtc.EglRenderer: void init(org.webrtc.EglBase$Context,int[],org.webrtc.RendererCommon$GlDrawer,boolean)
com.twilio.audioswitch.AudioSwitch$State: com.twilio.audioswitch.AudioSwitch$State[] values()
org.webrtc.CameraEnumerationAndroid$ClosestComparator: int diff(java.lang.Object)
com.google.firebase.firestore.remote.TestingHooks$ExistenceFilterMismatchInfo: TestingHooks$ExistenceFilterMismatchInfo()
androidx.lifecycle.ReportFragment$LifecycleCallbacks: void onActivityPostResumed(android.app.Activity)
org.webrtc.PeerConnectionFactory: PeerConnectionFactory(long)
org.webrtc.audio.JavaAudioDeviceModule$Builder: org.webrtc.audio.JavaAudioDeviceModule$Builder setOutputSampleRate(int)
org.webrtc.voiceengine.WebRtcAudioEffects: boolean isNoiseSuppressorBlacklisted()
androidx.window.embedding.EmbeddingCompat$Companion: java.lang.Integer getExtensionApiLevel()
org.webrtc.RtpCapabilities$CodecCapability: java.lang.String getName()
org.webrtc.TimestampAligner: void checkNativeAlignerExists()
com.google.android.gms.common.api.PendingResult: PendingResult()
com.cloudwebrtc.webrtc.GetUserMediaImpl: void reStartCamera(com.cloudwebrtc.webrtc.GetUserMediaImpl$IsCameraEnabled)
com.cloudwebrtc.webrtc.GetUserMediaImpl$IsCameraEnabled: boolean isEnabled(java.lang.String)
org.webrtc.NativeLibrary: NativeLibrary()
org.webrtc.WrappedNativeI420Buffer: java.nio.ByteBuffer getDataV()
org.webrtc.FrameCryptorFactory: org.webrtc.FrameCryptor nativeCreateFrameCryptorForRtpSender(long,java.lang.String,int,long)
org.webrtc.EglBase10Impl$1FakeSurfaceHolder: void setType(int)
com.cloudwebrtc.webrtc.record.AudioChannel: com.cloudwebrtc.webrtc.record.AudioChannel valueOf(java.lang.String)
androidx.lifecycle.ReportFragment$LifecycleCallbacks: void onActivityPreStopped(android.app.Activity)
com.cloudwebrtc.webrtc.audio.AudioSwitchManager: void setMicrophoneMute(boolean)
androidx.window.core.Version$bigInteger$2: java.lang.Object invoke()
com.google.firestore.v1.BatchGetDocumentsRequest$Builder: BatchGetDocumentsRequest$Builder()
io.flutter.embedding.engine.mutatorsstack.FlutterMutatorsStack: FlutterMutatorsStack()
org.webrtc.PeerConnectionDependencies: org.webrtc.PeerConnection$Observer getObserver()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: io.flutter.plugin.common.BinaryMessenger getMessenger()
org.webrtc.VideoEncoder$CodecSpecificInfoAV1: VideoEncoder$CodecSpecificInfoAV1()
androidx.window.layout.SidecarCompat: void onWindowLayoutChangeListenerAdded(android.app.Activity)
com.cloudwebrtc.webrtc.utils.ConstraintsArray: ConstraintsArray(java.util.ArrayList)
org.webrtc.audio.WebRtcAudioTrack: void releaseAudioResources()
androidx.window.layout.SidecarCompat: SidecarCompat(android.content.Context)
androidx.core.content.ContextCompat$Api28Impl: java.util.concurrent.Executor getMainExecutor(android.content.Context)
org.webrtc.EglBase$ConfigBuilder: org.webrtc.EglBase$ConfigBuilder setOpenGlesVersion(int)
com.example.demo_agora.MainActivity: MainActivity()
org.webrtc.PeerConnectionFactory: org.webrtc.MediaStream createLocalMediaStream(java.lang.String)
kotlin.collections.IntIterator: IntIterator()
kotlin.internal.jdk7.JDK7PlatformImplementations: JDK7PlatformImplementations()
kotlinx.coroutines.android.AndroidDispatcherFactory: AndroidDispatcherFactory()
org.webrtc.audio.WebRtcAudioTrack: void logBufferSizeInFrames()
io.flutter.embedding.android.FlutterImageView$SurfaceKind: io.flutter.embedding.android.FlutterImageView$SurfaceKind valueOf(java.lang.String)
androidx.window.layout.DisplayFeature: android.graphics.Rect getBounds()
com.google.common.base.Stopwatch: Stopwatch()
io.flutter.embedding.engine.FlutterJNI: void setDeferredComponentManager(io.flutter.embedding.engine.deferredcomponents.DeferredComponentManager)
org.webrtc.audio.WebRtcAudioTrack: WebRtcAudioTrack(android.content.Context,android.media.AudioManager,android.media.AudioAttributes,org.webrtc.audio.JavaAudioDeviceModule$AudioTrackErrorCallback,org.webrtc.audio.JavaAudioDeviceModule$AudioTrackStateCallback,boolean,boolean)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: java.lang.String peerConnectionInit(com.cloudwebrtc.webrtc.utils.ConstraintsMap,com.cloudwebrtc.webrtc.utils.ConstraintsMap)
org.webrtc.AndroidVideoDecoder: org.webrtc.VideoFrame$I420Buffer allocateI420Buffer(int,int)
androidx.versionedparcelable.CustomVersionedParcelable: CustomVersionedParcelable()
org.webrtc.TurnCustomizer: void nativeFreeTurnCustomizer(long)
org.webrtc.TextureBufferImpl: org.webrtc.VideoFrame$I420Buffer toI420()
kotlin.coroutines.jvm.internal.ContinuationImpl: ContinuationImpl(kotlin.coroutines.Continuation,kotlin.coroutines.CoroutineContext)
org.webrtc.AndroidVideoDecoder: java.lang.Thread createOutputThread()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void removeStreamForRendererById(java.lang.String)
org.webrtc.FileVideoCapturer$VideoReaderY4M: FileVideoCapturer$VideoReaderY4M(java.lang.String)
org.webrtc.MediaStream: void checkMediaStreamExists()
org.webrtc.audio.JavaAudioDeviceModule$Builder: org.webrtc.audio.JavaAudioDeviceModule$Builder setAudioFormat(int)
org.webrtc.VideoCodecStatus: org.webrtc.VideoCodecStatus[] $values()
org.webrtc.HardwareVideoEncoderFactory: org.webrtc.VideoEncoder createEncoder(org.webrtc.VideoCodecInfo)
org.webrtc.Camera2Capturer: boolean isScreencast()
com.google.firebase.firestore.index.IndexByteEncoder: IndexByteEncoder()
com.google.android.gms.common.api.GoogleApiActivity: GoogleApiActivity()
org.webrtc.RTCStats: java.lang.String toString()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void mediaStreamTrackRelease(java.lang.String,java.lang.String)
org.webrtc.PeerConnection: void close()
org.webrtc.TextureBufferImpl: org.webrtc.VideoFrame$Buffer cropAndScale(int,int,int,int,int,int)
org.webrtc.RendererCommon$ScalingType: org.webrtc.RendererCommon$ScalingType[] $values()
org.webrtc.PeerConnection: org.webrtc.RtpTransceiver nativeAddTransceiverWithTrack(long,org.webrtc.RtpTransceiver$RtpTransceiverInit)
org.webrtc.SessionDescription: java.lang.String getDescription()
androidx.window.embedding.ExtensionEmbeddingBackend$EmbeddingCallbackImpl: void setLastInfo(java.util.List)
io.flutter.embedding.engine.FlutterJNI: void nativeUnregisterTexture(long,long)
com.google.firestore.v1.StructuredQuery$CompositeFilter$Operator: com.google.firestore.v1.StructuredQuery$CompositeFilter$Operator valueOf(java.lang.String)
androidx.window.java.layout.WindowInfoTrackerCallbackAdapter$addListener$1$1$invokeSuspend$$inlined$collect$1: java.lang.Object emit(java.lang.Object,kotlin.coroutines.Continuation)
androidx.window.java.layout.WindowInfoTrackerCallbackAdapter$addListener$1$1: java.lang.Object invoke(kotlinx.coroutines.CoroutineScope,kotlin.coroutines.Continuation)
org.webrtc.HardwareVideoEncoder$BusyCount: void decrement()
org.webrtc.NetworkMonitor: void notifyObserversOfNetworkPreference(java.util.List,int)
com.cloudwebrtc.webrtc.SurfaceTextureRenderer: void surfaceCreated(android.graphics.SurfaceTexture)
org.webrtc.voiceengine.WebRtcAudioRecord: WebRtcAudioRecord(long)
io.flutter.embedding.engine.FlutterJNI: void setViewportMetrics(float,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int,int[],int[],int[])
androidx.window.embedding.ActivityFilter: boolean matchesIntent(android.content.Intent)
org.webrtc.VideoTrack: void nativeFreeSink(long)
org.webrtc.NetworkMonitorAutoDetect$NetworkState: NetworkMonitorAutoDetect$NetworkState(boolean,int,int,int,int)
org.webrtc.VideoDecoderFactory$-CC: org.webrtc.VideoCodecInfo[] $default$getSupportedCodecs(org.webrtc.VideoDecoderFactory)
androidx.window.embedding.SplitRuleParser: java.util.Set parseSplitRules$window_release(android.content.Context,int)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void createDataChannel(java.lang.String,java.lang.String,com.cloudwebrtc.webrtc.utils.ConstraintsMap,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.DtmfSender: boolean nativeInsertDtmf(long,java.lang.String,int,int)
io.flutter.plugins.firebase.core.FlutterFirebasePluginRegistry: FlutterFirebasePluginRegistry()
kotlin.coroutines.jvm.internal.BaseContinuationImpl: kotlin.coroutines.Continuation create(kotlin.coroutines.Continuation)
io.flutter.embedding.engine.FlutterJNI: void nativeInit(android.content.Context,java.lang.String[],java.lang.String,java.lang.String,java.lang.String,long)
org.webrtc.DataChannel: java.lang.String nativeLabel()
org.webrtc.voiceengine.WebRtcAudioTrack: boolean startPlayout()
org.webrtc.RtpTransceiver$RtpTransceiverDirection: org.webrtc.RtpTransceiver$RtpTransceiverDirection[] $values()
org.webrtc.VideoFrameDrawer: void release()
org.webrtc.IceCandidate: int hashCode()
org.webrtc.YuvConverter: void release()
com.google.firestore.v1.RunAggregationQueryRequest$Builder: RunAggregationQueryRequest$Builder()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: java.lang.String getNextTrackUUID()
org.webrtc.MediaStream: boolean removeTrack(org.webrtc.VideoTrack)
org.webrtc.VideoSource: void lambda$setVideoProcessor$0(org.webrtc.VideoFrame)
io.flutter.embedding.engine.FlutterJNI: void nativeDeferredComponentInstallFailure(int,java.lang.String,boolean)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void rtpTransceiverSetDirection(java.lang.String,java.lang.String,java.lang.String,io.flutter.plugin.common.MethodChannel$Result)
com.google.firestore.v1.StructuredQuery$CompositeFilter: StructuredQuery$CompositeFilter()
io.grpc.ChannelLogger: ChannelLogger()
io.flutter.embedding.engine.FlutterJNI: android.graphics.Bitmap decodeImage(java.nio.ByteBuffer,long)
org.webrtc.CameraVideoCapturer$MediaRecorderHandler: void onMediaRecorderSuccess()
com.google.firestore.v1.WriteResponse: WriteResponse()
org.webrtc.audio.WebRtcAudioManager: boolean isLowLatencyInputSupported(android.content.Context)
androidx.window.embedding.EmbeddingAdapter: EmbeddingAdapter()
com.cloudwebrtc.webrtc.audio.AudioSwitchManager: kotlin.Unit lambda$new$0(java.util.List,com.twilio.audioswitch.AudioDevice)
org.webrtc.CameraCapturer$7: CameraCapturer$7(org.webrtc.CameraCapturer,org.webrtc.CameraVideoCapturer$CameraSwitchHandler)
com.google.protobuf.ExtensionRegistryLite: ExtensionRegistryLite()
com.google.common.collect.Ordering: Ordering()
androidx.window.embedding.SplitPlaceholderRule: android.content.Intent getPlaceholderIntent()
org.webrtc.NetworkChangeDetector$NetworkInformation: org.webrtc.NetworkChangeDetector$ConnectionType getConnectionType()
org.webrtc.VideoEncoder$-CC: long $default$createNativeVideoEncoder(org.webrtc.VideoEncoder)
com.cloudwebrtc.webrtc.utils.ConstraintsArray: java.lang.Byte[] getByte(int)
org.webrtc.EglBase$Context: long getNativeEglContext()
org.webrtc.ScreenCapturerAndroid: void createVirtualDisplay()
org.webrtc.audio.WebRtcAudioEffects: boolean isNoiseSuppressorSupported()
org.webrtc.Camera2Session$CaptureSessionCallback: void chooseFocusMode(android.hardware.camera2.CaptureRequest$Builder)
com.cloudwebrtc.webrtc.GetUserMediaImpl: void resultError(java.lang.String,java.lang.String,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.RtpParameters$Encoding: RtpParameters$Encoding(java.lang.String,boolean,java.lang.Double)
org.webrtc.FileVideoCapturer: void dispose()
org.webrtc.VideoEncoder$CodecSpecificInfo: VideoEncoder$CodecSpecificInfo()
com.cloudwebrtc.webrtc.SurfaceTextureRenderer: void pauseVideo()
androidx.window.embedding.SplitRuleParser: androidx.window.embedding.SplitPlaceholderRule parseSplitPlaceholderRule(android.content.Context,android.content.res.XmlResourceParser)
org.webrtc.PeerConnection$IceConnectionState: org.webrtc.PeerConnection$IceConnectionState[] values()
com.google.firebase.firestore.MetadataChanges: com.google.firebase.firestore.MetadataChanges valueOf(java.lang.String)
org.webrtc.MediaStreamTrack: java.lang.String id()
org.webrtc.PeerConnection$RTCConfiguration: java.lang.Integer getIceCheckMinInterval()
org.webrtc.WrappedNativeI420Buffer: void release()
com.google.firebase.firestore.proto.MaybeDocument$Builder: MaybeDocument$Builder()
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapperFactory: org.webrtc.VideoCodecInfo[] getSupportedCodecs()
org.webrtc.SurfaceEglRenderer: void setFpsReduction(float)
org.webrtc.PeerConnection: org.webrtc.DataChannel createDataChannel(java.lang.String,org.webrtc.DataChannel$Init)
org.webrtc.FrameCryptorKeyProvider: byte[] nativeRatchetKey(long,java.lang.String,int)
org.webrtc.voiceengine.WebRtcAudioUtils: boolean hasMicrophone()
org.webrtc.VideoEncoderFallback: boolean isHardwareEncoder()
org.webrtc.MediaStream: boolean addTrack(org.webrtc.AudioTrack)
io.grpc.Context$Storage: Context$Storage()
org.webrtc.NetworkMonitor: void stopMonitoring()
org.webrtc.CameraCapturer: void createSessionInternal(int)
kotlin.jvm.internal.CallableReference: java.lang.Object call(java.lang.Object[])
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper: SimulcastVideoEncoderFactoryWrapper(org.webrtc.EglBase$Context,boolean,boolean)
org.webrtc.audio.WebRtcAudioRecord: boolean verifyAudioConfig(int,int,android.media.AudioFormat,android.media.AudioDeviceInfo,java.util.List)
org.webrtc.audio.WebRtcAudioTrack: void assertTrue(boolean)
androidx.window.embedding.ActivityRule: ActivityRule(java.util.Set,boolean,int,kotlin.jvm.internal.DefaultConstructorMarker)
org.webrtc.DataChannel$State: org.webrtc.DataChannel$State[] $values()
org.webrtc.RtpParameters: java.lang.String getTransactionId()
androidx.lifecycle.ReportFragment$LifecycleCallbacks: void onActivitySaveInstanceState(android.app.Activity,android.os.Bundle)
com.google.firestore.v1.ListenRequest: ListenRequest()
org.webrtc.DataChannel: void nativeUnregisterObserver(long)
org.webrtc.Camera2Session$SessionState: org.webrtc.Camera2Session$SessionState[] $values()
org.webrtc.voiceengine.WebRtcAudioTrack: android.media.AudioTrack createAudioTrack(int,int,int)
io.flutter.embedding.android.FlutterView: io.flutter.embedding.engine.FlutterEngine getAttachedFlutterEngine()
com.google.firestore.v1.TransactionOptions$ReadWrite: TransactionOptions$ReadWrite()
androidx.window.layout.HardwareFoldingFeature$Type: androidx.window.layout.HardwareFoldingFeature$Type access$getHINGE$cp()
org.webrtc.audio.WebRtcAudioRecord: void doAudioRecordStateCallback(int)
org.webrtc.VideoDecoderFactory: org.webrtc.VideoDecoder createDecoder(org.webrtc.VideoCodecInfo)
org.webrtc.TurnCustomizer: TurnCustomizer(long)
org.webrtc.SessionDescription$Type: SessionDescription$Type(java.lang.String,int)
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper: org.webrtc.VideoCodecStatus encode(org.webrtc.VideoFrame,org.webrtc.VideoEncoder$EncodeInfo)
io.grpc.TlsChannelCredentials$Feature: io.grpc.TlsChannelCredentials$Feature[] values()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: boolean putLocalTrack(java.lang.String,org.webrtc.MediaStreamTrack)
org.webrtc.YuvHelper: void I420Rotate(java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,int,int)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void createLocalMediaStream(io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.JniCommon: void nativeAddRef(long)
org.webrtc.PeerConnectionFactory$InitializationOptions$Builder: org.webrtc.PeerConnectionFactory$InitializationOptions$Builder setEnableInternalTracer(boolean)
org.webrtc.MediaConstraints: java.util.List getMandatory()
org.webrtc.NetworkMonitor: void nativeNotifyOfNetworkPreference(long,org.webrtc.NetworkChangeDetector$ConnectionType,int)
org.webrtc.VideoEncoder$ResolutionBitrateLimits: int getFrameSizePixels()
com.google.firebase.firestore.core.UserData$Source: com.google.firebase.firestore.core.UserData$Source valueOf(java.lang.String)
org.webrtc.Camera2Session$CaptureSessionCallback: Camera2Session$CaptureSessionCallback(org.webrtc.Camera2Session)
org.webrtc.audio.VolumeLogger$LogVolumeTask: VolumeLogger$LogVolumeTask(org.webrtc.audio.VolumeLogger,int,int)
org.webrtc.HardwareVideoEncoder: org.webrtc.VideoCodecStatus resetCodec(int,int,boolean)
org.webrtc.AudioProcessingFactory: long createNative()
org.webrtc.NetworkChangeDetector$Observer: void onNetworkPreference(java.util.List,int)
org.webrtc.NativeAndroidVideoTrackSource: void setState(boolean)
org.webrtc.AudioSource: AudioSource(long)
org.webrtc.Camera2Session$CaptureSessionCallback: void chooseStabilizationMode(android.hardware.camera2.CaptureRequest$Builder)
org.webrtc.EglBase10Impl: void createPbufferSurface(int,int)
org.webrtc.PeerConnectionFactory: org.webrtc.RtpCapabilities nativeGetRtpReceiverCapabilities(long,org.webrtc.MediaStreamTrack$MediaType)
org.webrtc.RTCStats: java.lang.String getType()
io.flutter.view.AccessibilityBridge$StringAttributeType: io.flutter.view.AccessibilityBridge$StringAttributeType[] values()
org.webrtc.audio.JavaAudioDeviceModule$SamplesReadyCallback: void onWebRtcAudioRecordSamplesReady(org.webrtc.audio.JavaAudioDeviceModule$AudioSamples)
androidx.window.core.Version$Companion: androidx.window.core.Version getVERSION_1_0()
com.google.protobuf.CodedOutputStream: CodedOutputStream()
org.webrtc.PeerConnection$KeyType: PeerConnection$KeyType(java.lang.String,int)
org.webrtc.EglRenderer: void pauseVideo()
com.google.firebase.firestore.FieldValue: FieldValue()
com.google.firebase.firestore.AggregateSource: com.google.firebase.firestore.AggregateSource[] values()
org.webrtc.VideoCapturer: boolean isScreencast()
kotlin.jvm.internal.Ref$IntRef: Ref$IntRef()
org.webrtc.VideoEncoderFallback: long nativeCreateEncoder(org.webrtc.VideoEncoder,org.webrtc.VideoEncoder)
io.grpc.CallCredentials: CallCredentials()
org.webrtc.DataChannel$Init: int getId()
org.webrtc.JavaI420Buffer: void lambda$allocate$0(java.nio.ByteBuffer)
com.google.protobuf.Writer$FieldOrder: com.google.protobuf.Writer$FieldOrder[] values()
org.webrtc.audio.WebRtcAudioRecord: void logMainParameters()
org.webrtc.NV21Buffer: void release()
org.webrtc.PeerConnection: org.webrtc.RtpTransceiver nativeAddTransceiverOfType(org.webrtc.MediaStreamTrack$MediaType,org.webrtc.RtpTransceiver$RtpTransceiverInit)
org.webrtc.voiceengine.BuildInfo: java.lang.String getDeviceModel()
com.cloudwebrtc.webrtc.utils.AnyThreadResult: void lambda$error$1(java.lang.String,java.lang.String,java.lang.Object)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void trackDispose(java.lang.String)
org.webrtc.TextureBufferImpl$1: void onDestroy(org.webrtc.TextureBufferImpl)
org.webrtc.MediaStreamTrack$MediaType: int getNative()
org.webrtc.Camera1Session: void checkIsOnCameraThread()
org.webrtc.CameraCapturer$4: void onFirstFrameAvailable()
org.webrtc.PeerConnection$IceServer: java.lang.String getPassword()
io.flutter.view.AccessibilityViewEmbedder: android.view.accessibility.AccessibilityNodeInfo getRootNode(android.view.View,int,android.graphics.Rect)
com.cloudwebrtc.webrtc.GetUserMediaImpl: void access$000(com.cloudwebrtc.webrtc.GetUserMediaImpl,com.cloudwebrtc.webrtc.utils.ConstraintsMap,io.flutter.plugin.common.MethodChannel$Result,org.webrtc.MediaStream,java.util.List)
io.grpc.okhttp.OkHttpChannelBuilder$NegotiationType: io.grpc.okhttp.OkHttpChannelBuilder$NegotiationType[] values()
org.webrtc.HardwareVideoEncoder: java.lang.Thread createOutputThread()
org.webrtc.Camera1Session: org.webrtc.Size findClosestPictureSize(android.hardware.Camera$Parameters,int,int)
io.flutter.view.AccessibilityViewEmbedder: android.view.View platformViewOfNode(int)
org.webrtc.PeerConnection$RTCConfiguration: boolean getDisableIPv6OnWifi()
org.webrtc.NetworkMonitorAutoDetect: java.lang.String getWifiSSID(org.webrtc.NetworkMonitorAutoDetect$NetworkState)
com.twilio.audioswitch.bluetooth.BluetoothHeadsetManager$Companion: BluetoothHeadsetManager$Companion()
org.webrtc.Camera2Session: void openCamera()
org.webrtc.voiceengine.WebRtcAudioManager: void setBlacklistDeviceForOpenSLESUsage(boolean)
org.webrtc.voiceengine.WebRtcAudioTrack: void setSpeakerMute(boolean)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void rtpTransceiverGetDirection(java.lang.String,java.lang.String,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.SurfaceViewRenderer: void surfaceCreated(android.view.SurfaceHolder)
org.webrtc.PlatformSoftwareVideoDecoderFactory$1: boolean test(android.media.MediaCodecInfo)
org.webrtc.GlGenericDrawer$ShaderCallbacks: void onPrepareShader(org.webrtc.GlShader,float[],int,int,int,int)
org.webrtc.PeerConnectionFactory: org.webrtc.PeerConnection createPeerConnection(org.webrtc.PeerConnection$RTCConfiguration,org.webrtc.PeerConnection$Observer)
androidx.fragment.app.FragmentActivity: FragmentActivity()
com.cloudwebrtc.webrtc.GetUserMediaImpl: void switchCamera(java.lang.String,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.audio.WebRtcAudioRecord$AudioRecordThread: void stopThread()
androidx.window.embedding.ActivityRule: ActivityRule(java.util.Set,boolean)
kotlin.jvm.internal.ReflectionFactory: ReflectionFactory()
androidx.window.embedding.SplitController: void addSplitListener(android.app.Activity,java.util.concurrent.Executor,androidx.core.util.Consumer)
org.webrtc.CameraEnumerationAndroid: org.webrtc.Size getClosestSupportedSize(java.util.List,int,int)
io.grpc.internal.GzipInflatingBuffer$State: io.grpc.internal.GzipInflatingBuffer$State[] values()
androidx.window.embedding.SplitPairFilter: android.content.ComponentName getSecondaryActivityName()
org.webrtc.RtpSender: boolean setTrack(org.webrtc.MediaStreamTrack,boolean)
io.flutter.embedding.engine.FlutterJNI: boolean isCodePointVariantSelector(int)
com.cloudwebrtc.webrtc.utils.ConstraintsArray: void pushNull()
io.flutter.embedding.engine.FlutterJNI: void nativeCleanupMessageData(long)
org.webrtc.VideoFrameDrawer$YuvUploader: int[] getYuvTextures()
org.webrtc.PeerConnection$RTCConfiguration: boolean getSurfaceIceCandidatesOnIceTransportTypeChanged()
org.webrtc.HardwareVideoEncoderFactory: org.webrtc.BitrateAdjuster createBitrateAdjuster(org.webrtc.VideoCodecMimeType,java.lang.String)
org.webrtc.MediaCodecUtils: boolean isHardwareAcceleratedQOrHigher(android.media.MediaCodecInfo)
org.webrtc.EglBase14$Context: android.opengl.EGLContext getRawContext()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void peerConnectionSetConfiguration(com.cloudwebrtc.webrtc.utils.ConstraintsMap,org.webrtc.PeerConnection)
org.webrtc.audio.WebRtcAudioManager: int getMinOutputFrameSize(int,int)
org.webrtc.AndroidVideoDecoder$1: AndroidVideoDecoder$1(org.webrtc.AndroidVideoDecoder,java.lang.String)
org.webrtc.CameraCapturer$2: void onCameraOpening()
org.webrtc.MediaStreamTrack$MediaType: org.webrtc.MediaStreamTrack$MediaType valueOf(java.lang.String)
org.webrtc.audio.WebRtcAudioUtils: boolean hasMicrophone(android.content.Context)
io.flutter.embedding.engine.FlutterJNI: boolean nativeFlutterTextUtilsIsVariationSelector(int)
org.webrtc.RendererCommon: void adjustOrigin(float[])
org.webrtc.Camera2Session$SessionState: org.webrtc.Camera2Session$SessionState valueOf(java.lang.String)
org.webrtc.NetworkMonitorAutoDetect$ConnectivityManagerDelegate: boolean supportNetworkCallback()
org.webrtc.Camera1Enumerator: java.lang.String[] getDeviceNames()
com.google.firestore.v1.Precondition$Builder: Precondition$Builder()
org.webrtc.Camera2Session$CameraStateCallback: java.lang.String getErrorDescription(int)
com.cloudwebrtc.webrtc.record.AudioTrackInterceptor: void release()
io.flutter.embedding.android.FlutterImageView: io.flutter.embedding.engine.renderer.FlutterRenderer getAttachedRenderer()
org.webrtc.voiceengine.BuildInfo: java.lang.String getBrand()
androidx.window.embedding.EmbeddingBackend: void registerRule(androidx.window.embedding.EmbeddingRule)
org.webrtc.RtpReceiver: long getNativeRtpReceiver()
androidx.window.layout.SidecarCompat$TranslatingCallback: void onDeviceStateChanged(androidx.window.sidecar.SidecarDeviceState)
androidx.window.core.Bounds: android.graphics.Rect toRect()
org.webrtc.voiceengine.BuildInfo: BuildInfo()
io.flutter.embedding.engine.systemchannels.PlatformChannel$SystemUiMode: io.flutter.embedding.engine.systemchannels.PlatformChannel$SystemUiMode[] values()
org.webrtc.CameraVideoCapturer$CameraSwitchHandler: void onCameraSwitchError(java.lang.String)
com.google.firebase.firestore.remote.TargetState: TargetState()
org.webrtc.MediaStream: void dispose()
org.webrtc.CameraCapturer$8: CameraCapturer$8(org.webrtc.CameraCapturer,org.webrtc.CameraVideoCapturer$CameraSwitchHandler,java.lang.String)
com.google.firestore.v1.StructuredQuery: StructuredQuery()
com.cloudwebrtc.webrtc.audio.AudioSwitchManager: java.util.List availableAudioDevices()
org.webrtc.Camera2Session$CameraStateCallback: void onOpened(android.hardware.camera2.CameraDevice)
io.flutter.plugins.firebase.core.FlutterFirebaseCoreRegistrar: FlutterFirebaseCoreRegistrar()
com.google.firestore.v1.Target: Target()
com.google.firebase.firestore.Source: com.google.firebase.firestore.Source[] values()
io.grpc.okhttp.internal.TlsVersion: io.grpc.okhttp.internal.TlsVersion[] values()
io.grpc.internal.KeepAliveManager$State: io.grpc.internal.KeepAliveManager$State[] values()
org.webrtc.NetworkMonitor: void startMonitoring(android.content.Context)
org.webrtc.audio.JavaAudioDeviceModule: void setPreferredInputDevice(android.media.AudioDeviceInfo)
com.cloudwebrtc.webrtc.record.MediaRecorderImpl: void startRecording(java.io.File)
org.webrtc.EglBase$-CC: org.webrtc.EglBase10 createEgl10(javax.microedition.khronos.egl.EGLContext,int[])
io.flutter.view.AccessibilityBridge$Flag: io.flutter.view.AccessibilityBridge$Flag[] values()
org.webrtc.PeerConnection$IceServer: java.lang.String getUsername()
org.webrtc.Camera1Capturer: void dispose()
org.webrtc.voiceengine.WebRtcAudioTrack: int initPlayout(int,int,double)
kotlin.jvm.internal.TypeIntrinsics: TypeIntrinsics()
org.webrtc.CameraCapturer$SwitchState: org.webrtc.CameraCapturer$SwitchState[] $values()
kotlin.coroutines.jvm.internal.BaseContinuationImpl: java.lang.Object invokeSuspend(java.lang.Object)
io.flutter.embedding.engine.renderer.FlutterRenderer$DisplayFeatureType: io.flutter.embedding.engine.renderer.FlutterRenderer$DisplayFeatureType valueOf(java.lang.String)
org.webrtc.NetworkMonitorAutoDetect$WifiDirectManagerDelegate: void release()
org.webrtc.NativePeerConnectionFactory: long createNativePeerConnection()
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin: void onReattachedToActivityForConfigChanges(io.flutter.embedding.engine.plugins.activity.ActivityPluginBinding)
androidx.window.layout.SidecarAdapter$Companion: SidecarAdapter$Companion(kotlin.jvm.internal.DefaultConstructorMarker)
org.webrtc.Logging$TraceLevel: org.webrtc.Logging$TraceLevel[] $values()
io.flutter.embedding.engine.FlutterJNI: java.lang.String getVMServiceUri()
org.webrtc.VideoDecoder: long createNativeVideoDecoder()
androidx.window.layout.HardwareFoldingFeature: android.graphics.Rect getBounds()
com.cloudwebrtc.webrtc.CameraEventsHandler: void onCameraOpening(java.lang.String)
io.flutter.embedding.engine.FlutterJNI: void invokePlatformMessageEmptyResponseCallback(int)
org.webrtc.audio.JavaAudioDeviceModule$Builder: org.webrtc.audio.JavaAudioDeviceModule$Builder setAudioRecordStateCallback(org.webrtc.audio.JavaAudioDeviceModule$AudioRecordStateCallback)
org.webrtc.MediaCodecWrapperFactoryImpl$MediaCodecWrapperImpl: java.nio.ByteBuffer getInputBuffer(int)
androidx.window.embedding.ExtensionEmbeddingBackend: java.util.Set getSplitRules()
org.webrtc.MediaConstraints$KeyValuePair: java.lang.String getValue()
kotlinx.coroutines.internal.OpDescriptor: OpDescriptor()
org.webrtc.VideoFileRenderer$1: VideoFileRenderer$1(org.webrtc.VideoFileRenderer,org.webrtc.EglBase$Context)
org.webrtc.CameraVideoCapturer$CameraStatistics: void release()
org.webrtc.RendererCommon$GlDrawer: void drawYuv(int[],float[],int,int,int,int,int,int)
org.webrtc.PeerConnectionFactory$InitializationOptions$Builder: org.webrtc.PeerConnectionFactory$InitializationOptions$Builder setNativeLibraryName(java.lang.String)
org.webrtc.VideoCodecInfo: VideoCodecInfo(int,java.lang.String,java.util.Map)
com.google.protobuf.LongArrayList: LongArrayList()
com.cloudwebrtc.webrtc.OrientationAwareScreenCapturer: void startCapture(int,int,int)
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer$1: void onFirstFrameRendered()
kotlin.jvm.internal.CallableReference: java.util.List getTypeParameters()
org.webrtc.audio.WebRtcAudioTrack: void reportWebRtcAudioTrackInitError(java.lang.String)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void rtpTransceiverStop(java.lang.String,java.lang.String,io.flutter.plugin.common.MethodChannel$Result)
com.cloudwebrtc.webrtc.record.AudioTrackInterceptor: int write(java.nio.ByteBuffer,int,int)
androidx.window.layout.SidecarWindowBackend$ExtensionListenerImpl: void onWindowLayoutChanged(android.app.Activity,androidx.window.layout.WindowLayoutInfo)
org.webrtc.FileVideoCapturer$1: void run()
io.grpc.internal.ReflectionLongAdderCounter: ReflectionLongAdderCounter()
com.cloudwebrtc.webrtc.PeerConnectionObserver: void rtpTransceiverGetDirection(java.lang.String,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.Camera1Session$SessionState: org.webrtc.Camera1Session$SessionState valueOf(java.lang.String)
androidx.window.embedding.ActivityRule: androidx.window.embedding.ActivityRule plus$window_release(androidx.window.embedding.ActivityFilter)
com.google.protobuf.WireFormat$JavaType: com.google.protobuf.WireFormat$JavaType valueOf(java.lang.String)
androidx.window.embedding.EmbeddingCompat$Companion: boolean isEmbeddingAvailable()
org.webrtc.HardwareVideoEncoderFactory: HardwareVideoEncoderFactory(org.webrtc.EglBase$Context,boolean,boolean,org.webrtc.Predicate)
androidx.window.embedding.SplitInfo: boolean equals(java.lang.Object)
org.webrtc.Camera2Session$CaptureSessionCallback: void lambda$onConfigured$0(org.webrtc.VideoFrame)
io.flutter.embedding.engine.FlutterJNI: boolean isCodePointEmojiModifier(int)
org.webrtc.PeerConnectionFactory: void nativeInitializeInternalTracer()
org.webrtc.ScreenCapturerAndroid: void changeCaptureFormat(int,int,int)
org.webrtc.SurfaceTextureHelper$2: void onRelease(org.webrtc.TextureBufferImpl)
androidx.window.embedding.ExtensionEmbeddingBackend$EmbeddingCallbackImpl: void onSplitInfoChanged(java.util.List)
io.flutter.view.AccessibilityBridge$CustomAccessibilityAction: AccessibilityBridge$CustomAccessibilityAction()
com.cloudwebrtc.webrtc.audio.AudioSwitchManager: void lambda$selectAudioOutput$5(java.lang.Class)
androidx.window.core.Version: boolean equals(java.lang.Object)
org.webrtc.SoftwareVideoDecoderFactory: org.webrtc.VideoDecoder createDecoder(org.webrtc.VideoCodecInfo)
org.webrtc.audio.WebRtcAudioTrack: boolean setStreamVolume(int)
org.webrtc.WrappedNativeI420Buffer: void retain()
androidx.window.layout.ExtensionsWindowLayoutInfoAdapter: androidx.window.layout.FoldingFeature translate$window_release(android.app.Activity,androidx.window.extensions.layout.FoldingFeature)
io.flutter.embedding.engine.systemchannels.PlatformChannel$SystemUiMode: io.flutter.embedding.engine.systemchannels.PlatformChannel$SystemUiMode valueOf(java.lang.String)
io.flutter.embedding.engine.FlutterJNI: FlutterJNI()
org.webrtc.FrameCryptor: long getNativeFrameCryptor()
io.flutter.embedding.engine.mutatorsstack.FlutterMutatorsStack: java.util.List getMutators()
org.webrtc.EncodedImage$FrameType: org.webrtc.EncodedImage$FrameType[] $values()
com.cloudwebrtc.webrtc.audio.AudioSwitchManager: void lambda$start$3()
org.webrtc.WrappedNativeI420Buffer: int getWidth()
androidx.window.embedding.SplitController: SplitController()
org.webrtc.DefaultVideoEncoderFactory: DefaultVideoEncoderFactory(org.webrtc.EglBase$Context,boolean,boolean)
org.webrtc.GlRectDrawer$ShaderCallbacks: GlRectDrawer$ShaderCallbacks()
org.webrtc.LibvpxVp9Decoder: long nativeCreateDecoder()
org.webrtc.VideoDecoder: org.webrtc.VideoCodecStatus initDecode(org.webrtc.VideoDecoder$Settings,org.webrtc.VideoDecoder$Callback)
kotlin.jvm.internal.Intrinsics: Intrinsics()
org.webrtc.Metrics$HistogramInfo: Metrics$HistogramInfo(int,int,int)
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor: void frameCryptorGetEnabled(java.util.Map,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.VideoCapturer: void initialize(org.webrtc.SurfaceTextureHelper,android.content.Context,org.webrtc.CapturerObserver)
androidx.window.embedding.EmbeddingCompat: EmbeddingCompat()
com.cloudwebrtc.webrtc.record.MediaRecorderImpl: MediaRecorderImpl(java.lang.Integer,org.webrtc.VideoTrack,com.cloudwebrtc.webrtc.record.AudioSamplesInterceptor)
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin: void stopListening()
io.flutter.embedding.engine.FlutterJNI: void ensureNotAttachedToNative()
org.webrtc.HardwareVideoEncoderFactory: boolean isSupportedCodec(android.media.MediaCodecInfo,org.webrtc.VideoCodecMimeType)
androidx.window.layout.SidecarCompat: androidx.window.layout.ExtensionInterfaceCompat$ExtensionCallbackInterface access$getExtensionCallback$p(androidx.window.layout.SidecarCompat)
org.webrtc.voiceengine.WebRtcAudioManager: int getSampleRateForApiLevel()
org.webrtc.GlTextureFrameBuffer: int getFrameBufferId()
kotlinx.coroutines.scheduling.CoroutineScheduler$WorkerState: kotlinx.coroutines.scheduling.CoroutineScheduler$WorkerState valueOf(java.lang.String)
org.webrtc.CameraEnumerationAndroid$CaptureFormat: java.lang.String toString()
org.webrtc.NetworkMonitor: void notifyObserversOfNetworkDisconnect(long)
org.webrtc.Camera1Capturer: void changeCaptureFormat(int,int,int)
androidx.fragment.app.FragmentTransitionImpl: FragmentTransitionImpl()
com.cloudwebrtc.webrtc.PeerConnectionObserver: void getReceivers(io.flutter.plugin.common.MethodChannel$Result)
kotlinx.coroutines.JobCancellingNode: JobCancellingNode()
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor$FrameCryptorStateObserver: void onCancel(java.lang.Object)
com.cloudwebrtc.webrtc.audio.AudioSwitchManager: void start()
org.webrtc.CryptoOptions$Builder: CryptoOptions$Builder()
kotlin.jvm.internal.FunctionReferenceImpl: FunctionReferenceImpl(int,java.lang.Class,java.lang.String,java.lang.String,int)
org.webrtc.AudioTrack: long getNativeAudioTrack()
androidx.window.embedding.EmbeddingAdapter: java.util.Set translate(java.util.Set)
io.flutter.embedding.engine.FlutterJNI: void nativeNotifyLowMemoryWarning(long)
org.webrtc.VideoFrame: long getTimestampNs()
io.flutter.embedding.engine.mutatorsstack.FlutterMutatorsStack$FlutterMutatorType: io.flutter.embedding.engine.mutatorsstack.FlutterMutatorsStack$FlutterMutatorType[] values()
io.grpc.okhttp.OkHttpFrameLogger$SettingParams: io.grpc.okhttp.OkHttpFrameLogger$SettingParams[] values()
org.webrtc.FrameCryptorKeyProvider: long getNativeKeyProvider()
io.flutter.embedding.engine.FlutterJNI: void requestDartDeferredLibrary(int)
org.webrtc.PeerConnection$RTCConfiguration: int getIceBackupCandidatePairPingInterval()
org.webrtc.CameraCapturer$9: CameraCapturer$9(org.webrtc.CameraCapturer,org.webrtc.CameraSession)
org.webrtc.Logging: void w(java.lang.String,java.lang.String)
org.webrtc.VideoFrameDrawer: org.webrtc.VideoFrame$Buffer prepareBufferForViewportSize(org.webrtc.VideoFrame$Buffer,int,int)
io.flutter.embedding.engine.systemchannels.TextInputChannel$TextCapitalization: io.flutter.embedding.engine.systemchannels.TextInputChannel$TextCapitalization valueOf(java.lang.String)
org.webrtc.EglRenderer$1: void run()
org.webrtc.PeerConnection: java.util.List nativeGetSenders()
io.flutter.plugins.firebase.core.GeneratedAndroidFirebaseCore$PigeonInitializeResponse: GeneratedAndroidFirebaseCore$PigeonInitializeResponse()
org.webrtc.audio.WebRtcAudioEffects: boolean isAcousticEchoCancelerSupported()
com.cloudwebrtc.webrtc.StateProvider: org.webrtc.MediaStreamTrack getLocalTrack(java.lang.String)
com.google.firestore.v1.MapValue$Builder: MapValue$Builder()
org.webrtc.SurfaceEglRenderer: void updateFrameDimensionsAndReportEvents(org.webrtc.VideoFrame)
org.webrtc.Camera2Enumerator: java.util.List getSupportedFormats(android.content.Context,java.lang.String)
io.flutter.embedding.engine.FlutterJNI: void dispatchSemanticsAction(int,int,java.nio.ByteBuffer,int)
org.webrtc.MediaConstraints$KeyValuePair: java.lang.String getKey()
org.webrtc.MediaConstraints$KeyValuePair: java.lang.String toString()
kotlin.jvm.internal.FunctionReference: FunctionReference(int)
com.google.firestore.v1.StructuredQuery$UnaryFilter$Operator: com.google.firestore.v1.StructuredQuery$UnaryFilter$Operator[] values()
com.cloudwebrtc.webrtc.GetUserMediaImpl: void addDefaultAudioConstraints(org.webrtc.MediaConstraints)
kotlin.jvm.internal.CallableReference: java.lang.String getName()
org.webrtc.PeerConnectionFactory$Builder: org.webrtc.PeerConnectionFactory$Builder setOptions(org.webrtc.PeerConnectionFactory$Options)
org.webrtc.HardwareVideoEncoder: void updateInputFormat(android.media.MediaFormat)
org.webrtc.Camera2Capturer: void dispose()
org.webrtc.RtpTransceiver: org.webrtc.RtpSender nativeGetSender(long)
androidx.window.layout.SidecarAdapter: java.util.List translate(java.util.List,androidx.window.sidecar.SidecarDeviceState)
androidx.window.embedding.SplitController: SplitController(kotlin.jvm.internal.DefaultConstructorMarker)
androidx.window.layout.HardwareFoldingFeature: androidx.window.layout.FoldingFeature$OcclusionType getOcclusionType()
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper: org.webrtc.VideoEncoder$Settings getStreamSettings()
com.google.protobuf.GeneratedMessageLite$MethodToInvoke: com.google.protobuf.GeneratedMessageLite$MethodToInvoke[] values()
org.webrtc.PeerConnectionDependencies: PeerConnectionDependencies(org.webrtc.PeerConnection$Observer,org.webrtc.SSLCertificateVerifier)
com.cloudwebrtc.webrtc.record.AudioChannel: AudioChannel(java.lang.String,int)
androidx.window.java.layout.WindowInfoTrackerCallbackAdapter$addListener$1$1$invokeSuspend$$inlined$collect$1: WindowInfoTrackerCallbackAdapter$addListener$1$1$invokeSuspend$$inlined$collect$1(androidx.core.util.Consumer)
org.webrtc.PeerConnection$IceGatheringState: org.webrtc.PeerConnection$IceGatheringState fromNativeIndex(int)
org.webrtc.EglBase10$Context: javax.microedition.khronos.egl.EGLContext getRawContext()
org.webrtc.EglRenderer: void logW(java.lang.String)
org.webrtc.Camera2Enumerator: java.util.List getSupportedFormats(java.lang.String)
org.webrtc.NetworkMonitor$2: NetworkMonitor$2(org.webrtc.NetworkMonitor,java.lang.String)
com.cloudwebrtc.webrtc.SurfaceTextureRenderer: void setFpsReduction(float)
org.webrtc.PeerConnection$PeerConnectionState: org.webrtc.PeerConnection$PeerConnectionState[] values()
org.webrtc.AudioSource: long getNativeAudioSource()
org.webrtc.GlTextureFrameBuffer: void release()
androidx.window.java.layout.WindowInfoTrackerCallbackAdapter: WindowInfoTrackerCallbackAdapter(androidx.window.layout.WindowInfoTracker)
org.webrtc.PeerConnection$IceGatheringState: PeerConnection$IceGatheringState(java.lang.String,int)
androidx.window.layout.FoldingFeature$Orientation$Companion: FoldingFeature$Orientation$Companion(kotlin.jvm.internal.DefaultConstructorMarker)
com.google.protobuf.FieldType$Collection: com.google.protobuf.FieldType$Collection[] values()
androidx.window.embedding.SplitController$Companion: void initialize(android.content.Context,int)
androidx.window.layout.WindowMetricsCalculatorCompat: int getNavigationBarHeight(android.content.Context)
org.webrtc.MediaCodecUtils: boolean isSoftwareOnly(android.media.MediaCodecInfo)
androidx.window.layout.SidecarWindowBackend: SidecarWindowBackend(androidx.window.layout.ExtensionInterfaceCompat)
org.webrtc.voiceengine.WebRtcAudioUtils: void setWebRtcBasedAcousticEchoCanceler(boolean)
androidx.window.embedding.SplitController: boolean isSplitSupported()
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer: void onListen(java.lang.Object,io.flutter.plugin.common.EventChannel$EventSink)
org.webrtc.PeerConnection$IceServer: org.webrtc.PeerConnection$IceServer$Builder builder(java.util.List)
okio.AsyncTimeout: AsyncTimeout()
org.webrtc.NetworkChangeDetector$NetworkInformation: NetworkChangeDetector$NetworkInformation(java.lang.String,org.webrtc.NetworkChangeDetector$ConnectionType,org.webrtc.NetworkChangeDetector$ConnectionType,long,org.webrtc.NetworkChangeDetector$IPAddress[])
org.webrtc.FrameCryptorFactory: org.webrtc.FrameCryptor createFrameCryptorForRtpSender(org.webrtc.RtpSender,java.lang.String,org.webrtc.FrameCryptorAlgorithm,org.webrtc.FrameCryptorKeyProvider)
com.cloudwebrtc.webrtc.PeerConnectionObserver: void sendEvent(com.cloudwebrtc.webrtc.utils.ConstraintsMap)
org.webrtc.AddIceObserver: void onAddSuccess()
org.webrtc.YuvHelper: void I420ToNV12(java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,int)
com.cloudwebrtc.webrtc.PeerConnectionObserver: org.webrtc.RtpTransceiver getRtpTransceiverById(java.lang.String)
org.webrtc.PeerConnectionFactory: void nativeInjectLoggable(org.webrtc.JNILogging,int)
org.webrtc.TextureBufferImpl: int getHeight()
androidx.window.embedding.SplitPairFilter: boolean matchesActivityIntentPair(android.app.Activity,android.content.Intent)
androidx.window.layout.ExtensionWindowLayoutInfoBackend$MulticastConsumer: boolean isEmpty()
org.webrtc.audio.LowLatencyAudioBufferManager: void maybeAdjustBufferSize(android.media.AudioTrack)
androidx.window.embedding.SplitRuleParser: androidx.window.embedding.SplitPairFilter parseSplitPairFilter(android.content.Context,android.content.res.XmlResourceParser)
com.cloudwebrtc.webrtc.utils.AnyThreadSink: void endOfStream()
org.webrtc.PeerConnectionFactory: java.lang.String fieldTrialsFindFullName(java.lang.String)
org.webrtc.RtpReceiver: void nativeSetFrameDecryptor(long,long)
org.webrtc.CryptoOptions$SFrame: CryptoOptions$SFrame(org.webrtc.CryptoOptions,boolean)
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer: void setEventChannel(io.flutter.plugin.common.EventChannel)
com.cloudwebrtc.webrtc.PeerConnectionObserver: void addTrack(org.webrtc.MediaStreamTrack,java.util.List,io.flutter.plugin.common.MethodChannel$Result)
io.grpc.okhttp.OkHttpFrameLogger$Direction: io.grpc.okhttp.OkHttpFrameLogger$Direction valueOf(java.lang.String)
org.webrtc.SdpObserver: void onSetSuccess()
kotlinx.coroutines.android.AndroidExceptionPreHandler: AndroidExceptionPreHandler()
io.flutter.view.AccessibilityViewEmbedder: AccessibilityViewEmbedder(android.view.View,int)
com.google.firebase.firestore.core.EventManager$QueryListenersInfo: EventManager$QueryListenersInfo()
kotlin.jvm.internal.CallableReference: boolean isFinal()
org.webrtc.LibaomAv1Encoder: long nativeCreateEncoder()
androidx.window.embedding.SplitController: void unregisterRule(androidx.window.embedding.EmbeddingRule)
org.webrtc.PeerConnectionFactory: org.webrtc.VideoSource createVideoSource(boolean,boolean)
io.flutter.embedding.android.FlutterSplashView$SavedState: java.lang.String access$602(io.flutter.embedding.android.FlutterSplashView$SavedState,java.lang.String)
org.webrtc.IceCandidate: boolean equals(java.lang.Object)
androidx.window.layout.SidecarWindowBackend: boolean isActivityRegistered(android.app.Activity)
org.webrtc.NetworkMonitor: void assertIsTrue(boolean)
org.webrtc.SurfaceTextureHelper$1: java.lang.Object call()
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin: void onDetachedFromActivityForConfigChanges()
com.cloudwebrtc.webrtc.utils.AnyThreadResult: void error(java.lang.String,java.lang.String,java.lang.Object)
io.flutter.embedding.engine.FlutterJNI: boolean nativeFlutterTextUtilsIsRegionalIndicator(int)
com.cloudwebrtc.webrtc.GetUserMediaImpl: void access$100(java.lang.String,java.lang.String,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.audio.JavaAudioDeviceModule: void release()
com.cloudwebrtc.webrtc.utils.EglUtils: org.webrtc.EglBase getRootEglBase()
androidx.window.embedding.EmbeddingBackend: void setSplitRules(java.util.Set)
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer: void setId(int)
io.flutter.embedding.android.FlutterSplashView$SavedState: FlutterSplashView$SavedState(android.os.Parcelable)
org.webrtc.ScreenCapturerAndroid: void checkNotDisposed()
org.webrtc.voiceengine.WebRtcAudioRecord: void setAudioSource(int)
org.webrtc.MediaCodecWrapperFactoryImpl$MediaCodecWrapperImpl: void configure(android.media.MediaFormat,android.view.Surface,android.media.MediaCrypto,int)
androidx.window.layout.WindowMetricsCalculator$-CC: androidx.window.layout.WindowMetricsCalculator getOrCreate()
org.webrtc.NetworkChangeDetector$Observer: void onConnectionTypeChanged(org.webrtc.NetworkChangeDetector$ConnectionType)
com.google.firebase.firestore.proto.NoDocument: NoDocument()
org.webrtc.audio.WebRtcAudioTrackUtils: void attachOutputCallback(org.webrtc.audio.JavaAudioDeviceModule$SamplesReadyCallback,org.webrtc.audio.JavaAudioDeviceModule)
org.webrtc.HardwareVideoEncoder: void requestKeyFrame(long)
org.webrtc.CameraVideoCapturer$CameraStatistics: void checkThread()
com.cloudwebrtc.webrtc.utils.ConstraintsMap: void putArray(java.lang.String,java.util.ArrayList)
org.webrtc.audio.JavaAudioDeviceModule$AudioRecordStateCallback: void onWebRtcAudioRecordStart()
org.webrtc.DataChannel: boolean nativeSend(byte[],boolean)
org.webrtc.ScreenCapturerAndroid$1: void run()
org.webrtc.audio.VolumeLogger$LogVolumeTask: void run()
io.grpc.okhttp.internal.framed.Http2$FrameLogger: Http2$FrameLogger()
org.webrtc.PeerConnection: void nativeFreeOwnedPeerConnection(long)
org.webrtc.MediaCodecVideoDecoderFactory: MediaCodecVideoDecoderFactory(org.webrtc.EglBase$Context,org.webrtc.Predicate)
org.webrtc.MediaCodecWrapper: java.nio.ByteBuffer getOutputBuffer(int)
org.webrtc.H264Utils: H264Utils()
org.webrtc.Camera1Session: void stop()
com.cloudwebrtc.webrtc.R$integer: R$integer()
org.webrtc.PeerConnection: void setLocalDescription(org.webrtc.SdpObserver,org.webrtc.SessionDescription)
org.webrtc.VideoEncoder: long createNativeVideoEncoder()
io.grpc.stub.ClientCalls$StubType: io.grpc.stub.ClientCalls$StubType[] values()
org.webrtc.RendererCommon$RendererEvents: void onFrameResolutionChanged(int,int,int)
com.cloudwebrtc.webrtc.PeerConnectionObserver: org.webrtc.RtpTransceiver$RtpTransceiverDirection stringToTransceiverDirection(java.lang.String)
org.webrtc.VideoEncoderFactory: org.webrtc.VideoCodecInfo[] getImplementations()
org.webrtc.PeerConnection$RTCConfiguration: org.webrtc.PeerConnection$TcpCandidatePolicy getTcpCandidatePolicy()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void setActivity(android.app.Activity)
org.webrtc.voiceengine.WebRtcAudioManager: boolean isLowLatencyInputSupported()
io.flutter.embedding.engine.FlutterJNI: void nativeRegisterTexture(long,long,java.lang.ref.WeakReference)
org.webrtc.FrameCryptor$FrameCryptionState: org.webrtc.FrameCryptor$FrameCryptionState fromNativeIndex(int)
org.webrtc.VideoFrame$TextureBuffer$-CC: org.webrtc.VideoFrame$TextureBuffer $default$applyTransformMatrix(org.webrtc.VideoFrame$TextureBuffer,android.graphics.Matrix,int,int)
org.webrtc.PeerConnection: boolean nativeOldGetStats(org.webrtc.StatsObserver,long)
org.webrtc.NetworkMonitor$2: void onNetworkPreference(java.util.List,int)
com.google.firestore.v1.TargetChange: TargetChange()
com.google.firebase.firestore.AggregateSource: com.google.firebase.firestore.AggregateSource valueOf(java.lang.String)
com.cloudwebrtc.webrtc.GetUserMediaImpl: void lambda$removeVideoCapturer$0(java.lang.String)
com.google.protobuf.DoubleArrayList: DoubleArrayList()
org.webrtc.LibvpxVp8Encoder: LibvpxVp8Encoder()
org.webrtc.VideoFrameDrawer: void drawFrame(org.webrtc.VideoFrame,org.webrtc.RendererCommon$GlDrawer,android.graphics.Matrix,int,int,int,int)
org.webrtc.PeerConnection: void nativeSetLocalDescriptionAutomatically(org.webrtc.SdpObserver)
org.webrtc.FileVideoCapturer: void tick()
org.webrtc.PeerConnection: void nativeCreateOffer(org.webrtc.SdpObserver,org.webrtc.MediaConstraints)
io.flutter.embedding.android.FlutterSplashView$SavedState: java.lang.String access$600(io.flutter.embedding.android.FlutterSplashView$SavedState)
org.webrtc.audio.WebRtcAudioRecord: java.util.concurrent.ScheduledExecutorService newDefaultScheduler()
io.grpc.internal.DnsNameResolverProvider: int priority()
com.cloudwebrtc.webrtc.PeerConnectionObserver: void rtpSenderSetStreams(java.lang.String,java.util.List,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.FrameCryptor: void nativeSetKeyIndex(long,int)
org.webrtc.CameraVideoCapturer$CameraEventsHandler: void onCameraDisconnected()
org.webrtc.PeerConnection: org.webrtc.SessionDescription getLocalDescription()
org.webrtc.PeerConnection$SignalingState: org.webrtc.PeerConnection$SignalingState valueOf(java.lang.String)
org.webrtc.GlTextureFrameBuffer: int getTextureId()
com.cloudwebrtc.webrtc.audio.AudioSwitchManager: void initAudioSwitch()
kotlinx.coroutines.channels.Receive: Receive()
org.webrtc.PeerConnection$Observer: void onRemoveTrack(org.webrtc.RtpReceiver)
org.webrtc.LibvpxVp9Decoder: boolean nativeIsSupported()
androidx.window.layout.SidecarWindowBackend$WindowLayoutChangeCallbackWrapper: SidecarWindowBackend$WindowLayoutChangeCallbackWrapper(android.app.Activity,java.util.concurrent.Executor,androidx.core.util.Consumer)
org.webrtc.PeerConnection: org.webrtc.RtpSender nativeCreateSender(java.lang.String,java.lang.String)
io.flutter.embedding.engine.mutatorsstack.FlutterMutatorView: android.graphics.Matrix getPlatformViewMatrix()
org.webrtc.voiceengine.WebRtcAudioRecord: int getDefaultAudioSource()
org.webrtc.VideoFileRenderer: void lambda$onFrame$0(org.webrtc.VideoFrame)
org.webrtc.CameraCapturer$1: CameraCapturer$1(org.webrtc.CameraCapturer)
org.webrtc.voiceengine.WebRtcAudioTrack: int getStreamMaxVolume()
org.webrtc.audio.VolumeLogger: VolumeLogger(android.media.AudioManager)
org.webrtc.NetworkChangeDetector$ConnectionType: NetworkChangeDetector$ConnectionType(java.lang.String,int)
io.flutter.embedding.engine.systemchannels.PlatformChannel$ClipboardContentFormat: io.flutter.embedding.engine.systemchannels.PlatformChannel$ClipboardContentFormat[] values()
io.flutter.embedding.engine.systemchannels.PlatformChannel$DeviceOrientation: io.flutter.embedding.engine.systemchannels.PlatformChannel$DeviceOrientation valueOf(java.lang.String)
androidx.window.layout.SidecarCompat: SidecarCompat(androidx.window.sidecar.SidecarInterface,androidx.window.layout.SidecarAdapter)
io.grpc.NameResolver: NameResolver()
org.webrtc.RtpParameters$Encoding: java.lang.Integer getMaxBitrateBps()
androidx.window.layout.WindowInfoTracker$Companion: androidx.window.layout.WindowBackend windowBackend$window_release(android.content.Context)
org.webrtc.Camera2Enumerator: org.webrtc.CameraVideoCapturer createCapturer(java.lang.String,org.webrtc.CameraVideoCapturer$CameraEventsHandler)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void streamDispose(java.lang.String)
androidx.window.embedding.ActivityFilter: boolean matchesActivity(android.app.Activity)
com.cloudwebrtc.webrtc.R$id: R$id()
androidx.window.embedding.SplitRule: int getLayoutDirection()
io.grpc.internal.ClientStreamListener$RpcProgress: io.grpc.internal.ClientStreamListener$RpcProgress valueOf(java.lang.String)
androidx.window.layout.HardwareFoldingFeature$Type$Companion: HardwareFoldingFeature$Type$Companion(kotlin.jvm.internal.DefaultConstructorMarker)
androidx.window.layout.SidecarWindowBackend$WindowLayoutChangeCallbackWrapper: void accept(androidx.window.layout.WindowLayoutInfo)
com.cloudwebrtc.webrtc.utils.PermissionUtils: void send(android.os.ResultReceiver,int,java.lang.String[],int[])
androidx.window.core.Version: java.lang.String getDescription()
org.webrtc.VideoCapturer: void startCapture(int,int,int)
androidx.window.embedding.SplitRule: int getMinWidth()
org.webrtc.EglRenderer: void onFrame(org.webrtc.VideoFrame)
org.webrtc.RendererCommon$GlDrawer: void release()
org.webrtc.audio.WebRtcAudioTrack: int GetPlayoutUnderrunCount()
org.webrtc.LibvpxVp9Encoder: long createNativeVideoEncoder()
org.webrtc.PeerConnection$Observer$-CC: void $default$onIceCandidateError(org.webrtc.PeerConnection$Observer,org.webrtc.IceCandidateErrorEvent)
org.webrtc.EglRenderer: void printStackTrace()
androidx.fragment.app.Fragment: Fragment()
androidx.window.layout.SidecarCompat: java.util.Map access$getWindowListenerRegisteredContexts$p(androidx.window.layout.SidecarCompat)
org.webrtc.EncodedImage$Builder: org.webrtc.EncodedImage$Builder setCaptureTimeNs(long)
org.webrtc.YuvHelper: void nativeI420ToNV12(java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,int,int)
io.grpc.Context$DirectExecutor: io.grpc.Context$DirectExecutor valueOf(java.lang.String)
org.webrtc.PeerConnectionFactory: void printStackTrace(org.webrtc.PeerConnectionFactory$ThreadInfo,boolean)
org.webrtc.VideoFrame: org.webrtc.VideoFrame$Buffer getBuffer()
org.webrtc.IceCandidate: boolean objectEquals(java.lang.Object,java.lang.Object)
org.webrtc.Logging: void enableLogTimeStamps()
io.flutter.embedding.engine.FlutterJNI: void runBundleAndSnapshotFromLibrary(java.lang.String,java.lang.String,java.lang.String,android.content.res.AssetManager,java.util.List)
org.webrtc.voiceengine.WebRtcAudioTrack$WebRtcAudioTrackErrorCallback: void onWebRtcAudioTrackStartError(java.lang.String)
org.webrtc.CameraVideoCapturer$-CC: void $default$removeMediaRecorderFromCamera(org.webrtc.CameraVideoCapturer,org.webrtc.CameraVideoCapturer$MediaRecorderHandler)
org.webrtc.CallSessionFileRotatingLogSink: void dispose()
androidx.window.layout.FoldingFeature$Orientation$Companion: FoldingFeature$Orientation$Companion()
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper: org.webrtc.VideoEncoder$ResolutionBitrateLimits[] getResolutionBitrateLimits()
org.webrtc.PeerConnection: long nativeGetNativePeerConnection()
org.webrtc.Camera1Enumerator: boolean isFrontFacing(java.lang.String)
kotlinx.coroutines.android.AndroidDispatcherFactory: kotlinx.coroutines.MainCoroutineDispatcher createDispatcher(java.util.List)
io.grpc.okhttp.internal.Platform$TlsExtensionType: io.grpc.okhttp.internal.Platform$TlsExtensionType[] values()
kotlin.coroutines.AbstractCoroutineContextElement: kotlin.coroutines.CoroutineContext$Element get(kotlin.coroutines.CoroutineContext$Key)
org.webrtc.SurfaceTextureHelper$3: SurfaceTextureHelper$3(org.webrtc.SurfaceTextureHelper)
org.webrtc.SurfaceTextureHelper: void lambda$dispose$6()
org.webrtc.PeerConnection$RTCConfiguration: org.webrtc.PeerConnection$AdapterType getNetworkPreference()
org.webrtc.MediaSource: void runWithReference(java.lang.Runnable)
org.webrtc.RendererCommon$GlDrawer: void drawOes(int,float[],int,int,int,int,int,int)
org.webrtc.voiceengine.WebRtcAudioUtils: boolean isDefaultSampleRateOverridden()
io.flutter.embedding.engine.FlutterJNI: void updateSemantics(java.nio.ByteBuffer,java.lang.String[],java.nio.ByteBuffer[])
org.webrtc.RtpParameters$Encoding: RtpParameters$Encoding(java.lang.String,boolean,double,int,java.lang.Integer,java.lang.Integer,java.lang.Integer,java.lang.Integer,java.lang.Double,java.lang.Long,boolean)
org.webrtc.StatsReport$Value: java.lang.String toString()
androidx.window.layout.SidecarAdapter: java.lang.String access$getTAG$cp()
org.webrtc.VideoEncoderFallback: VideoEncoderFallback(org.webrtc.VideoEncoder,org.webrtc.VideoEncoder)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: boolean putLocalStream(java.lang.String,org.webrtc.MediaStream)
com.google.protobuf.ProtoSyntax: com.google.protobuf.ProtoSyntax valueOf(java.lang.String)
androidx.window.embedding.SplitRule: SplitRule()
com.cloudwebrtc.webrtc.GetUserMediaImpl: java.util.Map access$400(com.cloudwebrtc.webrtc.GetUserMediaImpl)
org.webrtc.audio.WebRtcAudioEffects: WebRtcAudioEffects()
org.webrtc.TextureBufferImpl: org.webrtc.VideoFrame$I420Buffer lambda$toI420$1()
org.webrtc.AndroidVideoDecoder: org.webrtc.VideoFrame$Buffer copyI420Buffer(java.nio.ByteBuffer,int,int,int,int)
io.grpc.internal.GrpcUtil$Http2Error: io.grpc.internal.GrpcUtil$Http2Error[] values()
org.webrtc.EglBase: void releaseSurface()
io.flutter.embedding.engine.FlutterJNI: void setSemanticsEnabled(boolean)
com.google.firebase.firestore.remote.ConnectivityMonitor$NetworkStatus: com.google.firebase.firestore.remote.ConnectivityMonitor$NetworkStatus valueOf(java.lang.String)
org.webrtc.MediaCodecWrapper: android.media.MediaFormat getInputFormat()
org.webrtc.RtpSender: org.webrtc.MediaStreamTrack track()
com.google.firestore.admin.v1.Index$IndexField$Order: com.google.firestore.admin.v1.Index$IndexField$Order[] values()
org.webrtc.SdpObserver: void onSetFailure(java.lang.String)
org.webrtc.FrameDecryptor: long getNativeFrameDecryptor()
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor$FrameCryptorStateObserver$1: void onCancel(java.lang.Object)
kotlin.jvm.internal.CallableReference: boolean isAbstract()
org.webrtc.IceCandidate: java.lang.String getSdpMid()
org.webrtc.EglBase14Impl: void swapBuffers()
androidx.window.embedding.ExtensionEmbeddingBackend: void unregisterRule(androidx.window.embedding.EmbeddingRule)
org.webrtc.SurfaceViewRenderer: void onFrame(org.webrtc.VideoFrame)
com.cloudwebrtc.webrtc.GetUserMediaImpl$1: GetUserMediaImpl$1(com.cloudwebrtc.webrtc.GetUserMediaImpl,com.cloudwebrtc.webrtc.utils.ConstraintsMap,io.flutter.plugin.common.MethodChannel$Result,org.webrtc.MediaStream)
org.webrtc.GlShader: void release()
org.webrtc.PeerConnectionFactory: org.webrtc.VideoTrack createVideoTrack(java.lang.String,org.webrtc.VideoSource)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void addTrack(java.lang.String,java.lang.String,java.util.List,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.RtpCapabilities$CodecCapability: RtpCapabilities$CodecCapability(int,java.lang.String,org.webrtc.MediaStreamTrack$MediaType,java.lang.Integer,java.lang.Integer,java.lang.String,java.util.Map)
org.webrtc.RtpTransceiver: org.webrtc.RtpTransceiver$RtpTransceiverDirection getCurrentDirection()
org.webrtc.PeerConnectionFactory: void nativeInitializeAndroidGlobals()
androidx.window.R$attr: R$attr()
org.webrtc.EglBase14Impl: android.opengl.EGLContext createEglContext(android.opengl.EGLContext,android.opengl.EGLDisplay,android.opengl.EGLConfig,int)
org.webrtc.CameraCapturer$9: void run()
org.webrtc.AndroidVideoDecoder: void deliverTextureFrame(int,android.media.MediaCodec$BufferInfo,int,java.lang.Integer)
com.google.firestore.v1.StructuredQuery$FieldFilter$Operator: com.google.firestore.v1.StructuredQuery$FieldFilter$Operator valueOf(java.lang.String)
com.google.common.collect.Maps$EntryFunction: com.google.common.collect.Maps$EntryFunction[] values()
io.grpc.okhttp.internal.framed.ErrorCode: io.grpc.okhttp.internal.framed.ErrorCode valueOf(java.lang.String)
kotlin.coroutines.jvm.internal.BaseContinuationImpl: void releaseIntercepted()
androidx.window.embedding.EmbeddingCompat: void setSplitRules(java.util.Set)
org.webrtc.Predicate: org.webrtc.Predicate and(org.webrtc.Predicate)
com.cloudwebrtc.webrtc.GetUserMediaImpl$4: void onCameraSwitchError(java.lang.String)
org.webrtc.HardwareVideoEncoder: org.webrtc.VideoCodecStatus encodeByteBuffer(org.webrtc.VideoFrame,long)
org.webrtc.AndroidVideoDecoder$1: void run()
org.webrtc.audio.JavaAudioDeviceModule$Builder: org.webrtc.audio.JavaAudioDeviceModule$Builder setAudioAttributes(android.media.AudioAttributes)
org.webrtc.CameraSession$FailureType: org.webrtc.CameraSession$FailureType[] values()
org.webrtc.FrameCryptor$Observer: void onFrameCryptionStateChanged(java.lang.String,org.webrtc.FrameCryptor$FrameCryptionState)
org.webrtc.Camera1Session: org.webrtc.CameraEnumerationAndroid$CaptureFormat findClosestCaptureFormat(android.hardware.Camera$Parameters,int,int,int)
org.webrtc.FrameCryptorFactory: org.webrtc.FrameCryptorKeyProvider nativeCreateFrameCryptorKeyProvider(boolean,byte[],int,byte[])
org.webrtc.Logging$Severity: Logging$Severity(java.lang.String,int)
org.webrtc.FileVideoCapturer$VideoReader: void close()
org.webrtc.VideoSource: void adaptOutputFormat(int,int,int,int,int)
com.cloudwebrtc.webrtc.utils.ConstraintsArray: double getDouble(int)
io.grpc.NameResolver$ServiceConfigParser: NameResolver$ServiceConfigParser()
io.flutter.view.AccessibilityViewEmbedder: void copyAccessibilityFields(android.view.accessibility.AccessibilityNodeInfo,android.view.accessibility.AccessibilityNodeInfo)
org.webrtc.Logging: void v(java.lang.String,java.lang.String)
androidx.window.embedding.SplitRuleParser: java.util.Set parseSplitXml(android.content.Context,int)
androidx.window.java.layout.WindowInfoTrackerCallbackAdapter: void addListener(java.util.concurrent.Executor,androidx.core.util.Consumer,kotlinx.coroutines.flow.Flow)
org.webrtc.PeerConnectionFactory: org.webrtc.AudioSource createAudioSource(org.webrtc.MediaConstraints)
org.webrtc.YuvConverter$ShaderCallbacks: void onPrepareShader(org.webrtc.GlShader,float[],int,int,int,int)
androidx.window.layout.SidecarWindowBackend$WindowLayoutChangeCallbackWrapper: void accept$lambda-0(androidx.window.layout.SidecarWindowBackend$WindowLayoutChangeCallbackWrapper,androidx.window.layout.WindowLayoutInfo)
com.cloudwebrtc.webrtc.SurfaceTextureRenderer: void onFrame(org.webrtc.VideoFrame)
io.flutter.embedding.engine.systemchannels.PlatformChannel$HapticFeedbackType: io.flutter.embedding.engine.systemchannels.PlatformChannel$HapticFeedbackType valueOf(java.lang.String)
androidx.window.layout.HardwareFoldingFeature$Type: HardwareFoldingFeature$Type(java.lang.String)
org.webrtc.VideoFrame$TextureBuffer$Type: org.webrtc.VideoFrame$TextureBuffer$Type[] $values()
org.webrtc.YuvConverter$ShaderCallbacks: void setPlaneY()
org.webrtc.MediaStream: java.lang.String nativeGetId(long)
com.cloudwebrtc.webrtc.GetUserMediaImpl$3: void onReceiveResult(int,android.os.Bundle)
com.google.firestore.admin.v1.Index$IndexField: Index$IndexField()
org.webrtc.audio.JavaAudioDeviceModule$Builder: org.webrtc.audio.JavaAudioDeviceModule$Builder setAudioRecordErrorCallback(org.webrtc.audio.JavaAudioDeviceModule$AudioRecordErrorCallback)
io.flutter.embedding.engine.FlutterJNI: void nativePrefetchDefaultFontManager()
org.webrtc.voiceengine.WebRtcAudioUtils: java.lang.String getThreadInfo()
com.cloudwebrtc.webrtc.audio.AudioDeviceKind: com.cloudwebrtc.webrtc.audio.AudioDeviceKind valueOf(java.lang.String)
org.webrtc.SurfaceTextureHelper: void release()
org.webrtc.PeerConnection$IceServer: int hashCode()
kotlin.coroutines.jvm.internal.BaseContinuationImpl: java.lang.String toString()
com.cloudwebrtc.webrtc.PeerConnectionObserver: void lambda$getStatsForTrack$0(io.flutter.plugin.common.MethodChannel$Result,org.webrtc.RTCStatsReport)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$2: MethodCallHandlerImpl$2(com.cloudwebrtc.webrtc.MethodCallHandlerImpl,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.StatsReport: java.lang.String toString()
kotlin.jvm.internal.FunctionReference: boolean isSuspend()
org.webrtc.voiceengine.WebRtcAudioTrack$WebRtcAudioTrackErrorCallback: void onWebRtcAudioTrackInitError(java.lang.String)
org.webrtc.BaseBitrateAdjuster: BaseBitrateAdjuster()
org.webrtc.EglBase: void makeCurrent()
io.grpc.NameResolverRegistry: NameResolverRegistry()
org.webrtc.audio.JavaAudioDeviceModule: org.webrtc.audio.JavaAudioDeviceModule$Builder builder(android.content.Context)
com.google.firebase.firestore.FirestoreRegistrar: com.google.firebase.firestore.FirestoreMultiDbComponent lambda$getComponents$0(com.google.firebase.components.ComponentContainer)
org.webrtc.voiceengine.WebRtcAudioManager: boolean isAAudioSupported()
com.google.firestore.v1.Target$DocumentsTarget$Builder: Target$DocumentsTarget$Builder()
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin: void onAttachedToActivity(io.flutter.embedding.engine.plugins.activity.ActivityPluginBinding)
androidx.window.embedding.ActivityFilter: android.content.ComponentName getComponentName()
org.webrtc.DynamicBitrateAdjuster: void reportEncodedFrame(int)
androidx.window.embedding.ExtensionEmbeddingBackend: androidx.window.embedding.ExtensionEmbeddingBackend access$getGlobalInstance$cp()
com.cloudwebrtc.webrtc.record.VideoFileRenderer: VideoFileRenderer(java.lang.String,org.webrtc.EglBase$Context,boolean)
org.webrtc.audio.JavaAudioDeviceModule$AudioTrackErrorCallback: void onWebRtcAudioTrackInitError(java.lang.String)
org.webrtc.CameraEnumerationAndroid$CaptureFormat: CameraEnumerationAndroid$CaptureFormat(int,int,org.webrtc.CameraEnumerationAndroid$CaptureFormat$FramerateRange)
com.google.firebase.firestore.LoadBundleTaskProgress$TaskState: com.google.firebase.firestore.LoadBundleTaskProgress$TaskState[] values()
io.flutter.embedding.engine.FlutterJNI: android.graphics.Bitmap nativeGetBitmap(long)
org.webrtc.RendererCommon$ScalingType: RendererCommon$ScalingType(java.lang.String,int)
androidx.collection.ArraySet: ArraySet()
org.webrtc.YuvConverter$ShaderCallbacks: YuvConverter$ShaderCallbacks()
org.webrtc.NetworkChangeDetector$IPAddress: byte[] getAddress()
androidx.window.core.Version$Companion: androidx.window.core.Version getCURRENT()
org.webrtc.audio.JavaAudioDeviceModule$Builder: org.webrtc.audio.JavaAudioDeviceModule$Builder setScheduler(java.util.concurrent.ScheduledExecutorService)
androidx.window.core.Version: Version(int,int,int,java.lang.String)
org.webrtc.PeerConnectionFactory: void initializeFieldTrials(java.lang.String)
org.webrtc.CameraCapturer$4: void onCameraOpening(java.lang.String)
org.webrtc.RtpCapabilities$HeaderExtensionCapability: java.lang.String getUri()
org.webrtc.PeerConnection$IceGatheringState: org.webrtc.PeerConnection$IceGatheringState[] values()
org.webrtc.HardwareVideoEncoder: java.lang.String getImplementationName()
org.webrtc.FrameCryptorFactory: org.webrtc.FrameCryptor nativeCreateFrameCryptorForRtpReceiver(long,java.lang.String,int,long)
org.webrtc.EncodedImage$Builder: org.webrtc.EncodedImage$Builder setEncodedHeight(int)
org.webrtc.FrameCryptorAlgorithm: FrameCryptorAlgorithm(java.lang.String,int)
org.webrtc.MediaSource$State: MediaSource$State(java.lang.String,int)
org.webrtc.PeerConnection$IceGatheringState: org.webrtc.PeerConnection$IceGatheringState[] $values()
io.flutter.embedding.engine.FlutterJNI: void deferredComponentInstallFailure(int,java.lang.String,boolean)
org.webrtc.SdpObserver: void onCreateSuccess(org.webrtc.SessionDescription)
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer: FlutterRTCVideoRenderer(android.graphics.SurfaceTexture,io.flutter.view.TextureRegistry$SurfaceTextureEntry)
org.webrtc.PeerConnection: void setRemoteDescription(org.webrtc.SdpObserver,org.webrtc.SessionDescription)
io.grpc.internal.GzipInflatingBuffer: GzipInflatingBuffer()
org.webrtc.audio.WebRtcAudioTrack: WebRtcAudioTrack(android.content.Context,android.media.AudioManager)
org.webrtc.CameraEnumerationAndroid$CaptureFormat: int frameSize()
org.webrtc.PeerConnectionFactory$Builder: org.webrtc.PeerConnectionFactory$Builder setNetworkStatePredictorFactoryFactory(org.webrtc.NetworkStatePredictorFactoryFactory)
org.webrtc.CameraCapturer: boolean isScreencast()
org.webrtc.WrappedNativeVideoDecoder: org.webrtc.VideoCodecStatus decode(org.webrtc.EncodedImage,org.webrtc.VideoDecoder$DecodeInfo)
org.webrtc.VideoEncoderFactory$VideoEncoderSelector$-CC: org.webrtc.VideoCodecInfo $default$onResolutionChange(org.webrtc.VideoEncoderFactory$VideoEncoderSelector,int,int)
org.webrtc.EglBase10Impl: javax.microedition.khronos.egl.EGLConfig getEglConfig(javax.microedition.khronos.egl.EGL10,javax.microedition.khronos.egl.EGLDisplay,int[])
org.webrtc.MediaConstraints$KeyValuePair: int hashCode()
org.webrtc.voiceengine.WebRtcAudioUtils: void logAudioStateBasic(java.lang.String,android.media.AudioManager)
io.flutter.view.AccessibilityBridge$Action: io.flutter.view.AccessibilityBridge$Action[] values()
androidx.lifecycle.ReportFragment$LifecycleCallbacks: void onActivityStarted(android.app.Activity)
org.webrtc.NetworkMonitorAutoDetect$WifiDirectManagerDelegate: void lambda$new$0(android.net.wifi.p2p.WifiP2pGroup)
com.cloudwebrtc.webrtc.GetUserMediaImpl: void stopRecording(java.lang.Integer)
org.webrtc.MediaStreamTrack: long getNativeMediaStreamTrack()
kotlinx.coroutines.EventLoopImplBase: EventLoopImplBase()
org.webrtc.AndroidVideoDecoder: org.webrtc.VideoCodecStatus reinitDecode(int,int)
org.webrtc.CameraSession$FailureType: org.webrtc.CameraSession$FailureType[] $values()
com.google.firebase.firestore.core.Query$LimitType: com.google.firebase.firestore.core.Query$LimitType valueOf(java.lang.String)
org.webrtc.EglBase: void detachCurrent()
com.cloudwebrtc.webrtc.utils.ConstraintsArray: void pushArray(com.cloudwebrtc.webrtc.utils.ConstraintsArray)
org.webrtc.VideoSource: void setVideoProcessor(org.webrtc.VideoProcessor)
org.webrtc.Camera1Session: void stopInternal()
org.webrtc.HardwareVideoEncoder: void lambda$deliverEncodedImage$0(int)
org.webrtc.RtpSender: long nativeGetDtmfSender(long)
com.cloudwebrtc.webrtc.utils.MediaConstraintsUtils: java.lang.String getMapStrValue(com.cloudwebrtc.webrtc.utils.ConstraintsMap,java.lang.String)
org.webrtc.HardwareVideoDecoderFactory: org.webrtc.VideoCodecInfo[] getSupportedCodecs()
org.webrtc.PeerConnection$Observer: void onRenegotiationNeeded()
org.webrtc.voiceengine.WebRtcAudioUtils: void logAudioState(java.lang.String)
androidx.window.layout.EmptyDecorator: EmptyDecorator()
androidx.window.embedding.EmbeddingTranslatingCallback: EmbeddingTranslatingCallback(androidx.window.embedding.EmbeddingInterfaceCompat$EmbeddingCallbackInterface,androidx.window.embedding.EmbeddingAdapter)
org.webrtc.EglBase10Impl$1FakeSurfaceHolder: void setKeepScreenOn(boolean)
org.webrtc.MediaCodecWrapperFactoryImpl$MediaCodecWrapperImpl: android.view.Surface createInputSurface()
org.webrtc.MediaCodecWrapperFactoryImpl$MediaCodecWrapperImpl: java.nio.ByteBuffer getOutputBuffer(int)
org.webrtc.NetworkChangeDetector$Observer: void onNetworkConnect(org.webrtc.NetworkChangeDetector$NetworkInformation)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void rtpSenderSetTrack(java.lang.String,java.lang.String,java.lang.String,boolean,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.EglBase14Impl: void swapBuffers(long)
org.webrtc.VideoFileRenderer: void renderFrameOnRenderThread(org.webrtc.VideoFrame)
org.webrtc.EglBase14Impl: void detachCurrent()
androidx.window.core.Version: int hashCode()
org.webrtc.EglRenderer: void lambda$addFrameListener$3(org.webrtc.RendererCommon$GlDrawer,org.webrtc.EglRenderer$FrameListener,float,boolean)
com.cloudwebrtc.webrtc.PeerConnectionObserver: void createDataChannel(java.lang.String,com.cloudwebrtc.webrtc.utils.ConstraintsMap,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.Camera2Capturer: void initialize(org.webrtc.SurfaceTextureHelper,android.content.Context,org.webrtc.CapturerObserver)
org.webrtc.SdpObserver: void onCreateFailure(java.lang.String)
io.flutter.embedding.engine.FlutterJNI: boolean getIsSoftwareRenderingEnabled()
androidx.window.embedding.EmbeddingTranslatingCallback: void accept(java.lang.Object)
com.google.protobuf.Int32Value$Builder: Int32Value$Builder()
org.webrtc.Camera2Session: Camera2Session(org.webrtc.CameraSession$CreateSessionCallback,org.webrtc.CameraSession$Events,android.content.Context,android.hardware.camera2.CameraManager,org.webrtc.SurfaceTextureHelper,java.lang.String,int,int,int)
com.cloudwebrtc.webrtc.PeerConnectionObserver: org.webrtc.RtpTransceiver$RtpTransceiverInit mapToRtpTransceiverInit(java.util.Map)
io.flutter.embedding.engine.FlutterJNI: boolean isCodePointEmojiModifierBase(int)
org.webrtc.BitrateAdjuster: int getAdjustedBitrateBps()
kotlin.jvm.internal.FunctionReference: boolean isInline()
com.google.protobuf.NullValue: com.google.protobuf.NullValue valueOf(java.lang.String)
org.webrtc.SurfaceTextureHelper: void setFrameRotation(int)
org.webrtc.audio.WebRtcAudioTrack$AudioTrackThread: void stopThread()
com.google.firestore.v1.TargetChange$TargetChangeType: com.google.firestore.v1.TargetChange$TargetChangeType[] values()
androidx.window.embedding.EmptyEmbeddingComponent: void setEmbeddingRules(java.util.Set)
org.webrtc.DtmfSender: int interToneGap()
com.cloudwebrtc.webrtc.PeerConnectionObserver: void resultError(java.lang.String,java.lang.String,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.PeerConnectionFactory: long nativeGetNativePeerConnectionFactory(long)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: org.webrtc.MediaConstraints defaultConstraints()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: org.webrtc.MediaStreamTrack getTrackForId(java.lang.String,java.lang.String)
org.webrtc.EglBase14Impl$Context: EglBase14Impl$Context(android.opengl.EGLContext)
org.webrtc.voiceengine.WebRtcAudioManager: int getNativeOutputSampleRate()
com.google.firestore.v1.StructuredQuery$Direction: com.google.firestore.v1.StructuredQuery$Direction[] values()
com.google.protobuf.BooleanArrayList: BooleanArrayList()
com.google.android.gms.dynamite.DynamiteModule$DynamiteLoaderClassLoader: DynamiteModule$DynamiteLoaderClassLoader()
org.webrtc.CameraEnumerationAndroid$1: CameraEnumerationAndroid$1(int)
org.webrtc.PeerConnectionFactory: org.webrtc.PeerConnection createPeerConnection(org.webrtc.PeerConnection$RTCConfiguration,org.webrtc.MediaConstraints,org.webrtc.PeerConnection$Observer)
com.google.firestore.v1.ListenResponse$ResponseTypeCase: com.google.firestore.v1.ListenResponse$ResponseTypeCase valueOf(java.lang.String)
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer: void tryAddRendererToVideoTrack()
org.webrtc.VideoFrame$TextureBuffer: org.webrtc.VideoFrame$TextureBuffer applyTransformMatrix(android.graphics.Matrix,int,int)
org.webrtc.audio.WebRtcAudioUtils: boolean runningOnEmulator()
org.webrtc.PeerConnection: void nativeAddIceCandidateWithObserver(java.lang.String,int,java.lang.String,org.webrtc.AddIceObserver)
org.webrtc.MediaCodecWrapperFactoryImpl$MediaCodecWrapperImpl: void release()
com.cloudwebrtc.webrtc.SurfaceTextureRenderer: void init(org.webrtc.EglBase$Context,org.webrtc.RendererCommon$RendererEvents,int[],org.webrtc.RendererCommon$GlDrawer)
com.cloudwebrtc.webrtc.record.VideoFileRenderer: void lambda$release$3()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: android.app.Activity getActivity()
com.cloudwebrtc.webrtc.PeerConnectionObserver: java.lang.String signalingStateString(org.webrtc.PeerConnection$SignalingState)
io.grpc.internal.ManagedChannelImpl$ResolutionState: io.grpc.internal.ManagedChannelImpl$ResolutionState[] values()
androidx.window.embedding.EmbeddingAdapter: boolean translateIntentPredicates$lambda-8(java.util.Set,android.content.Intent)
org.webrtc.AndroidVideoDecoder: void stopOnOutputThread(java.lang.Exception)
androidx.core.app.NotificationCompat$BubbleMetadata$Api30Impl: android.app.Notification$BubbleMetadata toPlatform(androidx.core.app.NotificationCompat$BubbleMetadata)
org.webrtc.JavaI420Buffer: int getStrideU()
io.flutter.embedding.engine.FlutterJNI: void nativeMarkTextureFrameAvailable(long,long)
androidx.window.layout.WindowInfoTracker$Companion: void overrideDecorator(androidx.window.layout.WindowInfoTrackerDecorator)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$1: void onCreateFailure(java.lang.String)
org.webrtc.HardwareVideoEncoder: boolean canUseSurface()
kotlin.coroutines.AbstractCoroutineContextElement: kotlin.coroutines.CoroutineContext$Key getKey()
com.cloudwebrtc.webrtc.record.VideoFileRenderer: void lambda$release$2()
org.webrtc.RtpParameters: java.util.List getEncodings()
com.cloudwebrtc.webrtc.PeerConnectionObserver: java.lang.String connectionStateString(org.webrtc.PeerConnection$PeerConnectionState)
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin: boolean lambda$registerWith$0(com.cloudwebrtc.webrtc.FlutterWebRTCPlugin,io.flutter.view.FlutterNativeView)
com.cloudwebrtc.webrtc.utils.ConstraintsMap: void merge(java.util.Map)
androidx.window.layout.SidecarCompat: androidx.window.sidecar.SidecarInterface getSidecar()
androidx.window.embedding.ExtensionEmbeddingBackend$EmbeddingCallbackImpl: ExtensionEmbeddingBackend$EmbeddingCallbackImpl(androidx.window.embedding.ExtensionEmbeddingBackend)
org.webrtc.PeerConnection: void setLocalDescription(org.webrtc.SdpObserver)
org.webrtc.EglRenderer: void init(org.webrtc.EglBase$Context,int[],org.webrtc.RendererCommon$GlDrawer)
com.cloudwebrtc.webrtc.PeerConnectionObserver: void getStats(io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.SurfaceEglRenderer: void logD(java.lang.String)
org.webrtc.PeerConnection$PeerConnectionState: org.webrtc.PeerConnection$PeerConnectionState[] $values()
org.webrtc.Camera2Enumerator: boolean isSupported(android.content.Context)
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback: int access$500(io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback)
org.webrtc.ContextUtils: ContextUtils()
org.webrtc.SimulcastVideoEncoder: long createNativeVideoEncoder()
com.cloudwebrtc.webrtc.utils.ConstraintsArray: int size()
org.webrtc.Camera2Session$CaptureSessionCallback: void onConfigureFailed(android.hardware.camera2.CameraCaptureSession)
org.webrtc.RtpParameters$Codec: int getPayloadType()
com.cloudwebrtc.webrtc.PeerConnectionObserver: void onIceGatheringChange(org.webrtc.PeerConnection$IceGatheringState)
org.webrtc.RtpParameters$Encoding: java.lang.Double getScaleResolutionDownBy()
com.google.firebase.firestore.local.MemoryDocumentOverlayCache: MemoryDocumentOverlayCache()
androidx.window.layout.SidecarCompat$Companion: android.os.IBinder getActivityWindowToken$window_release(android.app.Activity)
org.webrtc.WrappedNativeI420Buffer: int getHeight()
org.webrtc.EglRenderer: void lambda$releaseEglSurface$5(java.lang.Runnable)
io.grpc.internal.DnsNameResolver$JdkAddressResolver: io.grpc.internal.DnsNameResolver$JdkAddressResolver valueOf(java.lang.String)
androidx.window.layout.WindowMetrics: java.lang.String toString()
com.google.firebase.firestore.local.QueryPurpose: com.google.firebase.firestore.local.QueryPurpose valueOf(java.lang.String)
org.webrtc.PeerConnection: boolean nativeSetBitrate(java.lang.Integer,java.lang.Integer,java.lang.Integer)
io.flutter.embedding.engine.mutatorsstack.FlutterMutatorsStack: void pushTransform(float[])
org.webrtc.TextureBufferImpl$RefCountMonitor: void onRelease(org.webrtc.TextureBufferImpl)
org.webrtc.YuvConverter: YuvConverter()
org.webrtc.audio.WebRtcAudioEffects: boolean isEffectTypeAvailable(java.util.UUID,java.util.UUID)
io.flutter.plugins.firebase.core.FlutterFirebasePluginRegistry: void lambda$getPluginConstantsForFirebaseApp$0(com.google.firebase.FirebaseApp,com.google.android.gms.tasks.TaskCompletionSource)
org.webrtc.RendererCommon: RendererCommon()
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor: void frameCryptorSetKeyIndex(java.util.Map,io.flutter.plugin.common.MethodChannel$Result)
androidx.window.embedding.EmbeddingBackend: void unregisterSplitListenerForActivity(androidx.core.util.Consumer)
androidx.window.layout.WindowMetricsCalculatorCompat: android.graphics.Rect computeWindowBoundsP$window_release(android.app.Activity)
kotlin.coroutines.jvm.internal.BaseContinuationImpl: kotlin.coroutines.Continuation getCompletion()
org.webrtc.PeerConnection$TcpCandidatePolicy: PeerConnection$TcpCandidatePolicy(java.lang.String,int)
org.webrtc.RtpTransceiver$RtpTransceiverDirection: org.webrtc.RtpTransceiver$RtpTransceiverDirection fromNativeIndex(int)
com.cloudwebrtc.webrtc.GetUserMediaImpl: int getPreferredInputDevice(android.media.AudioDeviceInfo)
androidx.window.java.layout.WindowInfoTrackerCallbackAdapter$addListener$1$1: WindowInfoTrackerCallbackAdapter$addListener$1$1(kotlinx.coroutines.flow.Flow,androidx.core.util.Consumer,kotlin.coroutines.Continuation)
com.google.firestore.v1.Target$QueryTarget$Builder: Target$QueryTarget$Builder()
org.webrtc.EncodedImage: java.nio.ByteBuffer getBuffer()
com.google.firestore.v1.Target$DocumentsTarget: Target$DocumentsTarget()
kotlin.jvm.internal.FunctionReference: FunctionReference(int,java.lang.Object)
com.google.android.gms.common.GooglePlayServicesMissingManifestValueException: GooglePlayServicesMissingManifestValueException()
com.google.protobuf.Int64Value: Int64Value()
androidx.lifecycle.Lifecycle$Event: androidx.lifecycle.Lifecycle$Event[] values()
org.webrtc.RtpParameters$DegradationPreference: org.webrtc.RtpParameters$DegradationPreference fromNativeIndex(int)
org.webrtc.voiceengine.WebRtcAudioEffects: boolean isAcousticEchoCancelerEffectAvailable()
androidx.window.layout.WindowLayoutInfo: WindowLayoutInfo(java.util.List)
kotlin.coroutines.jvm.internal.ContinuationImpl: void releaseIntercepted()
org.webrtc.SoftwareVideoEncoderFactory: long nativeCreateFactory()
org.webrtc.PeerConnection: PeerConnection(org.webrtc.NativePeerConnectionFactory)
io.flutter.embedding.engine.FlutterJNI: void removeIsDisplayingFlutterUiListener(io.flutter.embedding.engine.renderer.FlutterUiDisplayListener)
androidx.window.embedding.SplitPairFilter: android.content.ComponentName getPrimaryActivityName()
androidx.window.embedding.EmbeddingCompat$Companion: EmbeddingCompat$Companion()
org.webrtc.FrameCryptor: FrameCryptor(long)
androidx.window.layout.HardwareFoldingFeature: int hashCode()
org.webrtc.VideoEncoder$Settings: VideoEncoder$Settings(int,int,int,int,int,int,boolean)
org.webrtc.GlGenericDrawer: void drawOes(int,float[],int,int,int,int,int,int)
io.grpc.internal.CompositeReadableBuffer: CompositeReadableBuffer()
org.webrtc.MediaStream: java.lang.String toString()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: com.cloudwebrtc.webrtc.utils.ConstraintsMap getCameraInfo(int)
org.webrtc.voiceengine.WebRtcAudioRecord$AudioSamples: int getAudioFormat()
io.flutter.view.AccessibilityViewEmbedder: void setFlutterNodesTranslateBounds(android.view.accessibility.AccessibilityNodeInfo,android.graphics.Rect,android.view.accessibility.AccessibilityNodeInfo)
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin: kotlin.Unit lambda$startListening$1(java.util.List,com.twilio.audioswitch.AudioDevice)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$2: void onSetSuccess()
org.webrtc.PeerConnection: void getStats(org.webrtc.RTCStatsCollectorCallback)
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor: void frameCryptorGetKeyIndex(java.util.Map,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.DataChannel$Observer: void onBufferedAmountChange(long)
com.google.firebase.concurrent.ExecutorsRegistrar: ExecutorsRegistrar()
com.google.firebase.firestore.util.Logger$Level: com.google.firebase.firestore.util.Logger$Level valueOf(java.lang.String)
org.webrtc.RtpParameters$HeaderExtension: java.lang.String getUri()
androidx.window.layout.SidecarAdapter$Companion: java.util.List getSidecarDisplayFeatures(androidx.window.sidecar.SidecarWindowLayoutInfo)
com.google.firestore.v1.Value$Builder: Value$Builder()
androidx.window.embedding.SplitRule: boolean equals(java.lang.Object)
com.cloudwebrtc.webrtc.DataChannelObserver: void onCancel(java.lang.Object)
org.webrtc.CryptoOptions$Builder: org.webrtc.CryptoOptions$Builder setEnableAes128Sha1_32CryptoCipher(boolean)
io.flutter.embedding.engine.FlutterJNI: void setAsyncWaitForVsyncDelegate(io.flutter.embedding.engine.FlutterJNI$AsyncWaitForVsyncDelegate)
org.webrtc.PeerConnectionFactory$Builder: org.webrtc.PeerConnectionFactory$Builder setAudioProcessingFactory(org.webrtc.AudioProcessingFactory)
org.webrtc.DefaultVideoEncoderFactory: org.webrtc.VideoCodecInfo[] getSupportedCodecs()
org.webrtc.Logging: void enableLogThreads()
io.grpc.Metadata: Metadata()
org.webrtc.EglRenderer: void clearImage(float,float,float,float)
androidx.window.embedding.ActivityRule: int hashCode()
org.webrtc.voiceengine.WebRtcAudioRecord: int initRecording(int,int)
com.cloudwebrtc.webrtc.PeerConnectionObserver: void onAddTrack(org.webrtc.RtpReceiver,org.webrtc.MediaStream[])
org.webrtc.GlGenericDrawer: java.lang.String createFragmentShaderString(java.lang.String,org.webrtc.GlGenericDrawer$ShaderType)
org.webrtc.FrameCryptorKeyProvider: void checkKeyProviderExists()
com.cloudwebrtc.webrtc.utils.ConstraintsMap: boolean isNull(java.lang.String)
org.webrtc.SurfaceEglRenderer: void surfaceCreated(android.view.SurfaceHolder)
com.google.firestore.v1.DocumentTransform$FieldTransform$TransformTypeCase: com.google.firestore.v1.DocumentTransform$FieldTransform$TransformTypeCase[] values()
org.webrtc.audio.JavaAudioDeviceModule$AudioRecordErrorCallback: void onWebRtcAudioRecordInitError(java.lang.String)
org.webrtc.audio.WebRtcAudioTrack: int getInitialBufferSizeInFrames()
org.webrtc.SurfaceTextureHelper: void setTextureSize(int,int)
androidx.core.app.NotificationCompat$BubbleMetadata$Api29Impl: android.app.Notification$BubbleMetadata toPlatform(androidx.core.app.NotificationCompat$BubbleMetadata)
org.webrtc.DataChannel: void dispose()
org.webrtc.PeerConnection$SignalingState: org.webrtc.PeerConnection$SignalingState[] $values()
androidx.window.embedding.SplitInfo: SplitInfo(androidx.window.embedding.ActivityStack,androidx.window.embedding.ActivityStack,float)
org.webrtc.DefaultVideoDecoderFactory: org.webrtc.VideoDecoder createDecoder(org.webrtc.VideoCodecInfo)
com.cloudwebrtc.webrtc.PeerConnectionObserver: org.webrtc.PeerConnection getPeerConnection()
org.webrtc.PeerConnection: org.webrtc.RtpTransceiver addTransceiver(org.webrtc.MediaStreamTrack,org.webrtc.RtpTransceiver$RtpTransceiverInit)
org.webrtc.PeerConnectionFactory: long nativeCreateVideoSource(long,boolean,boolean)
io.flutter.embedding.engine.FlutterJNI: void lambda$decodeImage$0(long,android.graphics.ImageDecoder,android.graphics.ImageDecoder$ImageInfo,android.graphics.ImageDecoder$Source)
org.webrtc.Predicate: org.webrtc.Predicate or(org.webrtc.Predicate)
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin: void onCancel(java.lang.Object)
org.webrtc.PeerConnectionFactory: void initialize(org.webrtc.PeerConnectionFactory$InitializationOptions)
org.webrtc.EglBase14Impl: android.opengl.EGLDisplay getEglDisplay()
androidx.window.layout.SidecarCompat: void registerConfigurationChangeListener(android.app.Activity)
com.cloudwebrtc.webrtc.DataChannelObserver: void onMessage(org.webrtc.DataChannel$Buffer)
com.google.firestore.v1.StructuredQuery$CollectionSelector: StructuredQuery$CollectionSelector()
io.grpc.okhttp.NegotiationType: io.grpc.okhttp.NegotiationType valueOf(java.lang.String)
androidx.window.layout.FoldingFeature$State$Companion: FoldingFeature$State$Companion()
org.webrtc.NetworkMonitorAutoDetect$ConnectivityManagerDelegate: org.webrtc.NetworkMonitorAutoDetect$NetworkState getNetworkState(android.net.NetworkInfo)
io.flutter.plugins.GeneratedPluginRegistrant: void registerWith(io.flutter.embedding.engine.FlutterEngine)
io.flutter.embedding.engine.FlutterJNI: void handlePlatformMessageResponse(int,java.nio.ByteBuffer)
org.webrtc.RtpTransceiver: boolean nativeSetDirection(long,org.webrtc.RtpTransceiver$RtpTransceiverDirection)
org.webrtc.NativeAndroidVideoTrackSource: void onFrameCaptured(org.webrtc.VideoFrame)
org.webrtc.PeerConnectionFactory$Options: int getNetworkIgnoreMask()
org.webrtc.TurnCustomizer: long getNativeTurnCustomizer()
org.webrtc.FrameCryptor$FrameCryptionState: org.webrtc.FrameCryptor$FrameCryptionState[] values()
org.webrtc.VideoFrame: void retain()
org.webrtc.LibaomAv1Encoder: long createNativeVideoEncoder()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void peerConnectionSetLocalDescription(com.cloudwebrtc.webrtc.utils.ConstraintsMap,java.lang.String,io.flutter.plugin.common.MethodChannel$Result)
com.google.firestore.v1.WriteRequest$Builder: WriteRequest$Builder()
com.cloudwebrtc.webrtc.utils.ConstraintsArray: boolean isNull(int)
com.google.firebase.firestore.auth.CredentialsProvider: CredentialsProvider()
io.flutter.embedding.engine.FlutterJNI: void dispatchPointerDataPacket(java.nio.ByteBuffer,int)
org.webrtc.TextureBufferImpl: org.webrtc.YuvConverter getYuvConverter()
org.webrtc.ScreenCapturerAndroid: android.media.projection.MediaProjection getMediaProjection()
kotlinx.coroutines.scheduling.Task: Task()
org.webrtc.VideoEncoderFactory$VideoEncoderSelector: org.webrtc.VideoCodecInfo onResolutionChange(int,int)
org.webrtc.TimestampAligner: void nativeReleaseTimestampAligner(long)
io.flutter.embedding.engine.FlutterJNI: boolean nativeGetIsSoftwareRenderingEnabled()
org.webrtc.PeerConnection$Observer: void onIceCandidatesRemoved(org.webrtc.IceCandidate[])
org.webrtc.H264Utils: java.util.Map getDefaultH264Params(boolean)
com.cloudwebrtc.webrtc.record.VideoFileRenderer: void lambda$onFrame$1(org.webrtc.VideoFrame)
org.webrtc.MediaStreamTrack: java.lang.String nativeGetKind(long)
org.webrtc.PeerConnection$RTCConfiguration: int getIceConnectionReceivingTimeout()
org.webrtc.JNILogging: JNILogging(org.webrtc.Loggable)
com.cloudwebrtc.webrtc.utils.AnyThreadSink: AnyThreadSink(io.flutter.plugin.common.EventChannel$EventSink)
org.webrtc.EglBase10Impl: EglBase10Impl(javax.microedition.khronos.egl.EGLContext,int[])
org.webrtc.CameraCapturer$7: void run()
org.webrtc.NetworkMonitor$NetworkObserver: void onConnectionTypeChanged(org.webrtc.NetworkChangeDetector$ConnectionType)
org.webrtc.NetworkMonitor: java.util.List getNativeNetworkObserversSync()
org.webrtc.Camera2Capturer: void startCapture(int,int,int)
org.webrtc.Camera1Enumerator: java.util.List getSupportedFormats(int)
androidx.lifecycle.ViewModelProvider$KeyedFactory: ViewModelProvider$KeyedFactory()
io.flutter.view.AccessibilityBridge$Flag: io.flutter.view.AccessibilityBridge$Flag valueOf(java.lang.String)
org.webrtc.YuvConverter: org.webrtc.VideoFrame$I420Buffer convert(org.webrtc.VideoFrame$TextureBuffer)
com.google.firestore.v1.TransactionOptions: TransactionOptions()
androidx.window.layout.WindowMetricsCalculatorCompat: WindowMetricsCalculatorCompat()
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapperFactory: SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapperFactory(org.webrtc.VideoEncoderFactory)
org.webrtc.Camera2Session: void stop()
org.webrtc.Camera2Enumerator: android.hardware.camera2.CameraCharacteristics getCameraCharacteristics(java.lang.String)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: java.util.Map access$100(com.cloudwebrtc.webrtc.MethodCallHandlerImpl)
org.webrtc.VideoDecoder: org.webrtc.VideoCodecStatus decode(org.webrtc.EncodedImage,org.webrtc.VideoDecoder$DecodeInfo)
org.webrtc.voiceengine.WebRtcAudioEffects: boolean setNS(boolean)
org.webrtc.voiceengine.WebRtcAudioUtils: boolean isNoiseSuppressorSupported()
io.grpc.TlsChannelCredentials$Feature: io.grpc.TlsChannelCredentials$Feature valueOf(java.lang.String)
kotlin.jvm.internal.Lambda: int getArity()
org.webrtc.VideoFileRenderer: void release()
org.webrtc.DataChannel: org.webrtc.DataChannel$State state()
org.webrtc.RtpParameters$Encoding: boolean getAdaptivePTime()
org.webrtc.voiceengine.WebRtcAudioManager: boolean isLowLatencyOutputSupported()
org.webrtc.EglRenderer$EglSurfaceCreation: void setSurface(java.lang.Object)
org.webrtc.NativeCapturerObserver: NativeCapturerObserver(long)
org.webrtc.PeerConnection$RTCConfiguration: java.lang.Integer getIceCheckIntervalWeakConnectivity()
androidx.window.layout.WindowMetricsCalculator$Companion$reset$1: java.lang.Object invoke(java.lang.Object)
org.webrtc.RtpSender: void nativeSetStreams(long,java.util.List)
org.webrtc.NetworkMonitorAutoDetect: void setConnectivityManagerDelegateForTests(org.webrtc.NetworkMonitorAutoDetect$ConnectivityManagerDelegate)
com.cloudwebrtc.webrtc.OrientationAwareScreenCapturer: void onFrame(org.webrtc.VideoFrame)
org.webrtc.NetworkMonitorAutoDetect$WifiDirectManagerDelegate: void onWifiP2pGroupChange(android.net.wifi.p2p.WifiP2pGroup)
org.webrtc.AndroidVideoDecoder: org.webrtc.VideoCodecStatus release()
androidx.window.layout.EmptyDecorator: androidx.window.layout.WindowInfoTracker decorate(androidx.window.layout.WindowInfoTracker)
org.webrtc.TextureBufferImpl: void retain()
org.webrtc.EglBase$ConfigBuilder: org.webrtc.EglBase$ConfigBuilder setHasAlphaChannel(boolean)
org.webrtc.CameraVideoCapturer$CameraStatistics$1: CameraVideoCapturer$CameraStatistics$1(org.webrtc.CameraVideoCapturer$CameraStatistics)
io.grpc.internal.JsonUtil: JsonUtil()
org.webrtc.VideoTrack: void nativeAddSink(long,long)
com.cloudwebrtc.webrtc.StateProvider: java.lang.String getNextStreamUUID()
org.webrtc.AndroidVideoDecoder: boolean isSupportedColorFormat(int)
org.webrtc.EglRenderer: void setMirrorVertically(boolean)
org.webrtc.FrameCryptor: int nativeGetKeyIndex(long)
io.flutter.embedding.android.FlutterSplashView$SavedState: FlutterSplashView$SavedState(android.os.Parcel)
org.webrtc.PeerConnection$Observer: void onRemoveStream(org.webrtc.MediaStream)
org.webrtc.VideoFrame$TextureBuffer$Type: org.webrtc.VideoFrame$TextureBuffer$Type valueOf(java.lang.String)
org.webrtc.CallSessionFileRotatingLogSink: CallSessionFileRotatingLogSink(java.lang.String,int,org.webrtc.Logging$Severity)
org.webrtc.NetworkMonitor$1: NetworkMonitor$1(org.webrtc.NetworkMonitor)
io.flutter.embedding.engine.FlutterJNI: void markTextureFrameAvailable(long)
org.webrtc.FrameCryptorKeyProvider: FrameCryptorKeyProvider(long)
com.google.gson.stream.JsonToken: com.google.gson.stream.JsonToken[] values()
org.webrtc.PeerConnectionFactory: long getNativeOwnedFactoryAndThreads()
org.webrtc.VideoDecoderWrapper: void nativeOnDecodedFrame(long,org.webrtc.VideoFrame,java.lang.Integer,java.lang.Integer)
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin$LifeCycleObserver: void onActivityDestroyed(android.app.Activity)
com.google.rpc.Status: Status()
org.webrtc.voiceengine.WebRtcAudioRecord$WebRtcAudioRecordErrorCallback: void onWebRtcAudioRecordInitError(java.lang.String)
org.webrtc.Logging: void nativeEnableLogTimeStamps()
org.webrtc.GlShader: void useProgram()
org.webrtc.voiceengine.WebRtcAudioRecord$WebRtcAudioRecordSamplesReadyCallback: void onWebRtcAudioRecordSamplesReady(org.webrtc.voiceengine.WebRtcAudioRecord$AudioSamples)
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin$LifeCycleObserver: void onActivityStopped(android.app.Activity)
org.webrtc.audio.WebRtcAudioRecord: void nativeCacheDirectBufferAddress(long,java.nio.ByteBuffer)
org.webrtc.NetworkMonitor$InstanceHolder: NetworkMonitor$InstanceHolder()
org.webrtc.SurfaceViewRenderer: void init(org.webrtc.EglBase$Context,org.webrtc.RendererCommon$RendererEvents)
org.webrtc.PeerConnectionFactory$ThreadInfo: org.webrtc.PeerConnectionFactory$ThreadInfo getCurrent()
org.webrtc.RtpParameters$Encoding: java.lang.Integer getMinBitrateBps()
org.webrtc.EncodedImage: int getEncodedHeight()
org.webrtc.StatsReport$Value: StatsReport$Value(java.lang.String,java.lang.String)
org.webrtc.VideoEncoderWrapper: java.lang.Integer getScalingSettingsHigh(org.webrtc.VideoEncoder$ScalingSettings)
org.webrtc.RTCStats: double getTimestampUs()
org.webrtc.EglRenderer: void lambda$release$1(java.util.concurrent.CountDownLatch)
androidx.window.core.Version: int getMinor()
com.cloudwebrtc.webrtc.GetUserMediaImpl$VideoCapturerInfo: GetUserMediaImpl$VideoCapturerInfo(com.cloudwebrtc.webrtc.GetUserMediaImpl)
com.cloudwebrtc.webrtc.GetUserMediaImpl$ScreenRequestPermissionsFragment: GetUserMediaImpl$ScreenRequestPermissionsFragment()
org.webrtc.voiceengine.WebRtcAudioTrack$ErrorCallback: void onWebRtcAudioTrackInitError(java.lang.String)
org.webrtc.voiceengine.WebRtcAudioRecord: void reportWebRtcAudioRecordError(java.lang.String)
org.webrtc.DtmfSender: int nativeDuration(long)
androidx.window.layout.WindowInfoTrackerImpl$windowLayoutInfo$1: java.lang.Object invoke(kotlinx.coroutines.flow.FlowCollector,kotlin.coroutines.Continuation)
org.webrtc.Camera1Enumerator: java.util.List getSupportedFormats(java.lang.String)
org.webrtc.PeerConnectionFactory$InitializationOptions$Builder: org.webrtc.PeerConnectionFactory$InitializationOptions$Builder setInjectableLogger(org.webrtc.Loggable,org.webrtc.Logging$Severity)
org.webrtc.NetworkMonitorAutoDetect$NetworkState: int getUnderlyingNetworkTypeForVpn()
org.webrtc.RtpTransceiver: org.webrtc.RtpReceiver nativeGetReceiver(long)
org.webrtc.VideoEncoder$ResolutionBitrateLimits: int getMinStartBitrateBps()
androidx.window.layout.SidecarAdapter: boolean isEqualSidecarDeviceState(androidx.window.sidecar.SidecarDeviceState,androidx.window.sidecar.SidecarDeviceState)
org.webrtc.EncodedImage$Builder: org.webrtc.EncodedImage$Builder setQp(java.lang.Integer)
com.cloudwebrtc.webrtc.utils.ConstraintsArray: void pushBoolean(boolean)
io.flutter.embedding.engine.FlutterJNI: io.flutter.embedding.engine.FlutterJNI nativeSpawn(long,java.lang.String,java.lang.String,java.lang.String,java.util.List)
com.cloudwebrtc.webrtc.audio.AudioDeviceKind: com.cloudwebrtc.webrtc.audio.AudioDeviceKind fromAudioDevice(com.twilio.audioswitch.AudioDevice)
org.webrtc.BuiltinAudioDecoderFactoryFactory: long createNativeAudioDecoderFactory()
org.webrtc.voiceengine.WebRtcAudioRecord: void setErrorCallback(org.webrtc.voiceengine.WebRtcAudioRecord$WebRtcAudioRecordErrorCallback)
com.google.firebase.firestore.core.ActivityScope$StopListenerFragment: ActivityScope$StopListenerFragment()
com.cloudwebrtc.webrtc.utils.ConstraintsMap: ConstraintsMap()
androidx.window.embedding.SplitRule: int getMinSmallestWidth()
org.webrtc.VideoTrack: void nativeSetShouldReceive(long,boolean)
org.webrtc.MediaStreamTrack: java.lang.String kind()
org.webrtc.MediaStream: boolean nativeRemoveVideoTrack(long,long)
org.webrtc.audio.WebRtcAudioRecord: boolean enableBuiltInNS(boolean)
io.grpc.util.SecretRoundRobinLoadBalancerProvider$Provider: boolean isAvailable()
org.webrtc.CryptoOptions$SFrame: boolean getRequireFrameEncryption()
org.webrtc.SurfaceTextureHelper$FrameRefMonitor: void onNewBuffer(org.webrtc.VideoFrame$TextureBuffer)
com.google.firebase.firestore.local.IndexManager$IndexType: com.google.firebase.firestore.local.IndexManager$IndexType[] values()
io.grpc.internal.SerializeReentrantCallsDirectExecutor: SerializeReentrantCallsDirectExecutor()
org.webrtc.VideoEncoder$CodecSpecificInfoVP9: VideoEncoder$CodecSpecificInfoVP9()
org.webrtc.GlGenericDrawer: org.webrtc.GlShader createShader(org.webrtc.GlGenericDrawer$ShaderType)
org.webrtc.RtpSender: org.webrtc.RtpParameters nativeGetParameters(long)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$2: void onSetFailure(java.lang.String)
org.webrtc.NetworkMonitorAutoDetect$SimpleNetworkCallback: void onNetworkChanged(android.net.Network)
org.webrtc.HardwareVideoEncoder: org.webrtc.VideoCodecStatus release()
org.webrtc.EglRenderer: EglRenderer(java.lang.String)
org.webrtc.ThreadUtils: void executeUninterruptibly(org.webrtc.ThreadUtils$BlockingOperation)
org.webrtc.Logging: java.lang.String getStackTraceString(java.lang.Throwable)
io.flutter.view.AccessibilityBridge$TextDirection: io.flutter.view.AccessibilityBridge$TextDirection valueOf(java.lang.String)
org.webrtc.PeerConnectionFactory: void dispose()
org.webrtc.Camera2Capturer: void changeCaptureFormat(int,int,int)
io.flutter.embedding.engine.FlutterJNI: void nativeUpdateJavaAssetManager(long,android.content.res.AssetManager,java.lang.String)
com.cloudwebrtc.webrtc.utils.ConstraintsMap: java.lang.String toString()
org.webrtc.SimulcastVideoEncoderFactory: org.webrtc.VideoCodecInfo[] getSupportedCodecs()
org.webrtc.MediaCodecWrapper: void stop()
androidx.window.layout.SidecarWindowBackend: void getWindowLayoutChangeCallbacks$annotations()
io.grpc.InternalChannelz$ChannelTrace$Event$Severity: io.grpc.InternalChannelz$ChannelTrace$Event$Severity valueOf(java.lang.String)
org.webrtc.NativeAndroidVideoTrackSource: org.webrtc.VideoProcessor$FrameAdaptationParameters adaptFrame(org.webrtc.VideoFrame)
com.google.firestore.v1.FirestoreGrpc: FirestoreGrpc()
com.cloudwebrtc.webrtc.PeerConnectionObserver: org.webrtc.RtpParameters updateRtpParameters(org.webrtc.RtpParameters,java.util.Map)
org.webrtc.MediaSource: org.webrtc.MediaSource$State state()
org.webrtc.CameraCapturer: java.lang.String getCameraName()
androidx.lifecycle.ViewModel: ViewModel()
com.cloudwebrtc.webrtc.PeerConnectionObserver: void rtpTransceiverSetDirection(java.lang.String,java.lang.String,io.flutter.plugin.common.MethodChannel$Result)
androidx.collection.SimpleArrayMap: SimpleArrayMap()
org.webrtc.JniHelper: JniHelper()
com.cloudwebrtc.webrtc.R$layout: R$layout()
androidx.window.layout.SidecarCompat$DistinctSidecarElementCallback: SidecarCompat$DistinctSidecarElementCallback(androidx.window.layout.SidecarAdapter,androidx.window.sidecar.SidecarInterface$SidecarCallback)
org.webrtc.PeerConnection: long getNativeOwnedPeerConnection()
com.cloudwebrtc.webrtc.record.MediaRecorderImpl: java.io.File getRecordFile()
io.flutter.embedding.android.KeyData$Type: io.flutter.embedding.android.KeyData$Type valueOf(java.lang.String)
kotlin.jvm.internal.FunctionReferenceImpl: FunctionReferenceImpl(int,kotlin.reflect.KDeclarationContainer,java.lang.String,java.lang.String)
com.twilio.audioswitch.AudioDevice$Speakerphone: AudioDevice$Speakerphone()
io.grpc.ThreadLocalContextStorage: ThreadLocalContextStorage()
org.webrtc.VideoFrame$I420Buffer: java.nio.ByteBuffer getDataV()
org.webrtc.MediaStreamTrack: void checkMediaStreamTrackExists()
com.google.firestore.v1.DocumentTransform$FieldTransform$Builder: DocumentTransform$FieldTransform$Builder()
org.webrtc.WrappedNativeI420Buffer: java.nio.ByteBuffer getDataU()
org.webrtc.Predicate: org.webrtc.Predicate negate()
io.grpc.internal.PickFirstLoadBalancerProvider: int getPriority()
io.grpc.okhttp.internal.framed.ErrorCode: io.grpc.okhttp.internal.framed.ErrorCode[] values()
com.cloudwebrtc.webrtc.utils.ConstraintsMap: com.cloudwebrtc.webrtc.utils.ConstraintsMap getMap(java.lang.String)
com.cloudwebrtc.webrtc.PeerConnectionObserver: void rtpTransceiverSetCodecPreferences(java.lang.String,java.util.List,io.flutter.plugin.common.MethodChannel$Result)
io.flutter.embedding.android.TransparencyMode: io.flutter.embedding.android.TransparencyMode[] values()
androidx.window.embedding.SplitPlaceholderRule: SplitPlaceholderRule(java.util.Set,android.content.Intent,int,int,float,int)
com.google.firebase.firestore.local.QueryPurpose: com.google.firebase.firestore.local.QueryPurpose[] values()
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin$LifeCycleObserver: void onActivityStarted(android.app.Activity)
io.flutter.embedding.android.FlutterActivityLaunchConfigs$BackgroundMode: io.flutter.embedding.android.FlutterActivityLaunchConfigs$BackgroundMode valueOf(java.lang.String)
org.webrtc.Camera1Enumerator: Camera1Enumerator(boolean)
org.webrtc.PeerConnection$IceTransportsType: PeerConnection$IceTransportsType(java.lang.String,int)
org.webrtc.HardwareVideoEncoder: boolean isEncodingStatisticsSupported()
org.webrtc.HardwareVideoDecoderFactory: HardwareVideoDecoderFactory(org.webrtc.EglBase$Context,org.webrtc.Predicate)
org.webrtc.NetworkMonitorAutoDetect$SimpleNetworkCallback: void onCapabilitiesChanged(android.net.Network,android.net.NetworkCapabilities)
io.flutter.plugin.platform.SingleViewPresentation: SingleViewPresentation(android.content.Context,android.view.Display,io.flutter.plugin.platform.PlatformView,io.flutter.plugin.platform.AccessibilityEventsDelegate,int,android.view.View$OnFocusChangeListener)
org.webrtc.EncodedImage$Builder: org.webrtc.EncodedImage$Builder setFrameType(org.webrtc.EncodedImage$FrameType)
com.google.firebase.firestore.core.UserData$Source: com.google.firebase.firestore.core.UserData$Source[] values()
org.webrtc.YuvConverter$ShaderCallbacks: void onNewShader(org.webrtc.GlShader)
com.cloudwebrtc.webrtc.utils.ConstraintsArray: java.lang.String getString(int)
org.webrtc.VideoEncoder: org.webrtc.VideoCodecStatus initEncode(org.webrtc.VideoEncoder$Settings,org.webrtc.VideoEncoder$Callback)
io.flutter.embedding.engine.FlutterJNI: void nativeDestroy(long)
io.grpc.ChannelLogger$ChannelLogLevel: io.grpc.ChannelLogger$ChannelLogLevel valueOf(java.lang.String)
com.google.firebase.firestore.core.FieldFilter$Operator: com.google.firebase.firestore.core.FieldFilter$Operator valueOf(java.lang.String)
org.webrtc.voiceengine.WebRtcAudioRecord$WebRtcAudioRecordErrorCallback: void onWebRtcAudioRecordError(java.lang.String)
org.webrtc.PeerConnection$RTCConfiguration: java.lang.Integer getStableWritableConnectionPingIntervalMs()
io.flutter.embedding.android.FlutterImageView: android.media.ImageReader getImageReader()
org.webrtc.ScreenCapturerAndroid: void initialize(org.webrtc.SurfaceTextureHelper,android.content.Context,org.webrtc.CapturerObserver)
androidx.window.core.Version$Companion: Version$Companion()
org.webrtc.PeerConnection$RtcpMuxPolicy: org.webrtc.PeerConnection$RtcpMuxPolicy[] values()
org.webrtc.ThreadUtils: boolean awaitUninterruptibly(java.util.concurrent.CountDownLatch,long)
androidx.lifecycle.ReportFragment$LifecycleCallbacks: void onActivityPostStarted(android.app.Activity)
org.webrtc.VideoSource: void adaptOutputFormat(int,int,int)
org.webrtc.SurfaceViewRenderer: void pauseVideo()
io.flutter.plugins.firebase.firestore.FlutterFirebaseFirestoreRegistrar: FlutterFirebaseFirestoreRegistrar()
org.webrtc.RendererCommon: android.graphics.Matrix convertMatrixToAndroidGraphicsMatrix(float[])
org.webrtc.VideoFrame$TextureBuffer$Type: org.webrtc.VideoFrame$TextureBuffer$Type[] values()
androidx.window.embedding.ExtensionEmbeddingBackend$EmbeddingCallbackImpl: java.util.List getLastInfo()
org.webrtc.SessionDescription$Type: org.webrtc.SessionDescription$Type valueOf(java.lang.String)
com.google.firestore.v1.MapValue: MapValue()
kotlin.jvm.internal.CallableReference: boolean isSuspend()
androidx.window.layout.WindowInfoTrackerImpl: androidx.window.layout.WindowBackend access$getWindowBackend$p(androidx.window.layout.WindowInfoTrackerImpl)
org.webrtc.RtpTransceiver$RtpTransceiverInit: RtpTransceiver$RtpTransceiverInit(org.webrtc.RtpTransceiver$RtpTransceiverDirection)
org.webrtc.HardwareVideoEncoder: void releaseCodecOnOutputThread()
org.webrtc.YuvHelper: void I420ToNV12(java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,int,int)
androidx.window.embedding.ActivityStack: java.util.List getActivities$window_release()
org.webrtc.PeerConnection: boolean nativeAddLocalStream(long)
org.webrtc.CameraCapturer: void checkIsOnCameraThread()
org.webrtc.PeerConnection$RTCConfiguration: org.webrtc.PeerConnection$IceTransportsType getIceTransportsType()
com.google.firestore.v1.StructuredQuery$FieldFilter: StructuredQuery$FieldFilter()
org.webrtc.NetworkMonitorAutoDetect$WifiDirectManagerDelegate: NetworkMonitorAutoDetect$WifiDirectManagerDelegate(org.webrtc.NetworkChangeDetector$Observer,android.content.Context)
androidx.window.embedding.SplitPairRule: boolean getFinishPrimaryWithSecondary()
org.webrtc.Histogram: long nativeCreateCounts(java.lang.String,int,int,int)
androidx.lifecycle.ReportFragment$LifecycleCallbacks: void onActivityResumed(android.app.Activity)
org.webrtc.voiceengine.WebRtcAudioEffects: void enable(int)
org.webrtc.EglBase10Impl$1FakeSurfaceHolder: boolean isCreating()
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback$AnimationCallback: void onPrepare(android.view.WindowInsetsAnimation)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$1: void onCreateSuccess(org.webrtc.SessionDescription)
org.webrtc.NetworkStatePredictorFactoryFactory: long createNativeNetworkStatePredictorFactory()
org.webrtc.HardwareVideoEncoder$1: void run()
com.cloudwebrtc.webrtc.GetUserMediaImpl: java.lang.Integer getConstrainInt(com.cloudwebrtc.webrtc.utils.ConstraintsMap,java.lang.String)
androidx.window.core.Version$bigInteger$2: java.math.BigInteger invoke()
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor: void frameCryptorFactoryCreateFrameCryptor(java.util.Map,io.flutter.plugin.common.MethodChannel$Result)
kotlinx.coroutines.internal.ThreadSafeHeap: ThreadSafeHeap()
org.webrtc.NetworkMonitor: void stopMonitoring(long)
org.webrtc.Camera1Session$2: void lambda$onPreviewFrame$1(byte[])
org.webrtc.CryptoOptions$Srtp: boolean getEnableGcmCryptoSuites()
com.cloudwebrtc.webrtc.PeerConnectionObserver: void lambda$getStatsForTrack$1(io.flutter.plugin.common.MethodChannel$Result,org.webrtc.RTCStatsReport)
androidx.window.layout.ActivityCompatHelperApi24: boolean isInMultiWindowMode(android.app.Activity)
androidx.window.layout.WindowMetricsCalculator$Companion$overrideDecorator$1: androidx.window.layout.WindowMetricsCalculator invoke(androidx.window.layout.WindowMetricsCalculator)
com.google.firestore.v1.Value$ValueTypeCase: com.google.firestore.v1.Value$ValueTypeCase valueOf(java.lang.String)
kotlin.jvm.internal.CallableReference: CallableReference(java.lang.Object,java.lang.Class,java.lang.String,java.lang.String,boolean)
org.webrtc.RtpParameters$Encoding: java.lang.String getRid()
com.cloudwebrtc.webrtc.PeerConnectionObserver: void onRemoveStream(org.webrtc.MediaStream)
org.webrtc.VideoEncoder$-CC: org.webrtc.VideoEncoder$EncoderInfo $default$getEncoderInfo(org.webrtc.VideoEncoder)
org.webrtc.MediaCodecUtils: java.lang.Integer selectColorFormat(int[],android.media.MediaCodecInfo$CodecCapabilities)
org.webrtc.Camera2Session$CameraStateCallback: Camera2Session$CameraStateCallback(org.webrtc.Camera2Session)
io.grpc.internal.DnsNameResolverProvider: DnsNameResolverProvider()
io.flutter.plugin.platform.SingleViewPresentation: io.flutter.plugin.platform.PlatformView getView()
org.webrtc.SurfaceTextureHelper: boolean isTextureInUse()
androidx.window.embedding.EmbeddingAdapter: java.lang.Object component2(android.util.Pair)
org.webrtc.RtpSender: void checkRtpSenderExists()
org.webrtc.voiceengine.WebRtcAudioTrack: void setErrorCallback(org.webrtc.voiceengine.WebRtcAudioTrack$WebRtcAudioTrackErrorCallback)
kotlinx.coroutines.android.AndroidDispatcherFactory: int getLoadPriority()
org.webrtc.NetworkMonitorAutoDetect: boolean supportNetworkCallback()
com.cloudwebrtc.webrtc.GetUserMediaImpl: com.cloudwebrtc.webrtc.utils.ConstraintsMap getUserAudio(com.cloudwebrtc.webrtc.utils.ConstraintsMap,org.webrtc.MediaStream)
org.webrtc.PeerConnectionFactory: void onSignalingThreadReady()
org.webrtc.EncodedImage$Builder: org.webrtc.EncodedImage$Builder setRotation(int)
io.flutter.embedding.engine.mutatorsstack.FlutterMutatorsStack: android.graphics.Matrix getFinalMatrix()
org.webrtc.audio.WebRtcAudioTrack: int getStreamVolume()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: org.webrtc.PeerConnection getPeerConnection(java.lang.String)
org.webrtc.EncodedImage: java.lang.Integer getQp()
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor$FrameCryptorStateObserver: void onListen(java.lang.Object,io.flutter.plugin.common.EventChannel$EventSink)
org.webrtc.MediaStreamTrack: org.webrtc.MediaStreamTrack createMediaStreamTrack(long)
kotlin.jvm.internal.CallableReference: kotlin.reflect.KDeclarationContainer getOwner()
org.webrtc.PeerConnection: boolean nativeRemoveIceCandidates(org.webrtc.IceCandidate[])
org.webrtc.CameraCapturer: void switchCamera(org.webrtc.CameraVideoCapturer$CameraSwitchHandler,java.lang.String)
androidx.window.embedding.ExtensionEmbeddingBackend$SplitListenerWrapper: void accept(java.util.List)
androidx.window.layout.DisplayCompatHelperApi17: DisplayCompatHelperApi17()
kotlin.Unit: Unit()
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin$LifeCycleObserver: void onStart(androidx.lifecycle.LifecycleOwner)
com.cloudwebrtc.webrtc.PeerConnectionObserver: void registerDataChannelObserver(java.lang.String,org.webrtc.DataChannel)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void addTransceiver(java.lang.String,java.lang.String,java.util.Map,io.flutter.plugin.common.MethodChannel$Result)
com.google.firestore.v1.Target$QueryTarget: Target$QueryTarget()
androidx.window.layout.SidecarCompat$Companion: SidecarCompat$Companion()
com.cloudwebrtc.webrtc.audio.AudioSwitchManager: void lambda$new$1(int)
kotlin.coroutines.AbstractCoroutineContextElement: kotlin.coroutines.CoroutineContext plus(kotlin.coroutines.CoroutineContext)
org.webrtc.Size: java.lang.String toString()
org.webrtc.NV21Buffer: void nativeCropAndScale(int,int,int,int,int,int,byte[],int,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int)
org.webrtc.voiceengine.WebRtcAudioEffects: boolean canUseAcousticEchoCanceler()
androidx.window.layout.SidecarCompat: void onWindowLayoutChangeListenerRemoved(android.app.Activity)
androidx.window.layout.SidecarWindowBackend: void setWindowExtension(androidx.window.layout.ExtensionInterfaceCompat)
com.twilio.audioswitch.AudioSwitch$State: com.twilio.audioswitch.AudioSwitch$State valueOf(java.lang.String)
org.webrtc.NetworkMonitorAutoDetect$ConnectivityManagerDelegate: boolean hasInternetCapability(android.net.Network)
org.webrtc.SurfaceViewRenderer: void removeFrameListener(org.webrtc.EglRenderer$FrameListener)
com.cloudwebrtc.webrtc.audio.AudioDeviceKind: com.cloudwebrtc.webrtc.audio.AudioDeviceKind fromTypeName(java.lang.String)
androidx.window.layout.ExtensionWindowLayoutInfoBackend$MulticastConsumer: void accept(java.lang.Object)
org.webrtc.SurfaceViewRenderer: void onFrameResolutionChanged(int,int,int)
org.webrtc.VideoCapturer: void changeCaptureFormat(int,int,int)
com.cloudwebrtc.webrtc.utils.PermissionUtils: PermissionUtils()
org.webrtc.PeerConnection$RTCConfiguration: org.webrtc.PeerConnection$RtcpMuxPolicy getRtcpMuxPolicy()
com.google.common.collect.ImmutableSet: ImmutableSet()
org.webrtc.audio.JavaAudioDeviceModule$Builder: org.webrtc.audio.JavaAudioDeviceModule$Builder setAudioTrackStateCallback(org.webrtc.audio.JavaAudioDeviceModule$AudioTrackStateCallback)
androidx.window.layout.FoldingFeature$State: java.lang.String toString()
org.webrtc.MediaCodecWrapper: android.media.MediaFormat getOutputFormat(int)
org.webrtc.PeerConnection$BundlePolicy: org.webrtc.PeerConnection$BundlePolicy valueOf(java.lang.String)
androidx.window.embedding.SplitPlaceholderRule: androidx.window.embedding.SplitPlaceholderRule plus$window_release(androidx.window.embedding.ActivityFilter)
org.webrtc.CameraEnumerationAndroid$1: int progressivePenalty(int,int,int,int)
com.cloudwebrtc.webrtc.record.FrameCapturer: FrameCapturer(org.webrtc.VideoTrack,java.io.File,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.PeerConnectionFactory: void stopInternalTracingCapture()
org.webrtc.PeerConnection$IceServer: java.util.List getTlsEllipticCurves()
com.cloudwebrtc.webrtc.PeerConnectionObserver: java.lang.String iceConnectionStateString(org.webrtc.PeerConnection$IceConnectionState)
org.webrtc.WrappedNativeI420Buffer: org.webrtc.VideoFrame$I420Buffer toI420()
org.webrtc.RtpTransceiver: org.webrtc.RtpTransceiver$RtpTransceiverDirection nativeDirection(long)
org.webrtc.RtpSender: void setStreams(java.util.List)
androidx.window.embedding.EmbeddingCompat: void setEmbeddingCallback(androidx.window.embedding.EmbeddingInterfaceCompat$EmbeddingCallbackInterface)
org.webrtc.NetworkMonitorAutoDetect: void setWifiManagerDelegateForTests(org.webrtc.NetworkMonitorAutoDetect$WifiManagerDelegate)
org.webrtc.PeerConnection: boolean setBitrate(java.lang.Integer,java.lang.Integer,java.lang.Integer)
org.webrtc.voiceengine.BuildInfo: java.lang.String getAndroidBuildId()
org.webrtc.MediaStream: java.lang.String getId()
com.google.firebase.firestore.proto.NoDocument$Builder: NoDocument$Builder()
org.webrtc.CameraCapturer$4: void onCameraClosed()
org.webrtc.PeerConnectionFactory: long nativeCreateAudioTrack(long,java.lang.String,long)
androidx.window.core.Version$Companion: Version$Companion(kotlin.jvm.internal.DefaultConstructorMarker)
io.grpc.DecompressorRegistry: DecompressorRegistry()
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper: java.lang.String getImplementationName()
org.webrtc.AudioTrack: AudioTrack(long)
com.cloudwebrtc.webrtc.PeerConnectionObserver: void lambda$getStats$2(io.flutter.plugin.common.MethodChannel$Result,org.webrtc.RTCStatsReport)
org.webrtc.EglBase14Impl: void createDummyPbufferSurface()
androidx.window.layout.WindowMetricsCalculatorCompat: android.view.DisplayCutout getCutoutForDisplay(android.view.Display)
org.webrtc.JniCommon: void nativeFreeByteBuffer(java.nio.ByteBuffer)
org.webrtc.EglBase$ConfigBuilder: org.webrtc.EglBase$ConfigBuilder setSupportsPixelBuffer(boolean)
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer: void removeRendererFromVideoTrack()
org.webrtc.VideoSource: void lambda$setVideoProcessor$1(org.webrtc.VideoFrame)
androidx.window.embedding.EmbeddingCompat: EmbeddingCompat(androidx.window.extensions.embedding.ActivityEmbeddingComponent,androidx.window.embedding.EmbeddingAdapter)
org.webrtc.JniCommon: JniCommon()
com.cloudwebrtc.webrtc.PeerConnectionObserver: void onRenegotiationNeeded()
org.webrtc.EglBase10Impl: boolean hasSurface()
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor$FrameCryptorStateObserver: io.flutter.plugin.common.EventChannel$EventSink access$002(com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor$FrameCryptorStateObserver,io.flutter.plugin.common.EventChannel$EventSink)
org.webrtc.NetworkChangeDetector$Observer: NetworkChangeDetector$Observer()
org.webrtc.PeerConnection: void nativeClose()
org.webrtc.Logging: void e(java.lang.String,java.lang.String,java.lang.Throwable)
org.webrtc.Logging: void nativeLog(int,java.lang.String,java.lang.String)
org.webrtc.CameraEnumerationAndroid$ClosestComparator: int compare(java.lang.Object,java.lang.Object)
com.google.firebase.concurrent.UiExecutor: com.google.firebase.concurrent.UiExecutor valueOf(java.lang.String)
com.cloudwebrtc.webrtc.GetUserMediaImpl$ScreenRequestPermissionsFragment: void onActivityResult(int,int,android.content.Intent)
org.webrtc.Camera1Session$2: void lambda$onPreviewFrame$0(byte[])
org.webrtc.audio.WebRtcAudioRecord: boolean isNoiseSuppressorSupported()
org.webrtc.SurfaceTextureHelper: org.webrtc.VideoFrame$I420Buffer textureToYuv(org.webrtc.VideoFrame$TextureBuffer)
org.webrtc.DefaultVideoDecoderFactory: DefaultVideoDecoderFactory(org.webrtc.EglBase$Context)
org.webrtc.voiceengine.WebRtcAudioEffects: void assertTrue(boolean)
org.webrtc.voiceengine.WebRtcAudioEffects: boolean isAcousticEchoCancelerExcludedByUUID()
org.webrtc.voiceengine.WebRtcAudioTrack: void releaseAudioResources()
org.webrtc.PeerConnection: boolean getStats(org.webrtc.StatsObserver,org.webrtc.MediaStreamTrack)
org.webrtc.EglRenderer: void logE(java.lang.String,java.lang.Throwable)
com.google.firebase.firestore.remote.ConnectivityMonitor$NetworkStatus: com.google.firebase.firestore.remote.ConnectivityMonitor$NetworkStatus[] values()
org.webrtc.SessionDescription: java.lang.String getTypeInCanonicalForm()
org.webrtc.RtpSender: java.lang.String id()
com.cloudwebrtc.webrtc.R$string: R$string()
org.webrtc.audio.JavaAudioDeviceModule$AudioRecordStartErrorCode: org.webrtc.audio.JavaAudioDeviceModule$AudioRecordStartErrorCode[] values()
org.webrtc.Camera2Session$CameraStateCallback: void onClosed(android.hardware.camera2.CameraDevice)
androidx.window.embedding.EmbeddingInterfaceCompat$EmbeddingCallbackInterface: void onSplitInfoChanged(java.util.List)
org.webrtc.VideoTrack: void dispose()
androidx.window.layout.DisplayCompatHelperApi28: int safeInsetTop(android.view.DisplayCutout)
org.webrtc.JavaI420Buffer: int getHeight()
androidx.window.embedding.ExtensionEmbeddingBackend$SplitListenerWrapper: androidx.core.util.Consumer getCallback()
androidx.window.embedding.SplitInfo: boolean contains(android.app.Activity)
org.webrtc.TextureBufferImpl: int getUnscaledHeight()
io.grpc.util.OutlierDetectionLoadBalancerProvider: OutlierDetectionLoadBalancerProvider()
org.webrtc.Logging$TraceLevel: Logging$TraceLevel(java.lang.String,int,int)
org.webrtc.CryptoOptions$Builder: org.webrtc.CryptoOptions$Builder setRequireFrameEncryption(boolean)
org.webrtc.PeerConnection$PortPrunePolicy: org.webrtc.PeerConnection$PortPrunePolicy[] values()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: com.cloudwebrtc.webrtc.PeerConnectionObserver getPeerConnectionObserver(java.lang.String)
org.webrtc.NetworkMonitor: org.webrtc.NetworkMonitorAutoDetect createAndSetAutoDetectForTest(android.content.Context,java.lang.String)
com.google.firebase.firestore.model.MutableDocument$DocumentState: com.google.firebase.firestore.model.MutableDocument$DocumentState[] values()
com.cloudwebrtc.webrtc.OrientationAwareScreenCapturer: boolean isDeviceOrientationPortrait()
kotlin.jvm.internal.CallableReference: CallableReference()
org.webrtc.VideoCodecStatus: org.webrtc.VideoCodecStatus[] values()
io.flutter.embedding.engine.renderer.SurfaceTextureWrapper: SurfaceTextureWrapper(android.graphics.SurfaceTexture,java.lang.Runnable)
com.google.protobuf.Writer$FieldOrder: com.google.protobuf.Writer$FieldOrder valueOf(java.lang.String)
io.perfmark.PerfMark: PerfMark()
androidx.window.layout.WindowMetrics: WindowMetrics(android.graphics.Rect)
com.cloudwebrtc.webrtc.PeerConnectionObserver: void setPeerConnection(org.webrtc.PeerConnection)
org.webrtc.FrameCryptor: void setKeyIndex(int)
org.webrtc.RtpReceiver: java.lang.String nativeGetId(long)
android.support.v4.graphics.drawable.IconCompatParcelizer: androidx.core.graphics.drawable.IconCompat read(androidx.versionedparcelable.VersionedParcel)
org.webrtc.PeerConnection$IceServer: java.lang.String getHostname()
org.webrtc.TextureBufferImpl$2: TextureBufferImpl$2(org.webrtc.TextureBufferImpl)
org.webrtc.PeerConnection$TlsCertPolicy: org.webrtc.PeerConnection$TlsCertPolicy[] $values()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void rtpTransceiverSetCodecPreferences(java.lang.String,java.lang.String,java.util.List,io.flutter.plugin.common.MethodChannel$Result)
com.cloudwebrtc.webrtc.utils.ConstraintsArray: void pushMap(com.cloudwebrtc.webrtc.utils.ConstraintsMap)
androidx.window.layout.ExtensionInterfaceCompat: boolean validateExtensionInterface()
com.cloudwebrtc.webrtc.audio.AudioSwitchManager: void enableSpeakerButPreferBluetooth()
com.cloudwebrtc.webrtc.utils.PermissionUtils: void access$100(android.content.Context,android.app.Activity,java.lang.String[],android.os.ResultReceiver)
org.webrtc.CameraVideoCapturer$CameraEventsHandler: void onCameraError(java.lang.String)
io.grpc.MethodDescriptor$MethodType: io.grpc.MethodDescriptor$MethodType[] values()
org.webrtc.VideoDecoderFactory: org.webrtc.VideoCodecInfo[] getSupportedCodecs()
org.webrtc.CallSessionFileRotatingLogSink: byte[] nativeGetLogData(java.lang.String)
org.webrtc.JniHelper: byte[] getStringBytes(java.lang.String)
com.google.firestore.v1.DocumentTransform$FieldTransform$ServerValue: com.google.firestore.v1.DocumentTransform$FieldTransform$ServerValue[] values()
org.webrtc.EncodedImage: EncodedImage(java.nio.ByteBuffer,java.lang.Runnable,int,int,long,org.webrtc.EncodedImage$FrameType,int,java.lang.Integer)
com.google.android.gms.tasks.TaskCompletionSource: TaskCompletionSource()
org.webrtc.PeerConnection$IceServer$Builder: org.webrtc.PeerConnection$IceServer$Builder setPassword(java.lang.String)
org.webrtc.BaseBitrateAdjuster: double getAdjustedFramerateFps()
kotlinx.coroutines.android.AndroidDispatcherFactory: java.lang.String hintOnError()
io.flutter.embedding.android.TransparencyMode: io.flutter.embedding.android.TransparencyMode valueOf(java.lang.String)
android.support.v4.graphics.drawable.IconCompatParcelizer: IconCompatParcelizer()
org.webrtc.PeerConnectionFactory: void checkInitializeHasBeenCalled()
androidx.core.content.ContextCompat$Api24Impl: android.content.Context createDeviceProtectedStorageContext(android.content.Context)
org.webrtc.RtpReceiver: void checkRtpReceiverExists()
androidx.lifecycle.ReportFragment$LifecycleCallbacks: void onActivityPreDestroyed(android.app.Activity)
org.webrtc.VideoEncoderWrapper: void lambda$createEncoderCallback$0(long,org.webrtc.EncodedImage,org.webrtc.VideoEncoder$CodecSpecificInfo)
org.webrtc.PeerConnectionFactory$Builder: org.webrtc.PeerConnectionFactory$Builder setAudioDecoderFactoryFactory(org.webrtc.AudioDecoderFactoryFactory)
org.webrtc.VideoEncoder$Capabilities: VideoEncoder$Capabilities(boolean)
org.webrtc.CameraVideoCapturer$MediaRecorderHandler: void onMediaRecorderError(java.lang.String)
org.webrtc.PeerConnectionFactory: boolean startInternalTracingCapture(java.lang.String)
com.cloudwebrtc.webrtc.CameraEventsHandler: void onCameraError(java.lang.String)
org.webrtc.GlShader: int getUniformLocation(java.lang.String)
org.webrtc.voiceengine.WebRtcAudioRecord$AudioRecordThread: void stopThread()
org.webrtc.audio.WebRtcAudioTrack: void logBufferCapacityInFrames()
org.webrtc.BuiltinAudioDecoderFactoryFactory: long nativeCreateBuiltinAudioDecoderFactory()
io.flutter.embedding.engine.FlutterJNI: void nativeInvokePlatformMessageResponseCallback(long,int,java.nio.ByteBuffer,int)
org.webrtc.GlRectDrawer$ShaderCallbacks: void onPrepareShader(org.webrtc.GlShader,float[],int,int,int,int)
org.webrtc.DefaultVideoEncoderFactory: DefaultVideoEncoderFactory(org.webrtc.VideoEncoderFactory)
org.webrtc.PeerConnection$KeyType: org.webrtc.PeerConnection$KeyType[] values()
org.webrtc.Logging: java.util.logging.Logger createFallbackLogger()
org.webrtc.audio.JavaAudioDeviceModule: long getNativeAudioDeviceModulePointer()
org.webrtc.SoftwareVideoEncoderFactory: java.util.List nativeGetSupportedCodecs(long)
kotlinx.coroutines.ExecutorCoroutineDispatcher: ExecutorCoroutineDispatcher()
com.google.firestore.v1.DocumentRemove: DocumentRemove()
com.google.firestore.admin.v1.Index$IndexField$Order: com.google.firestore.admin.v1.Index$IndexField$Order valueOf(java.lang.String)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: MethodCallHandlerImpl(android.content.Context,io.flutter.plugin.common.BinaryMessenger,io.flutter.view.TextureRegistry)
io.flutter.embedding.engine.systemchannels.PlatformChannel$Brightness: io.flutter.embedding.engine.systemchannels.PlatformChannel$Brightness[] values()
org.webrtc.NetworkMonitorAutoDetect$NetworkState: int getNetworkType()
org.webrtc.SurfaceEglRenderer: void onFrame(org.webrtc.VideoFrame)
androidx.window.layout.WindowInfoTracker$-CC: void reset()
org.webrtc.CameraCapturer: void switchCamera(org.webrtc.CameraVideoCapturer$CameraSwitchHandler)
org.webrtc.PeerConnectionFactory$InitializationOptions: PeerConnectionFactory$InitializationOptions(android.content.Context,java.lang.String,boolean,org.webrtc.NativeLibraryLoader,java.lang.String,org.webrtc.Loggable,org.webrtc.Logging$Severity)
androidx.window.core.Version$Companion: androidx.window.core.Version getVERSION_0_1()
kotlin.jvm.internal.FunctionReference: kotlin.reflect.KCallable computeReflected()
org.webrtc.RtcCertificatePem: java.lang.String getPrivateKey()
org.webrtc.RendererCommon$VideoLayoutMeasure: void setScalingType(org.webrtc.RendererCommon$ScalingType)
org.webrtc.voiceengine.WebRtcAudioUtils: java.util.List getBlackListedModelsForAecUsage()
org.webrtc.RtpTransceiver: void nativeStopStandard(long)
org.webrtc.audio.WebRtcAudioRecord: WebRtcAudioRecord(android.content.Context,java.util.concurrent.ScheduledExecutorService,android.media.AudioManager,int,int,org.webrtc.audio.JavaAudioDeviceModule$AudioRecordErrorCallback,org.webrtc.audio.JavaAudioDeviceModule$AudioRecordStateCallback,org.webrtc.audio.JavaAudioDeviceModule$SamplesReadyCallback,boolean,boolean)
org.webrtc.JavaI420Buffer: void retain()
org.webrtc.audio.WebRtcAudioManager: int getSampleRateForApiLevel(android.media.AudioManager)
com.cloudwebrtc.webrtc.SurfaceTextureRenderer: void init(org.webrtc.EglBase$Context,int[],org.webrtc.RendererCommon$GlDrawer)
com.google.firebase.firestore.util.Logger$Level: com.google.firebase.firestore.util.Logger$Level[] values()
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper: boolean isHardwareEncoder()
org.webrtc.EglRenderer: void release()
org.webrtc.RefCountDelegate: void release()
com.google.firebase.firestore.core.OrderBy$Direction: com.google.firebase.firestore.core.OrderBy$Direction[] values()
com.cloudwebrtc.webrtc.utils.ConstraintsMap: boolean getBoolean(java.lang.String)
org.webrtc.MediaCodecUtils: boolean codecSupportsType(android.media.MediaCodecInfo,org.webrtc.VideoCodecMimeType)
org.webrtc.YuvHelper: void I420ToNV12(java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,int,int,int)
com.google.firestore.admin.v1.Index$QueryScope: com.google.firestore.admin.v1.Index$QueryScope[] values()
androidx.window.embedding.SplitRule$Api30Impl: SplitRule$Api30Impl()
org.webrtc.VideoSource: void setIsScreencast(boolean)
androidx.core.graphics.drawable.IconCompatParcelizer: androidx.core.graphics.drawable.IconCompat read(androidx.versionedparcelable.VersionedParcel)
org.webrtc.audio.WebRtcAudioTrack: boolean stopPlayout()
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper: org.webrtc.VideoEncoder$ScalingSettings getScalingSettings$lambda-4(com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper)
org.webrtc.MediaCodecWrapperFactoryImpl$MediaCodecWrapperImpl: void stop()
kotlin.jvm.internal.FunctionReference: kotlin.reflect.KFunction getReflected()
kotlin.jvm.internal.FunctionReferenceImpl: FunctionReferenceImpl(int,java.lang.Object,java.lang.Class,java.lang.String,java.lang.String,int)
org.webrtc.YuvConverter: YuvConverter(org.webrtc.VideoFrameDrawer)
org.webrtc.NetworkChangeDetector: void destroy()
org.webrtc.SurfaceViewRenderer: void disableFpsReduction()
com.google.firebase.firestore.core.DocumentViewChange$Type: com.google.firebase.firestore.core.DocumentViewChange$Type valueOf(java.lang.String)
com.cloudwebrtc.webrtc.record.AudioTrackInterceptor: void stop()
androidx.window.layout.FoldingFeature$State$Companion: FoldingFeature$State$Companion(kotlin.jvm.internal.DefaultConstructorMarker)
org.webrtc.Camera1Capturer: void startCapture(int,int,int)
com.cloudwebrtc.webrtc.SurfaceTextureRenderer: void surfaceDestroyed()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void addTransceiverOfType(java.lang.String,java.lang.String,java.util.Map,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.SurfaceViewRenderer: void logD(java.lang.String)
androidx.window.embedding.EmptyEmbeddingComponent: void setSplitInfoCallback(java.util.function.Consumer)
org.webrtc.RtpParameters$Rtcp: RtpParameters$Rtcp(java.lang.String,boolean)
org.webrtc.VideoEncoder$ScalingSettings: java.lang.String toString()
org.webrtc.VideoFileRenderer: void onFrame(org.webrtc.VideoFrame)
com.google.firestore.v1.Precondition$ConditionTypeCase: com.google.firestore.v1.Precondition$ConditionTypeCase valueOf(java.lang.String)
org.webrtc.Camera1Enumerator: int getCameraIndex(java.lang.String)
org.webrtc.NetworkMonitor: void nativeNotifyOfActiveNetworkList(long,org.webrtc.NetworkChangeDetector$NetworkInformation[])
org.webrtc.PeerConnection$PortPrunePolicy: org.webrtc.PeerConnection$PortPrunePolicy[] $values()
com.cloudwebrtc.webrtc.GetUserMediaImpl: boolean access$500(com.cloudwebrtc.webrtc.GetUserMediaImpl)
org.webrtc.audio.JavaAudioDeviceModule$AudioSamples: JavaAudioDeviceModule$AudioSamples(int,int,int,byte[])
org.webrtc.Camera1Capturer: void switchCamera(org.webrtc.CameraVideoCapturer$CameraSwitchHandler)
org.webrtc.PeerConnection: void nativeNewGetStatsSender(long,org.webrtc.RTCStatsCollectorCallback)
org.webrtc.FrameCryptorKeyProvider: boolean setKey(java.lang.String,int,byte[])
com.google.firebase.firestore.index.IndexEntry: IndexEntry()
org.webrtc.VideoEncoderWrapper: void nativeOnEncodedFrame(long,org.webrtc.EncodedImage)
org.webrtc.VideoDecoderFallback: long nativeCreateDecoder(org.webrtc.VideoDecoder,org.webrtc.VideoDecoder)
org.webrtc.NetworkMonitor: org.webrtc.NetworkChangeDetector createNetworkChangeDetector(android.content.Context,java.lang.String)
org.webrtc.MediaCodecWrapper: android.media.MediaFormat getOutputFormat()
com.google.firestore.v1.Write$OperationCase: com.google.firestore.v1.Write$OperationCase[] values()
androidx.window.embedding.ActivityFilter: java.lang.String getIntentAction()
com.google.firestore.v1.WriteRequest: WriteRequest()
org.webrtc.PeerConnection: org.webrtc.RtcCertificatePem getCertificate()
org.webrtc.RtpSender: long nativeGetTrack(long)
com.cloudwebrtc.webrtc.utils.ConstraintsMap: void putDouble(java.lang.String,double)
org.webrtc.EglBase10Impl$Context: javax.microedition.khronos.egl.EGLContext getRawContext()
org.webrtc.SurfaceTextureHelper: android.graphics.SurfaceTexture getSurfaceTexture()
org.webrtc.PeerConnection: void restartIce()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$1: MethodCallHandlerImpl$1(com.cloudwebrtc.webrtc.MethodCallHandlerImpl,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.EglRenderer: void clearSurfaceOnRenderThread(float,float,float,float)
org.webrtc.Metrics: void enable()
org.webrtc.CalledByNativeUnchecked: java.lang.String value()
io.flutter.embedding.engine.loader.FlutterLoader: FlutterLoader()
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback: android.view.View access$602(io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback,android.view.View)
org.webrtc.TextureBufferImpl: int getTextureId()
androidx.window.layout.WindowLayoutInfo: java.lang.String toString()
org.webrtc.MediaCodecWrapperFactory: org.webrtc.MediaCodecWrapper createByCodecName(java.lang.String)
io.grpc.internal.ProxyDetectorImpl: ProxyDetectorImpl()
org.webrtc.audio.WebRtcAudioRecord: boolean stopRecording()
androidx.window.layout.ExtensionInterfaceCompat: void onWindowLayoutChangeListenerRemoved(android.app.Activity)
org.webrtc.HardwareVideoDecoderFactory$1: HardwareVideoDecoderFactory$1()
org.webrtc.GlRectDrawer$ShaderCallbacks: void onNewShader(org.webrtc.GlShader)
com.google.firebase.firestore.model.mutation.Overlay: Overlay()
io.grpc.internal.ServiceConfigUtil: ServiceConfigUtil()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$4: void onSetSuccess()
org.webrtc.DynamicBitrateAdjuster: int getAdjustedBitrateBps()
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor: void frameCryptorFactoryCreateKeyProvider(java.util.Map,io.flutter.plugin.common.MethodChannel$Result)
com.cloudwebrtc.webrtc.CameraEventsHandler: CameraEventsHandler()
org.webrtc.PlatformSoftwareVideoDecoderFactory$1: PlatformSoftwareVideoDecoderFactory$1()
com.google.firebase.firestore.core.Query$LimitType: com.google.firebase.firestore.core.Query$LimitType[] values()
androidx.window.core.Version: int getMajor()
org.webrtc.H264Utils: boolean nativeIsSameH264Profile(java.util.Map,java.util.Map)
org.webrtc.VideoSource$1: VideoSource$1(org.webrtc.VideoSource)
org.webrtc.MediaCodecUtils: MediaCodecUtils()
org.webrtc.SurfaceEglRenderer: void surfaceDestroyed(android.view.SurfaceHolder)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void getDisplayMedia(com.cloudwebrtc.webrtc.utils.ConstraintsMap,io.flutter.plugin.common.MethodChannel$Result)
androidx.window.embedding.ExtensionEmbeddingBackend$Companion: ExtensionEmbeddingBackend$Companion(kotlin.jvm.internal.DefaultConstructorMarker)
com.cloudwebrtc.webrtc.GetUserMediaImpl$NoSuchFieldWithNameException: GetUserMediaImpl$NoSuchFieldWithNameException(com.cloudwebrtc.webrtc.GetUserMediaImpl,java.lang.String,java.lang.String,java.lang.NoSuchFieldException)
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper: org.webrtc.VideoEncoder$ResolutionBitrateLimits[] getResolutionBitrateLimits$lambda-9(com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper)
com.cloudwebrtc.webrtc.R: R()
androidx.fragment.app.FragmentManagerState: FragmentManagerState()
org.webrtc.EncodedImage$Builder: org.webrtc.EncodedImage$Builder setBuffer(java.nio.ByteBuffer,java.lang.Runnable)
org.webrtc.AndroidVideoDecoder: void deliverDecodedFrame()
io.flutter.embedding.engine.FlutterJNI: void prefetchDefaultFontManager()
android.support.v4.graphics.drawable.IconCompatParcelizer: void write(androidx.core.graphics.drawable.IconCompat,androidx.versionedparcelable.VersionedParcel)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void peerConnectionCreateOffer(java.lang.String,com.cloudwebrtc.webrtc.utils.ConstraintsMap,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.MediaSource$State: org.webrtc.MediaSource$State fromNativeIndex(int)
org.webrtc.ThreadUtils$ThreadChecker: void detachThread()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void onMethodCall(io.flutter.plugin.common.MethodCall,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.VideoCodecInfo: java.lang.String getName()
org.webrtc.CameraCapturer: void stopCapture()
org.webrtc.EglBase$ConfigBuilder: org.webrtc.EglBase$ConfigBuilder setIsRecordable(boolean)
androidx.window.embedding.EmbeddingAdapter: java.util.function.Predicate translateIntentPredicates(java.util.Set)
org.webrtc.DtmfSender: int nativeInterToneGap(long)
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor$FrameCryptorStateObserver: io.flutter.plugin.common.EventChannel$EventSink access$000(com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor$FrameCryptorStateObserver)
com.cloudwebrtc.webrtc.GetUserMediaImpl: android.content.Context access$300(com.cloudwebrtc.webrtc.GetUserMediaImpl)
org.webrtc.audio.WebRtcAudioEffects: void enable(int)
org.webrtc.NetworkChangeDetector: java.util.List getActiveNetworkList()
androidx.window.layout.WindowMetricsCalculator$Companion: void overrideDecorator(androidx.window.layout.WindowMetricsCalculatorDecorator)
org.webrtc.Histogram: Histogram(long)
org.webrtc.PeerConnection$IceServer: PeerConnection$IceServer(java.lang.String,java.lang.String,java.lang.String,org.webrtc.PeerConnection$TlsCertPolicy,java.lang.String)
androidx.window.layout.SidecarCompat$FirstAttachAdapter: void onViewAttachedToWindow(android.view.View)
kotlinx.coroutines.android.AndroidExceptionPreHandler: java.lang.reflect.Method preHandler()
org.webrtc.PeerConnectionFactory: void nativeStopInternalTracingCapture()
org.webrtc.TextureBufferImpl: org.webrtc.VideoFrame$TextureBuffer applyTransformMatrix(android.graphics.Matrix,int,int)
org.webrtc.MediaCodecWrapper: void releaseOutputBuffer(int,boolean)
org.webrtc.RtpSender: java.util.List nativeGetStreams(long)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void dataChannelClose(java.lang.String,java.lang.String)
org.webrtc.MediaCodecWrapper: void queueInputBuffer(int,int,int,long,int)
androidx.loader.app.LoaderManagerImpl$LoaderViewModel: LoaderManagerImpl$LoaderViewModel()
org.webrtc.WrappedNativeI420Buffer: int getStrideV()
androidx.window.layout.ExtensionInterfaceCompat$ExtensionCallbackInterface: void onWindowLayoutChanged(android.app.Activity,androidx.window.layout.WindowLayoutInfo)
org.webrtc.DynamicBitrateAdjuster: double getBitrateAdjustmentScale()
org.webrtc.audio.JavaAudioDeviceModule$Builder: org.webrtc.audio.JavaAudioDeviceModule$Builder setSampleRate(int)
org.webrtc.PeerConnection$IceServer: boolean equals(java.lang.Object)
androidx.window.layout.WindowLayoutInfo: int hashCode()
org.webrtc.Camera1Session: void startCapturing()
org.webrtc.PeerConnection$PortPrunePolicy: org.webrtc.PeerConnection$PortPrunePolicy valueOf(java.lang.String)
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin$LifeCycleObserver: void onPause(androidx.lifecycle.LifecycleOwner)
org.webrtc.PeerConnection$AdapterType: org.webrtc.PeerConnection$AdapterType fromNativeIndex(int)
org.webrtc.HardwareVideoEncoderFactory: boolean isMediaCodecAllowed(android.media.MediaCodecInfo)
io.grpc.internal.TransportTracer: TransportTracer()
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer: void setStream(org.webrtc.MediaStream,java.lang.String,java.lang.String)
org.webrtc.FrameCryptorKeyProvider: byte[] nativeExportKey(long,java.lang.String,int)
org.webrtc.JavaI420Buffer: org.webrtc.VideoFrame$Buffer cropAndScale(int,int,int,int,int,int)
org.webrtc.NetEqFactoryFactory: long createNativeNetEqFactory()
org.webrtc.FrameCryptorKeyProvider: void dispose()
org.webrtc.PeerConnection: boolean removeIceCandidates(org.webrtc.IceCandidate[])
org.webrtc.Loggable: void onLogMessage(java.lang.String,org.webrtc.Logging$Severity,java.lang.String)
androidx.window.embedding.EmbeddingAdapter: androidx.window.embedding.SplitInfo translate(androidx.window.extensions.embedding.SplitInfo)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: java.lang.String getNextStreamUUID()
androidx.window.layout.HardwareFoldingFeature: HardwareFoldingFeature(androidx.window.core.Bounds,androidx.window.layout.HardwareFoldingFeature$Type,androidx.window.layout.FoldingFeature$State)
org.webrtc.audio.JavaAudioDeviceModule$AudioSamples: int getAudioFormat()
org.webrtc.SurfaceTextureHelper: android.os.Handler getHandler()
androidx.window.embedding.SplitPlaceholderRule: boolean equals(java.lang.Object)
org.webrtc.CryptoOptions$Builder: org.webrtc.CryptoOptions createCryptoOptions()
org.webrtc.VideoSource$1: void onCapturerStarted(boolean)
org.webrtc.audio.JavaAudioDeviceModule$AudioTrackStateCallback: void onWebRtcAudioTrackStop()
org.webrtc.JNILogging: void logToInjectable(java.lang.String,java.lang.Integer,java.lang.String)
org.webrtc.DataChannel$Init: boolean getOrdered()
org.webrtc.MediaConstraints: MediaConstraints()
androidx.window.layout.WindowMetricsCalculator$Companion: void reset()
androidx.window.java.layout.WindowInfoTrackerCallbackAdapter: void removeWindowLayoutInfoListener(androidx.core.util.Consumer)
org.webrtc.ThreadUtils$2: ThreadUtils$2(java.util.concurrent.CountDownLatch)
org.webrtc.LibvpxVp8Encoder: long createNativeVideoEncoder()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void getSources(io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.Histogram: org.webrtc.Histogram createCounts(java.lang.String,int,int,int)
org.webrtc.LibvpxVp8Decoder: long createNativeVideoDecoder()
org.webrtc.CameraVideoCapturer$-CC: void $default$addMediaRecorderToCamera(org.webrtc.CameraVideoCapturer,android.media.MediaRecorder,org.webrtc.CameraVideoCapturer$MediaRecorderHandler)
io.grpc.SecurityLevel: io.grpc.SecurityLevel valueOf(java.lang.String)
io.flutter.embedding.android.FlutterImageView: android.view.Surface getSurface()
org.webrtc.VideoDecoder$Callback: void onDecodedFrame(org.webrtc.VideoFrame,java.lang.Integer,java.lang.Integer)
org.webrtc.RtcCertificatePem: org.webrtc.RtcCertificatePem generateCertificate()
org.webrtc.audio.JavaAudioDeviceModule: long nativeCreateAudioDeviceModule(android.content.Context,android.media.AudioManager,org.webrtc.audio.WebRtcAudioRecord,org.webrtc.audio.WebRtcAudioTrack,int,int,boolean,boolean)
org.webrtc.PeerConnection: org.webrtc.RtpTransceiver addTransceiver(org.webrtc.MediaStreamTrack$MediaType)
org.webrtc.PeerConnection$SdpSemantics: org.webrtc.PeerConnection$SdpSemantics[] $values()
io.flutter.embedding.android.FlutterView: android.view.accessibility.AccessibilityNodeProvider getAccessibilityNodeProvider()
org.webrtc.PeerConnection: void createAnswer(org.webrtc.SdpObserver,org.webrtc.MediaConstraints)
io.flutter.view.AccessibilityBridge$StringAttribute: AccessibilityBridge$StringAttribute()
com.cloudwebrtc.webrtc.utils.AnyThreadResult: void notImplemented()
org.webrtc.PeerConnection: org.webrtc.PeerConnection$SignalingState signalingState()
kotlinx.coroutines.CoroutineDispatcher: CoroutineDispatcher()
org.webrtc.SurfaceEglRenderer: void init(org.webrtc.EglBase$Context,org.webrtc.RendererCommon$RendererEvents,int[],org.webrtc.RendererCommon$GlDrawer)
androidx.window.layout.ExtensionWindowLayoutInfoBackend$MulticastConsumer: void addListener(androidx.core.util.Consumer)
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer$1: FlutterRTCVideoRenderer$1(com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer)
org.webrtc.CameraCapturer$2: void onFrameCaptured(org.webrtc.CameraSession,org.webrtc.VideoFrame)
org.webrtc.NV12Buffer: int getWidth()
org.webrtc.VideoDecoderFallback: long createNativeVideoDecoder()
org.webrtc.audio.WebRtcAudioRecord: boolean enableBuiltInAEC(boolean)
org.webrtc.voiceengine.WebRtcAudioUtils: java.lang.String streamTypeToString(int)
org.webrtc.JniHelper: java.lang.Object getStringClass()
org.webrtc.Logging: void enableLogToDebugOutput(org.webrtc.Logging$Severity)
org.webrtc.FileVideoCapturer$VideoReader: org.webrtc.VideoFrame getNextFrame()
org.webrtc.NetworkChangeDetector$NetworkInformation: org.webrtc.NetworkChangeDetector$ConnectionType getUnderlyingConnectionTypeForVpn()
androidx.window.core.Version: java.lang.String toString()
org.webrtc.PeerConnection: void nativeSetLocalDescription(org.webrtc.SdpObserver,org.webrtc.SessionDescription)
org.webrtc.CameraVideoCapturer$CameraStatistics: CameraVideoCapturer$CameraStatistics(org.webrtc.SurfaceTextureHelper,org.webrtc.CameraVideoCapturer$CameraEventsHandler)
io.grpc.okhttp.internal.Protocol: io.grpc.okhttp.internal.Protocol valueOf(java.lang.String)
org.webrtc.MediaConstraints$KeyValuePair: boolean equals(java.lang.Object)
org.webrtc.SoftwareVideoEncoderFactory: SoftwareVideoEncoderFactory()
androidx.window.layout.SidecarWindowBackend: void callbackRemovedForActivity(android.app.Activity)
com.cloudwebrtc.webrtc.GetUserMediaImpl$ScreenRequestPermissionsFragment: void onResume()
org.webrtc.EncodedImage$Builder: EncodedImage$Builder()
io.flutter.plugin.editing.TextInputPlugin$InputTarget$Type: io.flutter.plugin.editing.TextInputPlugin$InputTarget$Type[] values()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void peerConnectionAddStream(java.lang.String,java.lang.String,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.MediaCodecWrapperFactoryImpl$MediaCodecWrapperImpl: android.media.MediaFormat getOutputFormat(int)
io.flutter.embedding.android.FlutterView: io.flutter.plugin.common.BinaryMessenger getBinaryMessenger()
com.cloudwebrtc.webrtc.PeerConnectionObserver: void onConnectionChange(org.webrtc.PeerConnection$PeerConnectionState)
com.cloudwebrtc.webrtc.PeerConnectionObserver: void getSenders(io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.GlGenericDrawer: void prepareShader(org.webrtc.GlGenericDrawer$ShaderType,float[],int,int,int,int)
io.grpc.Status$Code: io.grpc.Status$Code valueOf(java.lang.String)
org.webrtc.RtpCapabilities$CodecCapability: RtpCapabilities$CodecCapability()
com.google.firestore.v1.DocumentTransform$FieldTransform$TransformTypeCase: com.google.firestore.v1.DocumentTransform$FieldTransform$TransformTypeCase valueOf(java.lang.String)
org.webrtc.RendererCommon: float[] convertMatrixFromAndroidGraphicsMatrix(android.graphics.Matrix)
androidx.fragment.app.FragmentManagerImpl: FragmentManagerImpl()
io.flutter.embedding.android.FlutterSurfaceView: io.flutter.embedding.engine.renderer.FlutterRenderer getAttachedRenderer()
org.webrtc.voiceengine.WebRtcAudioTrack: WebRtcAudioTrack(long)
org.webrtc.NetworkMonitorAutoDetect$ConnectivityManagerDelegate: android.net.Network[] getAllNetworks()
org.webrtc.EglRenderer: void lambda$removeFrameListener$4(java.util.concurrent.CountDownLatch,org.webrtc.EglRenderer$FrameListener)
io.flutter.plugin.platform.SingleViewPresentation: void onCreate(android.os.Bundle)
io.flutter.embedding.engine.FlutterJNI: void setLocalizationPlugin(io.flutter.plugin.localization.LocalizationPlugin)
org.webrtc.RtpParameters$Codec: java.lang.Integer getNumChannels()
org.webrtc.CameraCapturer$6: CameraCapturer$6(org.webrtc.CameraCapturer,org.webrtc.CameraSession)
org.webrtc.PeerConnectionFactory: org.webrtc.RtpCapabilities nativeGetRtpSenderCapabilities(long,org.webrtc.MediaStreamTrack$MediaType)
com.cloudwebrtc.webrtc.StateProvider: java.lang.String getNextTrackUUID()
org.webrtc.RtpTransceiver: void stopInternal()
org.webrtc.GlTextureFrameBuffer: int getHeight()
org.webrtc.PeerConnectionFactory$Builder: org.webrtc.PeerConnectionFactory$Builder setNetEqFactoryFactory(org.webrtc.NetEqFactoryFactory)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: com.cloudwebrtc.webrtc.utils.ConstraintsMap capabilitiestoMap(org.webrtc.RtpCapabilities)
org.webrtc.Predicate$-CC: org.webrtc.Predicate $default$negate(org.webrtc.Predicate)
org.webrtc.NetworkMonitorAutoDetect$ConnectivityManagerDelegate: void registerNetworkCallback(android.net.ConnectivityManager$NetworkCallback)
org.webrtc.audio.WebRtcAudioManager: int getInputBufferSize(android.content.Context,android.media.AudioManager,int,int)
org.webrtc.GlShader: int getAttribLocation(java.lang.String)
org.webrtc.CameraVideoCapturer$CameraEventsHandler: void onCameraFreezed(java.lang.String)
androidx.window.layout.SidecarCompat$FirstAttachAdapter: SidecarCompat$FirstAttachAdapter(androidx.window.layout.SidecarCompat,android.app.Activity)
org.webrtc.VideoFrame$Buffer: org.webrtc.VideoFrame$Buffer cropAndScale(int,int,int,int,int,int)
com.google.firebase.firestore.remote.Stream$State: com.google.firebase.firestore.remote.Stream$State[] values()
com.google.firestore.v1.StructuredQuery$UnaryFilter$Operator: com.google.firestore.v1.StructuredQuery$UnaryFilter$Operator valueOf(java.lang.String)
com.google.android.gms.common.api.internal.LifecycleCallback: com.google.android.gms.common.api.internal.LifecycleFragment getChimeraLifecycleFragmentImpl(com.google.android.gms.common.api.internal.LifecycleActivity)
org.webrtc.audio.JavaAudioDeviceModule: void setSpeakerMute(boolean)
org.webrtc.AndroidVideoDecoder: void copyPlane(java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,int,int)
androidx.window.layout.SidecarWindowBackend: void unregisterLayoutChangeCallback(androidx.core.util.Consumer)
org.webrtc.MediaSource: void lambda$new$0(long)
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper: org.webrtc.VideoCodecStatus encode$lambda-2(com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper,org.webrtc.VideoFrame,org.webrtc.VideoEncoder$EncodeInfo)
org.webrtc.FileVideoCapturer: boolean isScreencast()
io.flutter.embedding.android.FlutterTextureView: io.flutter.embedding.engine.renderer.FlutterRenderer getAttachedRenderer()
androidx.window.embedding.SplitInfo: androidx.window.embedding.ActivityStack getSecondaryActivityStack()
com.cloudwebrtc.webrtc.utils.PermissionUtils$RequestPermissionsFragment: void checkSelfPermissions(boolean)
com.cloudwebrtc.webrtc.R$styleable: R$styleable()
org.webrtc.PeerConnectionFactory: long getNativePeerConnectionFactory()
org.webrtc.WrappedNativeVideoEncoder: org.webrtc.VideoEncoder$ScalingSettings getScalingSettings()
org.webrtc.CameraCapturer$6: void run()
com.google.protobuf.WireFormat$FieldType: com.google.protobuf.WireFormat$FieldType valueOf(java.lang.String)
org.webrtc.voiceengine.WebRtcAudioRecord: void assertTrue(boolean)
io.flutter.view.AccessibilityViewEmbedder: boolean requestSendAccessibilityEvent(android.view.View,android.view.View,android.view.accessibility.AccessibilityEvent)
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin$LifeCycleObserver: FlutterWebRTCPlugin$LifeCycleObserver(com.cloudwebrtc.webrtc.FlutterWebRTCPlugin,com.cloudwebrtc.webrtc.FlutterWebRTCPlugin$1)
org.webrtc.AudioTrack: void nativeSetVolume(long,double)
org.webrtc.PeerConnection$Observer$-CC: void $default$onTrack(org.webrtc.PeerConnection$Observer,org.webrtc.RtpTransceiver)
org.webrtc.voiceengine.WebRtcAudioManager: void nativeCacheAudioParameters(int,int,int,boolean,boolean,boolean,boolean,boolean,boolean,boolean,int,int,long)
org.webrtc.EglRenderer: EglRenderer(java.lang.String,org.webrtc.VideoFrameDrawer)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void resultError(java.lang.String,java.lang.String,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.RendererCommon$GlDrawer: void drawRgb(int,float[],int,int,int,int,int,int)
org.webrtc.SurfaceViewRenderer: SurfaceViewRenderer(android.content.Context)
org.webrtc.Camera2Enumerator: Camera2Enumerator(android.content.Context)
org.webrtc.CameraEnumerationAndroid$2: CameraEnumerationAndroid$2(int,int)
org.webrtc.PeerConnection$PeerConnectionState: PeerConnection$PeerConnectionState(java.lang.String,int)
org.webrtc.NetworkMonitor: void init(android.content.Context)
org.webrtc.JniHelper: java.lang.Object getValue(java.util.Map$Entry)
org.webrtc.HardwareVideoEncoder: org.webrtc.VideoCodecStatus initEncode(org.webrtc.VideoEncoder$Settings,org.webrtc.VideoEncoder$Callback)
org.webrtc.EglBase: org.webrtc.EglBase$Context getEglBaseContext()
org.webrtc.Predicate$-CC: org.webrtc.Predicate $default$and(org.webrtc.Predicate,org.webrtc.Predicate)
com.google.firebase.firestore.model.FieldIndex$IndexState: FieldIndex$IndexState()
org.webrtc.DataChannel$State: DataChannel$State(java.lang.String,int)
org.webrtc.PeerConnectionDependencies$Builder: org.webrtc.PeerConnectionDependencies createPeerConnectionDependencies()
org.webrtc.Camera1Session: void listenForBytebufferFrames()
androidx.window.embedding.MatcherUtils: boolean areComponentsMatching$window_release(android.content.ComponentName,android.content.ComponentName)
io.flutter.embedding.engine.renderer.SurfaceTextureWrapper: void detachFromGLContext()
org.webrtc.SimulcastVideoEncoder: boolean isHardwareEncoder()
io.flutter.embedding.engine.renderer.SurfaceTextureWrapper: void getTransformMatrix(float[])
org.webrtc.VideoDecoder$Settings: VideoDecoder$Settings(int,int,int)
org.webrtc.SurfaceTextureHelper$2: void onRetain(org.webrtc.TextureBufferImpl)
androidx.window.core.Version: androidx.window.core.Version access$getVERSION_1_0$cp()
io.grpc.InternalConfigSelector: InternalConfigSelector()
org.webrtc.GlRectDrawer: void drawOes(int,float[],int,int,int,int,int,int)
androidx.window.layout.DisplayCompatHelperApi28: DisplayCompatHelperApi28()
org.webrtc.DataChannel: int nativeId()
org.webrtc.voiceengine.WebRtcAudioUtils: void setWebRtcBasedNoiseSuppressor(boolean)
org.webrtc.DataChannel: long nativeRegisterObserver(org.webrtc.DataChannel$Observer)
androidx.lifecycle.ViewModelStore: ViewModelStore()
org.webrtc.PeerConnection$IceTransportsType: org.webrtc.PeerConnection$IceTransportsType[] values()
org.webrtc.NetworkMonitor: boolean networkBindingSupported()
org.webrtc.CameraCapturer$4: void onCameraError(java.lang.String)
io.flutter.embedding.engine.FlutterJNI: void onDisplayOverlaySurface(int,int,int,int,int)
com.google.android.gms.common.api.Api$AbstractClientBuilder: Api$AbstractClientBuilder()
com.google.firestore.v1.Write$OperationCase: com.google.firestore.v1.Write$OperationCase valueOf(java.lang.String)
org.webrtc.Camera1Session: void lambda$listenForTextureFrames$0(org.webrtc.VideoFrame)
org.webrtc.audio.WebRtcAudioEffects: boolean setNS(boolean)
androidx.window.embedding.SplitRuleParser: SplitRuleParser()
org.webrtc.PeerConnectionFactory: void nativeShutdownInternalTracer()
org.webrtc.RtpTransceiver: org.webrtc.MediaStreamTrack$MediaType getMediaType()
io.grpc.okhttp.OkHttpChannelBuilder: io.grpc.okhttp.OkHttpChannelBuilder forTarget(java.lang.String)
com.google.firebase.firestore.FirebaseFirestore: void setClientLanguage(java.lang.String)
org.webrtc.audio.WebRtcAudioRecord: boolean logActiveRecordingConfigs(int,java.util.List)
org.webrtc.voiceengine.WebRtcAudioRecord: boolean startRecording()
kotlinx.coroutines.scheduling.CoroutineScheduler$WorkerState: kotlinx.coroutines.scheduling.CoroutineScheduler$WorkerState[] values()
org.webrtc.RtpTransceiver: RtpTransceiver(long)
com.google.firebase.firestore.core.OnlineState: com.google.firebase.firestore.core.OnlineState valueOf(java.lang.String)
org.webrtc.FrameCryptor: boolean nativeIsEnabled(long)
androidx.window.layout.WindowInfoTrackerImpl$windowLayoutInfo$1: java.lang.Object invoke(java.lang.Object,java.lang.Object)
com.google.firebase.StartupTime: StartupTime()
org.webrtc.JavaI420Buffer: int getStrideY()
io.flutter.embedding.android.FlutterView: void setVisibility(int)
com.google.firestore.v1.Cursor$Builder: Cursor$Builder()
org.webrtc.audio.VolumeLogger: void start()
io.grpc.ConnectivityState: io.grpc.ConnectivityState[] values()
org.webrtc.PeerConnection$RtcpMuxPolicy: PeerConnection$RtcpMuxPolicy(java.lang.String,int)
com.cloudwebrtc.webrtc.PeerConnectionObserver: void dataChannelClose(java.lang.String)
org.webrtc.PeerConnection: org.webrtc.PeerConnection$IceConnectionState iceConnectionState()
org.webrtc.FecControllerFactoryFactoryInterface: long createNative()
com.google.android.gms.common.internal.zzj: zzj()
androidx.window.layout.WindowMetricsCalculatorDecorator: androidx.window.layout.WindowMetricsCalculator decorate(androidx.window.layout.WindowMetricsCalculator)
androidx.window.layout.FoldingFeature: boolean isSeparating()
org.webrtc.PeerConnectionFactory: org.webrtc.PeerConnectionFactory nativeCreatePeerConnectionFactory(android.content.Context,org.webrtc.PeerConnectionFactory$Options,long,long,long,org.webrtc.VideoEncoderFactory,org.webrtc.VideoDecoderFactory,long,long,long,long,long)
com.cloudwebrtc.webrtc.DataChannelObserver: void sendEvent(com.cloudwebrtc.webrtc.utils.ConstraintsMap)
androidx.window.embedding.EmbeddingBackend: void unregisterRule(androidx.window.embedding.EmbeddingRule)
org.webrtc.LibvpxVp9Encoder: boolean isHardwareEncoder()
kotlinx.coroutines.android.AndroidExceptionPreHandler: void handleException(kotlin.coroutines.CoroutineContext,java.lang.Throwable)
com.cloudwebrtc.webrtc.record.OutputAudioSamplesInterceptor: void detachCallback(java.lang.Integer)
org.webrtc.SoftwareVideoDecoderFactory: SoftwareVideoDecoderFactory()
io.grpc.stub.ClientCalls: ClientCalls()
org.webrtc.LibvpxVp9Decoder: LibvpxVp9Decoder()
com.cloudwebrtc.webrtc.record.FrameCapturer: void onFrame(org.webrtc.VideoFrame)
okio.Buffer: Buffer()
androidx.window.java.R: R()
io.flutter.embedding.engine.FlutterJNI: void addIsDisplayingFlutterUiListener(io.flutter.embedding.engine.renderer.FlutterUiDisplayListener)
org.webrtc.audio.JavaAudioDeviceModule$AudioRecordStartErrorCode: org.webrtc.audio.JavaAudioDeviceModule$AudioRecordStartErrorCode valueOf(java.lang.String)
org.webrtc.MediaStreamTrack$State: org.webrtc.MediaStreamTrack$State[] values()
androidx.window.layout.SidecarCompat: androidx.window.layout.WindowLayoutInfo getWindowLayoutInfo(android.app.Activity)
org.webrtc.EglBase10Impl$1FakeSurfaceHolder: void removeCallback(android.view.SurfaceHolder$Callback)
org.webrtc.WrappedNativeVideoEncoder: boolean isHardwareEncoder()
org.webrtc.MediaStream: MediaStream(long)
org.webrtc.VideoEncoder$-CC: org.webrtc.VideoCodecStatus $default$setRates(org.webrtc.VideoEncoder,org.webrtc.VideoEncoder$RateControlParameters)
org.webrtc.NetworkChangeDetector$Observer: void onNetworkDisconnect(long)
io.flutter.embedding.engine.FlutterJNI: void onSurfaceChanged(int,int)
com.cloudwebrtc.webrtc.utils.ConstraintsMap: int getInt(java.lang.String)
org.webrtc.NetworkChangeDetector: boolean supportNetworkCallback()
org.webrtc.EglRenderer$EglSurfaceCreation: EglRenderer$EglSurfaceCreation(org.webrtc.EglRenderer)
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback: android.view.View$OnApplyWindowInsetsListener getInsetsListener()
org.webrtc.NV21Buffer: org.webrtc.VideoFrame$Buffer cropAndScale(int,int,int,int,int,int)
org.webrtc.EglRenderer: void logD(java.lang.String)
org.webrtc.audio.WebRtcAudioRecord: int getBytesPerSample(int)
org.webrtc.NetworkMonitor: int androidSdkInt()
org.webrtc.PeerConnection: void setAudioRecording(boolean)
org.webrtc.ScreenCapturerAndroid: ScreenCapturerAndroid(android.content.Intent,android.media.projection.MediaProjection$Callback)
io.flutter.plugins.GeneratedPluginRegistrant: GeneratedPluginRegistrant()
com.cloudwebrtc.webrtc.utils.ConstraintsMap: java.util.Map toMap()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$3: void onCreateSuccess(org.webrtc.SessionDescription)
com.cloudwebrtc.webrtc.PeerConnectionObserver: void onIceConnectionReceivingChange(boolean)
org.webrtc.WrappedVideoDecoderFactory: org.webrtc.VideoDecoder createDecoder(org.webrtc.VideoCodecInfo)
com.google.android.gms.tasks.Task: Task()
org.webrtc.RtpTransceiver$RtpTransceiverDirection: org.webrtc.RtpTransceiver$RtpTransceiverDirection[] values()
org.webrtc.NativeAndroidVideoTrackSource: void adaptOutputFormat(org.webrtc.VideoSource$AspectRatio,java.lang.Integer,org.webrtc.VideoSource$AspectRatio,java.lang.Integer,java.lang.Integer)
org.webrtc.PeerConnection$Observer: void onSignalingChange(org.webrtc.PeerConnection$SignalingState)
org.webrtc.voiceengine.WebRtcAudioTrack: void logUnderrunCount()
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper: long createNativeVideoEncoder()
org.webrtc.MediaStream: void addNativeAudioTrack(long)
com.google.firestore.admin.v1.Index$IndexField$ArrayConfig: com.google.firestore.admin.v1.Index$IndexField$ArrayConfig valueOf(java.lang.String)
org.webrtc.GlRectDrawer: void drawRgb(int,float[],int,int,int,int,int,int)
androidx.window.embedding.SplitController: void initialize(android.content.Context,int)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void getReceivers(java.lang.String,io.flutter.plugin.common.MethodChannel$Result)
io.flutter.embedding.engine.FlutterJNI: void dispatchSemanticsAction(int,io.flutter.view.AccessibilityBridge$Action)
kotlinx.coroutines.internal.LockFreeLinkedListNode: LockFreeLinkedListNode()
org.webrtc.MediaCodecVideoDecoderFactory: boolean isSupportedCodec(android.media.MediaCodecInfo,org.webrtc.VideoCodecMimeType)
com.cloudwebrtc.webrtc.GetUserMediaImpl: java.lang.String getFacingMode(com.cloudwebrtc.webrtc.utils.ConstraintsMap)
org.webrtc.WrappedNativeVideoEncoder: org.webrtc.VideoCodecStatus release()
org.webrtc.PeerConnection$RTCConfiguration: org.webrtc.PeerConnection$SdpSemantics getSdpSemantics()
org.webrtc.RtpSender: void nativeSetFrameEncryptor(long,long)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void rtpSenderSetParameters(java.lang.String,java.lang.String,java.util.Map,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.RtpTransceiver: void checkRtpTransceiverExists()
org.webrtc.PeerConnectionFactory$Builder: org.webrtc.PeerConnectionFactory$Builder setAudioDeviceModule(org.webrtc.audio.AudioDeviceModule)
androidx.window.layout.SidecarAdapter$Companion: int getSidecarDevicePosture$window_release(androidx.window.sidecar.SidecarDeviceState)
androidx.core.app.RemoteActionCompat: RemoteActionCompat()
com.cloudwebrtc.webrtc.utils.ConstraintsArray: void pushDouble(double)
org.webrtc.SoftwareVideoDecoderFactory: long nativeCreateDecoder(long,org.webrtc.VideoCodecInfo)
org.webrtc.VideoEncoderFactory: org.webrtc.VideoCodecInfo[] getSupportedCodecs()
com.google.common.util.concurrent.DirectExecutor: com.google.common.util.concurrent.DirectExecutor valueOf(java.lang.String)
androidx.window.embedding.ActivityStack: java.lang.String toString()
kotlin.jvm.internal.FunctionReference: FunctionReference(int,java.lang.Object,java.lang.Class,java.lang.String,java.lang.String,int)
com.google.firestore.bundle.BundledQuery: BundledQuery()
org.webrtc.audio.AudioDeviceModule: void release()
org.webrtc.EglBase$-CC: org.webrtc.EglBase10 createEgl10(org.webrtc.EglBase10$Context,int[])
com.cloudwebrtc.webrtc.utils.ConstraintsMap: void putMap(java.lang.String,java.util.Map)
androidx.window.embedding.SplitRuleParser: androidx.window.embedding.ActivityRule parseSplitActivityRule(android.content.Context,android.content.res.XmlResourceParser)
com.cloudwebrtc.webrtc.SurfaceTextureRenderer: void disableFpsReduction()
com.google.firebase.firestore.model.ObjectValue: ObjectValue()
org.webrtc.SurfaceTextureHelper$2: SurfaceTextureHelper$2(org.webrtc.SurfaceTextureHelper)
io.grpc.internal.KeepAliveManager$State: io.grpc.internal.KeepAliveManager$State valueOf(java.lang.String)
androidx.window.layout.SidecarCompat: void register(android.os.IBinder,android.app.Activity)
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor: FlutterRTCFrameCryptor(com.cloudwebrtc.webrtc.StateProvider)
org.webrtc.FrameCryptorFactory: FrameCryptorFactory()
com.cloudwebrtc.webrtc.record.MediaRecorderImpl: void stopRecording()
androidx.window.embedding.ActivityFilter: boolean equals(java.lang.Object)
org.webrtc.EncodedImage: int getFrameType()
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin$LifeCycleObserver: void onActivityResumed(android.app.Activity)
androidx.window.java.layout.WindowInfoTrackerCallbackAdapter: void removeListener(androidx.core.util.Consumer)
org.webrtc.TimestampAligner: long nativeRtcTimeNanos()
org.webrtc.PeerConnection: boolean removeTrack(org.webrtc.RtpSender)
org.webrtc.GlTextureFrameBuffer: int getWidth()
androidx.window.core.Version: int compareTo(androidx.window.core.Version)
org.webrtc.EglBase: void release()
org.webrtc.StatsReport: StatsReport(java.lang.String,java.lang.String,double,org.webrtc.StatsReport$Value[])
org.webrtc.voiceengine.WebRtcAudioTrack: void reportWebRtcAudioTrackError(java.lang.String)
org.webrtc.AndroidVideoDecoder: org.webrtc.VideoCodecStatus initDecodeInternal(int,int)
androidx.window.layout.FoldingFeature: androidx.window.layout.FoldingFeature$OcclusionType getOcclusionType()
org.webrtc.Predicate$-CC: org.webrtc.Predicate $default$or(org.webrtc.Predicate,org.webrtc.Predicate)
com.cloudwebrtc.webrtc.GetUserMediaImpl$3$1: GetUserMediaImpl$3$1(com.cloudwebrtc.webrtc.GetUserMediaImpl$3)
org.webrtc.voiceengine.WebRtcAudioRecord$WebRtcAudioRecordErrorCallback: void onWebRtcAudioRecordStartError(org.webrtc.voiceengine.WebRtcAudioRecord$AudioRecordStartErrorCode,java.lang.String)
org.webrtc.EncodedImage$FrameType: int getNative()
org.webrtc.BaseBitrateAdjuster: void setTargets(int,double)
org.webrtc.RtpTransceiver: org.webrtc.RtpSender getSender()
io.grpc.internal.MessageDeframer$State: io.grpc.internal.MessageDeframer$State[] values()
com.cloudwebrtc.webrtc.record.VideoFileRenderer: void initVideoEncoder()
androidx.window.layout.ExtensionWindowLayoutInfoBackend: void unregisterLayoutChangeCallback(androidx.core.util.Consumer)
org.webrtc.EglBase10Impl: void createSurfaceInternal(java.lang.Object)
com.google.firestore.v1.StructuredQuery$CollectionSelector$Builder: StructuredQuery$CollectionSelector$Builder()
androidx.window.layout.ActivityCompatHelperApi24: ActivityCompatHelperApi24()
org.webrtc.Logging$Severity: org.webrtc.Logging$Severity[] values()
org.webrtc.PeerConnection$SignalingState: org.webrtc.PeerConnection$SignalingState fromNativeIndex(int)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$4: MethodCallHandlerImpl$4(com.cloudwebrtc.webrtc.MethodCallHandlerImpl,io.flutter.plugin.common.MethodChannel$Result)
kotlinx.coroutines.android.HandlerDispatcher: HandlerDispatcher()
org.webrtc.MediaCodecWrapper: void start()
androidx.window.embedding.SplitPairFilter: SplitPairFilter(android.content.ComponentName,android.content.ComponentName,java.lang.String)
org.webrtc.PeerConnection: void getStats(org.webrtc.RtpReceiver,org.webrtc.RTCStatsCollectorCallback)
org.webrtc.voiceengine.WebRtcAudioTrack$AudioTrackThread: void stopThread()
org.webrtc.EglBase14Impl$Context: long getNativeEglContext()
org.webrtc.EglBase14Impl: void checkIsNotReleased()
org.webrtc.EglBase$-CC: org.webrtc.EglBase create(org.webrtc.EglBase$Context,int[])
org.webrtc.audio.WebRtcAudioRecord: int channelCountToConfiguration(int)
org.webrtc.PeerConnection$RTCConfiguration: java.lang.Integer getStunCandidateKeepaliveInterval()
org.webrtc.PeerConnection$Observer$-CC: void $default$onAddTrack(org.webrtc.PeerConnection$Observer,org.webrtc.RtpReceiver,org.webrtc.MediaStream[])
io.grpc.CallCredentials$MetadataApplier: CallCredentials$MetadataApplier()
org.webrtc.EglBase: boolean hasSurface()
com.google.firebase.firestore.remote.WatchChangeAggregator$BloomFilterApplicationStatus: com.google.firebase.firestore.remote.WatchChangeAggregator$BloomFilterApplicationStatus[] values()
org.webrtc.CameraCapturer$SwitchState: org.webrtc.CameraCapturer$SwitchState valueOf(java.lang.String)
androidx.window.embedding.SplitController: void clearRegisteredRules()
org.webrtc.voiceengine.BuildInfo: java.lang.String getBuildType()
org.webrtc.VideoTrack: void addSink(org.webrtc.VideoSink)
io.grpc.util.SecretRoundRobinLoadBalancerProvider$Provider: SecretRoundRobinLoadBalancerProvider$Provider()
org.webrtc.PeerConnectionDependencies: org.webrtc.PeerConnectionDependencies$Builder builder(org.webrtc.PeerConnection$Observer)
org.webrtc.VideoFrame: int getRotatedHeight()
org.webrtc.PeerConnection$IceServer$Builder: PeerConnection$IceServer$Builder(java.util.List)
org.webrtc.EglBase: void createDummyPbufferSurface()
org.webrtc.CameraEnumerationAndroid: CameraEnumerationAndroid()
org.webrtc.JniHelper: java.lang.Object getKey(java.util.Map$Entry)
org.webrtc.RtpCapabilities$HeaderExtensionCapability: boolean getPreferredEncrypted()
com.google.android.gms.common.internal.safeparcel.AbstractSafeParcelable: AbstractSafeParcelable()
org.webrtc.audio.WebRtcAudioUtils: java.lang.String audioSourceToString(int)
org.webrtc.EglRenderer: void setMirror(boolean)
org.webrtc.PeerConnectionFactory: void initializeInternalTracer()
com.cloudwebrtc.webrtc.PeerConnectionObserver: java.util.Map rtpParametersToMap(org.webrtc.RtpParameters)
org.webrtc.NetworkMonitor: NetworkMonitor()
org.webrtc.RefCountDelegate: void retain()
org.webrtc.Camera2Session: void stopInternal()
androidx.window.layout.DisplayCompatHelperApi28: int safeInsetBottom(android.view.DisplayCutout)
org.webrtc.GlUtil: java.nio.FloatBuffer createFloatBuffer(float[])
org.webrtc.CameraCapturer: void createCameraSession(org.webrtc.CameraSession$CreateSessionCallback,org.webrtc.CameraSession$Events,android.content.Context,org.webrtc.SurfaceTextureHelper,java.lang.String,int,int,int)
org.webrtc.CryptoOptions: org.webrtc.CryptoOptions$SFrame getSFrame()
org.webrtc.RtpParameters$HeaderExtension: int getId()
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback: void remove()
org.webrtc.CameraEnumerationAndroid$CaptureFormat$FramerateRange: int hashCode()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void mediaStreamTrackSetEnabled(java.lang.String,boolean,java.lang.String)
org.webrtc.EglRenderer$2: EglRenderer$2(org.webrtc.EglRenderer)
org.webrtc.SurfaceTextureHelper: void lambda$setFrameRotation$4(int)
androidx.window.R: R()
org.webrtc.PeerConnectionDependencies$Builder: org.webrtc.PeerConnectionDependencies$Builder setSSLCertificateVerifier(org.webrtc.SSLCertificateVerifier)
org.webrtc.voiceengine.WebRtcAudioManager: boolean init()
org.webrtc.Metrics: Metrics()
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper: org.webrtc.VideoEncoder$ScalingSettings getScalingSettings()
androidx.core.content.ContextCompat$Api24Impl: boolean isDeviceProtectedStorage(android.content.Context)
com.cloudwebrtc.webrtc.PeerConnectionObserver: void onListen(java.lang.Object,io.flutter.plugin.common.EventChannel$EventSink)
org.webrtc.NetworkMonitor: void addObserver(org.webrtc.NetworkMonitor$NetworkObserver)
androidx.window.embedding.ExtensionEmbeddingBackend$SplitListenerWrapper: ExtensionEmbeddingBackend$SplitListenerWrapper(android.app.Activity,java.util.concurrent.Executor,androidx.core.util.Consumer)
androidx.window.layout.WindowInfoTrackerImpl: kotlinx.coroutines.flow.Flow windowLayoutInfo(android.app.Activity)
androidx.window.layout.FoldingFeature$OcclusionType$Companion: FoldingFeature$OcclusionType$Companion(kotlin.jvm.internal.DefaultConstructorMarker)
androidx.window.embedding.SplitPlaceholderRule: SplitPlaceholderRule(java.util.Set,android.content.Intent,int,int,float,int,int,kotlin.jvm.internal.DefaultConstructorMarker)
org.webrtc.ThreadUtils: boolean joinUninterruptibly(java.lang.Thread,long)
androidx.activity.ComponentActivity$NonConfigurationInstances: ComponentActivity$NonConfigurationInstances()
org.webrtc.CameraVideoCapturer: void switchCamera(org.webrtc.CameraVideoCapturer$CameraSwitchHandler)
org.webrtc.NativeAndroidVideoTrackSource: void nativeSetState(long,boolean)
org.webrtc.RtpParameters$DegradationPreference: RtpParameters$DegradationPreference(java.lang.String,int)
org.webrtc.RendererCommon$VideoLayoutMeasure: RendererCommon$VideoLayoutMeasure()
org.webrtc.SoftwareVideoEncoderFactory: org.webrtc.VideoCodecInfo[] getSupportedCodecs()
com.cloudwebrtc.webrtc.record.VideoFileRenderer: void lambda$initVideoEncoder$0()
org.webrtc.voiceengine.WebRtcAudioEffects: android.media.audiofx.AudioEffect$Descriptor[] getAvailableEffects()
com.cloudwebrtc.webrtc.PeerConnectionObserver: void addTransceiver(org.webrtc.MediaStreamTrack,java.util.Map,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.audio.WebRtcAudioRecord: boolean checkDeviceMatch(android.media.AudioDeviceInfo,android.media.AudioDeviceInfo)
org.webrtc.voiceengine.WebRtcAudioManager: void setStereoInput(boolean)
org.webrtc.ThreadUtils$BlockingOperation: void run()
org.webrtc.SurfaceTextureHelper$FrameRefMonitor: void onReleaseBuffer(org.webrtc.VideoFrame$TextureBuffer)
androidx.window.layout.WindowMetricsCalculator: androidx.window.layout.WindowMetrics computeMaximumWindowMetrics(android.app.Activity)
com.cloudwebrtc.webrtc.utils.ConstraintsArray: boolean getBoolean(int)
kotlin.coroutines.jvm.internal.SuspendLambda: SuspendLambda(int)
org.webrtc.SoftwareVideoDecoderFactory: long nativeCreateFactory()
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer: int access$000(com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer)
org.webrtc.CameraCapturer: void startCapture(int,int,int)
org.webrtc.NativeAndroidVideoTrackSource: org.webrtc.VideoProcessor$FrameAdaptationParameters nativeAdaptFrame(long,int,int,int,long)
com.cloudwebrtc.webrtc.CameraEventsHandler: void onCameraFreezed(java.lang.String)
androidx.window.layout.HardwareFoldingFeature$Type: androidx.window.layout.HardwareFoldingFeature$Type access$getFOLD$cp()
org.webrtc.CameraSession$FailureType: org.webrtc.CameraSession$FailureType valueOf(java.lang.String)
org.webrtc.audio.VolumeLogger: void stop()
androidx.window.core.Version$Companion: androidx.window.core.Version parse(java.lang.String)
com.cloudwebrtc.webrtc.PeerConnectionObserver: void rtpSenderSetTrack(java.lang.String,org.webrtc.MediaStreamTrack,io.flutter.plugin.common.MethodChannel$Result,boolean)
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor: void frameCryptorDispose(java.util.Map,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.RendererCommon$VideoLayoutMeasure: void setScalingType(org.webrtc.RendererCommon$ScalingType,org.webrtc.RendererCommon$ScalingType)
org.webrtc.Camera1Enumerator: java.lang.String getDeviceName(int)
org.webrtc.NetworkMonitor: void nativeNotifyOfNetworkConnect(long,org.webrtc.NetworkChangeDetector$NetworkInformation)
com.google.firestore.v1.Document: Document()
org.webrtc.TextureBufferImpl$RefCountMonitor: void onRetain(org.webrtc.TextureBufferImpl)
com.cloudwebrtc.webrtc.utils.ConstraintsArray: java.util.ArrayList toArrayList()
org.webrtc.PeerConnectionFactory: org.webrtc.PeerConnection createPeerConnectionInternal(org.webrtc.PeerConnection$RTCConfiguration,org.webrtc.MediaConstraints,org.webrtc.PeerConnection$Observer,org.webrtc.SSLCertificateVerifier)
org.webrtc.audio.WebRtcAudioRecord: void scheduleLogRecordingConfigurationsTask(android.media.AudioRecord)
androidx.window.embedding.SplitController: void setStaticSplitRules(java.util.Set)
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin$LifeCycleObserver: void onStop(androidx.lifecycle.LifecycleOwner)
org.webrtc.EglRenderer: void createEglSurface(android.graphics.SurfaceTexture)
org.webrtc.CameraVideoCapturer$CameraEventsHandler: void onCameraClosed()
org.webrtc.RtpCapabilities$HeaderExtensionCapability: int getPreferredId()
org.webrtc.DtmfSender: boolean insertDtmf(java.lang.String,int,int)
com.google.firestore.v1.DocumentMask$Builder: DocumentMask$Builder()
androidx.window.core.Bounds: Bounds(int,int,int,int)
org.webrtc.EglBase14Impl: void releaseSurface()
org.webrtc.MediaCodecWrapper: int dequeueOutputBuffer(android.media.MediaCodec$BufferInfo,long)
org.webrtc.Camera1Session: void listenForTextureFrames()
kotlin.coroutines.jvm.internal.ContinuationImpl: ContinuationImpl(kotlin.coroutines.Continuation)
org.webrtc.JniCommon: java.nio.ByteBuffer nativeAllocateByteBuffer(int)
org.webrtc.NetworkMonitorAutoDetect: NetworkMonitorAutoDetect(org.webrtc.NetworkChangeDetector$Observer,android.content.Context)
androidx.window.layout.SidecarWindowBackend$Companion: androidx.window.layout.ExtensionInterfaceCompat initAndVerifyExtension(android.content.Context)
org.webrtc.EglBase: int surfaceWidth()
androidx.window.layout.FoldingFeature$State: FoldingFeature$State(java.lang.String)
org.webrtc.voiceengine.WebRtcAudioManager$VolumeLogger: WebRtcAudioManager$VolumeLogger(android.media.AudioManager)
org.webrtc.NativeLibrary: boolean isLoaded()
org.webrtc.NetworkMonitorAutoDetect: long networkToNetId(android.net.Network)
org.webrtc.PeerConnection$Observer$-CC: void $default$onRemoveTrack(org.webrtc.PeerConnection$Observer,org.webrtc.RtpReceiver)
org.webrtc.RtpParameters$Encoding: java.lang.Integer getMaxFramerate()
com.google.firestore.v1.DocumentDelete: DocumentDelete()
androidx.window.layout.SidecarWindowBackend$Companion: void resetInstance()
org.webrtc.voiceengine.WebRtcAudioManager: void storeAudioParameters()
androidx.window.core.Version: androidx.window.core.Version access$getVERSION_0_1$cp()
org.webrtc.NetworkMonitorAutoDetect: org.webrtc.NetworkChangeDetector$ConnectionType getConnectionType(boolean,int,int)
androidx.window.java.layout.WindowInfoTrackerCallbackAdapter$addListener$1$1: java.lang.Object invoke(java.lang.Object,java.lang.Object)
org.webrtc.audio.WebRtcAudioTrack: void reportWebRtcAudioTrackStartError(org.webrtc.audio.JavaAudioDeviceModule$AudioTrackStartErrorCode,java.lang.String)
org.webrtc.VideoCodecMimeType: org.webrtc.VideoCodecMimeType[] values()
org.webrtc.GlUtil$GlOutOfMemoryException: GlUtil$GlOutOfMemoryException(int,java.lang.String)
org.webrtc.MediaStream: void addNativeVideoTrack(long)
org.webrtc.FrameCryptorAlgorithm: org.webrtc.FrameCryptorAlgorithm[] values()
androidx.window.java.layout.WindowInfoTrackerCallbackAdapter: kotlinx.coroutines.flow.Flow windowLayoutInfo(android.app.Activity)
org.webrtc.HardwareVideoEncoderFactory: HardwareVideoEncoderFactory(org.webrtc.EglBase$Context,boolean,boolean)
org.webrtc.PeerConnectionFactory: org.webrtc.RtpCapabilities getRtpSenderCapabilities(org.webrtc.MediaStreamTrack$MediaType)
com.cloudwebrtc.webrtc.StateProvider: android.content.Context getApplicationContext()
org.webrtc.VideoEncoder: java.lang.String getImplementationName()
io.flutter.embedding.engine.FlutterJNI: void onSurfaceCreated(android.view.Surface)
org.webrtc.Metrics: void add(java.lang.String,org.webrtc.Metrics$HistogramInfo)
org.webrtc.EncodedImage: long getCaptureTimeNs()
org.webrtc.VideoFrame: int getRotation()
org.webrtc.NV12Buffer: int getHeight()
org.webrtc.RtpReceiver: org.webrtc.RtpParameters nativeGetParameters(long)
org.webrtc.IceCandidate: java.lang.String toString()
org.webrtc.CameraCapturer: void initialize(org.webrtc.SurfaceTextureHelper,android.content.Context,org.webrtc.CapturerObserver)
org.webrtc.GlGenericDrawer: GlGenericDrawer(java.lang.String,java.lang.String,org.webrtc.GlGenericDrawer$ShaderCallbacks)
org.webrtc.voiceengine.WebRtcAudioManager: boolean isCommunicationModeEnabled()
org.webrtc.RendererCommon: float convertScalingTypeToVisibleFraction(org.webrtc.RendererCommon$ScalingType)
io.flutter.plugins.firebase.firestore.FlutterFirebaseFirestoreRegistrar: java.util.List getComponents()
com.google.firestore.v1.Value: Value()
org.webrtc.SurfaceViewRenderer: void setMirror(boolean)
org.webrtc.audio.WebRtcAudioRecord: android.media.AudioRecord createAudioRecordOnMOrHigher(int,int,int,int,int)
org.webrtc.Camera2Enumerator: java.lang.String[] getDeviceNames()
androidx.window.layout.HardwareFoldingFeature: androidx.window.layout.FoldingFeature$Orientation getOrientation()
io.flutter.embedding.engine.FlutterJNI: void attachToNative()
org.webrtc.YuvHelper: void nativeCopyPlane(java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,int,int)
com.cloudwebrtc.webrtc.utils.ConstraintsMap: java.lang.String getString(java.lang.String)
org.webrtc.audio.WebRtcAudioRecord$AudioRecordThread: void run()
org.webrtc.WrappedNativeVideoEncoder: java.lang.String getImplementationName()
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer: boolean checkVideoTrack(java.lang.String,java.lang.String)
com.cloudwebrtc.webrtc.PeerConnectionObserver: void rtpTransceiverGetCurrentDirection(java.lang.String,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.voiceengine.WebRtcAudioRecord$AudioRecordStartErrorCode: WebRtcAudioRecord$AudioRecordStartErrorCode(java.lang.String,int)
org.webrtc.SurfaceTextureHelper$2: void onDestroy(org.webrtc.TextureBufferImpl)
okio.Okio: Okio()
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin$LifeCycleObserver: void onActivityPaused(android.app.Activity)
com.google.firestore.v1.StructuredAggregationQuery$Aggregation$Avg$Builder: StructuredAggregationQuery$Aggregation$Avg$Builder()
org.webrtc.PeerConnection: void setAudioPlayout(boolean)
org.webrtc.CapturerObserver: void onCapturerStopped()
org.webrtc.audio.JavaAudioDeviceModule$AudioRecordErrorCallback: void onWebRtcAudioRecordStartError(org.webrtc.audio.JavaAudioDeviceModule$AudioRecordStartErrorCode,java.lang.String)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void rtpSenderSetStreams(java.lang.String,java.lang.String,java.util.List,io.flutter.plugin.common.MethodChannel$Result)
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer$1: void onFrameResolutionChanged(int,int,int)
org.webrtc.PeerConnection$AdapterType: org.webrtc.PeerConnection$AdapterType valueOf(java.lang.String)
org.webrtc.PeerConnection$IceServer$Builder: org.webrtc.PeerConnection$IceServer createIceServer()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void requestPermissions(java.util.ArrayList,com.cloudwebrtc.webrtc.utils.Callback,com.cloudwebrtc.webrtc.utils.Callback)
com.cloudwebrtc.webrtc.GetUserMediaImpl$3: GetUserMediaImpl$3(com.cloudwebrtc.webrtc.GetUserMediaImpl,android.os.Handler,io.flutter.plugin.common.MethodChannel$Result,org.webrtc.MediaStream)
org.webrtc.voiceengine.WebRtcAudioRecord$AudioRecordStartErrorCode: org.webrtc.voiceengine.WebRtcAudioRecord$AudioRecordStartErrorCode valueOf(java.lang.String)
org.webrtc.PeerConnection$CandidateNetworkPolicy: org.webrtc.PeerConnection$CandidateNetworkPolicy[] $values()
org.webrtc.PeerConnection$CandidateNetworkPolicy: PeerConnection$CandidateNetworkPolicy(java.lang.String,int)
androidx.window.embedding.ExtensionEmbeddingBackend: void setEmbeddingExtension(androidx.window.embedding.EmbeddingInterfaceCompat)
org.webrtc.voiceengine.WebRtcAudioManager: void dispose()
org.webrtc.CameraCapturer$1: void onDone(org.webrtc.CameraSession)
kotlin.coroutines.intrinsics.CoroutineSingletons: kotlin.coroutines.intrinsics.CoroutineSingletons valueOf(java.lang.String)
org.webrtc.JavaI420Buffer: org.webrtc.VideoFrame$Buffer cropAndScaleI420(org.webrtc.VideoFrame$I420Buffer,int,int,int,int,int,int)
com.cloudwebrtc.webrtc.GetUserMediaImpl: void setTorch(java.lang.String,boolean,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.VideoTrack: long nativeWrapSink(org.webrtc.VideoSink)
org.webrtc.audio.JavaAudioDeviceModule$Builder: org.webrtc.audio.JavaAudioDeviceModule$Builder setSamplesReadyCallback(org.webrtc.audio.JavaAudioDeviceModule$SamplesReadyCallback)
org.webrtc.RtpParameters$Codec: java.lang.String getName()
org.webrtc.EglBase: void createPbufferSurface(int,int)
org.webrtc.Camera1Enumerator: android.hardware.Camera$CameraInfo getCameraInfo(int)
org.webrtc.MediaCodecWrapper: android.media.MediaCodecInfo getCodecInfo()
androidx.window.embedding.EmbeddingCompat$Companion: androidx.window.extensions.embedding.ActivityEmbeddingComponent embeddingComponent()
org.webrtc.Camera2Enumerator: java.util.List getSupportedSizes(android.hardware.camera2.CameraCharacteristics)
androidx.lifecycle.Lifecycle$Event: androidx.lifecycle.Lifecycle$Event valueOf(java.lang.String)
org.webrtc.BuiltinAudioEncoderFactoryFactory: long createNativeAudioEncoderFactory()
org.webrtc.VideoCapturer: void dispose()
org.webrtc.audio.JavaAudioDeviceModule$AudioTrackErrorCallback: void onWebRtcAudioTrackStartError(org.webrtc.audio.JavaAudioDeviceModule$AudioTrackStartErrorCode,java.lang.String)
org.webrtc.VideoFrame: int getRotatedWidth()
org.webrtc.NetworkMonitor: void removeObserver(org.webrtc.NetworkMonitor$NetworkObserver)
com.google.firestore.v1.StructuredAggregationQuery$Aggregation$Count: StructuredAggregationQuery$Aggregation$Count()
com.cloudwebrtc.webrtc.audio.AudioSwitchManager: void lambda$initAudioSwitch$2()
org.webrtc.PeerConnectionDependencies: org.webrtc.SSLCertificateVerifier getSSLCertificateVerifier()
org.webrtc.Logging: void injectLoggable(org.webrtc.Loggable,org.webrtc.Logging$Severity)
org.webrtc.EglBase10Impl: void createDummyPbufferSurface()
androidx.window.embedding.SplitPlaceholderRule: java.util.Set getFilters()
org.webrtc.audio.JavaAudioDeviceModule$AudioTrackStartErrorCode: JavaAudioDeviceModule$AudioTrackStartErrorCode(java.lang.String,int)
org.webrtc.RtpParameters$DegradationPreference: org.webrtc.RtpParameters$DegradationPreference[] values()
io.flutter.embedding.engine.FlutterJNI: void nativeDispatchSemanticsAction(long,int,int,java.nio.ByteBuffer,int)
org.webrtc.CameraVideoCapturer: void removeMediaRecorderFromCamera(org.webrtc.CameraVideoCapturer$MediaRecorderHandler)
androidx.window.layout.WindowMetricsCalculatorCompat: androidx.window.layout.WindowMetrics computeCurrentWindowMetrics(android.app.Activity)
io.flutter.embedding.android.FlutterView: io.flutter.embedding.android.FlutterImageView getCurrentImageSurface()
com.cloudwebrtc.webrtc.GetUserMediaImpl: void startRecordingToFile(java.lang.String,java.lang.Integer,org.webrtc.VideoTrack,com.cloudwebrtc.webrtc.record.AudioChannel)
androidx.window.embedding.EmbeddingBackend: boolean isSplitSupported()
org.webrtc.voiceengine.WebRtcAudioUtils: java.lang.String deviceTypeToString(int)
org.webrtc.CameraEnumerationAndroid$2: int diff(java.lang.Object)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void dataChannelSend(java.lang.String,java.lang.String,java.nio.ByteBuffer,java.lang.Boolean)
org.webrtc.PeerConnection$IceServer$Builder: org.webrtc.PeerConnection$IceServer$Builder setTlsAlpnProtocols(java.util.List)
org.webrtc.SurfaceTextureHelper: SurfaceTextureHelper(org.webrtc.EglBase$Context,android.os.Handler,boolean,org.webrtc.YuvConverter,org.webrtc.SurfaceTextureHelper$FrameRefMonitor)
io.grpc.okhttp.OkHttpChannelProvider: int priority()
androidx.window.layout.FoldingFeature$Orientation: FoldingFeature$Orientation(java.lang.String)
org.webrtc.PeerConnection$IceServer$Builder: org.webrtc.PeerConnection$IceServer$Builder setTlsEllipticCurves(java.util.List)
com.cloudwebrtc.webrtc.CameraEventsHandler: void onCameraDisconnected()
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor: void keyProviderRatchetKey(java.util.Map,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.NetworkChangeDetector$NetworkInformation: long getHandle()
org.webrtc.NetworkMonitorAutoDetect$WifiManagerDelegate: java.lang.String getWifiSSID()
org.webrtc.EncodedImage: int getEncodedWidth()
com.cloudwebrtc.webrtc.GetUserMediaImpl: java.lang.Object getPrivateProperty(java.lang.Class,java.lang.Object,java.lang.String)
org.webrtc.voiceengine.WebRtcAudioManager: WebRtcAudioManager(long)
org.webrtc.SurfaceViewRenderer: void lambda$onFrameResolutionChanged$0(int,int)
org.webrtc.CryptoOptions$Builder: org.webrtc.CryptoOptions$Builder setEnableEncryptedRtpHeaderExtensions(boolean)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$4: void onCreateFailure(java.lang.String)
com.google.firebase.firestore.LoadBundleTaskProgress$TaskState: com.google.firebase.firestore.LoadBundleTaskProgress$TaskState valueOf(java.lang.String)
com.google.firestore.v1.RunAggregationQueryResponse: RunAggregationQueryResponse()
org.webrtc.NetworkMonitor: void startMonitoring()
org.webrtc.PeerConnection: java.util.List nativeGetReceivers()
org.webrtc.ThreadUtils: void invokeAtFrontUninterruptibly(android.os.Handler,java.lang.Runnable)
org.webrtc.VideoEncoder$ResolutionBitrateLimits: int getMinBitrateBps()
org.webrtc.audio.JavaAudioDeviceModule: void setMicrophoneMute(boolean)
org.webrtc.VideoEncoderFactory: org.webrtc.VideoEncoderFactory$VideoEncoderSelector getEncoderSelector()
com.google.firebase.firestore.core.Filter: Filter()
org.webrtc.PeerConnection$PeerConnectionState: org.webrtc.PeerConnection$PeerConnectionState valueOf(java.lang.String)
android.support.v4.app.RemoteActionCompatParcelizer: RemoteActionCompatParcelizer()
com.cloudwebrtc.webrtc.utils.ConstraintsMap: void putBoolean(java.lang.String,boolean)
org.webrtc.RtpTransceiver: void nativeSetCodecPreferences(long,java.util.List)
com.google.firebase.firestore.proto.Target: Target()
com.google.firestore.v1.DocumentChange: DocumentChange()
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper: org.webrtc.VideoCodecInfo[] getSupportedCodecs()
org.webrtc.EglRenderer: void postToRenderThread(java.lang.Runnable)
org.webrtc.PlatformSoftwareVideoDecoderFactory: org.webrtc.VideoDecoder createDecoder(org.webrtc.VideoCodecInfo)
org.webrtc.AndroidVideoDecoder: org.webrtc.VideoFrame$Buffer copyNV12ToI420Buffer(java.nio.ByteBuffer,int,int,int,int)
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor$FrameCryptorStateObserver$1: FlutterRTCFrameCryptor$FrameCryptorStateObserver$1(com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor$FrameCryptorStateObserver,com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor)
org.webrtc.VideoFrameDrawer: void drawTexture(org.webrtc.RendererCommon$GlDrawer,org.webrtc.VideoFrame$TextureBuffer,android.graphics.Matrix,int,int,int,int,int,int)
io.grpc.internal.GrpcUtil$Http2Error: io.grpc.internal.GrpcUtil$Http2Error valueOf(java.lang.String)
org.webrtc.voiceengine.WebRtcAudioEffects: boolean isNoiseSuppressorSupported()
org.webrtc.RtpReceiver: java.lang.String id()
org.webrtc.PeerConnectionFactory: org.webrtc.PeerConnection createPeerConnection(java.util.List,org.webrtc.PeerConnection$Observer)
io.flutter.embedding.engine.FlutterJNI: void registerTexture(long,io.flutter.embedding.engine.renderer.SurfaceTextureWrapper)
org.webrtc.VideoSink: void onFrame(org.webrtc.VideoFrame)
com.google.protobuf.ProtoSyntax: com.google.protobuf.ProtoSyntax[] values()
org.webrtc.DataChannel: void checkDataChannelExists()
androidx.window.layout.SidecarAdapter: androidx.window.layout.WindowLayoutInfo translate(androidx.window.sidecar.SidecarWindowLayoutInfo,androidx.window.sidecar.SidecarDeviceState)
androidx.window.core.Version: java.math.BigInteger getBigInteger()
org.webrtc.AndroidVideoDecoder: org.webrtc.VideoCodecStatus decode(org.webrtc.EncodedImage,org.webrtc.VideoDecoder$DecodeInfo)
org.webrtc.ScreenCapturerAndroid: void onFrame(org.webrtc.VideoFrame)
org.webrtc.CandidatePairChangeEvent: CandidatePairChangeEvent(org.webrtc.IceCandidate,org.webrtc.IceCandidate,int,java.lang.String,int)
org.webrtc.voiceengine.WebRtcAudioTrack: int getBufferSizeInFrames()
org.webrtc.VideoCodecInfo: java.lang.String toString()
io.flutter.embedding.engine.FlutterJNI: boolean nativeFlutterTextUtilsIsEmojiModifier(int)
org.webrtc.ThreadUtils: void checkIsOnMainThread()
org.webrtc.NV21Buffer: int getHeight()
org.webrtc.PeerConnection: void addIceCandidate(org.webrtc.IceCandidate,org.webrtc.AddIceObserver)
org.webrtc.FrameCryptor$FrameCryptionState: FrameCryptor$FrameCryptionState(java.lang.String,int)
io.flutter.view.FlutterCallbackInformation: FlutterCallbackInformation(java.lang.String,java.lang.String,java.lang.String)
org.webrtc.SurfaceTextureHelper: void lambda$new$0(android.graphics.SurfaceTexture)
org.webrtc.YuvConverter$ShaderCallbacks: void setPlaneV()
org.webrtc.VideoEncoder$Settings: VideoEncoder$Settings(int,int,int,int,int,int,boolean,org.webrtc.VideoEncoder$Capabilities)
org.webrtc.EglBase10Impl: int surfaceWidth()
org.webrtc.BuiltinAudioDecoderFactoryFactory: BuiltinAudioDecoderFactoryFactory()
org.webrtc.HardwareVideoDecoderFactory: HardwareVideoDecoderFactory(org.webrtc.EglBase$Context)
org.webrtc.Logging: void e(java.lang.String,java.lang.String)
com.cloudwebrtc.webrtc.utils.ConstraintsArray: void pushString(java.lang.String)
com.google.firebase.firestore.model.FieldIndex$Segment$Kind: com.google.firebase.firestore.model.FieldIndex$Segment$Kind valueOf(java.lang.String)
org.webrtc.RtpTransceiver$RtpTransceiverDirection: RtpTransceiver$RtpTransceiverDirection(java.lang.String,int,int)
org.webrtc.audio.JavaAudioDeviceModule$AudioTrackStateCallback: void onWebRtcAudioTrackStart()
androidx.window.core.Bounds: boolean equals(java.lang.Object)
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback: boolean access$300(io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback)
org.webrtc.VideoEncoder$BitrateAllocation: int getSum()
org.webrtc.PeerConnection$RTCConfiguration: java.lang.Integer getIceUnwritableTimeout()
androidx.lifecycle.ReportFragment$LifecycleCallbacks: void onActivityPaused(android.app.Activity)
com.cloudwebrtc.webrtc.OrientationAwareScreenCapturer: void initialize(org.webrtc.SurfaceTextureHelper,android.content.Context,org.webrtc.CapturerObserver)
org.webrtc.voiceengine.WebRtcAudioTrack: void logBufferSizeInFrames()
org.webrtc.DefaultVideoDecoderFactory: org.webrtc.VideoCodecInfo[] getSupportedCodecs()
org.webrtc.PeerConnection$BundlePolicy: org.webrtc.PeerConnection$BundlePolicy[] $values()
io.flutter.embedding.engine.systemchannels.TextInputChannel$TextInputType: io.flutter.embedding.engine.systemchannels.TextInputChannel$TextInputType valueOf(java.lang.String)
org.webrtc.PeerConnection: void nativeSetAudioRecording(boolean)
org.webrtc.PeerConnection$RTCConfiguration: boolean getPruneTurnPorts()
io.flutter.embedding.engine.FlutterJNI: void onSurfaceDestroyed()
com.google.firestore.v1.Precondition$ConditionTypeCase: com.google.firestore.v1.Precondition$ConditionTypeCase[] values()
com.google.firestore.v1.StructuredQuery$FieldReference$Builder: StructuredQuery$FieldReference$Builder()
org.webrtc.NetworkMonitorAutoDetect$SimpleNetworkCallback: void onLinkPropertiesChanged(android.net.Network,android.net.LinkProperties)
org.webrtc.CameraCapturer$4: void onCameraDisconnected()
org.webrtc.DataChannel$State: org.webrtc.DataChannel$State valueOf(java.lang.String)
org.webrtc.Camera1Session: void updateCameraParameters(android.hardware.Camera,android.hardware.Camera$Parameters,org.webrtc.CameraEnumerationAndroid$CaptureFormat,org.webrtc.Size,boolean)
com.google.firebase.firestore.FirebaseFirestoreException$Code: com.google.firebase.firestore.FirebaseFirestoreException$Code[] values()
com.google.firebase.components.ComponentDiscoveryService: ComponentDiscoveryService()
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin: com.cloudwebrtc.webrtc.MethodCallHandlerImpl access$100(com.cloudwebrtc.webrtc.FlutterWebRTCPlugin)
org.webrtc.YuvHelper: void I420Copy(java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,int,int)
org.webrtc.Camera1Session: Camera1Session(org.webrtc.CameraSession$Events,boolean,android.content.Context,org.webrtc.SurfaceTextureHelper,int,android.hardware.Camera,android.hardware.Camera$CameraInfo,org.webrtc.CameraEnumerationAndroid$CaptureFormat,long)
org.webrtc.voiceengine.WebRtcAudioEffects: boolean isAcousticEchoCancelerBlacklisted()
org.webrtc.Camera2Capturer: void createCameraSession(org.webrtc.CameraSession$CreateSessionCallback,org.webrtc.CameraSession$Events,android.content.Context,org.webrtc.SurfaceTextureHelper,java.lang.String,int,int,int)
com.google.android.gms.dynamite.zzn: zzn()
org.webrtc.SurfaceViewRenderer: void setFpsReduction(float)
androidx.window.embedding.SplitRule$Api30Impl: android.graphics.Rect getBounds(android.view.WindowMetrics)
io.flutter.embedding.engine.plugins.lifecycle.HiddenLifecycleReference: HiddenLifecycleReference(androidx.lifecycle.Lifecycle)
org.webrtc.PeerConnectionFactory: long nativeCreateAudioSource(long,org.webrtc.MediaConstraints)
org.webrtc.EglBase10Impl: javax.microedition.khronos.egl.EGLDisplay getEglDisplay()
androidx.window.layout.SidecarCompat$DistinctSidecarElementCallback: void onDeviceStateChanged(androidx.window.sidecar.SidecarDeviceState)
org.webrtc.VideoEncoder$ResolutionBitrateLimits: VideoEncoder$ResolutionBitrateLimits(int,int,int,int)
com.cloudwebrtc.webrtc.utils.ConstraintsMap: boolean hasKey(java.lang.String)
org.webrtc.HardwareVideoEncoder$BusyCount: void waitForZero()
io.grpc.internal.ClientStreamListener$RpcProgress: io.grpc.internal.ClientStreamListener$RpcProgress[] values()
org.webrtc.DtmfSender: void checkDtmfSenderExists()
org.webrtc.VideoFrame$TextureBuffer: org.webrtc.VideoFrame$TextureBuffer$Type getType()
io.flutter.embedding.engine.FlutterJNI: void nativeDispatchEmptyPlatformMessage(long,java.lang.String,int)
org.webrtc.IceCandidate: IceCandidate(java.lang.String,int,java.lang.String,java.lang.String,org.webrtc.PeerConnection$AdapterType)
androidx.window.embedding.SplitController$Companion: androidx.window.embedding.SplitController getInstance()
org.webrtc.NetworkMonitorAutoDetect: org.webrtc.NetworkChangeDetector$ConnectionType getUnderlyingConnectionTypeForVpn(org.webrtc.NetworkMonitorAutoDetect$NetworkState)
org.webrtc.Camera2Session$CameraStateCallback: void onDisconnected(android.hardware.camera2.CameraDevice)
com.cloudwebrtc.webrtc.GetUserMediaImpl: void setPreferredInputDevice(int)
org.webrtc.CameraVideoCapturer$CameraEventsHandler: void onCameraOpening(java.lang.String)
androidx.window.layout.HardwareFoldingFeature$Companion: HardwareFoldingFeature$Companion()
io.flutter.embedding.engine.FlutterJNI: io.flutter.embedding.engine.FlutterJNI spawn(java.lang.String,java.lang.String,java.lang.String,java.util.List)
org.webrtc.DataChannel$Init: java.lang.String getProtocol()
org.webrtc.PeerConnection$Observer$-CC: void $default$onStandardizedIceConnectionChange(org.webrtc.PeerConnection$Observer,org.webrtc.PeerConnection$IceConnectionState)
androidx.window.layout.HardwareFoldingFeature: java.lang.String toString()
io.flutter.embedding.engine.FlutterJNI: long performNativeAttach(io.flutter.embedding.engine.FlutterJNI)
org.webrtc.BitrateAdjuster: void setTargets(int,double)
org.webrtc.Camera1Session$1: Camera1Session$1(org.webrtc.Camera1Session)
org.webrtc.NetworkChangeDetector$ConnectionType: org.webrtc.NetworkChangeDetector$ConnectionType[] $values()
com.google.protobuf.Timestamp$Builder: Timestamp$Builder()
org.webrtc.ThreadUtils$1: void run()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void restartIce(java.lang.String)
org.webrtc.voiceengine.WebRtcAudioManager$VolumeLogger: void start()
org.webrtc.CameraCapturer$SwitchState: CameraCapturer$SwitchState(java.lang.String,int)
org.webrtc.HardwareVideoEncoder: org.webrtc.VideoEncoder$EncoderInfo getEncoderInfo()
org.webrtc.NetworkMonitor: void startMonitoring(android.content.Context,long,java.lang.String)
io.flutter.embedding.engine.FlutterJNI: void nativeSurfaceDestroyed(long)
org.webrtc.CameraEnumerationAndroid$1: int diff(java.lang.Object)
org.webrtc.voiceengine.WebRtcAudioEffects: boolean setAEC(boolean)
kotlin.coroutines.jvm.internal.BaseContinuationImpl: java.lang.StackTraceElement getStackTraceElement()
org.webrtc.EglBase14Impl: boolean hasSurface()
io.flutter.plugins.pathprovider.Messages$StorageDirectory: io.flutter.plugins.pathprovider.Messages$StorageDirectory valueOf(java.lang.String)
org.webrtc.RtpTransceiver$RtpTransceiverInit: RtpTransceiver$RtpTransceiverInit(org.webrtc.RtpTransceiver$RtpTransceiverDirection,java.util.List)
kotlinx.coroutines.channels.BufferOverflow: kotlinx.coroutines.channels.BufferOverflow valueOf(java.lang.String)
org.webrtc.voiceengine.WebRtcAudioTrack: void reportWebRtcAudioTrackStartError(org.webrtc.voiceengine.WebRtcAudioTrack$AudioTrackStartErrorCode,java.lang.String)
org.webrtc.RtcCertificatePem: org.webrtc.RtcCertificatePem nativeGenerateCertificate(org.webrtc.PeerConnection$KeyType,long)
org.webrtc.RtpParameters$Codec: org.webrtc.MediaStreamTrack$MediaType getKind()
org.webrtc.WrappedNativeVideoEncoder: org.webrtc.VideoCodecStatus setRateAllocation(org.webrtc.VideoEncoder$BitrateAllocation,int)
org.webrtc.MediaStream: void removeMediaStreamTrack(java.util.List,long)
org.webrtc.CryptoOptions: org.webrtc.CryptoOptions$Srtp getSrtp()
com.cloudwebrtc.webrtc.audio.AudioSwitchManager: AudioSwitchManager(android.content.Context)
io.flutter.embedding.android.FlutterActivityLaunchConfigs$BackgroundMode: io.flutter.embedding.android.FlutterActivityLaunchConfigs$BackgroundMode[] values()
org.webrtc.PeerConnection: PeerConnection(long)
org.webrtc.DataChannel: void registerObserver(org.webrtc.DataChannel$Observer)
io.grpc.NameResolver$Listener2: NameResolver$Listener2()
org.webrtc.Camera1Session: void create(org.webrtc.CameraSession$CreateSessionCallback,org.webrtc.CameraSession$Events,boolean,android.content.Context,org.webrtc.SurfaceTextureHelper,java.lang.String,int,int,int)
androidx.window.layout.SidecarAdapter: boolean isEqualSidecarDisplayFeature(androidx.window.sidecar.SidecarDisplayFeature,androidx.window.sidecar.SidecarDisplayFeature)
androidx.window.layout.WindowInfoTracker$Companion: WindowInfoTracker$Companion()
org.webrtc.SurfaceTextureHelper: void startListening(org.webrtc.VideoSink)
org.webrtc.PeerConnection$RTCConfiguration: org.webrtc.RtcCertificatePem getCertificate()
io.flutter.embedding.android.FlutterSplashView$SavedState: android.os.Bundle access$700(io.flutter.embedding.android.FlutterSplashView$SavedState)
org.webrtc.audio.WebRtcAudioRecord$AudioRecordThread: WebRtcAudioRecord$AudioRecordThread(org.webrtc.audio.WebRtcAudioRecord,java.lang.String)
org.webrtc.RtpReceiver: org.webrtc.MediaStreamTrack track()
org.webrtc.EglRenderer: void renderFrameOnRenderThread()
org.webrtc.DataChannel: void unregisterObserver()
org.webrtc.VideoCodecMimeType: org.webrtc.VideoCodecMimeType valueOf(java.lang.String)
org.webrtc.audio.WebRtcAudioManager: int getOutputBufferSize(android.content.Context,android.media.AudioManager,int,int)
com.cloudwebrtc.webrtc.audio.AudioSwitchManager: com.twilio.audioswitch.AudioDevice selectedAudioDevice()
org.webrtc.EncodedImage$FrameType: org.webrtc.EncodedImage$FrameType valueOf(java.lang.String)
org.webrtc.TextureBufferImpl$2: void onDestroy(org.webrtc.TextureBufferImpl)
org.webrtc.WrappedNativeI420Buffer: org.webrtc.VideoFrame$Buffer cropAndScale(int,int,int,int,int,int)
com.google.firebase.platforminfo.GlobalLibraryVersionRegistrar: GlobalLibraryVersionRegistrar()
org.webrtc.VideoEncoder$ScalingSettings: VideoEncoder$ScalingSettings(int,int)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void removeTrack(java.lang.String,java.lang.String,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.FrameCryptor: boolean isEnabled()
org.webrtc.PeerConnection$RtcpMuxPolicy: org.webrtc.PeerConnection$RtcpMuxPolicy[] $values()
org.webrtc.audio.JavaAudioDeviceModule$Builder: org.webrtc.audio.JavaAudioDeviceModule$Builder setInputSampleRate(int)
io.flutter.embedding.engine.systemchannels.TextInputChannel$TextCapitalization: io.flutter.embedding.engine.systemchannels.TextInputChannel$TextCapitalization[] values()
org.webrtc.TextureBufferImpl$2: void onRelease(org.webrtc.TextureBufferImpl)
androidx.fragment.app.FragmentTransition$FragmentContainerTransition: FragmentTransition$FragmentContainerTransition()
org.webrtc.SurfaceTextureHelper$FrameRefMonitor: void onRetainBuffer(org.webrtc.VideoFrame$TextureBuffer)
org.webrtc.SurfaceEglRenderer: void init(org.webrtc.EglBase$Context,int[],org.webrtc.RendererCommon$GlDrawer)
org.webrtc.audio.WebRtcAudioManager: WebRtcAudioManager()
org.webrtc.PeerConnection: void removeStream(org.webrtc.MediaStream)
org.webrtc.VideoSource$AspectRatio: VideoSource$AspectRatio(int,int)
androidx.window.layout.SidecarAdapter: boolean isEqualSidecarWindowLayoutInfo(androidx.window.sidecar.SidecarWindowLayoutInfo,androidx.window.sidecar.SidecarWindowLayoutInfo)
org.webrtc.voiceengine.WebRtcAudioRecord$AudioRecordThread: void run()
org.webrtc.EglBase14Impl: android.opengl.EGLConfig getEglConfig(android.opengl.EGLDisplay,int[])
androidx.window.embedding.SplitPairRule: boolean getClearTop()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void access$000(java.lang.String,java.lang.String,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.DataChannel$State: org.webrtc.DataChannel$State fromNativeIndex(int)
com.google.protobuf.FieldType: com.google.protobuf.FieldType valueOf(java.lang.String)
org.webrtc.RtpTransceiver: org.webrtc.MediaStreamTrack$MediaType nativeGetMediaType(long)
org.webrtc.PeerConnectionFactory: void stopAecDump()
androidx.window.embedding.SplitPairRule: boolean getFinishSecondaryWithPrimary()
org.webrtc.HardwareVideoDecoderFactory$1: boolean test(android.media.MediaCodecInfo)
org.webrtc.CameraSession$CreateSessionCallback: void onDone(org.webrtc.CameraSession)
org.webrtc.RtpTransceiver: void stop()
org.webrtc.EglRenderer$EglSurfaceCreation: void run()
org.webrtc.MediaCodecVideoDecoderFactory: android.media.MediaCodecInfo findCodecForType(org.webrtc.VideoCodecMimeType)
androidx.window.layout.SidecarWindowBackend$Companion: SidecarWindowBackend$Companion(kotlin.jvm.internal.DefaultConstructorMarker)
org.webrtc.CameraSession$Events: void onCameraError(org.webrtc.CameraSession,java.lang.String)
org.webrtc.LibvpxVp9Encoder: long nativeCreateEncoder()
com.cloudwebrtc.webrtc.utils.ConstraintsArray: void pushByte(byte[])
com.google.protobuf.Timestamp: Timestamp()
org.webrtc.VideoEncoderFallback: long createNativeVideoEncoder()
com.google.firebase.firestore.proto.WriteBatch: WriteBatch()
org.webrtc.MediaStreamTrack$MediaType: org.webrtc.MediaStreamTrack$MediaType[] values()
io.flutter.embedding.engine.FlutterJNI: void updateJavaAssetManager(android.content.res.AssetManager,java.lang.String)
org.webrtc.audio.WebRtcAudioTrack: android.media.AudioAttributes$Builder applyAttributesOnQOrHigher(android.media.AudioAttributes$Builder,android.media.AudioAttributes)
org.webrtc.GlGenericDrawer$ShaderType: org.webrtc.GlGenericDrawer$ShaderType valueOf(java.lang.String)
org.webrtc.PeerConnection$RTCConfiguration: PeerConnection$RTCConfiguration(java.util.List)
org.webrtc.GlGenericDrawer: void release()
io.flutter.embedding.engine.systemchannels.PlatformChannel$Brightness: io.flutter.embedding.engine.systemchannels.PlatformChannel$Brightness valueOf(java.lang.String)
org.webrtc.VideoTrack: void setShouldReceive(boolean)
org.webrtc.GlGenericDrawer: void drawRgb(int,float[],int,int,int,int,int,int)
com.cloudwebrtc.webrtc.StateProvider: io.flutter.plugin.common.BinaryMessenger getMessenger()
io.grpc.okhttp.OkHttpChannelBuilder$NegotiationType: io.grpc.okhttp.OkHttpChannelBuilder$NegotiationType valueOf(java.lang.String)
org.webrtc.audio.WebRtcAudioUtils: void logAudioStateBasic(java.lang.String,android.content.Context,android.media.AudioManager)
com.cloudwebrtc.webrtc.PeerConnectionObserver: void onIceCandidatesRemoved(org.webrtc.IceCandidate[])
org.webrtc.NetworkMonitor$2: java.lang.String getFieldTrialsString()
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin: void registerWith(io.flutter.plugin.common.PluginRegistry$Registrar)
org.webrtc.Camera2Capturer: void switchCamera(org.webrtc.CameraVideoCapturer$CameraSwitchHandler)
org.webrtc.voiceengine.WebRtcAudioTrack$AudioTrackStartErrorCode: org.webrtc.voiceengine.WebRtcAudioTrack$AudioTrackStartErrorCode[] $values()
org.webrtc.audio.WebRtcAudioRecord: void nativeDataIsRecorded(long,int,long)
org.webrtc.VideoFrame$Buffer: int getWidth()
org.webrtc.PeerConnectionFactory: boolean nativeStartAecDump(long,int,int)
com.google.firebase.firestore.core.OnlineState: com.google.firebase.firestore.core.OnlineState[] values()
org.webrtc.VideoDecoderWrapper: org.webrtc.VideoDecoder$Callback createDecoderCallback(long)
androidx.window.layout.SidecarAdapter$Companion: void setSidecarDisplayFeatures(androidx.window.sidecar.SidecarWindowLayoutInfo,java.util.List)
androidx.lifecycle.ReportFragment$LifecycleCallbacks: void onActivityDestroyed(android.app.Activity)
org.webrtc.voiceengine.WebRtcAudioUtils: boolean isAcousticEchoCancelerSupported()
org.webrtc.NV12Buffer: void nativeCropAndScale(int,int,int,int,int,int,java.nio.ByteBuffer,int,int,int,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int)
org.webrtc.audio.WebRtcAudioUtils: java.lang.String modeToString(int)
androidx.window.embedding.SplitController: java.util.concurrent.locks.ReentrantLock access$getGlobalLock$cp()
org.webrtc.NetworkMonitor: void updateCurrentConnectionType(org.webrtc.NetworkChangeDetector$ConnectionType)
io.flutter.embedding.engine.plugins.lifecycle.HiddenLifecycleReference: androidx.lifecycle.Lifecycle getLifecycle()
com.google.android.gms.common.api.internal.BasePendingResult: BasePendingResult()
androidx.window.embedding.ActivityStack: boolean contains(android.app.Activity)
org.webrtc.CameraCapturer: void dispose()
org.webrtc.RtpParameters: org.webrtc.RtpParameters$Rtcp getRtcp()
com.google.protobuf.WireFormat$JavaType: com.google.protobuf.WireFormat$JavaType[] values()
com.google.firestore.v1.StructuredAggregationQuery$Aggregation$Avg: StructuredAggregationQuery$Aggregation$Avg()
org.webrtc.WebRtcClassLoader: java.lang.Object getClassLoader()
io.flutter.embedding.engine.FlutterJNI: void updateRefreshRate()
org.webrtc.SurfaceTextureHelper: void lambda$stopListening$1()
com.cloudwebrtc.webrtc.utils.PermissionUtils$RequestPermissionsFragment: void onRequestPermissionsResult(int,java.lang.String[],int[])
org.webrtc.CameraCapturer$2: void onCameraDisconnected(org.webrtc.CameraSession)
io.grpc.LoadBalancer$Helper: LoadBalancer$Helper()
io.grpc.okhttp.OkHttpChannelBuilder: io.grpc.okhttp.OkHttpChannelBuilder sslSocketFactory(javax.net.ssl.SSLSocketFactory)
io.flutter.embedding.engine.FlutterJNI: void detachFromNativeAndReleaseResources()
io.grpc.MethodDescriptor$MethodType: io.grpc.MethodDescriptor$MethodType valueOf(java.lang.String)
androidx.window.layout.WindowLayoutInfo: java.util.List getDisplayFeatures()
org.webrtc.audio.JavaAudioDeviceModule$Builder: org.webrtc.audio.JavaAudioDeviceModule$Builder setUseStereoInput(boolean)
androidx.window.embedding.EmbeddingBackend: void registerSplitListenerForActivity(android.app.Activity,java.util.concurrent.Executor,androidx.core.util.Consumer)
org.webrtc.NetworkMonitor: void nativeNotifyOfNetworkDisconnect(long,long)
com.google.firebase.firestore.core.ViewSnapshot$SyncState: com.google.firebase.firestore.core.ViewSnapshot$SyncState[] values()
org.webrtc.RtpParameters$DegradationPreference: org.webrtc.RtpParameters$DegradationPreference[] $values()
androidx.window.embedding.SplitPairFilter: boolean matchesActivityPair(android.app.Activity,android.app.Activity)
org.webrtc.PeerConnectionFactory: org.webrtc.PeerConnectionFactory$Builder builder()
org.webrtc.BuiltinAudioEncoderFactoryFactory: long nativeCreateBuiltinAudioEncoderFactory()
androidx.window.java.layout.WindowInfoTrackerCallbackAdapter$addListener$1$1: kotlin.coroutines.Continuation create(java.lang.Object,kotlin.coroutines.Continuation)
org.webrtc.RtpParameters$Encoding: int getNetworkPriority()
org.webrtc.SurfaceViewRenderer: void release()
org.webrtc.PeerConnection: org.webrtc.RtpSender addTrack(org.webrtc.MediaStreamTrack)
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin: void sendEvent(java.lang.Object)
com.cloudwebrtc.webrtc.record.VideoFileRenderer: void release()
com.google.protobuf.GeneratedMessageLite$ExtendableMessage: GeneratedMessageLite$ExtendableMessage()
org.webrtc.SurfaceTextureHelper: void tryDeliverTextureFrame()
org.webrtc.HardwareVideoEncoderFactory: boolean isHardwareSupportedInCurrentSdkVp8(android.media.MediaCodecInfo)
org.webrtc.WrappedNativeI420Buffer: java.nio.ByteBuffer getDataY()
org.webrtc.NV12Buffer: org.webrtc.VideoFrame$Buffer cropAndScale(int,int,int,int,int,int)
io.flutter.view.AccessibilityViewEmbedder: java.lang.Integer getRecordFlutterId(android.view.View,android.view.accessibility.AccessibilityRecord)
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor$FrameCryptorStateObserver: java.lang.String frameCryptorErrorStateToString(org.webrtc.FrameCryptor$FrameCryptionState)
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback: android.view.WindowInsets access$400(io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback)
io.grpc.internal.PickFirstLoadBalancerProvider: PickFirstLoadBalancerProvider()
org.webrtc.SurfaceViewRenderer: void clearImage()
org.webrtc.voiceengine.WebRtcAudioUtils: java.util.List getBlackListedModelsForNsUsage()
org.webrtc.VideoCodecMimeType: org.webrtc.VideoCodecMimeType[] $values()
com.google.firebase.firestore.FirestoreRegistrar: FirestoreRegistrar()
com.google.firebase.firestore.proto.WriteBatch$Builder: WriteBatch$Builder()
com.cloudwebrtc.webrtc.audio.AudioSwitchManager: void selectAudioOutput(com.cloudwebrtc.webrtc.audio.AudioDeviceKind)
androidx.window.embedding.EmbeddingAdapter: java.util.function.Predicate translateParentMetricsPredicate(androidx.window.embedding.SplitRule)
org.webrtc.audio.WebRtcAudioUtils: void logIsStreamMute(java.lang.String,android.media.AudioManager,int,java.lang.StringBuilder)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void dispose()
com.cloudwebrtc.webrtc.GetUserMediaImpl$ScreenRequestPermissionsFragment: void finish()
org.webrtc.RtcCertificatePem: RtcCertificatePem(java.lang.String,java.lang.String)
org.webrtc.AndroidVideoDecoder: void releaseSurface()
org.webrtc.audio.JavaAudioDeviceModule$AudioSamples: int getSampleRate()
org.webrtc.YuvConverter: void lambda$convertInternal$0(java.nio.ByteBuffer)
org.webrtc.audio.WebRtcAudioRecord: void assertTrue(boolean)
com.google.protobuf.UnsafeUtil: UnsafeUtil()
org.webrtc.SurfaceTextureHelper: org.webrtc.SurfaceTextureHelper create(java.lang.String,org.webrtc.EglBase$Context,boolean,org.webrtc.YuvConverter,org.webrtc.SurfaceTextureHelper$FrameRefMonitor)
androidx.lifecycle.ReportFragment$LifecycleCallbacks: void onActivityPrePaused(android.app.Activity)
org.webrtc.VideoFrame$Buffer: void retain()
org.webrtc.audio.WebRtcAudioTrack: void setSpeakerMute(boolean)
org.webrtc.LibvpxVp9Encoder: boolean nativeIsSupported()
com.cloudwebrtc.webrtc.PeerConnectionObserver: void dispose()
org.webrtc.ThreadUtils: java.lang.StackTraceElement[] concatStackTraces(java.lang.StackTraceElement[],java.lang.StackTraceElement[])
org.webrtc.RtpParameters: org.webrtc.RtpParameters$DegradationPreference getDegradationPreference()
org.webrtc.MediaConstraints: java.lang.String toString()
org.webrtc.Camera2Capturer: void stopCapture()
org.webrtc.MediaCodecWrapperFactoryImpl$MediaCodecWrapperImpl: void start()
org.webrtc.NativeAndroidVideoTrackSource: void nativeAdaptOutputFormat(long,int,int,java.lang.Integer,int,int,java.lang.Integer,java.lang.Integer)
org.webrtc.TextureBufferImpl$1: TextureBufferImpl$1(java.lang.Runnable)
com.cloudwebrtc.webrtc.GetUserMediaImpl: java.util.Map createVideoCapturer(org.webrtc.CameraEnumerator,boolean,java.lang.String)
androidx.window.core.Bounds: int getWidth()
org.webrtc.voiceengine.WebRtcAudioRecord: void nativeDataIsRecorded(int,long)
org.webrtc.SurfaceEglRenderer: void disableFpsReduction()
com.google.firebase.firestore.model.MutableDocument$DocumentType: com.google.firebase.firestore.model.MutableDocument$DocumentType valueOf(java.lang.String)
com.google.firestore.v1.DocumentTransform$FieldTransform: DocumentTransform$FieldTransform()
kotlin.coroutines.AbstractCoroutineContextElement: java.lang.Object fold(java.lang.Object,kotlin.jvm.functions.Function2)
org.webrtc.Camera2Session: int getFrameOrientation()
org.webrtc.VideoEncoder$EncoderInfo: boolean getApplyAlignmentToAllSimulcastLayers()
org.webrtc.Size: Size(int,int)
com.cloudwebrtc.webrtc.utils.ConstraintsMap: com.cloudwebrtc.webrtc.utils.ConstraintsArray getArray(java.lang.String)
org.webrtc.NetworkChangeDetectorFactory: org.webrtc.NetworkChangeDetector create(org.webrtc.NetworkChangeDetector$Observer,android.content.Context)
org.webrtc.audio.WebRtcAudioRecord: void reportWebRtcAudioRecordStartError(org.webrtc.audio.JavaAudioDeviceModule$AudioRecordStartErrorCode,java.lang.String)
org.webrtc.CameraEnumerationAndroid$ClosestComparator: CameraEnumerationAndroid$ClosestComparator()
com.cloudwebrtc.webrtc.R$attr: R$attr()
com.cloudwebrtc.webrtc.PeerConnectionObserver: void onSignalingChange(org.webrtc.PeerConnection$SignalingState)
androidx.window.layout.SidecarCompat$Companion: androidx.window.core.Version getSidecarVersion()
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer: boolean checkMediaStream(java.lang.String,java.lang.String)
org.webrtc.voiceengine.WebRtcAudioUtils: int getDefaultSampleRateHz()
org.webrtc.voiceengine.WebRtcAudioEffects: boolean effectTypeIsVoIP(java.util.UUID)
org.webrtc.Predicate$1: Predicate$1(org.webrtc.Predicate,org.webrtc.Predicate)
org.webrtc.VideoFrame$I420Buffer: java.nio.ByteBuffer getDataU()
io.grpc.ManagedChannelProvider: ManagedChannelProvider()
com.twilio.audioswitch.bluetooth.BluetoothHeadsetManager$HeadsetState: BluetoothHeadsetManager$HeadsetState()
org.webrtc.audio.JavaAudioDeviceModule$Builder: JavaAudioDeviceModule$Builder(android.content.Context)
org.webrtc.HardwareVideoDecoderFactory: HardwareVideoDecoderFactory()
org.webrtc.TimestampAligner: long nativeTranslateTimestamp(long,long)
io.grpc.internal.JndiResourceResolverFactory: JndiResourceResolverFactory()
androidx.window.embedding.EmbeddingAdapter: boolean translateActivityIntentPredicates$lambda-3(androidx.window.embedding.EmbeddingAdapter,java.util.Set,android.util.Pair)
org.webrtc.MediaCodecUtils: java.util.Map getCodecProperties(org.webrtc.VideoCodecMimeType,boolean)
kotlinx.coroutines.MainCoroutineDispatcher: MainCoroutineDispatcher()
org.webrtc.CameraEnumerationAndroid$CaptureFormat: boolean equals(java.lang.Object)
androidx.window.layout.HardwareFoldingFeature$Type$Companion: androidx.window.layout.HardwareFoldingFeature$Type getHINGE()
org.webrtc.MediaCodecWrapper: void setParameters(android.os.Bundle)
org.webrtc.RtpSender: long getNativeRtpSender()
org.webrtc.WrappedNativeVideoEncoder: WrappedNativeVideoEncoder()
org.webrtc.Camera1Enumerator: java.util.List convertFramerates(java.util.List)
org.webrtc.CryptoOptions: CryptoOptions(boolean,boolean,boolean,boolean)
com.google.protobuf.MapFieldLite: MapFieldLite()
com.google.firebase.firestore.Source: com.google.firebase.firestore.Source valueOf(java.lang.String)
io.flutter.plugin.platform.SingleViewPresentation: SingleViewPresentation(android.content.Context,android.view.Display,io.flutter.plugin.platform.AccessibilityEventsDelegate,io.flutter.plugin.platform.SingleViewPresentation$PresentationState,android.view.View$OnFocusChangeListener,boolean)
androidx.window.embedding.SplitPairRule: java.util.Set getFilters()
org.webrtc.CameraVideoCapturer$CameraStatistics$1: void run()
com.cloudwebrtc.webrtc.record.AudioTrackInterceptor: int getUnderrunCount()
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback: boolean access$202(io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback,boolean)
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper: org.webrtc.VideoCodecStatus initEncode(org.webrtc.VideoEncoder$Settings,org.webrtc.VideoEncoder$Callback)
org.webrtc.MediaCodecWrapperFactoryImpl$MediaCodecWrapperImpl: android.media.MediaFormat getInputFormat()
org.webrtc.NetworkMonitorAutoDetect$SimpleNetworkCallback: NetworkMonitorAutoDetect$SimpleNetworkCallback(org.webrtc.NetworkMonitorAutoDetect,java.util.Set)
org.webrtc.ThreadUtils: void joinUninterruptibly(java.lang.Thread)
org.webrtc.WrappedNativeVideoEncoder: org.webrtc.VideoCodecStatus encode(org.webrtc.VideoFrame,org.webrtc.VideoEncoder$EncodeInfo)
org.webrtc.Camera1Session$1: void onError(int,android.hardware.Camera)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: boolean peerConnectionDispose(com.cloudwebrtc.webrtc.PeerConnectionObserver)
io.flutter.view.AccessibilityViewEmbedder: void setFlutterNodeParent(android.view.accessibility.AccessibilityNodeInfo,android.view.View,android.view.accessibility.AccessibilityNodeInfo)
org.webrtc.PeerConnection$IceServer$Builder: org.webrtc.PeerConnection$IceServer$Builder setTlsCertPolicy(org.webrtc.PeerConnection$TlsCertPolicy)
com.cloudwebrtc.webrtc.DataChannelObserver: void onBufferedAmountChange(long)
com.google.firestore.v1.StructuredAggregationQuery$Aggregation: StructuredAggregationQuery$Aggregation()
org.webrtc.HardwareVideoEncoder: org.webrtc.VideoCodecStatus setRates(org.webrtc.VideoEncoder$RateControlParameters)
io.flutter.embedding.engine.FlutterJNI: java.lang.String[] computePlatformResolvedLocale(java.lang.String[])
org.webrtc.RtpParameters$Encoding: java.lang.Long getSsrc()
org.webrtc.SurfaceViewRenderer: void addFrameListener(org.webrtc.EglRenderer$FrameListener,float,org.webrtc.RendererCommon$GlDrawer)
org.webrtc.PeerConnection$IceTransportsType: org.webrtc.PeerConnection$IceTransportsType[] $values()
org.webrtc.DtmfSender: int duration()
org.webrtc.ThreadUtils$1: ThreadUtils$1(java.lang.Thread)
org.webrtc.CameraEnumerationAndroid$CaptureFormat$FramerateRange: java.lang.String toString()
org.webrtc.audio.JavaAudioDeviceModule$AudioSamples: int getChannelCount()
org.webrtc.NetworkMonitor: void notifyObserversOfNetworkConnect(org.webrtc.NetworkChangeDetector$NetworkInformation)
androidx.window.embedding.SplitController$Companion: SplitController$Companion(kotlin.jvm.internal.DefaultConstructorMarker)
androidx.window.layout.SidecarCompat$TranslatingCallback: SidecarCompat$TranslatingCallback(androidx.window.layout.SidecarCompat)
org.webrtc.EglBase$-CC: org.webrtc.EglBase create(org.webrtc.EglBase$Context)
org.webrtc.ThreadUtils$1Result: ThreadUtils$1Result()
org.webrtc.voiceengine.WebRtcAudioManager: int getMinOutputFrameSize(int,int)
org.webrtc.WrappedVideoDecoderFactory: WrappedVideoDecoderFactory(org.webrtc.EglBase$Context)
com.cloudwebrtc.webrtc.PeerConnectionObserver: void addTransceiverOfType(java.lang.String,java.util.Map,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.SurfaceTextureHelper: void dispose()
org.webrtc.Logging: void log(org.webrtc.Logging$Severity,java.lang.String,java.lang.String)
org.webrtc.SurfaceEglRenderer: void surfaceChanged(android.view.SurfaceHolder,int,int,int)
org.webrtc.voiceengine.WebRtcAudioManager: boolean isAcousticEchoCancelerSupported()
androidx.window.layout.SidecarAdapter: SidecarAdapter()
org.webrtc.VideoFrame$I420Buffer: int getBufferType()
org.webrtc.PeerConnection$IceServer: PeerConnection$IceServer(java.lang.String,java.lang.String,java.lang.String)
androidx.window.layout.WindowMetricsCalculator$Companion$reset$1: WindowMetricsCalculator$Companion$reset$1()
io.flutter.embedding.engine.FlutterJNI: io.flutter.embedding.engine.FlutterOverlaySurface createOverlaySurface()
org.webrtc.SurfaceTextureHelper: org.webrtc.SurfaceTextureHelper create(java.lang.String,org.webrtc.EglBase$Context)
org.webrtc.PeerConnection$IceConnectionState: org.webrtc.PeerConnection$IceConnectionState[] $values()
org.webrtc.JavaI420Buffer: JavaI420Buffer(int,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.lang.Runnable)
com.cloudwebrtc.webrtc.record.VideoFileRenderer: void drainAudio()
org.webrtc.audio.WebRtcAudioRecord: void reportWebRtcAudioRecordInitError(java.lang.String)
com.google.firebase.firestore.DocumentSnapshot$ServerTimestampBehavior: com.google.firebase.firestore.DocumentSnapshot$ServerTimestampBehavior valueOf(java.lang.String)
org.webrtc.RtpCapabilities$HeaderExtensionCapability: RtpCapabilities$HeaderExtensionCapability(java.lang.String,int,boolean)
org.webrtc.SessionDescription: SessionDescription(org.webrtc.SessionDescription$Type,java.lang.String)
androidx.window.layout.WindowMetricsCalculator$Companion$decorator$1: WindowMetricsCalculator$Companion$decorator$1()
org.webrtc.RtpTransceiver: boolean setDirection(org.webrtc.RtpTransceiver$RtpTransceiverDirection)
androidx.window.layout.ExtensionWindowLayoutInfoBackend$MulticastConsumer: ExtensionWindowLayoutInfoBackend$MulticastConsumer(android.app.Activity)
org.webrtc.FrameCryptorAlgorithm: org.webrtc.FrameCryptorAlgorithm[] $values()
org.webrtc.voiceengine.WebRtcAudioUtils: boolean deviceIsBlacklistedForOpenSLESUsage()
androidx.window.layout.HardwareFoldingFeature: boolean equals(java.lang.Object)
io.grpc.SecurityLevel: io.grpc.SecurityLevel[] values()
org.webrtc.PeerConnection$RtcpMuxPolicy: org.webrtc.PeerConnection$RtcpMuxPolicy valueOf(java.lang.String)
org.webrtc.EglRenderer: void disableFpsReduction()
org.webrtc.Camera1Session$SessionState: org.webrtc.Camera1Session$SessionState[] $values()
org.webrtc.FileVideoCapturer$VideoReaderY4M: org.webrtc.VideoFrame getNextFrame()
com.cloudwebrtc.webrtc.utils.AnyThreadResult: void lambda$success$0(java.lang.Object)
org.webrtc.CameraCapturer$SwitchState: org.webrtc.CameraCapturer$SwitchState[] values()
org.webrtc.Metrics: void nativeEnable()
org.webrtc.VideoSource$1: void onCapturerStopped()
org.webrtc.Camera1Session$SessionState: Camera1Session$SessionState(java.lang.String,int)
com.google.firestore.v1.BatchGetDocumentsResponse$ResultCase: com.google.firestore.v1.BatchGetDocumentsResponse$ResultCase valueOf(java.lang.String)
org.webrtc.Camera2Session$CaptureSessionCallback: void onConfigured(android.hardware.camera2.CameraCaptureSession)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void reStartCamera()
org.webrtc.RtpSender: java.lang.String nativeGetId(long)
org.webrtc.SurfaceViewRenderer: void onMeasure(int,int)
androidx.lifecycle.ReportFragment$LifecycleCallbacks: void onActivityCreated(android.app.Activity,android.os.Bundle)
org.webrtc.ThreadUtils: ThreadUtils()
org.webrtc.NetworkChangeDetector$IPAddress: NetworkChangeDetector$IPAddress(byte[])
org.webrtc.CameraEnumerationAndroid: org.webrtc.CameraEnumerationAndroid$CaptureFormat$FramerateRange getClosestSupportedFramerateRange(java.util.List,int)
org.webrtc.R: R()
org.webrtc.PeerConnection: boolean addIceCandidate(org.webrtc.IceCandidate)
androidx.window.embedding.EmbeddingAdapter: boolean translateActivityPredicates$lambda-6(java.util.Set,android.app.Activity)
org.webrtc.SoftwareVideoEncoderFactory: org.webrtc.VideoEncoder createEncoder(org.webrtc.VideoCodecInfo)
org.webrtc.Camera2Session: void findCaptureFormat()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void peerConnectionClose(java.lang.String)
org.webrtc.RtpReceiver: void setFrameDecryptor(org.webrtc.FrameDecryptor)
org.webrtc.SurfaceViewRenderer: SurfaceViewRenderer(android.content.Context,android.util.AttributeSet)
org.webrtc.FrameEncryptor: long getNativeFrameEncryptor()
org.webrtc.PeerConnection$Observer: void onAddStream(org.webrtc.MediaStream)
androidx.window.core.Version: androidx.window.core.Version access$getUNKNOWN$cp()
com.google.protobuf.Any: Any()
androidx.arch.core.executor.ArchTaskExecutor: ArchTaskExecutor()
org.webrtc.NetworkMonitor: void startMonitoring(android.content.Context,java.lang.String)
org.webrtc.EglBase10Impl$1FakeSurfaceHolder: android.graphics.Canvas lockCanvas()
org.webrtc.FrameCryptorFactory: org.webrtc.FrameCryptor createFrameCryptorForRtpReceiver(org.webrtc.RtpReceiver,java.lang.String,org.webrtc.FrameCryptorAlgorithm,org.webrtc.FrameCryptorKeyProvider)
androidx.window.layout.WindowBackend: void unregisterLayoutChangeCallback(androidx.core.util.Consumer)
io.grpc.okhttp.OkHttpFrameLogger$SettingParams: io.grpc.okhttp.OkHttpFrameLogger$SettingParams valueOf(java.lang.String)
androidx.window.layout.SidecarWindowBackend$ExtensionListenerImpl: SidecarWindowBackend$ExtensionListenerImpl(androidx.window.layout.SidecarWindowBackend)
org.webrtc.PeerConnection$ContinualGatheringPolicy: org.webrtc.PeerConnection$ContinualGatheringPolicy[] values()
org.webrtc.DataChannel: void nativeClose()
org.webrtc.NetworkMonitor$1: org.webrtc.NetworkChangeDetector create(org.webrtc.NetworkChangeDetector$Observer,android.content.Context)
org.webrtc.VideoFrameDrawer: void drawFrame(org.webrtc.VideoFrame,org.webrtc.RendererCommon$GlDrawer,android.graphics.Matrix)
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback: int access$100(io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback)
org.webrtc.EncodedImage: org.webrtc.EncodedImage$Builder builder()
org.webrtc.DataChannel: int id()
com.google.protobuf.FieldType$Collection: com.google.protobuf.FieldType$Collection valueOf(java.lang.String)
com.google.firestore.v1.DocumentTransform: DocumentTransform()
androidx.window.layout.DisplayCompatHelperApi28: int safeInsetLeft(android.view.DisplayCutout)
com.cloudwebrtc.webrtc.StateProvider: android.app.Activity getActivity()
androidx.window.layout.WindowMetricsCalculatorCompat: android.graphics.Rect computeWindowBoundsQ$window_release(android.app.Activity)
org.webrtc.CameraEnumerationAndroid$1: int diff(org.webrtc.CameraEnumerationAndroid$CaptureFormat$FramerateRange)
org.webrtc.CameraEnumerationAndroid: void reportCameraResolution(org.webrtc.Histogram,org.webrtc.Size)
androidx.window.layout.DisplayCompatHelperApi28: int safeInsetRight(android.view.DisplayCutout)
org.webrtc.AndroidVideoDecoder: org.webrtc.VideoCodecStatus initDecode(org.webrtc.VideoDecoder$Settings,org.webrtc.VideoDecoder$Callback)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void peerConnectionGetStats(java.lang.String,java.lang.String,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.MediaCodecWrapper: void release()
kotlin.jvm.internal.CallableReference: kotlin.reflect.KCallable computeReflected()
org.webrtc.MediaCodecWrapperFactoryImpl$MediaCodecWrapperImpl: void setParameters(android.os.Bundle)
com.google.protobuf.GeneratedMessageLite$MethodToInvoke: com.google.protobuf.GeneratedMessageLite$MethodToInvoke valueOf(java.lang.String)
com.google.protobuf.WireFormat$FieldType: com.google.protobuf.WireFormat$FieldType[] values()
org.webrtc.RtpParameters$Rtcp: boolean getReducedSize()
org.webrtc.DataChannel$Observer: void onMessage(org.webrtc.DataChannel$Buffer)
org.webrtc.EglBase14Impl: EglBase14Impl(android.opengl.EGLContext,int[])
org.webrtc.DtmfSender: boolean nativeCanInsertDtmf(long)
org.webrtc.VideoCodecMimeType: VideoCodecMimeType(java.lang.String,int,java.lang.String)
org.webrtc.SoftwareVideoDecoderFactory$1: SoftwareVideoDecoderFactory$1(org.webrtc.SoftwareVideoDecoderFactory,long)
androidx.window.layout.WindowMetricsCalculatorCompat: android.graphics.Rect computeWindowBoundsN$window_release(android.app.Activity)
org.webrtc.PeerConnection: boolean nativeSetConfiguration(org.webrtc.PeerConnection$RTCConfiguration)
org.webrtc.audio.WebRtcAudioTrack: void logMainParametersExtended()
org.webrtc.NetworkMonitorAutoDetect$ConnectivityManagerDelegate: android.net.NetworkRequest createNetworkRequest()
kotlin.coroutines.jvm.internal.BaseContinuationImpl: void resumeWith(java.lang.Object)
org.webrtc.NativeAndroidVideoTrackSource: org.webrtc.VideoProcessor$FrameAdaptationParameters createFrameAdaptationParameters(int,int,int,int,int,int,long,boolean)
org.webrtc.PeerConnection$IceConnectionState: PeerConnection$IceConnectionState(java.lang.String,int)
com.google.firebase.firestore.remote.Stream$State: com.google.firebase.firestore.remote.Stream$State valueOf(java.lang.String)
androidx.lifecycle.ReportFragment$LifecycleCallbacks: void onActivityStopped(android.app.Activity)
androidx.window.layout.WindowInfoTrackerImpl$Companion: WindowInfoTrackerImpl$Companion()
com.cloudwebrtc.webrtc.GetUserMediaImpl$ScreenRequestPermissionsFragment: void requestStart(android.app.Activity,int)
org.webrtc.EglBase$ConfigBuilder: int[] createConfigAttributes()
org.webrtc.EncodedImage: int getRotation()
androidx.window.embedding.EmbeddingAdapter: java.util.function.Predicate translateActivityIntentPredicates(java.util.Set)
com.cloudwebrtc.webrtc.PeerConnectionObserver: void close()
org.webrtc.VideoFrameDrawer$YuvUploader: int[] uploadYuvData(int,int,int[],java.nio.ByteBuffer[])
org.webrtc.DataChannel: java.lang.String label()
org.webrtc.SurfaceTextureHelper$1: SurfaceTextureHelper$1(org.webrtc.EglBase$Context,android.os.Handler,boolean,org.webrtc.YuvConverter,org.webrtc.SurfaceTextureHelper$FrameRefMonitor,java.lang.String)
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor$FrameCryptorStateObserver: void onFrameCryptionStateChanged(java.lang.String,org.webrtc.FrameCryptor$FrameCryptionState)
androidx.window.layout.WindowInfoTracker: kotlinx.coroutines.flow.Flow windowLayoutInfo(android.app.Activity)
org.webrtc.PeerConnection$BundlePolicy: PeerConnection$BundlePolicy(java.lang.String,int)
org.webrtc.PeerConnection: void nativeNewGetStats(org.webrtc.RTCStatsCollectorCallback)
org.webrtc.VideoFileRenderer: VideoFileRenderer(java.lang.String,int,int,org.webrtc.EglBase$Context)
io.flutter.embedding.engine.FlutterOverlaySurface: android.view.Surface getSurface()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void peerConnectionAddICECandidate(com.cloudwebrtc.webrtc.utils.ConstraintsMap,java.lang.String,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.voiceengine.WebRtcAudioTrack: boolean setStreamVolume(int)
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$FallbackFactory: org.webrtc.VideoEncoder createEncoder(org.webrtc.VideoCodecInfo)
org.webrtc.FrameCryptorAlgorithm: org.webrtc.FrameCryptorAlgorithm valueOf(java.lang.String)
io.flutter.embedding.engine.systemchannels.PlatformViewsChannel$PlatformViewCreationRequest$RequestedDisplayMode: io.flutter.embedding.engine.systemchannels.PlatformViewsChannel$PlatformViewCreationRequest$RequestedDisplayMode valueOf(java.lang.String)
org.webrtc.EglRenderer: void lambda$init$0(org.webrtc.EglBase$Context,int[])
org.webrtc.DtmfSender: java.lang.String tones()
org.webrtc.WrappedNativeI420Buffer: int getStrideY()
com.google.firebase.firestore.core.LimboDocumentChange$Type: com.google.firebase.firestore.core.LimboDocumentChange$Type valueOf(java.lang.String)
org.webrtc.WrappedNativeVideoDecoder: java.lang.String getImplementationName()
org.webrtc.RtpTransceiver$RtpTransceiverInit: RtpTransceiver$RtpTransceiverInit(org.webrtc.RtpTransceiver$RtpTransceiverDirection,java.util.List,java.util.List)
com.google.type.LatLng$Builder: LatLng$Builder()
org.webrtc.GlGenericDrawer: void drawYuv(int[],float[],int,int,int,int,int,int)
org.webrtc.NetworkMonitorAutoDetect: void destroy()
com.google.firestore.v1.StructuredQuery$FieldFilter$Builder: StructuredQuery$FieldFilter$Builder()
org.webrtc.PeerConnection: void nativeRestartIce()
okio.SegmentPool: SegmentPool()
com.google.protobuf.ByteString: ByteString()
com.cloudwebrtc.webrtc.StateProvider: com.cloudwebrtc.webrtc.PeerConnectionObserver getPeerConnectionObserver(java.lang.String)
org.webrtc.EglRenderer$1: EglRenderer$1(org.webrtc.EglRenderer)
androidx.window.layout.WindowMetricsCalculatorCompat: androidx.window.layout.WindowMetrics computeMaximumWindowMetrics(android.app.Activity)
androidx.window.embedding.EmbeddingInterfaceCompat: void setSplitRules(java.util.Set)
org.webrtc.CameraSession: void stop()
org.webrtc.VideoFrame$Buffer$-CC: int $default$getBufferType(org.webrtc.VideoFrame$Buffer)
org.webrtc.EglBase10Impl: int surfaceHeight()
com.twilio.audioswitch.AudioDevice$WiredHeadset: AudioDevice$WiredHeadset()
com.cloudwebrtc.webrtc.utils.AnyThreadSink: void success(java.lang.Object)
org.webrtc.PeerConnection: org.webrtc.PeerConnection$IceConnectionState nativeIceConnectionState()
com.cloudwebrtc.webrtc.CameraEventsHandler: void onCameraClosed()
org.webrtc.PeerConnection$IceServer: org.webrtc.PeerConnection$TlsCertPolicy getTlsCertPolicy()
androidx.window.core.Version$bigInteger$2: Version$bigInteger$2(androidx.window.core.Version)
io.flutter.embedding.engine.FlutterJNI: boolean nativeFlutterTextUtilsIsEmojiModifierBase(int)
org.webrtc.JavaI420Buffer: org.webrtc.JavaI420Buffer allocate(int,int)
androidx.window.layout.WindowInfoTracker$Companion: androidx.window.layout.WindowInfoTracker getOrCreate(android.content.Context)
com.cloudwebrtc.webrtc.SurfaceTextureRenderer: void init(org.webrtc.EglBase$Context,org.webrtc.RendererCommon$RendererEvents)
org.webrtc.NativeCapturerObserver: void onCapturerStopped()
org.webrtc.RtpParameters$Encoding: java.lang.Integer getNumTemporalLayers()
io.flutter.view.AccessibilityViewEmbedder: boolean performAction(int,int,android.os.Bundle)
org.webrtc.TimestampAligner: long translateTimestamp(long)
org.webrtc.PeerConnection$RTCConfiguration: org.webrtc.TurnCustomizer getTurnCustomizer()
org.webrtc.MediaStreamTrack: boolean nativeSetEnabled(long,boolean)
org.webrtc.RTCStatsReport: double getTimestampUs()
io.flutter.embedding.engine.FlutterJNI: void nativeDispatchPointerDataPacket(long,java.nio.ByteBuffer,int)
org.webrtc.PeerConnection: org.webrtc.RtpTransceiver addTransceiver(org.webrtc.MediaStreamTrack)
org.webrtc.Metrics: org.webrtc.Metrics getAndReset()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: java.util.List createIceServers(com.cloudwebrtc.webrtc.utils.ConstraintsArray)
org.webrtc.PeerConnectionFactory: void nativeFreeFactory(long)
org.webrtc.audio.WebRtcAudioTrack: int initPlayout(int,int,double)
org.webrtc.WrappedNativeI420Buffer: WrappedNativeI420Buffer(int,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,long)
androidx.window.R$styleable: R$styleable()
org.webrtc.HardwareVideoEncoder: boolean shouldForceKeyFrame(long)
org.webrtc.Camera2Enumerator: int getFpsUnitFactor(android.util.Range[])
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: org.webrtc.MediaStreamTrack getLocalTrack(java.lang.String)
org.webrtc.RtpReceiver: void SetObserver(org.webrtc.RtpReceiver$Observer)
org.webrtc.YuvHelper: void I420Copy(java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,int,int,int)
org.webrtc.Camera2Enumerator: java.util.List getSupportedFormats(android.hardware.camera2.CameraManager,java.lang.String)
org.webrtc.YuvHelper: YuvHelper()
androidx.window.layout.WindowBackend: void registerLayoutChangeCallback(android.app.Activity,java.util.concurrent.Executor,androidx.core.util.Consumer)
io.flutter.embedding.engine.FlutterJNI: boolean isAttached()
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper: org.webrtc.VideoCodecStatus setRates(org.webrtc.VideoEncoder$RateControlParameters)
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin$LifeCycleObserver: void onActivitySaveInstanceState(android.app.Activity,android.os.Bundle)
org.webrtc.PeerConnection: org.webrtc.RtpSender createSender(java.lang.String,java.lang.String)
com.cloudwebrtc.webrtc.PeerConnectionObserver: java.util.Map mediaStreamToMap(org.webrtc.MediaStream)
org.webrtc.NetworkMonitorAutoDetect$ConnectivityManagerDelegate: org.webrtc.NetworkMonitorAutoDetect$NetworkState getNetworkState(android.net.Network)
io.grpc.okhttp.OkHttpChannelBuilder: io.grpc.okhttp.OkHttpChannelBuilder scheduledExecutorService(java.util.concurrent.ScheduledExecutorService)
org.webrtc.RTCStatsReport: java.lang.String toString()
com.google.firestore.v1.StructuredQuery$Order: StructuredQuery$Order()
com.google.firestore.v1.StructuredAggregationQuery: StructuredAggregationQuery()
org.webrtc.SurfaceViewRenderer: void setScalingType(org.webrtc.RendererCommon$ScalingType)
org.webrtc.HardwareVideoEncoder$BusyCount: void increment()
org.webrtc.audio.WebRtcAudioRecord: void setMicrophoneMute(boolean)
com.google.firestore.v1.Write$Builder: Write$Builder()
org.webrtc.audio.JavaAudioDeviceModule$AudioRecordStateCallback: void onWebRtcAudioRecordStop()
com.cloudwebrtc.webrtc.record.AudioSamplesInterceptor: void attachCallback(java.lang.Integer,org.webrtc.audio.JavaAudioDeviceModule$SamplesReadyCallback)
org.webrtc.voiceengine.WebRtcAudioUtils: void setWebRtcBasedAutomaticGainControl(boolean)
org.webrtc.voiceengine.WebRtcAudioTrack: void setAudioTrackUsageAttribute(int)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void mediaStreamAddTrack(java.lang.String,java.lang.String,io.flutter.plugin.common.MethodChannel$Result)
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor: void keyProviderDispose(java.util.Map,io.flutter.plugin.common.MethodChannel$Result)
io.flutter.embedding.engine.FlutterJNI: void dispatchPlatformMessage(java.lang.String,java.nio.ByteBuffer,int,int)
org.webrtc.VideoDecoderWrapper: VideoDecoderWrapper()
org.webrtc.VideoFrame: void release()
org.webrtc.MediaStreamTrack$State: org.webrtc.MediaStreamTrack$State[] $values()
androidx.window.layout.SidecarCompat$registerConfigurationChangeListener$configChangeObserver$1: SidecarCompat$registerConfigurationChangeListener$configChangeObserver$1(androidx.window.layout.SidecarCompat,android.app.Activity)
org.webrtc.VideoProcessor: void onFrameCaptured(org.webrtc.VideoFrame,org.webrtc.VideoProcessor$FrameAdaptationParameters)
org.webrtc.Camera2Capturer: Camera2Capturer(android.content.Context,java.lang.String,org.webrtc.CameraVideoCapturer$CameraEventsHandler)
com.google.protobuf.ByteString$LeafByteString: ByteString$LeafByteString()
androidx.window.layout.ActivityCompatHelperApi30: ActivityCompatHelperApi30()
org.webrtc.VideoEncoder$EncodeInfo: VideoEncoder$EncodeInfo(org.webrtc.EncodedImage$FrameType[])
org.webrtc.MediaStreamTrack$MediaType: org.webrtc.MediaStreamTrack$MediaType fromNativeIndex(int)
org.webrtc.SoftwareVideoDecoderFactory: java.util.List nativeGetSupportedCodecs(long)
org.webrtc.RendererCommon$RendererEvents: void onFirstFrameRendered()
org.webrtc.RendererCommon$VideoLayoutMeasure: android.graphics.Point measure(int,int,int,int)
org.webrtc.audio.WebRtcAudioEffects: void assertTrue(boolean)
io.flutter.view.AccessibilityViewEmbedder: android.view.accessibility.AccessibilityNodeInfo createAccessibilityNodeInfo(int)
org.webrtc.EglBase14Impl: org.webrtc.EglBase$Context getEglBaseContext()
org.webrtc.audio.WebRtcAudioEffects: void release()
org.webrtc.PeerConnectionFactory: java.lang.String nativeFindFieldTrialsFullName(java.lang.String)
com.google.common.collect.ImmutableMap: ImmutableMap()
org.webrtc.VideoEncoder$BitrateAllocation: VideoEncoder$BitrateAllocation(int[][])
org.webrtc.RtpReceiver: long nativeGetTrack(long)
org.webrtc.NetworkMonitorAutoDetect: void registerReceiver()
androidx.window.embedding.EmptyEmbeddingComponent: EmptyEmbeddingComponent()
org.webrtc.VideoDecoderFallback: VideoDecoderFallback(org.webrtc.VideoDecoder,org.webrtc.VideoDecoder)
io.grpc.internal.AutoConfiguredLoadBalancerFactory$EmptyPicker: AutoConfiguredLoadBalancerFactory$EmptyPicker()
org.webrtc.HardwareVideoEncoderFactory: int getForcedKeyFrameIntervalMs(org.webrtc.VideoCodecMimeType,java.lang.String)
com.google.firebase.firestore.MetadataChanges: com.google.firebase.firestore.MetadataChanges[] values()
com.google.firebase.provider.FirebaseInitProvider: FirebaseInitProvider()
io.flutter.view.AccessibilityBridge$TextDirection: io.flutter.view.AccessibilityBridge$TextDirection[] values()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$5: MethodCallHandlerImpl$5(com.cloudwebrtc.webrtc.MethodCallHandlerImpl)
org.webrtc.RendererCommon: android.graphics.Point getDisplaySize(float,float,int,int)
org.webrtc.EglBase$-CC: org.webrtc.EglBase14 createEgl14(org.webrtc.EglBase14$Context,int[])
io.grpc.util.SecretRoundRobinLoadBalancerProvider$Provider: io.grpc.NameResolver$ConfigOrError parseLoadBalancingPolicyConfig(java.util.Map)
org.webrtc.MediaStreamTrack: org.webrtc.MediaStreamTrack$State state()
com.cloudwebrtc.webrtc.StateProvider: org.webrtc.PeerConnectionFactory getPeerConnectionFactory()
androidx.lifecycle.ReportFragment$LifecycleCallbacks: void onActivityPostCreated(android.app.Activity,android.os.Bundle)
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$FallbackFactory: org.webrtc.VideoCodecInfo[] getSupportedCodecs()
com.google.firestore.v1.StructuredQuery$Filter$FilterTypeCase: com.google.firestore.v1.StructuredQuery$Filter$FilterTypeCase[] values()
androidx.lifecycle.Lifecycle$State: androidx.lifecycle.Lifecycle$State valueOf(java.lang.String)
org.webrtc.FrameCryptor: int getKeyIndex()
org.webrtc.MediaStreamTrack$State: org.webrtc.MediaStreamTrack$State fromNativeIndex(int)
io.flutter.embedding.android.FlutterView: void setWindowInfoListenerDisplayFeatures(androidx.window.layout.WindowLayoutInfo)
androidx.window.core.Bounds: boolean isEmpty()
org.webrtc.EglBase14Impl: int surfaceHeight()
org.webrtc.VideoEncoderWrapper: VideoEncoderWrapper()
com.google.firebase.firestore.core.DocumentViewChange$Type: com.google.firebase.firestore.core.DocumentViewChange$Type[] values()
io.grpc.internal.PickFirstLoadBalancerProvider: boolean isAvailable()
io.flutter.embedding.engine.FlutterJNI: boolean isCodePointEmoji(int)
org.webrtc.RtpSender: void dispose()
com.google.firestore.v1.StructuredQuery$FieldFilter$Operator: com.google.firestore.v1.StructuredQuery$FieldFilter$Operator[] values()
org.webrtc.RendererCommon$ScalingType: org.webrtc.RendererCommon$ScalingType valueOf(java.lang.String)
androidx.window.layout.SidecarWindowBackend$Companion: androidx.window.layout.SidecarWindowBackend getInstance(android.content.Context)
androidx.window.layout.ExtensionWindowLayoutInfoBackend$MulticastConsumer: void removeListener(androidx.core.util.Consumer)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$4: void onSetFailure(java.lang.String)
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper: void setStreamSettings(org.webrtc.VideoEncoder$Settings)
com.cloudwebrtc.webrtc.GetUserMediaImpl: boolean access$502(com.cloudwebrtc.webrtc.GetUserMediaImpl,boolean)
com.cloudwebrtc.webrtc.record.AudioTrackInterceptor: int getPlaybackHeadPosition()
com.google.protobuf.NullValue: com.google.protobuf.NullValue[] values()
org.webrtc.AndroidVideoDecoder: void reformat(android.media.MediaFormat)
androidx.window.layout.SidecarWindowBackend: androidx.window.layout.SidecarWindowBackend access$getGlobalInstance$cp()
io.flutter.embedding.engine.FlutterJNI: void loadDartDeferredLibrary(int,java.lang.String[])
org.webrtc.TextureBufferImpl: android.os.Handler getToI420Handler()
org.webrtc.VideoFileRenderer: void lambda$release$3()
com.google.firestore.v1.Precondition: Precondition()
org.webrtc.RtpParameters$Codec: RtpParameters$Codec(int,java.lang.String,org.webrtc.MediaStreamTrack$MediaType,java.lang.Integer,java.lang.Integer,java.util.Map)
io.grpc.InternalChannelz: InternalChannelz()
org.webrtc.RtpSender: boolean nativeSetParameters(long,org.webrtc.RtpParameters)
androidx.window.embedding.SplitRule: SplitRule(int,int,float,int)
com.twilio.audioswitch.AudioDevice$Earpiece: AudioDevice$Earpiece()
org.webrtc.VideoFrame: VideoFrame(org.webrtc.VideoFrame$Buffer,int,long)
org.webrtc.CameraCapturer$8: void run()
androidx.window.layout.WindowMetricsCalculator$-CC: void reset()
org.webrtc.Camera2Enumerator: boolean isFrontFacing(java.lang.String)
org.webrtc.voiceengine.WebRtcAudioTrack$AudioTrackThread: void run()
io.flutter.embedding.engine.FlutterEngineGroupCache: FlutterEngineGroupCache()
org.webrtc.SurfaceTextureHelper: void stopListening()
org.webrtc.AndroidVideoDecoder: org.webrtc.VideoCodecStatus releaseInternal()
org.webrtc.Camera1Enumerator: boolean isBackFacing(java.lang.String)
androidx.window.embedding.SplitPairRule: SplitPairRule(java.util.Set,boolean,boolean,boolean,int,int,float,int,int,kotlin.jvm.internal.DefaultConstructorMarker)
androidx.window.layout.FoldingFeature$OcclusionType$Companion: FoldingFeature$OcclusionType$Companion()
com.google.firestore.v1.StructuredQuery$FieldReference: StructuredQuery$FieldReference()
org.webrtc.VideoEncoderFactory$VideoEncoderSelector: void onCurrentEncoder(org.webrtc.VideoCodecInfo)
org.webrtc.NetworkChangeDetector: org.webrtc.NetworkChangeDetector$ConnectionType getCurrentConnectionType()
org.webrtc.voiceengine.WebRtcAudioEffects: boolean isEffectTypeAvailable(java.util.UUID)
org.webrtc.MediaStreamTrack: boolean nativeGetEnabled(long)
androidx.arch.core.internal.SafeIterableMap: SafeIterableMap()
org.webrtc.H264Utils: boolean isSameH264Profile(java.util.Map,java.util.Map)
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapperFactory: org.webrtc.VideoEncoder createEncoder(org.webrtc.VideoCodecInfo)
androidx.window.embedding.SplitRule: float getSplitRatio()
org.webrtc.EglBase: void createSurface(android.graphics.SurfaceTexture)
org.webrtc.NativeLibrary$DefaultLoader: NativeLibrary$DefaultLoader()
org.webrtc.EglRenderer$2: void run()
org.webrtc.PeerConnection: org.webrtc.RtpSender addTrack(org.webrtc.MediaStreamTrack,java.util.List)
com.cloudwebrtc.webrtc.utils.ConstraintsArray: void pushInt(int)
org.webrtc.voiceengine.WebRtcAudioRecord$AudioRecordThread: WebRtcAudioRecord$AudioRecordThread(org.webrtc.voiceengine.WebRtcAudioRecord,java.lang.String)
com.cloudwebrtc.webrtc.GetUserMediaImpl$3$1: void onStop()
org.webrtc.EglBase10Impl$1FakeSurfaceHolder: android.graphics.Canvas lockCanvas(android.graphics.Rect)
org.webrtc.Camera2Session: void reportError(java.lang.String)
org.webrtc.RtpReceiver: void nativeUnsetObserver(long,long)
org.webrtc.PeerConnectionFactory: void nativeDeleteLoggable()
io.grpc.LoadBalancerRegistry: LoadBalancerRegistry()
org.webrtc.PeerConnection$IceServer: java.util.List getTlsAlpnProtocols()
org.webrtc.PeerConnection$RTCConfiguration: java.lang.String getTurnLoggingId()
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper: org.webrtc.VideoCodecStatus release$lambda-1(com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper)
io.flutter.embedding.engine.FlutterJNI: boolean isCodePointRegionalIndicator(int)
org.webrtc.LibaomAv1Encoder: boolean isHardwareEncoder()
org.webrtc.PeerConnection$IceServer: PeerConnection$IceServer(java.lang.String)
androidx.window.layout.SidecarWindowBackend$WindowLayoutChangeCallbackWrapper: android.app.Activity getActivity()
org.webrtc.EglBase$-CC: org.webrtc.EglBase$ConfigBuilder configBuilder()
org.webrtc.HardwareVideoEncoderFactory: boolean isH264HighProfileSupported(android.media.MediaCodecInfo)
androidx.window.core.Bounds: boolean isZero()
org.webrtc.VideoEncoder: org.webrtc.VideoCodecStatus release()
org.webrtc.VideoFrame$Buffer: int getHeight()
org.webrtc.audio.WebRtcAudioTrack: void setNativeAudioTrack(long)
org.webrtc.voiceengine.WebRtcAudioManager: boolean hasEarpiece()
com.cloudwebrtc.webrtc.R$drawable: R$drawable()
com.google.firebase.heartbeatinfo.HeartBeatInfo$HeartBeat: com.google.firebase.heartbeatinfo.HeartBeatInfo$HeartBeat valueOf(java.lang.String)
org.webrtc.NetworkMonitorAutoDetect: void connectionTypeChanged(org.webrtc.NetworkMonitorAutoDetect$NetworkState)
org.webrtc.RtpSender: boolean setParameters(org.webrtc.RtpParameters)
org.webrtc.audio.WebRtcAudioRecord: void logMainParametersExtended()
io.grpc.internal.DnsNameResolverProvider: boolean isAvailable()
com.google.firestore.v1.BitSequence: BitSequence()
org.webrtc.DataChannel$Init: int getMaxRetransmitTimeMs()
org.webrtc.VideoSource: void dispose()
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor$FrameCryptorStateObserver: FlutterRTCFrameCryptor$FrameCryptorStateObserver(com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor,io.flutter.plugin.common.BinaryMessenger,java.lang.String)
org.webrtc.voiceengine.WebRtcAudioRecord$AudioSamples: byte[] getData()
org.webrtc.SessionDescription$Type: java.lang.String canonicalForm()
org.webrtc.NetworkChangeDetector$ConnectionType: org.webrtc.NetworkChangeDetector$ConnectionType valueOf(java.lang.String)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: android.content.Context getApplicationContext()
androidx.window.layout.ExtensionsWindowLayoutInfoAdapter: androidx.window.layout.WindowLayoutInfo translate$window_release(android.app.Activity,androidx.window.extensions.layout.WindowLayoutInfo)
org.webrtc.VideoFrame$Buffer: int getBufferType()
androidx.window.embedding.EmbeddingInterfaceCompat: void setEmbeddingCallback(androidx.window.embedding.EmbeddingInterfaceCompat$EmbeddingCallbackInterface)
androidx.window.embedding.EmbeddingAdapter: java.util.function.Predicate translateActivityPairPredicates(java.util.Set)
androidx.window.layout.WindowInfoTrackerImpl$Companion: WindowInfoTrackerImpl$Companion(kotlin.jvm.internal.DefaultConstructorMarker)
io.flutter.embedding.engine.FlutterJNI: void onVsync(long,long,long)
org.webrtc.audio.WebRtcAudioTrackUtils: WebRtcAudioTrackUtils()
androidx.window.embedding.SplitPairFilter: boolean equals(java.lang.Object)
org.webrtc.RtpParameters$HeaderExtension: RtpParameters$HeaderExtension(java.lang.String,int,boolean)
org.webrtc.PeerConnection$SdpSemantics: org.webrtc.PeerConnection$SdpSemantics[] values()
org.webrtc.YuvConverter: org.webrtc.VideoFrame$I420Buffer convertInternal(org.webrtc.VideoFrame$TextureBuffer)
org.webrtc.voiceengine.WebRtcAudioTrack: void assertTrue(boolean)
com.google.firebase.firestore.core.ActivityScope$StopListenerSupportFragment: ActivityScope$StopListenerSupportFragment()
org.webrtc.Camera1Session$2: void onPreviewFrame(byte[],android.hardware.Camera)
androidx.window.core.Version: androidx.window.core.Version parse(java.lang.String)
org.webrtc.PeerConnection$RTCConfiguration: java.util.List getIceServers()
com.google.firebase.firestore.core.ViewSnapshot$SyncState: com.google.firebase.firestore.core.ViewSnapshot$SyncState valueOf(java.lang.String)
org.webrtc.VideoEncoder: boolean isHardwareEncoder()
androidx.window.embedding.ActivityStack: ActivityStack(java.util.List,boolean,int,kotlin.jvm.internal.DefaultConstructorMarker)
androidx.window.layout.SidecarAdapter$Companion: androidx.window.layout.DisplayFeature translate$window_release(androidx.window.sidecar.SidecarDisplayFeature,androidx.window.sidecar.SidecarDeviceState)
io.flutter.embedding.engine.systemchannels.PlatformChannel$SoundType: io.flutter.embedding.engine.systemchannels.PlatformChannel$SoundType[] values()
io.flutter.plugins.firebase.core.FlutterFirebasePluginRegistry: void registerPlugin(java.lang.String,io.flutter.plugins.firebase.core.FlutterFirebasePlugin)
org.webrtc.EncodedImage$Builder: org.webrtc.EncodedImage$Builder setEncodedWidth(int)
org.webrtc.AndroidVideoDecoder: void deliverByteFrame(int,android.media.MediaCodec$BufferInfo,int,java.lang.Integer)
com.cloudwebrtc.webrtc.utils.ConstraintsArray: com.cloudwebrtc.webrtc.utils.ConstraintsMap getMap(int)
org.webrtc.audio.JavaAudioDeviceModule$Builder: org.webrtc.audio.JavaAudioDeviceModule$Builder setUseHardwareNoiseSuppressor(boolean)
org.webrtc.MediaCodecWrapperFactoryImpl: org.webrtc.MediaCodecWrapper createByCodecName(java.lang.String)
com.cloudwebrtc.webrtc.PeerConnectionObserver: void rtpSenderSetParameters(java.lang.String,java.util.Map,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.MediaCodecWrapperFactoryImpl: MediaCodecWrapperFactoryImpl()
org.webrtc.NetworkMonitorAutoDetect: void setIncludeWifiDirect(boolean)
io.flutter.view.AccessibilityViewEmbedder: boolean onAccessibilityHoverEvent(int,android.view.MotionEvent)
org.webrtc.audio.WebRtcAudioUtils: java.lang.String deviceTypeToString(int)
org.webrtc.RtpTransceiver: org.webrtc.RtpTransceiver$RtpTransceiverDirection nativeCurrentDirection(long)
org.webrtc.SoftwareVideoDecoderFactory: org.webrtc.VideoCodecInfo[] getSupportedCodecs()
io.flutter.view.FlutterCallbackInformation: io.flutter.view.FlutterCallbackInformation lookupCallbackInformation(long)
org.webrtc.EglBase14Impl: org.webrtc.EglBase14Impl$Context getEglBaseContext()
com.cloudwebrtc.webrtc.utils.ObjectType: ObjectType(java.lang.String,int)
org.webrtc.PeerConnection$Observer: void onIceCandidate(org.webrtc.IceCandidate)
com.google.protobuf.FloatArrayList: FloatArrayList()
org.webrtc.RtpSender: org.webrtc.DtmfSender dtmf()
io.grpc.NameResolverProvider: NameResolverProvider()
io.grpc.ClientCall: ClientCall()
org.webrtc.EglBase10Impl: void checkIsNotReleased()
com.google.firestore.v1.BatchGetDocumentsRequest: BatchGetDocumentsRequest()
io.grpc.internal.MessageDeframer$State: io.grpc.internal.MessageDeframer$State valueOf(java.lang.String)
androidx.window.layout.HardwareFoldingFeature: androidx.window.layout.FoldingFeature$State getState()
io.flutter.embedding.engine.systemchannels.SettingsChannel$PlatformBrightness: io.flutter.embedding.engine.systemchannels.SettingsChannel$PlatformBrightness[] values()
io.flutter.embedding.engine.FlutterJNI: io.flutter.view.FlutterCallbackInformation nativeLookupCallbackInformation(long)
org.webrtc.HardwareVideoEncoder$1: HardwareVideoEncoder$1(org.webrtc.HardwareVideoEncoder)
androidx.window.layout.SidecarCompat$FirstAttachAdapter: void onViewDetachedFromWindow(android.view.View)
org.webrtc.audio.JavaAudioDeviceModule$AudioTrackStartErrorCode: org.webrtc.audio.JavaAudioDeviceModule$AudioTrackStartErrorCode[] values()
org.webrtc.TextureBufferImpl: org.webrtc.VideoFrame$TextureBuffer$Type getType()
org.webrtc.MediaCodecVideoDecoderFactory: org.webrtc.VideoCodecInfo[] getSupportedCodecs()
org.webrtc.EglRenderer: java.lang.String averageTimeAsString(long,int)
org.webrtc.PeerConnectionFactory$Builder: org.webrtc.PeerConnectionFactory$Builder setVideoEncoderFactory(org.webrtc.VideoEncoderFactory)
org.webrtc.MediaConstraints$KeyValuePair: MediaConstraints$KeyValuePair(java.lang.String,java.lang.String)
io.flutter.view.AccessibilityBridge$AccessibilityFeature: io.flutter.view.AccessibilityBridge$AccessibilityFeature valueOf(java.lang.String)
org.webrtc.audio.WebRtcAudioRecord: android.media.AudioRecord createAudioRecordOnLowerThanM(int,int,int,int,int)
android.support.v4.app.RemoteActionCompatParcelizer: androidx.core.app.RemoteActionCompat read(androidx.versionedparcelable.VersionedParcel)
org.webrtc.DefaultVideoEncoderFactory: org.webrtc.VideoEncoder createEncoder(org.webrtc.VideoCodecInfo)
org.webrtc.SoftwareVideoEncoderFactory: long nativeCreateEncoder(long,org.webrtc.VideoCodecInfo)
io.grpc.internal.GrpcUtil: GrpcUtil()
androidx.core.graphics.drawable.IconCompatParcelizer: IconCompatParcelizer()
androidx.window.embedding.EmbeddingAdapter: java.util.function.Predicate translateActivityPredicates(java.util.Set)
androidx.window.layout.HardwareFoldingFeature$Type$Companion: HardwareFoldingFeature$Type$Companion()
org.webrtc.voiceengine.WebRtcAudioRecord$AudioSamples: int getSampleRate()
org.webrtc.voiceengine.WebRtcAudioTrack: boolean stopPlayout()
org.webrtc.TextureBufferImpl: int getUnscaledWidth()
org.webrtc.SurfaceTextureHelper: void forceFrame()
com.google.protobuf.JavaType: com.google.protobuf.JavaType[] values()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void lambda$requestPermissions$0(java.util.ArrayList,com.cloudwebrtc.webrtc.utils.Callback,com.cloudwebrtc.webrtc.utils.Callback,java.lang.String[],int[])
org.webrtc.PlatformSoftwareVideoDecoderFactory$1: boolean test(java.lang.Object)
org.webrtc.TextureBufferImpl: TextureBufferImpl(int,int,org.webrtc.VideoFrame$TextureBuffer$Type,int,android.graphics.Matrix,android.os.Handler,org.webrtc.YuvConverter,java.lang.Runnable)
org.webrtc.CameraEnumerationAndroid$CaptureFormat: CameraEnumerationAndroid$CaptureFormat(int,int,int,int)
org.webrtc.PeerConnection$Observer: void onIceConnectionReceivingChange(boolean)
com.google.android.gms.common.api.internal.zzd: zzd()
io.flutter.plugins.firebase.core.GeneratedAndroidFirebaseCore$PigeonFirebaseOptions: GeneratedAndroidFirebaseCore$PigeonFirebaseOptions()
org.webrtc.PeerConnectionFactory: long nativeCreatePeerConnection(long,org.webrtc.PeerConnection$RTCConfiguration,org.webrtc.MediaConstraints,long,org.webrtc.SSLCertificateVerifier)
org.webrtc.RTCStats: java.lang.String getId()
com.cloudwebrtc.webrtc.GetUserMediaImpl$2: void invoke(java.lang.Object[])
org.webrtc.VideoEncoder$RateControlParameters: VideoEncoder$RateControlParameters(org.webrtc.VideoEncoder$BitrateAllocation,double)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void getTransceivers(java.lang.String,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.EglBase$-CC: org.webrtc.EglBase10 createEgl10(int[])
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback: void install()
io.flutter.embedding.android.DrawableSplashScreen$DrawableSplashScreenView: void setSplashDrawable(android.graphics.drawable.Drawable)
org.webrtc.voiceengine.WebRtcAudioRecord: boolean enableBuiltInAEC(boolean)
org.webrtc.RtpTransceiver$RtpTransceiverInit: java.util.List getStreamIds()
org.webrtc.RtpParameters$Encoding: boolean getActive()
com.google.firebase.firestore.util.AsyncQueue$TimerId: com.google.firebase.firestore.util.AsyncQueue$TimerId[] values()
org.webrtc.CameraCapturer$4: CameraCapturer$4(org.webrtc.CameraCapturer)
com.cloudwebrtc.webrtc.utils.ConstraintsMap: com.cloudwebrtc.webrtc.utils.ObjectType getType(java.lang.String)
androidx.window.embedding.SplitRuleParser: androidx.window.embedding.ActivityFilter parseActivityFilter(android.content.Context,android.content.res.XmlResourceParser)
org.webrtc.HardwareVideoEncoderFactory: HardwareVideoEncoderFactory(boolean,boolean)
androidx.window.R$id: R$id()
org.webrtc.audio.AudioDeviceModule: long getNativeAudioDeviceModulePointer()
org.webrtc.voiceengine.WebRtcAudioTrack$AudioTrackThread: WebRtcAudioTrack$AudioTrackThread(org.webrtc.voiceengine.WebRtcAudioTrack,java.lang.String)
org.webrtc.PeerConnection$IceConnectionState: org.webrtc.PeerConnection$IceConnectionState valueOf(java.lang.String)
org.webrtc.PeerConnectionFactory$InitializationOptions$Builder: org.webrtc.PeerConnectionFactory$InitializationOptions$Builder setFieldTrials(java.lang.String)
kotlinx.coroutines.JobNode: JobNode()
kotlinx.coroutines.scheduling.SchedulerTimeSource: SchedulerTimeSource()
org.webrtc.BitrateAdjuster: void reportEncodedFrame(int)
org.webrtc.audio.WebRtcAudioUtils: java.lang.String streamTypeToString(int)
org.webrtc.PeerConnection$Observer: void onStandardizedIceConnectionChange(org.webrtc.PeerConnection$IceConnectionState)
io.flutter.embedding.engine.renderer.SurfaceTextureWrapper: void updateTexImage()
org.webrtc.audio.WebRtcAudioEffects: android.media.audiofx.AudioEffect$Descriptor[] getAvailableEffects()
kotlin.jvm.internal.CallableReference: java.lang.String getSignature()
androidx.window.layout.FoldingFeature$OcclusionType: FoldingFeature$OcclusionType(java.lang.String)
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin$LifeCycleObserver: FlutterWebRTCPlugin$LifeCycleObserver(com.cloudwebrtc.webrtc.FlutterWebRTCPlugin)
com.google.firestore.admin.v1.Index$IndexField$ValueModeCase: com.google.firestore.admin.v1.Index$IndexField$ValueModeCase[] values()
com.cloudwebrtc.webrtc.record.AudioChannel: com.cloudwebrtc.webrtc.record.AudioChannel[] values()
org.webrtc.GlGenericDrawer$ShaderCallbacks: void onNewShader(org.webrtc.GlShader)
com.cloudwebrtc.webrtc.record.FrameCapturer: void lambda$onFrame$0()
org.webrtc.PeerConnection: org.webrtc.SessionDescription getRemoteDescription()
org.webrtc.audio.WebRtcAudioRecord: boolean startRecording()
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin: void onListen(java.lang.Object,io.flutter.plugin.common.EventChannel$EventSink)
com.cloudwebrtc.webrtc.utils.ConstraintsMap: java.util.ArrayList getListArray(java.lang.String)
org.webrtc.FileVideoCapturer: void changeCaptureFormat(int,int,int)
com.google.firestore.bundle.BundledQuery$Builder: BundledQuery$Builder()
androidx.window.embedding.ActivityRule: java.util.Set getFilters()
org.webrtc.NV21Buffer: int getWidth()
androidx.window.layout.WindowInfoTrackerImpl$windowLayoutInfo$1: void invokeSuspend$lambda-0(kotlinx.coroutines.channels.Channel,androidx.window.layout.WindowLayoutInfo)
io.flutter.embedding.engine.renderer.FlutterRenderer$DisplayFeatureState: io.flutter.embedding.engine.renderer.FlutterRenderer$DisplayFeatureState[] values()
org.webrtc.MediaStreamTrack$MediaType: org.webrtc.MediaStreamTrack$MediaType[] $values()
org.webrtc.DataChannel$Init: boolean getNegotiated()
org.webrtc.audio.JavaAudioDeviceModule$Builder: org.webrtc.audio.JavaAudioDeviceModule$Builder setUseHardwareAcousticEchoCanceler(boolean)
org.webrtc.TextureBufferImpl$1: void onRetain(org.webrtc.TextureBufferImpl)
com.google.firestore.v1.StructuredQuery$CompositeFilter$Operator: com.google.firestore.v1.StructuredQuery$CompositeFilter$Operator[] values()
com.google.firebase.database.collection.ImmutableSortedMap: ImmutableSortedMap()
org.webrtc.Camera2Session$CameraStateCallback: void onError(android.hardware.camera2.CameraDevice,int)
org.webrtc.CryptoOptions$Srtp: boolean getEnableEncryptedRtpHeaderExtensions()
io.grpc.stub.ClientCalls$StubType: io.grpc.stub.ClientCalls$StubType valueOf(java.lang.String)
org.webrtc.RtpTransceiver: void setCodecPreferences(java.util.List)
org.webrtc.Histogram: void addSample(int)
com.cloudwebrtc.webrtc.record.VideoFileRenderer: void onFrame(org.webrtc.VideoFrame)
org.webrtc.JavaI420Buffer: int getStrideV()
org.webrtc.NetworkMonitorAutoDetect$ConnectivityManagerDelegate: NetworkMonitorAutoDetect$ConnectivityManagerDelegate(android.net.ConnectivityManager,java.util.Set,java.lang.String)
org.webrtc.PeerConnection$ContinualGatheringPolicy: org.webrtc.PeerConnection$ContinualGatheringPolicy valueOf(java.lang.String)
org.webrtc.Camera2Enumerator: boolean isBackFacing(java.lang.String)
org.webrtc.PeerConnection$PeerConnectionState: org.webrtc.PeerConnection$PeerConnectionState fromNativeIndex(int)
org.webrtc.voiceengine.WebRtcAudioUtils: void logAudioDeviceInfo(java.lang.String,android.media.AudioManager)
org.webrtc.EglBase: void swapBuffers(long)
androidx.window.embedding.EmbeddingCompat$Companion: EmbeddingCompat$Companion(kotlin.jvm.internal.DefaultConstructorMarker)
com.cloudwebrtc.webrtc.StateProvider: boolean putLocalStream(java.lang.String,org.webrtc.MediaStream)
org.webrtc.JavaI420Buffer: org.webrtc.JavaI420Buffer wrap(int,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.lang.Runnable)
org.webrtc.RtpParameters$DegradationPreference: org.webrtc.RtpParameters$DegradationPreference valueOf(java.lang.String)
org.webrtc.CameraCapturer: void changeCaptureFormat(int,int,int)
org.webrtc.audio.WebRtcAudioUtils: WebRtcAudioUtils()
org.webrtc.audio.JavaAudioDeviceModule$Builder: org.webrtc.audio.JavaAudioDeviceModule createAudioDeviceModule()
org.webrtc.ThreadUtils$3: ThreadUtils$3(org.webrtc.ThreadUtils$1Result,java.util.concurrent.Callable,org.webrtc.ThreadUtils$1CaughtException,java.util.concurrent.CountDownLatch)
com.google.protobuf.GeneratedMessageLite: GeneratedMessageLite()
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper: org.webrtc.VideoCodecStatus setRates$lambda-8(com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper,org.webrtc.VideoEncoder$RateControlParameters)
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback: ImeSyncDeferringInsetsCallback(android.view.View,int,int)
io.flutter.embedding.engine.FlutterJNI: void dispatchSemanticsAction(int,io.flutter.view.AccessibilityBridge$Action,java.lang.Object)
androidx.window.embedding.ActivityRule: boolean getAlwaysExpand()
org.webrtc.VideoDecoder$DecodeInfo: VideoDecoder$DecodeInfo(boolean,long)
org.webrtc.NetworkMonitorAutoDetect$SimpleNetworkCallback: void onAvailable(android.net.Network)
org.webrtc.LibvpxVp8Encoder: long nativeCreateEncoder()
org.webrtc.EglBase10Impl$1FakeSurfaceHolder: EglBase10Impl$1FakeSurfaceHolder(org.webrtc.EglBase10Impl,android.view.Surface)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void peerConnectionDispose(java.lang.String)
com.cloudwebrtc.webrtc.PeerConnectionObserver: void onDataChannel(org.webrtc.DataChannel)
androidx.core.graphics.drawable.IconCompat: IconCompat()
org.webrtc.PeerConnection$IceGatheringState: org.webrtc.PeerConnection$IceGatheringState valueOf(java.lang.String)
io.flutter.embedding.engine.FlutterJNI: void dispatchEmptyPlatformMessage(java.lang.String,int)
org.webrtc.audio.JavaAudioDeviceModule$AudioRecordStartErrorCode: org.webrtc.audio.JavaAudioDeviceModule$AudioRecordStartErrorCode[] $values()
com.google.protobuf.FieldSet: FieldSet()
org.webrtc.VideoSource: long getNativeVideoTrackSource()
org.webrtc.PeerConnection: java.util.List getTransceivers()
org.webrtc.DataChannel$Init: DataChannel$Init()
org.webrtc.NetworkMonitor: org.webrtc.NetworkChangeDetector$ConnectionType getCurrentConnectionType()
org.webrtc.MediaSource$State: org.webrtc.MediaSource$State valueOf(java.lang.String)
androidx.window.layout.ActivityCompatHelperApi30: android.graphics.Rect maximumWindowBounds(android.app.Activity)
androidx.window.layout.ActivityCompatHelperApi30: android.graphics.Rect currentWindowBounds(android.app.Activity)
com.cloudwebrtc.webrtc.record.OutputAudioSamplesInterceptor: void attachCallback(java.lang.Integer,org.webrtc.audio.JavaAudioDeviceModule$SamplesReadyCallback)
androidx.core.app.RemoteActionCompatParcelizer: void write(androidx.core.app.RemoteActionCompat,androidx.versionedparcelable.VersionedParcel)
org.webrtc.FileVideoCapturer: void initialize(org.webrtc.SurfaceTextureHelper,android.content.Context,org.webrtc.CapturerObserver)
org.webrtc.HardwareVideoEncoder$BusyCount: HardwareVideoEncoder$BusyCount()
androidx.window.embedding.SplitInfo: java.lang.String toString()
org.webrtc.audio.WebRtcAudioRecord: void releaseAudioResources()
io.grpc.okhttp.OkHttpChannelProvider: OkHttpChannelProvider()
org.webrtc.EglBase10Impl$1FakeSurfaceHolder: void setSizeFromLayout()
com.google.firestore.admin.v1.Index$IndexField$ValueModeCase: com.google.firestore.admin.v1.Index$IndexField$ValueModeCase valueOf(java.lang.String)
androidx.window.layout.WindowInfoTrackerImpl$windowLayoutInfo$1: WindowInfoTrackerImpl$windowLayoutInfo$1(androidx.window.layout.WindowInfoTrackerImpl,android.app.Activity,kotlin.coroutines.Continuation)
com.cloudwebrtc.webrtc.record.AudioSamplesInterceptor: AudioSamplesInterceptor()
org.webrtc.PeerConnection: long createNativePeerConnectionObserver(org.webrtc.PeerConnection$Observer)
io.grpc.okhttp.internal.Protocol: io.grpc.okhttp.internal.Protocol[] values()
org.webrtc.NetworkMonitorAutoDetect$ConnectivityManagerDelegate: org.webrtc.NetworkChangeDetector$IPAddress[] getIPAddresses(android.net.LinkProperties)
org.webrtc.voiceengine.WebRtcAudioManager: boolean getStereoOutput()
io.flutter.plugin.platform.SingleViewPresentation: io.flutter.plugin.platform.SingleViewPresentation$PresentationState detachState()
org.webrtc.FrameCryptor$FrameCryptionState: org.webrtc.FrameCryptor$FrameCryptionState valueOf(java.lang.String)
org.webrtc.voiceengine.WebRtcAudioRecord: void logMainParametersExtended()
io.grpc.ManagedChannelBuilder: ManagedChannelBuilder()
org.webrtc.NV12Buffer: void release()
org.webrtc.YuvHelper: void I420Copy(java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,int)
org.webrtc.PeerConnectionFactory: void nativeInitializeFieldTrials(java.lang.String)
org.webrtc.EglRenderer: void addFrameListener(org.webrtc.EglRenderer$FrameListener,float,org.webrtc.RendererCommon$GlDrawer,boolean)
androidx.window.layout.SidecarWindowBackend$Companion: boolean isSidecarVersionSupported(androidx.window.core.Version)
kotlinx.coroutines.NodeList: NodeList()
org.webrtc.EglBase14Impl: void makeCurrent()
org.webrtc.RtcCertificatePem: org.webrtc.RtcCertificatePem generateCertificate(org.webrtc.PeerConnection$KeyType,long)
com.google.android.gms.signin.internal.zaa: zaa()
io.grpc.util.OutlierDetectionLoadBalancerProvider: boolean isAvailable()
org.webrtc.PeerConnection$ContinualGatheringPolicy: org.webrtc.PeerConnection$ContinualGatheringPolicy[] $values()
org.webrtc.Logging: void deleteInjectedLoggable()
com.cloudwebrtc.webrtc.record.VideoFileRenderer: void drainEncoder()
androidx.window.embedding.SplitController: java.util.Set getSplitRules()
io.flutter.embedding.android.FlutterView$ZeroSides: io.flutter.embedding.android.FlutterView$ZeroSides[] values()
org.webrtc.VideoFrame$I420Buffer: int getStrideY()
org.webrtc.HardwareVideoEncoderFactory: android.media.MediaCodecInfo findCodecForType(org.webrtc.VideoCodecMimeType)
org.webrtc.FrameCryptorKeyProvider: byte[] ratchetKey(java.lang.String,int)
androidx.window.layout.HardwareFoldingFeature$Type: java.lang.String toString()
org.webrtc.DynamicBitrateAdjuster: void setTargets(int,double)
com.google.firebase.firestore.core.CompositeFilter$Operator: com.google.firebase.firestore.core.CompositeFilter$Operator[] values()
com.google.protobuf.IntArrayList: IntArrayList()
androidx.window.layout.WindowMetricsCalculator: androidx.window.layout.WindowMetrics computeCurrentWindowMetrics(android.app.Activity)
kotlin.coroutines.jvm.internal.ContinuationImpl: kotlin.coroutines.Continuation intercepted()
androidx.window.layout.WindowMetricsCalculatorCompat: android.graphics.Rect computeWindowBoundsIceCreamSandwich$window_release(android.app.Activity)
org.webrtc.Camera1Capturer: void switchCamera(org.webrtc.CameraVideoCapturer$CameraSwitchHandler,java.lang.String)
androidx.window.embedding.ExtensionEmbeddingBackend: java.util.concurrent.CopyOnWriteArrayList getSplitChangeCallbacks()
org.webrtc.HardwareVideoEncoder: boolean isSemiPlanar(int)
androidx.window.embedding.ExtensionEmbeddingBackend: void unregisterSplitListenerForActivity(androidx.core.util.Consumer)
org.webrtc.PeerConnection: org.webrtc.PeerConnection$PeerConnectionState nativeConnectionState()
org.webrtc.AndroidVideoDecoder: void releaseCodecOnOutputThread()
org.webrtc.CameraCapturer$5: void run()
io.flutter.plugins.firebase.core.FlutterFirebasePlugin: com.google.android.gms.tasks.Task getPluginConstantsForFirebaseApp(com.google.firebase.FirebaseApp)
org.webrtc.EglBase10Impl$1FakeSurfaceHolder: void addCallback(android.view.SurfaceHolder$Callback)
org.webrtc.EglRenderer: void lambda$clearImage$6(float,float,float,float)
org.webrtc.AndroidVideoDecoder$DecodedTextureMetadata: AndroidVideoDecoder$DecodedTextureMetadata(long,java.lang.Integer)
androidx.window.layout.SidecarAdapter$Companion: int getRawSidecarDevicePosture(androidx.window.sidecar.SidecarDeviceState)
com.cloudwebrtc.webrtc.PeerConnectionObserver: void onIceCandidate(org.webrtc.IceCandidate)
com.google.firebase.firestore.model.MutableDocument$DocumentType: com.google.firebase.firestore.model.MutableDocument$DocumentType[] values()
com.cloudwebrtc.webrtc.utils.ConstraintsArray: com.cloudwebrtc.webrtc.utils.ObjectType getType(int)
androidx.window.core.Bounds: int getHeight()
com.google.protobuf.ExtensionSchema: ExtensionSchema()
org.webrtc.PeerConnection: void nativeRemoveLocalStream(long)
org.webrtc.DataChannel: boolean send(org.webrtc.DataChannel$Buffer)
androidx.window.layout.WindowInfoTracker$Companion: void reset()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void peerConnectionSetRemoteDescription(com.cloudwebrtc.webrtc.utils.ConstraintsMap,java.lang.String,io.flutter.plugin.common.MethodChannel$Result)
com.cloudwebrtc.webrtc.record.VideoFileRenderer: void renderFrameOnRenderThread(org.webrtc.VideoFrame)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$3: void onCreateFailure(java.lang.String)
com.google.firebase.appcheck.AppCheckTokenResult: AppCheckTokenResult()
org.webrtc.audio.WebRtcAudioTrack: void nativeGetPlayoutData(long,int)
org.webrtc.audio.WebRtcAudioManager: int getSampleRate(android.media.AudioManager)
org.webrtc.audio.WebRtcAudioTrack: boolean startPlayout()
io.flutter.embedding.engine.FlutterJNI: void nativeSetSemanticsEnabled(long,boolean)
org.webrtc.PeerConnection$Observer: void onIceCandidateError(org.webrtc.IceCandidateErrorEvent)
com.google.firestore.v1.Write: Write()
org.webrtc.RtpSender: org.webrtc.RtpParameters getParameters()
org.webrtc.Predicate: boolean test(java.lang.Object)
org.webrtc.voiceengine.WebRtcAudioManager: boolean isDeviceBlacklistedForOpenSLESUsage()
org.webrtc.PeerConnection$RTCConfiguration: int getAudioJitterBufferMaxPackets()
org.webrtc.PeerConnection$IceTransportsType: org.webrtc.PeerConnection$IceTransportsType valueOf(java.lang.String)
androidx.window.layout.FoldingFeature: androidx.window.layout.FoldingFeature$State getState()
org.webrtc.TimestampAligner: long getRtcTimeNanos()
org.webrtc.NetworkMonitor$2: void onNetworkDisconnect(long)
org.webrtc.PeerConnection: void nativeSetAudioPlayout(boolean)
io.flutter.embedding.engine.systemchannels.PlatformChannel$SystemUiOverlay: io.flutter.embedding.engine.systemchannels.PlatformChannel$SystemUiOverlay valueOf(java.lang.String)
org.webrtc.EglBase$-CC: org.webrtc.EglBase14 createEgl14(int[])
org.webrtc.ScreenCapturerAndroid: void dispose()
com.cloudwebrtc.webrtc.utils.AnyThreadSink: void error(java.lang.String,java.lang.String,java.lang.Object)
org.webrtc.ThreadUtils$4: java.lang.Object call()
androidx.window.layout.SidecarCompat$Companion: SidecarCompat$Companion(kotlin.jvm.internal.DefaultConstructorMarker)
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper: org.webrtc.VideoCodecStatus setRateAllocation(org.webrtc.VideoEncoder$BitrateAllocation,int)
androidx.window.embedding.ExtensionEmbeddingBackend$SplitListenerWrapper: void accept$lambda-1(androidx.window.embedding.ExtensionEmbeddingBackend$SplitListenerWrapper,java.util.List)
org.webrtc.WrappedNativeVideoEncoder: org.webrtc.VideoCodecStatus initEncode(org.webrtc.VideoEncoder$Settings,org.webrtc.VideoEncoder$Callback)
org.webrtc.Logging: Logging()
org.webrtc.Metrics$HistogramInfo: void addSample(int,int)
org.webrtc.PeerConnectionFactory: long nativeCreateLocalMediaStream(long,java.lang.String)
androidx.window.embedding.SplitController: androidx.window.embedding.SplitController getInstance()
org.webrtc.PeerConnection$TlsCertPolicy: org.webrtc.PeerConnection$TlsCertPolicy[] values()
androidx.window.layout.WindowMetricsCalculatorCompat: void getRectSizeFromDisplay(android.app.Activity,android.graphics.Rect)
org.webrtc.RtpSender: RtpSender(long)
org.webrtc.PeerConnection$RTCConfiguration: org.webrtc.PeerConnection$BundlePolicy getBundlePolicy()
com.google.firebase.firestore.Query$Direction: com.google.firebase.firestore.Query$Direction[] values()
org.webrtc.audio.WebRtcAudioRecord: java.lang.String lambda$scheduleLogRecordingConfigurationsTask$0(android.media.AudioRecord)
io.flutter.embedding.android.FlutterImageView$SurfaceKind: io.flutter.embedding.android.FlutterImageView$SurfaceKind[] values()
io.flutter.embedding.engine.FlutterJNI: void setAccessibilityDelegate(io.flutter.embedding.engine.FlutterJNI$AccessibilityDelegate)
org.webrtc.MediaCodecVideoDecoderFactory: boolean isH264HighProfileSupported(android.media.MediaCodecInfo)
io.flutter.embedding.engine.FlutterJNI: void onPreEngineRestart()
org.webrtc.voiceengine.WebRtcAudioUtils: void logAudioStateVolume(java.lang.String,android.media.AudioManager)
org.webrtc.PlatformSoftwareVideoDecoderFactory: org.webrtc.VideoCodecInfo[] getSupportedCodecs()
org.webrtc.VideoEncoder$CodecSpecificInfoH264: VideoEncoder$CodecSpecificInfoH264()
kotlin.jvm.internal.FunctionReference: boolean isExternal()
org.webrtc.MediaStreamTrack: java.lang.String nativeGetId(long)
com.cloudwebrtc.webrtc.PeerConnectionObserver: void onSelectedCandidatePairChanged(org.webrtc.CandidatePairChangeEvent)
io.flutter.embedding.engine.FlutterJNI: void nativeSurfaceCreated(long,android.view.Surface)
androidx.window.layout.HardwareFoldingFeature: androidx.window.layout.HardwareFoldingFeature$Type getType$window_release()
org.webrtc.NetworkMonitor: void nativeNotifyConnectionTypeChanged(long)
org.webrtc.RtpTransceiver$RtpTransceiverInit: int getDirectionNativeIndex()
org.webrtc.PeerConnection$IceServer: org.webrtc.PeerConnection$IceServer$Builder builder(java.lang.String)
org.webrtc.RendererCommon: android.graphics.Point getDisplaySize(org.webrtc.RendererCommon$ScalingType,float,int,int)
com.cloudwebrtc.webrtc.PeerConnectionObserver: void onCancel(java.lang.Object)
org.webrtc.EglBase10Impl: javax.microedition.khronos.egl.EGLContext createEglContext(javax.microedition.khronos.egl.EGLContext,javax.microedition.khronos.egl.EGLDisplay,javax.microedition.khronos.egl.EGLConfig,int)
org.webrtc.CameraEnumerationAndroid$CaptureFormat$FramerateRange: boolean equals(java.lang.Object)
org.webrtc.FrameCryptorKeyProvider: boolean nativeSetKey(long,java.lang.String,int,byte[])
org.webrtc.voiceengine.WebRtcAudioRecord: int channelCountToConfiguration(int)
androidx.window.embedding.ExtensionEmbeddingBackend: androidx.window.embedding.EmbeddingInterfaceCompat getEmbeddingExtension()
io.flutter.embedding.android.RenderMode: io.flutter.embedding.android.RenderMode valueOf(java.lang.String)
org.webrtc.audio.WebRtcAudioTrack: void doAudioTrackStateCallback(int)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void removeTrackForRendererById(java.lang.String)
org.webrtc.TimestampAligner: TimestampAligner()
com.google.firebase.firestore.remote.WatchChange$WatchTargetChangeType: com.google.firebase.firestore.remote.WatchChange$WatchTargetChangeType valueOf(java.lang.String)
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer: void setVideoTrack(org.webrtc.VideoTrack)
androidx.window.embedding.ActivityStack: ActivityStack(java.util.List,boolean)
org.webrtc.EncodedImage$Builder: org.webrtc.EncodedImage$Builder setCaptureTimeMs(long)
org.webrtc.PeerConnection$SignalingState: PeerConnection$SignalingState(java.lang.String,int)
org.webrtc.DataChannel$State: org.webrtc.DataChannel$State[] values()
org.webrtc.SurfaceEglRenderer: SurfaceEglRenderer(java.lang.String)
com.cloudwebrtc.webrtc.record.OutputAudioSamplesInterceptor: OutputAudioSamplesInterceptor(org.webrtc.audio.JavaAudioDeviceModule)
com.twilio.audioswitch.AudioDevice$BluetoothHeadset: AudioDevice$BluetoothHeadset()
org.webrtc.RtpReceiver: void dispose()
org.webrtc.voiceengine.WebRtcAudioUtils: void logDeviceInfo(java.lang.String)
org.webrtc.VideoEncoder: org.webrtc.VideoCodecStatus encode(org.webrtc.VideoFrame,org.webrtc.VideoEncoder$EncodeInfo)
com.google.firebase.firestore.proto.MaybeDocument$DocumentTypeCase: com.google.firebase.firestore.proto.MaybeDocument$DocumentTypeCase valueOf(java.lang.String)
org.webrtc.VideoEncoderFactory$-CC: org.webrtc.VideoEncoderFactory$VideoEncoderSelector $default$getEncoderSelector(org.webrtc.VideoEncoderFactory)
org.webrtc.HardwareVideoEncoder: org.webrtc.VideoEncoder$ScalingSettings getScalingSettings()
org.webrtc.NV21Buffer: void retain()
com.google.firebase.firestore.model.MutableDocument$DocumentState: com.google.firebase.firestore.model.MutableDocument$DocumentState valueOf(java.lang.String)
org.webrtc.PeerConnectionFactory: org.webrtc.VideoSource createVideoSource(boolean)
io.flutter.embedding.engine.FlutterJNI: void asyncWaitForVsync(long)
kotlin.coroutines.jvm.internal.SuspendLambda: int getArity()
com.cloudwebrtc.webrtc.utils.PermissionUtils$1: void onReceiveResult(int,android.os.Bundle)
org.webrtc.VideoTrack: VideoTrack(long)
org.webrtc.RTCStatsReport: org.webrtc.RTCStatsReport create(long,java.util.Map)
com.google.protobuf.CodedInputStream: CodedInputStream()
com.google.firebase.firestore.local.IndexManager$IndexType: com.google.firebase.firestore.local.IndexManager$IndexType valueOf(java.lang.String)
org.webrtc.EglBase10Impl$Context: long getNativeEglContext()
org.webrtc.PeerConnectionFactory$Builder: org.webrtc.PeerConnectionFactory createPeerConnectionFactory()
org.webrtc.voiceengine.WebRtcAudioEffects: boolean canUseNoiseSuppressor()
org.webrtc.VideoCodecInfo: java.util.Map getParams()
androidx.window.layout.SidecarCompat: void setExtensionCallback(androidx.window.layout.ExtensionInterfaceCompat$ExtensionCallbackInterface)
org.webrtc.voiceengine.BuildInfo: java.lang.String getDevice()
org.webrtc.CameraSession$CreateSessionCallback: void onFailure(org.webrtc.CameraSession$FailureType,java.lang.String)
org.webrtc.MediaStream: boolean addPreservedTrack(org.webrtc.VideoTrack)
com.cloudwebrtc.webrtc.utils.PermissionUtils$1: PermissionUtils$1(android.os.Handler,com.cloudwebrtc.webrtc.utils.PermissionUtils$Callback)
org.webrtc.voiceengine.WebRtcAudioRecord$AudioRecordStartErrorCode: org.webrtc.voiceengine.WebRtcAudioRecord$AudioRecordStartErrorCode[] values()
kotlin.jvm.internal.Lambda: Lambda(int)
com.cloudwebrtc.webrtc.PeerConnectionObserver: java.util.Map transceiverToMap(java.lang.String,org.webrtc.RtpTransceiver)
org.webrtc.PeerConnection$ContinualGatheringPolicy: PeerConnection$ContinualGatheringPolicy(java.lang.String,int)
org.webrtc.VideoSource: VideoSource(long)
org.webrtc.ThreadUtils: void awaitUninterruptibly(java.util.concurrent.CountDownLatch)
org.webrtc.Camera1Session$2: Camera1Session$2(org.webrtc.Camera1Session)
org.webrtc.GlShader: void setVertexAttribArray(java.lang.String,int,int,java.nio.FloatBuffer)
androidx.window.layout.SidecarCompat$TranslatingCallback: void onWindowLayoutChanged(android.os.IBinder,androidx.window.sidecar.SidecarWindowLayoutInfo)
org.webrtc.AudioDecoderFactoryFactory: long createNativeAudioDecoderFactory()
org.webrtc.PeerConnectionFactory$Builder: org.webrtc.PeerConnectionFactory$Builder setNetworkControllerFactoryFactory(org.webrtc.NetworkControllerFactoryFactory)
org.webrtc.CameraSession$-CC: int getDeviceOrientation(android.content.Context)
androidx.window.layout.HardwareFoldingFeature$Type$Companion: androidx.window.layout.HardwareFoldingFeature$Type getFOLD()
org.webrtc.WrappedNativeVideoDecoder: WrappedNativeVideoDecoder()
org.webrtc.AndroidVideoDecoder$FrameInfo: AndroidVideoDecoder$FrameInfo(long,int)
com.google.firebase.firestore.FirestoreRegistrar: java.util.List getComponents()
io.grpc.okhttp.OkHttpChannelProvider: io.grpc.ManagedChannelBuilder builderForTarget(java.lang.String)
org.webrtc.PeerConnection$RTCConfiguration: boolean getEnableDscp()
org.webrtc.voiceengine.WebRtcAudioManager: int getLowLatencyOutputFramesPerBuffer()
com.cloudwebrtc.webrtc.PeerConnectionObserver: void onAddStream(org.webrtc.MediaStream)
org.webrtc.TextureBufferImpl: void release()
kotlin.jvm.internal.FunctionReference: boolean equals(java.lang.Object)
com.google.firestore.v1.Target$Builder: Target$Builder()
org.webrtc.Camera2Session$SessionState: Camera2Session$SessionState(java.lang.String,int)
org.webrtc.PeerConnectionFactory$Builder: PeerConnectionFactory$Builder()
org.webrtc.PeerConnection: java.util.List getSenders()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void getSenders(java.lang.String,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.SurfaceViewRenderer: void surfaceDestroyed(android.view.SurfaceHolder)
com.cloudwebrtc.webrtc.GetUserMediaImpl: void getDisplayMedia(com.cloudwebrtc.webrtc.utils.ConstraintsMap,io.flutter.plugin.common.MethodChannel$Result,org.webrtc.MediaStream)
com.cloudwebrtc.webrtc.record.AudioTrackInterceptor: int write(byte[],int,int)
com.google.firestore.bundle.BundledQuery$LimitType: com.google.firestore.bundle.BundledQuery$LimitType valueOf(java.lang.String)
org.webrtc.voiceengine.WebRtcAudioTrack: void logMainParametersExtended()
org.webrtc.PeerConnectionFactory$ThreadInfo: PeerConnectionFactory$ThreadInfo(java.lang.Thread,int)
androidx.window.embedding.EmbeddingBackend: java.util.Set getSplitRules()
com.cloudwebrtc.webrtc.GetUserMediaImpl: com.cloudwebrtc.webrtc.StateProvider access$200(com.cloudwebrtc.webrtc.GetUserMediaImpl)
com.cloudwebrtc.webrtc.StateProvider: boolean putLocalTrack(java.lang.String,org.webrtc.MediaStreamTrack)
com.cloudwebrtc.webrtc.PeerConnectionObserver: org.webrtc.RtpParameters$Encoding mapToEncoding(java.util.Map)
org.webrtc.audio.JavaAudioDeviceModule$Builder: org.webrtc.audio.JavaAudioDeviceModule$Builder setAudioSource(int)
org.webrtc.Camera1Capturer: boolean isScreencast()
org.webrtc.RtpTransceiver: org.webrtc.RtpReceiver getReceiver()
kotlin.jvm.internal.FunctionReference: java.lang.String toString()
org.webrtc.PeerConnection$RTCConfiguration: java.lang.Boolean getCombinedAudioVideoBwe()
io.flutter.embedding.android.FlutterSplashView$SavedState: void writeToParcel(android.os.Parcel,int)
org.webrtc.PeerConnection$RTCConfiguration: java.lang.Integer getIceUnwritableMinChecks()
org.webrtc.audio.JavaAudioDeviceModule$AudioTrackStartErrorCode: org.webrtc.audio.JavaAudioDeviceModule$AudioTrackStartErrorCode valueOf(java.lang.String)
com.cloudwebrtc.webrtc.utils.AnyThreadSink: void post(java.lang.Runnable)
org.webrtc.TextureBufferImpl: int getWidth()
org.webrtc.NetworkMonitorAutoDetect$ConnectivityManagerDelegate: long getDefaultNetId()
org.webrtc.Size: int hashCode()
org.webrtc.DataChannel$Buffer: DataChannel$Buffer(java.nio.ByteBuffer,boolean)
org.webrtc.GlRectDrawer: void drawYuv(int[],float[],int,int,int,int,int,int)
org.webrtc.Camera2Enumerator: java.util.List convertFramerates(android.util.Range[],int)
org.webrtc.ThreadUtils$ThreadChecker: void checkIsOnValidThread()
org.webrtc.NativeLibrary$DefaultLoader: boolean load(java.lang.String)
org.webrtc.PeerConnection$RTCConfiguration: java.lang.Integer getScreencastMinBitrate()
org.webrtc.voiceengine.WebRtcAudioRecord$AudioRecordStartErrorCode: org.webrtc.voiceengine.WebRtcAudioRecord$AudioRecordStartErrorCode[] $values()
com.google.firebase.firestore.proto.UnknownDocument$Builder: UnknownDocument$Builder()
org.webrtc.audio.WebRtcAudioManager: boolean isLowLatencyOutputSupported(android.content.Context)
androidx.window.layout.ExtensionWindowLayoutInfoBackend: ExtensionWindowLayoutInfoBackend(androidx.window.extensions.layout.WindowLayoutComponent)
com.google.firestore.v1.StructuredAggregationQuery$Aggregation$Sum$Builder: StructuredAggregationQuery$Aggregation$Sum$Builder()
kotlin.jvm.internal.CallableReference: kotlin.reflect.KType getReturnType()
io.grpc.okhttp.internal.TlsVersion: io.grpc.okhttp.internal.TlsVersion valueOf(java.lang.String)
org.webrtc.CameraCapturer$2: CameraCapturer$2(org.webrtc.CameraCapturer)
com.google.firebase.firestore.model.FieldIndex$IndexOffset: FieldIndex$IndexOffset()
org.webrtc.PeerConnectionFactory$Options: boolean getDisableEncryption()
org.webrtc.SurfaceTextureHelper: org.webrtc.SurfaceTextureHelper create(java.lang.String,org.webrtc.EglBase$Context,boolean,org.webrtc.YuvConverter)
kotlin.jvm.internal.CallableReference: CallableReference(java.lang.Object)
org.webrtc.RtpReceiver: org.webrtc.RtpParameters getParameters()
org.webrtc.GlGenericDrawer$ShaderType: GlGenericDrawer$ShaderType(java.lang.String,int)
org.webrtc.PeerConnection$AdapterType: PeerConnection$AdapterType(java.lang.String,int,java.lang.Integer)
org.webrtc.Histogram: long nativeCreateEnumeration(java.lang.String,int)
org.webrtc.NetworkMonitorAutoDetect: org.webrtc.NetworkChangeDetector$ConnectionType getConnectionType(org.webrtc.NetworkMonitorAutoDetect$NetworkState)
org.webrtc.NativeAndroidVideoTrackSource: void setIsScreencast(boolean)
io.flutter.embedding.engine.FlutterJNI: void nativeUpdateRefreshRate(float)
org.webrtc.VideoProcessor: void setSink(org.webrtc.VideoSink)
androidx.window.layout.SidecarCompat: androidx.window.layout.SidecarAdapter access$getSidecarAdapter$p(androidx.window.layout.SidecarCompat)
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback$AnimationCallback: android.view.WindowInsets onProgress(android.view.WindowInsets,java.util.List)
org.webrtc.NativeAndroidVideoTrackSource: void nativeOnFrameCaptured(long,int,long,org.webrtc.VideoFrame$Buffer)
com.cloudwebrtc.webrtc.PeerConnectionObserver: java.lang.String getUIDForStream(org.webrtc.MediaStream)
org.webrtc.RTCStats: java.util.Map getMembers()
org.webrtc.WrappedNativeI420Buffer: int getStrideU()
org.webrtc.FrameCryptorFactory: org.webrtc.FrameCryptorKeyProvider createFrameCryptorKeyProvider(boolean,byte[],int,byte[])
com.google.protobuf.UnknownFieldSchema: UnknownFieldSchema()
io.flutter.embedding.engine.systemchannels.PlatformChannel$SystemUiOverlay: io.flutter.embedding.engine.systemchannels.PlatformChannel$SystemUiOverlay[] values()
androidx.window.embedding.SplitPairRule: boolean equals(java.lang.Object)
org.webrtc.NetworkMonitorAutoDetect: org.webrtc.NetworkMonitorAutoDetect$NetworkState getCurrentNetworkState()
org.webrtc.RtpParameters$Codec: java.lang.Integer getClockRate()
com.google.firestore.v1.BatchGetDocumentsResponse: BatchGetDocumentsResponse()
org.webrtc.audio.WebRtcAudioRecord: int logRecordingConfigurations(android.media.AudioRecord,boolean)
org.webrtc.voiceengine.WebRtcAudioTrack: void nativeGetPlayoutData(int,long)
com.google.firestore.v1.StructuredQuery$UnaryFilter$Builder: StructuredQuery$UnaryFilter$Builder()
androidx.window.layout.WindowMetrics: android.graphics.Rect getBounds()
io.flutter.embedding.engine.FlutterJNI: void onFirstFrame()
org.webrtc.audio.WebRtcAudioTrack: android.media.AudioAttributes getAudioAttributes(android.media.AudioAttributes)
org.webrtc.MediaCodecWrapperFactoryImpl$MediaCodecWrapperImpl: int dequeueOutputBuffer(android.media.MediaCodec$BufferInfo,long)
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor: boolean handleMethodCall(io.flutter.plugin.common.MethodCall,io.flutter.plugin.common.MethodChannel$Result)
com.cloudwebrtc.webrtc.PeerConnectionObserver: java.lang.String transceiverDirectionString(org.webrtc.RtpTransceiver$RtpTransceiverDirection)
io.flutter.embedding.engine.renderer.SurfaceTextureWrapper: void attachToGLContext(int)
io.flutter.embedding.engine.FlutterJNI: void nativeLoadDartDeferredLibrary(long,int,java.lang.String[])
org.webrtc.PeerConnectionFactory: void onWorkerThreadReady()
androidx.window.layout.HardwareFoldingFeature$Companion: HardwareFoldingFeature$Companion(kotlin.jvm.internal.DefaultConstructorMarker)
io.flutter.view.AccessibilityViewEmbedder: android.view.accessibility.AccessibilityNodeInfo convertToFlutterNode(android.view.accessibility.AccessibilityNodeInfo,int,android.view.View)
org.webrtc.Logging: void nativeEnableLogThreads()
org.webrtc.EglBase10Impl: void createSurface(android.view.Surface)
org.webrtc.GlTextureFrameBuffer: GlTextureFrameBuffer(int)
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback: android.view.WindowInsetsAnimation$Callback getAnimationCallback()
org.webrtc.RtpTransceiver: org.webrtc.RtpTransceiver$RtpTransceiverDirection getDirection()
org.webrtc.SurfaceTextureHelper: void lambda$forceFrame$3()
androidx.window.layout.FoldingFeature$OcclusionType: java.lang.String toString()
org.webrtc.BaseBitrateAdjuster: int getAdjustedBitrateBps()
org.webrtc.Histogram: org.webrtc.Histogram createEnumeration(java.lang.String,int)
org.webrtc.RtpCapabilities$CodecCapability: java.util.Map getParameters()
org.webrtc.VideoEncoderFactory$VideoEncoderSelector: org.webrtc.VideoCodecInfo onAvailableBitrate(int)
com.google.android.gms.internal.common.zzc: zzc()
org.webrtc.RTCStats: org.webrtc.RTCStats create(long,java.lang.String,java.lang.String,java.util.Map)
com.cloudwebrtc.webrtc.GetUserMediaImpl: java.lang.String getSourceIdConstraint(com.cloudwebrtc.webrtc.utils.ConstraintsMap)
androidx.window.layout.SidecarCompat$DistinctElementCallback: void onWindowLayoutChanged(android.app.Activity,androidx.window.layout.WindowLayoutInfo)
androidx.window.layout.HardwareFoldingFeature: boolean isSeparating()
org.webrtc.Histogram: void nativeAddSample(long,int)
io.grpc.ManagedChannel: ManagedChannel()
androidx.window.embedding.ExtensionEmbeddingBackend: boolean isSplitSupported()
org.webrtc.NetworkMonitorAutoDetect: org.webrtc.NetworkChangeDetector$ConnectionType getCurrentConnectionType()
com.google.firebase.firestore.model.FieldIndex: FieldIndex()
org.webrtc.Logging$Severity: org.webrtc.Logging$Severity[] $values()
org.webrtc.MediaStreamTrack: boolean enabled()
io.flutter.embedding.engine.mutatorsstack.FlutterMutatorsStack$FlutterMutatorType: io.flutter.embedding.engine.mutatorsstack.FlutterMutatorsStack$FlutterMutatorType valueOf(java.lang.String)
com.google.firestore.v1.StructuredQuery$Projection: StructuredQuery$Projection()
org.webrtc.EncodedImage$FrameType: org.webrtc.EncodedImage$FrameType fromNativeIndex(int)
org.webrtc.EglRenderer: void addFrameListener(org.webrtc.EglRenderer$FrameListener,float,org.webrtc.RendererCommon$GlDrawer)
androidx.window.layout.WindowMetrics: boolean equals(java.lang.Object)
com.cloudwebrtc.webrtc.record.AudioTrackInterceptor: int getBufferCapacityInFrames()
androidx.window.embedding.ExtensionEmbeddingBackend$Companion: ExtensionEmbeddingBackend$Companion()
com.cloudwebrtc.webrtc.record.AudioSamplesInterceptor: void detachCallback(java.lang.Integer)
org.webrtc.EglRenderer: void releaseEglSurface(java.lang.Runnable)
com.google.firestore.v1.Document$Builder: Document$Builder()
org.webrtc.NetworkChangeDetector$Observer: java.lang.String getFieldTrialsString()
org.webrtc.SurfaceViewRenderer: void setScalingType(org.webrtc.RendererCommon$ScalingType,org.webrtc.RendererCommon$ScalingType)
io.grpc.Context$DirectExecutor: io.grpc.Context$DirectExecutor[] values()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void getUserMedia(com.cloudwebrtc.webrtc.utils.ConstraintsMap,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.audio.LowLatencyAudioBufferManager: LowLatencyAudioBufferManager()
org.webrtc.voiceengine.WebRtcAudioManager$VolumeLogger$LogVolumeTask: WebRtcAudioManager$VolumeLogger$LogVolumeTask(org.webrtc.voiceengine.WebRtcAudioManager$VolumeLogger,int,int)
androidx.window.embedding.SplitController: void registerRule(androidx.window.embedding.EmbeddingRule)
org.webrtc.audio.WebRtcAudioTrack: int getStreamMaxVolume()
org.webrtc.CameraSession$-CC: org.webrtc.VideoFrame$TextureBuffer createTextureBufferWithModifiedTransformMatrix(org.webrtc.TextureBufferImpl,boolean,int)
androidx.window.embedding.SplitInfo: int hashCode()
org.webrtc.MediaStream: void removeAudioTrack(long)
com.cloudwebrtc.webrtc.record.AudioSamplesInterceptor: void onWebRtcAudioRecordSamplesReady(org.webrtc.audio.JavaAudioDeviceModule$AudioSamples)
org.webrtc.EncodedImage$FrameType: EncodedImage$FrameType(java.lang.String,int,int)
org.webrtc.audio.WebRtcAudioTrack$AudioTrackThread: void run()
kotlinx.coroutines.internal.LockFreeLinkedListHead: LockFreeLinkedListHead()
io.flutter.embedding.android.FlutterView$ZeroSides: io.flutter.embedding.android.FlutterView$ZeroSides valueOf(java.lang.String)
org.webrtc.ScreenCapturerAndroid: void startCapture(int,int,int)
com.cloudwebrtc.webrtc.PeerConnectionObserver: java.util.Map rtpSenderToMap(org.webrtc.RtpSender)
androidx.window.embedding.ExtensionEmbeddingBackend$Companion: androidx.window.embedding.ExtensionEmbeddingBackend getInstance()
kotlinx.coroutines.CancelHandler: CancelHandler()
org.webrtc.MediaSource: MediaSource(long)
org.webrtc.EncodedImage: void release()
org.webrtc.NetworkMonitorAutoDetect: long getDefaultNetId()
org.webrtc.CameraVideoCapturer$CameraStatistics: void addFrame()
org.webrtc.FrameCryptor: void dispose()
org.webrtc.PeerConnection$BundlePolicy: org.webrtc.PeerConnection$BundlePolicy[] values()
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer: void setStream(org.webrtc.MediaStream,java.lang.String)
kotlin.reflect.KVisibility: kotlin.reflect.KVisibility valueOf(java.lang.String)
io.flutter.embedding.engine.mutatorsstack.FlutterMutatorsStack: void pushClipRect(int,int,int,int)
org.webrtc.SurfaceViewRenderer: java.lang.String getResourceName()
org.webrtc.Camera1Enumerator: Camera1Enumerator()
com.google.firestore.v1.ListenResponse: ListenResponse()
org.webrtc.RtcCertificatePem: org.webrtc.RtcCertificatePem generateCertificate(org.webrtc.PeerConnection$KeyType)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void streamDispose(org.webrtc.MediaStream)
kotlin.internal.PlatformImplementations: PlatformImplementations()
androidx.window.embedding.EmbeddingRule: EmbeddingRule()
org.webrtc.SoftwareVideoEncoderFactory$1: boolean isHardwareEncoder()
org.webrtc.HardwareVideoEncoder: org.webrtc.VideoCodecStatus encode(org.webrtc.VideoFrame,org.webrtc.VideoEncoder$EncodeInfo)
org.webrtc.PeerConnection: boolean nativeAddIceCandidate(java.lang.String,int,java.lang.String)
com.google.common.util.concurrent.DirectExecutor: com.google.common.util.concurrent.DirectExecutor[] values()
io.grpc.internal.GzipInflatingBuffer$State: io.grpc.internal.GzipInflatingBuffer$State valueOf(java.lang.String)
org.webrtc.WebRtcClassLoader: WebRtcClassLoader()
androidx.window.embedding.ExtensionEmbeddingBackend: void access$setGlobalInstance$cp(androidx.window.embedding.ExtensionEmbeddingBackend)
androidx.window.layout.WindowMetricsCalculator$Companion: WindowMetricsCalculator$Companion()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$1: void onSetSuccess()
com.cloudwebrtc.webrtc.GetUserMediaImpl: void removeVideoCapturerSync(java.lang.String)
org.webrtc.audio.WebRtcAudioRecord: boolean isAudioConfigVerified()
androidx.window.embedding.SplitRuleParser: androidx.window.embedding.SplitPairRule parseSplitPairRule(android.content.Context,android.content.res.XmlResourceParser)
io.grpc.okhttp.internal.CipherSuite: io.grpc.okhttp.internal.CipherSuite[] values()
io.grpc.internal.PickFirstLoadBalancerProvider: io.grpc.NameResolver$ConfigOrError parseLoadBalancingPolicyConfig(java.util.Map)
org.webrtc.VideoTrack: boolean shouldReceive()
org.webrtc.EglRenderer$ErrorCallback: void onGlOutOfMemory()
com.cloudwebrtc.webrtc.record.VideoFileRenderer: void lambda$onWebRtcAudioRecordSamplesReady$4(org.webrtc.audio.JavaAudioDeviceModule$AudioSamples)
kotlin.UninitializedPropertyAccessException: UninitializedPropertyAccessException()
kotlin.random.Random: Random()
kotlin.jvm.internal.CallableReference: kotlin.reflect.KCallable getReflected()
org.webrtc.JavaI420Buffer: int getWidth()
org.webrtc.SurfaceTextureHelper: void updateTexImage()
com.google.firebase.firestore.util.AsyncQueue$TimerId: com.google.firebase.firestore.util.AsyncQueue$TimerId valueOf(java.lang.String)
org.webrtc.CameraEnumerator: boolean isBackFacing(java.lang.String)
io.flutter.embedding.engine.FlutterJNI: void removeEngineLifecycleListener(io.flutter.embedding.engine.FlutterEngine$EngineLifecycleListener)
org.webrtc.SurfaceViewRenderer: void init(org.webrtc.EglBase$Context,org.webrtc.RendererCommon$RendererEvents,int[],org.webrtc.RendererCommon$GlDrawer)
org.webrtc.RtpCapabilities$CodecCapability: java.lang.Integer getNumChannels()
android.support.v4.app.RemoteActionCompatParcelizer: void write(androidx.core.app.RemoteActionCompat,androidx.versionedparcelable.VersionedParcel)
org.webrtc.DtmfSender: DtmfSender(long)
org.webrtc.SimulcastVideoEncoder: long nativeCreateEncoder(org.webrtc.VideoEncoderFactory,org.webrtc.VideoEncoderFactory,org.webrtc.VideoCodecInfo)
org.webrtc.MediaCodecWrapper: android.view.Surface createInputSurface()
org.webrtc.ThreadUtils$4: ThreadUtils$4(java.lang.Runnable)
androidx.lifecycle.ReportFragment$LifecycleCallbacks: ReportFragment$LifecycleCallbacks()
androidx.window.core.Bounds: int hashCode()
org.webrtc.NetworkControllerFactoryFactory: long createNativeNetworkControllerFactory()
org.webrtc.RtpParameters$Rtcp: java.lang.String getCname()
androidx.window.core.Version: Version(int,int,int,java.lang.String,kotlin.jvm.internal.DefaultConstructorMarker)
org.webrtc.PeerConnectionFactory: org.webrtc.PeerConnection createPeerConnection(java.util.List,org.webrtc.MediaConstraints,org.webrtc.PeerConnection$Observer)
org.webrtc.RtpParameters$Codec: java.util.Map getParameters()
org.webrtc.ScreenCapturerAndroid: boolean isScreencast()
org.webrtc.JavaI420Buffer: java.nio.ByteBuffer getDataY()
com.cloudwebrtc.webrtc.audio.AudioSwitchManager: void lambda$stop$4()
org.webrtc.NetworkMonitorAutoDetect$WifiDirectManagerDelegate: void onWifiP2pStateChange(int)
io.flutter.embedding.engine.FlutterJNI: java.lang.String getObservatoryUri()
kotlinx.coroutines.EventLoop: EventLoop()
com.google.firebase.firestore.DocumentSnapshot$ServerTimestampBehavior: com.google.firebase.firestore.DocumentSnapshot$ServerTimestampBehavior[] values()
io.grpc.Status$Code: io.grpc.Status$Code[] values()
org.webrtc.MediaCodecWrapper: java.nio.ByteBuffer getInputBuffer(int)
org.webrtc.audio.JavaAudioDeviceModule$Builder: org.webrtc.audio.JavaAudioDeviceModule$Builder setUseLowLatency(boolean)
org.webrtc.NetworkMonitor: void addNetworkObserver(org.webrtc.NetworkMonitor$NetworkObserver)
org.webrtc.NativeLibraryLoader: boolean load(java.lang.String)
org.webrtc.VideoEncoder: org.webrtc.VideoEncoder$EncoderInfo getEncoderInfo()
io.flutter.embedding.engine.renderer.SurfaceTextureWrapper: void release()
org.webrtc.EglBase10Impl$1FakeSurfaceHolder: void setFixedSize(int,int)
org.webrtc.EglBase$-CC: org.webrtc.EglBase create()
org.webrtc.EglBase: void swapBuffers()
org.webrtc.NetworkMonitorAutoDetect$ConnectivityManagerDelegate: NetworkMonitorAutoDetect$ConnectivityManagerDelegate(android.content.Context,java.util.Set,java.lang.String)
androidx.window.layout.ExtensionWindowLayoutInfoBackend$MulticastConsumer: void accept(androidx.window.extensions.layout.WindowLayoutInfo)
org.webrtc.RtpTransceiver$RtpTransceiverInit: java.util.List getSendEncodings()
org.webrtc.NativeCapturerObserver: void onCapturerStarted(boolean)
org.webrtc.MediaStream: boolean nativeRemoveAudioTrack(long,long)
org.webrtc.FrameCryptor: long nativeSetObserver(long,org.webrtc.FrameCryptor$Observer)
org.webrtc.audio.WebRtcAudioRecord: void setNativeAudioRecord(long)
org.webrtc.audio.WebRtcAudioEffects: boolean setAEC(boolean)
org.webrtc.VideoProcessor$-CC: void $default$onFrameCaptured(org.webrtc.VideoProcessor,org.webrtc.VideoFrame,org.webrtc.VideoProcessor$FrameAdaptationParameters)
com.cloudwebrtc.webrtc.GetUserMediaImpl: void removeVideoCapturer(java.lang.String)
org.webrtc.FileVideoCapturer$1: FileVideoCapturer$1(org.webrtc.FileVideoCapturer)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$2: void onCreateFailure(java.lang.String)
com.cloudwebrtc.webrtc.GetUserMediaImpl$1: void invoke(java.lang.Object[])
org.webrtc.MediaCodecUtils: boolean isHardwareAccelerated(android.media.MediaCodecInfo)
org.webrtc.HardwareVideoEncoder: void fillInputBuffer(java.nio.ByteBuffer,org.webrtc.VideoFrame$Buffer)
org.webrtc.NetworkMonitorAutoDetect: boolean isReceiverRegisteredForTesting()
org.webrtc.PeerConnectionFactory: long nativeCreateVideoTrack(long,java.lang.String,long)
org.webrtc.voiceengine.WebRtcAudioUtils: boolean isAutomaticGainControlSupported()
kotlin.jvm.internal.CallableReference: java.lang.Object getBoundReceiver()
org.webrtc.TextureBufferImpl$RefCountMonitor: void onDestroy(org.webrtc.TextureBufferImpl)
org.webrtc.NV21Buffer: NV21Buffer(byte[],int,int,java.lang.Runnable)
androidx.window.layout.WindowMetricsCalculator$Companion$overrideDecorator$1: WindowMetricsCalculator$Companion$overrideDecorator$1(java.lang.Object)
com.cloudwebrtc.webrtc.PeerConnectionObserver: java.util.Map mediaTrackToMap(org.webrtc.MediaStreamTrack)
kotlin.jvm.internal.CallableReference: java.util.List getAnnotations()
com.cloudwebrtc.webrtc.GetUserMediaImpl: com.cloudwebrtc.webrtc.utils.ConstraintsMap getUserVideo(com.cloudwebrtc.webrtc.utils.ConstraintsMap,org.webrtc.MediaStream)
androidx.window.layout.WindowMetricsCalculatorCompat: android.graphics.Point getRealSizeForDisplay$window_release(android.view.Display)
org.webrtc.VideoFrame$I420Buffer: java.nio.ByteBuffer getDataY()
org.webrtc.PeerConnectionFactory$InitializationOptions: org.webrtc.PeerConnectionFactory$InitializationOptions$Builder builder(android.content.Context)
io.grpc.okhttp.OkHttpFrameLogger$Direction: io.grpc.okhttp.OkHttpFrameLogger$Direction[] values()
androidx.window.embedding.SplitRule: int hashCode()
org.webrtc.CameraVideoCapturer$CameraSwitchHandler: void onCameraSwitchDone(boolean)
io.flutter.embedding.engine.systemchannels.PlatformChannel$SoundType: io.flutter.embedding.engine.systemchannels.PlatformChannel$SoundType valueOf(java.lang.String)
com.cloudwebrtc.webrtc.record.VideoFileRenderer: void onWebRtcAudioRecordSamplesReady(org.webrtc.audio.JavaAudioDeviceModule$AudioSamples)
io.grpc.LoadBalancer$Subchannel: LoadBalancer$Subchannel()
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer: void onCancel(java.lang.Object)
org.webrtc.EglRenderer$HandlerWithExceptionCallback: EglRenderer$HandlerWithExceptionCallback(android.os.Looper,java.lang.Runnable)
io.flutter.embedding.engine.mutatorsstack.FlutterMutatorsStack: java.util.List getFinalClippingPaths()
org.webrtc.VideoEncoderFactory$-CC: org.webrtc.VideoCodecInfo[] $default$getImplementations(org.webrtc.VideoEncoderFactory)
com.google.firestore.v1.ExistenceFilter: ExistenceFilter()
org.webrtc.AddIceObserver: void onAddFailure(java.lang.String)
org.webrtc.MediaStreamTrack$State: org.webrtc.MediaStreamTrack$State valueOf(java.lang.String)
com.google.firestore.v1.BatchGetDocumentsResponse$ResultCase: com.google.firestore.v1.BatchGetDocumentsResponse$ResultCase[] values()
io.grpc.okhttp.OkHttpChannelProvider: boolean isAvailable()
androidx.window.embedding.SplitInfo: float getSplitRatio()
com.cloudwebrtc.webrtc.utils.ConstraintsMap: void putString(java.lang.String,java.lang.String)
org.webrtc.CameraCapturer: void switchCameraInternal(org.webrtc.CameraVideoCapturer$CameraSwitchHandler,java.lang.String)
com.cloudwebrtc.webrtc.record.AudioTrackInterceptor: int getPlayState()
com.google.firestore.v1.ArrayValue$Builder: ArrayValue$Builder()
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper: org.webrtc.VideoCodecStatus setRateAllocation$lambda-3(com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper,org.webrtc.VideoEncoder$BitrateAllocation,int)
org.webrtc.PeerConnection: boolean startRtcEventLog(int,int)
org.webrtc.VideoTrack: boolean nativeGetShouldReceive(long)
org.webrtc.HardwareVideoEncoderFactory: boolean isHardwareSupportedInCurrentSdkVp9(android.media.MediaCodecInfo)
org.webrtc.EglBase10Impl$1FakeSurfaceHolder: void unlockCanvasAndPost(android.graphics.Canvas)
org.webrtc.CameraEnumerationAndroid$CaptureFormat: int hashCode()
com.cloudwebrtc.webrtc.record.AudioTrackInterceptor: void play()
io.grpc.internal.DnsNameResolver$JdkAddressResolver: io.grpc.internal.DnsNameResolver$JdkAddressResolver[] values()
org.webrtc.SessionDescription$Type: org.webrtc.SessionDescription$Type fromCanonicalForm(java.lang.String)
com.google.firebase.firestore.remote.WatchChangeAggregator$BloomFilterApplicationStatus: com.google.firebase.firestore.remote.WatchChangeAggregator$BloomFilterApplicationStatus valueOf(java.lang.String)
org.webrtc.NetworkMonitorAutoDetect$NetworkState: int getUnderlyingNetworkSubtypeForVpn()
org.webrtc.NV12Buffer: NV12Buffer(int,int,int,int,java.nio.ByteBuffer,java.lang.Runnable)
org.webrtc.FrameCryptor: void nativeUnSetObserver(long)
androidx.window.embedding.ActivityRule: boolean equals(java.lang.Object)
androidx.window.core.Bounds: Bounds(android.graphics.Rect)
org.webrtc.EglBase14Impl$Context: android.opengl.EGLContext getRawContext()
androidx.window.embedding.ActivityStack: boolean equals(java.lang.Object)
androidx.window.layout.SidecarCompat: void unregisterComponentCallback(android.app.Activity)
io.flutter.embedding.engine.FlutterJNI: void nativeSurfaceChanged(long,int,int)
com.cloudwebrtc.webrtc.utils.ConstraintsMap: ConstraintsMap(java.util.Map)
org.webrtc.PeerConnection: org.webrtc.PeerConnection$PeerConnectionState connectionState()
org.webrtc.EglRenderer: void removeFrameListener(org.webrtc.EglRenderer$FrameListener)
io.flutter.view.AccessibilityBridge$StringAttributeType: io.flutter.view.AccessibilityBridge$StringAttributeType valueOf(java.lang.String)
com.cloudwebrtc.webrtc.utils.EglUtils: org.webrtc.EglBase$Context getRootEglBaseContext()
org.webrtc.CameraEnumerator: java.util.List getSupportedFormats(java.lang.String)
kotlin.jvm.internal.FunctionReference: int getArity()
kotlin.jvm.internal.CallableReference: kotlin.reflect.KCallable compute()
com.cloudwebrtc.webrtc.R$dimen: R$dimen()
org.webrtc.RtpCapabilities: java.util.List getHeaderExtensions()
org.webrtc.RtpParameters: java.util.List getHeaderExtensions()
androidx.window.layout.WindowMetricsCalculator$-CC: void overrideDecorator(androidx.window.layout.WindowMetricsCalculatorDecorator)
org.webrtc.ScreenCapturerAndroid$2: void run()
io.flutter.plugins.firebase.core.FlutterFirebasePluginRegistry: com.google.android.gms.tasks.Task getPluginConstantsForFirebaseApp(com.google.firebase.FirebaseApp)
com.cloudwebrtc.webrtc.record.AudioTrackInterceptor: AudioTrackInterceptor(android.media.AudioTrack,org.webrtc.audio.JavaAudioDeviceModule$SamplesReadyCallback)
io.grpc.internal.PickFirstLoadBalancerProvider: java.lang.String getPolicyName()
com.google.firestore.admin.v1.Index$IndexField$ArrayConfig: com.google.firestore.admin.v1.Index$IndexField$ArrayConfig[] values()
org.webrtc.VideoSource: org.webrtc.CapturerObserver getCapturerObserver()
org.webrtc.SurfaceViewRenderer: void postOrRun(java.lang.Runnable)
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback: boolean access$302(io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback,boolean)
org.webrtc.PeerConnection$RTCConfiguration: org.webrtc.CryptoOptions getCryptoOptions()
org.webrtc.audio.WebRtcAudioUtils: java.lang.String getThreadInfo()
org.webrtc.VideoFrameDrawer: VideoFrameDrawer()
com.cloudwebrtc.webrtc.PeerConnectionObserver: void removeTrack(java.lang.String,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.voiceengine.WebRtcAudioEffects: void release()
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor: void keyProviderSetKey(java.util.Map,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.VideoTrack: void nativeRemoveSink(long,long)
com.google.firebase.platforminfo.LibraryVersion: LibraryVersion()
androidx.window.layout.WindowLayoutInfo: boolean equals(java.lang.Object)
io.flutter.plugins.firebase.core.GeneratedAndroidFirebaseCore: GeneratedAndroidFirebaseCore()
com.google.firestore.v1.DocumentTransform$FieldTransform$ServerValue: com.google.firestore.v1.DocumentTransform$FieldTransform$ServerValue valueOf(java.lang.String)
com.cloudwebrtc.webrtc.audio.AudioSwitchManager: void selectAudioOutput(java.lang.Class)
org.webrtc.audio.WebRtcAudioRecord$1: WebRtcAudioRecord$1(java.util.concurrent.atomic.AtomicInteger)
org.webrtc.ScreenCapturerAndroid$1: ScreenCapturerAndroid$1(org.webrtc.ScreenCapturerAndroid)
org.webrtc.VideoDecoder$-CC: long $default$createNativeVideoDecoder(org.webrtc.VideoDecoder)
io.flutter.embedding.engine.FlutterJNI: void nativeRunBundleAndSnapshotFromLibrary(long,java.lang.String,java.lang.String,java.lang.String,android.content.res.AssetManager,java.util.List)
org.webrtc.NetworkChangeDetector$NetworkInformation: org.webrtc.NetworkChangeDetector$IPAddress[] getIpAddresses()
org.webrtc.NetworkMonitorAutoDetect$NetworkState: int getNetworkSubType()
io.flutter.embedding.engine.FlutterJNI: void onEndFrame()
com.cloudwebrtc.webrtc.FlutterRTCVideoRenderer: void listenRendererEvents()
kotlinx.coroutines.CoroutineStart: kotlinx.coroutines.CoroutineStart valueOf(java.lang.String)
org.webrtc.audio.WebRtcAudioTrackUtils: void detachOutputCallback(org.webrtc.audio.JavaAudioDeviceModule)
io.grpc.internal.ClientTransportFactory$ClientTransportOptions: ClientTransportFactory$ClientTransportOptions()
org.webrtc.audio.WebRtcAudioUtils: java.lang.String channelMaskToString(int)
org.webrtc.DtmfSender: void dispose()
kotlin.coroutines.jvm.internal.SuspendLambda: java.lang.String toString()
org.webrtc.LibvpxVp8Decoder: long nativeCreateDecoder()
org.webrtc.ThreadUtils$2: void run()
org.webrtc.Predicate$3: boolean test(java.lang.Object)
com.google.firestore.bundle.BundledQuery$LimitType: com.google.firestore.bundle.BundledQuery$LimitType[] values()
org.webrtc.PlatformSoftwareVideoDecoderFactory: PlatformSoftwareVideoDecoderFactory(org.webrtc.EglBase$Context)
io.flutter.embedding.engine.FlutterJNI: void setPlatformMessageHandler(io.flutter.embedding.engine.dart.PlatformMessageHandler)
org.webrtc.PeerConnectionFactory: void nativeStopAecDump(long)
org.webrtc.EglBase10Impl$1FakeSurfaceHolder: android.graphics.Rect getSurfaceFrame()
org.webrtc.AndroidVideoDecoder: java.lang.String getImplementationName()
org.webrtc.IceCandidate: java.lang.String getSdp()
org.webrtc.PeerConnectionFactory$InitializationOptions$Builder: org.webrtc.PeerConnectionFactory$InitializationOptions$Builder setNativeLibraryLoader(org.webrtc.NativeLibraryLoader)
org.webrtc.RtpCapabilities: RtpCapabilities(java.util.List,java.util.List)
com.google.firebase.database.collection.LLRBNode$Color: com.google.firebase.database.collection.LLRBNode$Color valueOf(java.lang.String)
org.webrtc.JniCommon: void nativeReleaseRef(long)
org.webrtc.voiceengine.WebRtcAudioEffects: WebRtcAudioEffects()
org.webrtc.VideoCodecStatus: org.webrtc.VideoCodecStatus valueOf(java.lang.String)
androidx.window.layout.SidecarCompat: boolean validateExtensionInterface()
com.google.firebase.database.collection.RBTreeSortedMap$Builder$BooleanChunk: RBTreeSortedMap$Builder$BooleanChunk()
org.webrtc.Camera1Capturer: void initialize(org.webrtc.SurfaceTextureHelper,android.content.Context,org.webrtc.CapturerObserver)
org.webrtc.NetworkMonitorAutoDetect$WifiDirectManagerDelegate: java.util.List getActiveNetworkList()
androidx.core.app.RemoteActionCompatParcelizer: RemoteActionCompatParcelizer()
io.grpc.internal.ManagedChannelImpl$ResolutionState: io.grpc.internal.ManagedChannelImpl$ResolutionState valueOf(java.lang.String)
org.webrtc.SessionDescription$Type: org.webrtc.SessionDescription$Type[] $values()
org.webrtc.VideoEncoder$CodecSpecificInfoVP8: VideoEncoder$CodecSpecificInfoVP8()
com.google.firebase.firestore.proto.MaybeDocument: MaybeDocument()
org.webrtc.DataChannel: org.webrtc.DataChannel$State nativeState()
org.webrtc.PeerConnection: org.webrtc.PeerConnection$SignalingState nativeSignalingState()
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin: void onDetachedFromEngine(io.flutter.embedding.engine.plugins.FlutterPlugin$FlutterPluginBinding)
org.webrtc.RtpParameters: RtpParameters(java.lang.String,org.webrtc.RtpParameters$DegradationPreference,org.webrtc.RtpParameters$Rtcp,java.util.List,java.util.List,java.util.List)
com.google.android.gms.internal.base.zac: zac()
androidx.window.layout.WindowInfoTrackerImpl: WindowInfoTrackerImpl(androidx.window.layout.WindowMetricsCalculator,androidx.window.layout.WindowBackend)
io.flutter.embedding.engine.FlutterJNI: void destroyOverlaySurfaces()
org.webrtc.audio.JavaAudioDeviceModule: boolean isBuiltInAcousticEchoCancelerSupported()
com.cloudwebrtc.webrtc.utils.ObjectType: com.cloudwebrtc.webrtc.utils.ObjectType[] values()
org.webrtc.voiceengine.WebRtcAudioRecord: void reportWebRtcAudioRecordStartError(org.webrtc.voiceengine.WebRtcAudioRecord$AudioRecordStartErrorCode,java.lang.String)
org.webrtc.MediaStreamTrack: void dispose()
kotlin.jvm.internal.FunctionReference: boolean isOperator()
org.webrtc.JavaI420Buffer: void checkCapacity(java.nio.ByteBuffer,int,int,int)
androidx.window.embedding.ExtensionEmbeddingBackend: void setSplitRules(java.util.Set)
org.webrtc.DtmfSender: java.lang.String nativeTones(long)
org.webrtc.YuvHelper: void I420Copy(java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,int,int,int,int,int)
org.webrtc.PeerConnection$CandidateNetworkPolicy: org.webrtc.PeerConnection$CandidateNetworkPolicy[] values()
kotlin.jvm.internal.FunctionReference: boolean isInfix()
org.webrtc.PeerConnectionFactory: void shutdownInternalTracer()
androidx.window.layout.SidecarCompat$DistinctElementCallback: SidecarCompat$DistinctElementCallback(androidx.window.layout.ExtensionInterfaceCompat$ExtensionCallbackInterface)
org.webrtc.NetworkMonitorAutoDetect$WifiDirectManagerDelegate: void onReceive(android.content.Context,android.content.Intent)
io.grpc.ClientStreamTracer$Factory: ClientStreamTracer$Factory()
org.webrtc.CameraCapturer: void reportCameraSwitchError(java.lang.String,org.webrtc.CameraVideoCapturer$CameraSwitchHandler)
com.google.firestore.v1.CommitRequest: CommitRequest()
com.cloudwebrtc.webrtc.DataChannelObserver: java.lang.String dataChannelStateString(org.webrtc.DataChannel$State)
org.webrtc.MediaStream: boolean removeTrack(org.webrtc.AudioTrack)
org.webrtc.ScreenCapturerAndroid: long getNumCapturedFrames()
org.webrtc.NativeCapturerObserver: void onFrameCaptured(org.webrtc.VideoFrame)
org.webrtc.voiceengine.WebRtcAudioUtils: boolean useWebRtcBasedAcousticEchoCanceler()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void peerConnectionCreateAnswer(java.lang.String,com.cloudwebrtc.webrtc.utils.ConstraintsMap,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.VideoFrameDrawer$YuvUploader: VideoFrameDrawer$YuvUploader()
org.webrtc.audio.WebRtcAudioUtils: void logAudioStateVolume(java.lang.String,android.media.AudioManager)
org.webrtc.EglRenderer: void createEglSurfaceInternal(java.lang.Object)
org.webrtc.LibvpxVp9Decoder: long createNativeVideoDecoder()
org.webrtc.RtpTransceiver: java.lang.String nativeGetMid(long)
com.cloudwebrtc.webrtc.utils.AnyThreadResult: void success(java.lang.Object)
org.webrtc.PeerConnectionFactory: boolean startAecDump(int,int)
org.webrtc.YuvHelper: void nativeI420Copy(java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,int,int)
com.google.firestore.v1.StructuredQuery$Direction: com.google.firestore.v1.StructuredQuery$Direction valueOf(java.lang.String)
kotlin.jvm.internal.FunctionReference: int hashCode()
com.google.firestore.v1.ArrayValue: ArrayValue()
org.webrtc.SurfaceViewRenderer: void onFirstFrameRendered()
org.webrtc.PeerConnection: org.webrtc.RtpSender nativeAddTrack(long,java.util.List)
org.webrtc.NetworkMonitor: boolean isOnline()
org.webrtc.StatsObserver: void onComplete(org.webrtc.StatsReport[])
org.webrtc.SurfaceViewRenderer: void surfaceChanged(android.view.SurfaceHolder,int,int,int)
com.cloudwebrtc.webrtc.utils.ConstraintsArray: com.cloudwebrtc.webrtc.utils.ConstraintsArray getArray(int)
androidx.window.layout.SidecarCompat$registerConfigurationChangeListener$configChangeObserver$1: void onConfigurationChanged(android.content.res.Configuration)
org.webrtc.FileVideoCapturer: void stopCapture()
io.flutter.embedding.engine.systemchannels.PlatformChannel$HapticFeedbackType: io.flutter.embedding.engine.systemchannels.PlatformChannel$HapticFeedbackType[] values()
org.webrtc.VideoCodecInfo: VideoCodecInfo(java.lang.String,java.util.Map)
com.cloudwebrtc.webrtc.DataChannelObserver: void onListen(java.lang.Object,io.flutter.plugin.common.EventChannel$EventSink)
org.webrtc.PeerConnectionFactory: void checkPeerConnectionFactoryExists()
io.flutter.embedding.engine.renderer.SurfaceTextureWrapper: SurfaceTextureWrapper(android.graphics.SurfaceTexture)
org.webrtc.RtpReceiver$Observer: void onFirstPacketReceived(org.webrtc.MediaStreamTrack$MediaType)
org.webrtc.voiceengine.WebRtcAudioRecord: void logMainParameters()
org.webrtc.VideoEncoder: org.webrtc.VideoEncoder$ResolutionBitrateLimits[] getResolutionBitrateLimits()
org.webrtc.Camera1Enumerator: java.util.List enumerateFormats(int)
androidx.window.layout.WindowInfoTracker$-CC: androidx.window.layout.WindowInfoTracker getOrCreate(android.content.Context)
org.webrtc.Camera2Enumerator: java.util.List convertSizes(android.util.Size[])
org.webrtc.voiceengine.WebRtcAudioUtils: void setDefaultSampleRateHz(int)
org.webrtc.VideoFrame$TextureBuffer: android.graphics.Matrix getTransformMatrix()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl$3: MethodCallHandlerImpl$3(com.cloudwebrtc.webrtc.MethodCallHandlerImpl,io.flutter.plugin.common.MethodChannel$Result)
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback: android.view.View access$600(io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback)
io.flutter.embedding.engine.FlutterJNI: void setRefreshRateFPS(float)
com.google.firebase.concurrent.UiExecutor: com.google.firebase.concurrent.UiExecutor[] values()
com.cloudwebrtc.webrtc.utils.ConstraintsMap: void putInt(java.lang.String,int)
org.webrtc.Logging: void enableTracing(java.lang.String,java.util.EnumSet)
com.cloudwebrtc.webrtc.GetUserMediaImpl: void hasTorch(java.lang.String,io.flutter.plugin.common.MethodChannel$Result)
io.flutter.plugin.editing.TextInputPlugin$InputTarget$Type: io.flutter.plugin.editing.TextInputPlugin$InputTarget$Type valueOf(java.lang.String)
io.grpc.internal.TransportFrameUtil: TransportFrameUtil()
org.webrtc.voiceengine.WebRtcAudioEffects: org.webrtc.voiceengine.WebRtcAudioEffects create()
org.webrtc.CameraVideoCapturer: void switchCamera(org.webrtc.CameraVideoCapturer$CameraSwitchHandler,java.lang.String)
io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback$AnimationCallback: ImeSyncDeferringInsetsCallback$AnimationCallback(io.flutter.plugin.editing.ImeSyncDeferringInsetsCallback)
org.webrtc.PeerConnection$IceServer$Builder: org.webrtc.PeerConnection$IceServer$Builder setHostname(java.lang.String)
org.webrtc.EglBase$-CC: org.webrtc.EglBase14 createEgl14(android.opengl.EGLContext,int[])
org.webrtc.CalledByNative: java.lang.String value()
org.webrtc.EglBase10Impl: long nativeGetCurrentNativeEGLContext()
org.webrtc.AudioEncoderFactoryFactory: long createNativeAudioEncoderFactory()
io.flutter.embedding.engine.FlutterJNI: void onDisplayPlatformView(int,int,int,int,int,int,int,io.flutter.embedding.engine.mutatorsstack.FlutterMutatorsStack)
org.webrtc.PeerConnection$KeyType: org.webrtc.PeerConnection$KeyType[] $values()
androidx.window.java.layout.WindowInfoTrackerCallbackAdapter: void addWindowLayoutInfoListener(android.app.Activity,java.util.concurrent.Executor,androidx.core.util.Consumer)
io.flutter.embedding.engine.FlutterJNI: void ensureAttachedToNative()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void mediaStreamTrackSetVolume(java.lang.String,double,java.lang.String)
org.webrtc.EglRenderer$HandlerWithExceptionCallback: void dispatchMessage(android.os.Message)
org.webrtc.PeerConnection$Observer$-CC: void $default$onSelectedCandidatePairChanged(org.webrtc.PeerConnection$Observer,org.webrtc.CandidatePairChangeEvent)
org.webrtc.AndroidVideoDecoder: org.webrtc.SurfaceTextureHelper createSurfaceTextureHelper()
org.webrtc.PeerConnectionFactory: org.webrtc.PeerConnection createPeerConnection(org.webrtc.PeerConnection$RTCConfiguration,org.webrtc.PeerConnectionDependencies)
org.webrtc.WrappedVideoDecoderFactory: boolean disableSurfaceTextureFrame(java.lang.String)
org.webrtc.RtpTransceiver: void nativeStopInternal(long)
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper: SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper(org.webrtc.VideoEncoder)
org.webrtc.LibvpxVp8Encoder: boolean isHardwareEncoder()
org.webrtc.FrameCryptor: void setObserver(org.webrtc.FrameCryptor$Observer)
org.webrtc.IceCandidate: IceCandidate(java.lang.String,int,java.lang.String)
io.grpc.internal.JsonParser: JsonParser()
org.webrtc.CameraCapturer: CameraCapturer(java.lang.String,org.webrtc.CameraVideoCapturer$CameraEventsHandler,org.webrtc.CameraEnumerator)
org.webrtc.Camera2Session$CameraCaptureCallback: Camera2Session$CameraCaptureCallback()
io.flutter.embedding.android.FlutterSplashView$SavedState: android.os.Bundle access$702(io.flutter.embedding.android.FlutterSplashView$SavedState,android.os.Bundle)
androidx.window.embedding.SplitRule: SplitRule(int,int,float,int,int,kotlin.jvm.internal.DefaultConstructorMarker)
org.webrtc.TextureBufferImpl: org.webrtc.TextureBufferImpl applyTransformMatrix(android.graphics.Matrix,int,int)
org.webrtc.voiceengine.WebRtcAudioTrack: void reportWebRtcAudioTrackInitError(java.lang.String)
androidx.window.layout.WindowInfoTrackerImpl$windowLayoutInfo$1: kotlin.coroutines.Continuation create(java.lang.Object,kotlin.coroutines.Continuation)
org.webrtc.PeerConnectionFactory$Options: boolean getDisableNetworkMonitor()
org.webrtc.BuiltinAudioEncoderFactoryFactory: BuiltinAudioEncoderFactoryFactory()
com.google.firebase.firestore.model.FieldIndex$Segment$Kind: com.google.firebase.firestore.model.FieldIndex$Segment$Kind[] values()
org.webrtc.TextureBufferImpl: android.graphics.Matrix getTransformMatrix()
org.webrtc.VideoCodecInfo: int hashCode()
org.webrtc.TextureBufferImpl$2: void onRetain(org.webrtc.TextureBufferImpl)
androidx.window.layout.WindowMetricsCalculator$Companion: androidx.window.layout.WindowMetricsCalculator getOrCreate()
io.grpc.Context: Context()
io.flutter.embedding.engine.FlutterJNI: void nativeInvokePlatformMessageEmptyResponseCallback(long,int)
com.cloudwebrtc.webrtc.utils.Callback: void invoke(java.lang.Object[])
org.webrtc.HardwareVideoEncoderFactory: boolean isHardwareSupportedInCurrentSdk(android.media.MediaCodecInfo,org.webrtc.VideoCodecMimeType)
org.webrtc.PeerConnection: void nativeStopRtcEventLog()
androidx.window.embedding.SplitController: void removeSplitListener(androidx.core.util.Consumer)
org.webrtc.audio.WebRtcAudioRecord: int initRecording(int,int)
io.grpc.ChannelLogger$ChannelLogLevel: io.grpc.ChannelLogger$ChannelLogLevel[] values()
org.webrtc.Camera1Capturer: void stopCapture()
org.webrtc.MediaCodecWrapperFactoryImpl$MediaCodecWrapperImpl: android.media.MediaCodecInfo getCodecInfo()
io.grpc.ClientStreamTracer: ClientStreamTracer()
com.google.firestore.v1.StructuredAggregationQuery$Builder: StructuredAggregationQuery$Builder()
org.webrtc.GlShader: int compileShader(int,java.lang.String)
org.webrtc.SimulcastVideoEncoder: SimulcastVideoEncoder(org.webrtc.VideoEncoderFactory,org.webrtc.VideoEncoderFactory,org.webrtc.VideoCodecInfo)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: org.webrtc.MediaStream getStreamForId(java.lang.String,java.lang.String)
io.grpc.internal.DelayedStream: DelayedStream()
org.webrtc.EglBase10Impl: void makeCurrent()
io.flutter.embedding.engine.systemchannels.PlatformChannel$ClipboardContentFormat: io.flutter.embedding.engine.systemchannels.PlatformChannel$ClipboardContentFormat valueOf(java.lang.String)
com.google.firebase.firestore.remote.WatchChange$WatchTargetChangeType: com.google.firebase.firestore.remote.WatchChange$WatchTargetChangeType[] values()
org.webrtc.RefCountDelegate: RefCountDelegate(java.lang.Runnable)
androidx.window.embedding.EmbeddingTranslatingCallback: void accept(java.util.List)
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: void peerConnectionRemoveStream(java.lang.String,java.lang.String,io.flutter.plugin.common.MethodChannel$Result)
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor$FrameCryptorStateObserver$1: void onListen(java.lang.Object,io.flutter.plugin.common.EventChannel$EventSink)
androidx.window.layout.FoldingFeature$Orientation: java.lang.String toString()
org.webrtc.SessionDescription$Type: org.webrtc.SessionDescription$Type[] values()
org.webrtc.Predicate$2: Predicate$2(org.webrtc.Predicate,org.webrtc.Predicate)
org.webrtc.BitrateAdjuster: double getAdjustedFramerateFps()
org.webrtc.GlRectDrawer: void release()
com.cloudwebrtc.webrtc.PeerConnectionObserver: PeerConnectionObserver(org.webrtc.PeerConnection$RTCConfiguration,com.cloudwebrtc.webrtc.StateProvider,io.flutter.plugin.common.BinaryMessenger,java.lang.String)
androidx.window.embedding.EmbeddingAdapter: boolean translateParentMetricsPredicate$lambda-4(androidx.window.embedding.SplitRule,android.view.WindowMetrics)
org.webrtc.RendererCommon: float[] getLayoutMatrix(boolean,float,float)
org.webrtc.VideoFrame$I420Buffer: int getStrideU()
org.webrtc.EglRenderer: void logStatistics()
androidx.fragment.app.FragmentTransaction$Op: FragmentTransaction$Op()
io.flutter.embedding.engine.systemchannels.PlatformViewsChannel$PlatformViewCreationRequest$RequestedDisplayMode: io.flutter.embedding.engine.systemchannels.PlatformViewsChannel$PlatformViewCreationRequest$RequestedDisplayMode[] values()
org.webrtc.voiceengine.WebRtcAudioUtils: void logIsStreamMute(java.lang.String,android.media.AudioManager,int,java.lang.StringBuilder)
org.webrtc.RefCountDelegate: boolean safeRetain()
androidx.window.layout.SidecarAdapter$Companion: SidecarAdapter$Companion()
androidx.window.embedding.SplitPairRule: SplitPairRule(java.util.Set,boolean,boolean,boolean,int,int,float,int)
io.grpc.okhttp.Utils: Utils()
com.cloudwebrtc.webrtc.SimulcastVideoEncoderFactoryWrapper$StreamEncoderWrapper: org.webrtc.VideoEncoder$EncoderInfo getEncoderInfo()
com.cloudwebrtc.webrtc.FlutterWebRTCPlugin$LifeCycleObserver: void onResume(androidx.lifecycle.LifecycleOwner)
org.webrtc.EglBase14Impl: void createPbufferSurface(int,int)
org.webrtc.RtpSender: java.util.List getStreams()
org.webrtc.PeerConnection: java.util.List nativeGetTransceivers()
io.flutter.embedding.engine.FlutterJNI: void ensureRunningOnMainThread()
org.webrtc.audio.JavaAudioDeviceModule$Builder: org.webrtc.audio.JavaAudioDeviceModule$Builder setEnableVolumeLogger(boolean)
org.webrtc.NetworkMonitorAutoDetect$WifiManagerDelegate: NetworkMonitorAutoDetect$WifiManagerDelegate()
org.webrtc.SimulcastVideoEncoderFactory: SimulcastVideoEncoderFactory(org.webrtc.VideoEncoderFactory,org.webrtc.VideoEncoderFactory)
com.google.firestore.v1.StructuredQuery$Filter$Builder: StructuredQuery$Filter$Builder()
org.webrtc.MediaSource: void checkMediaSourceExists()
com.google.firestore.v1.StructuredAggregationQuery$Aggregation$Builder: StructuredAggregationQuery$Aggregation$Builder()
org.webrtc.CameraCapturer: void printStackTrace()
org.webrtc.voiceengine.BuildInfo: java.lang.String getBuildRelease()
org.webrtc.MediaSource: org.webrtc.MediaSource$State nativeGetState(long)
org.webrtc.TextureBufferImpl: TextureBufferImpl(int,int,org.webrtc.VideoFrame$TextureBuffer$Type,int,android.graphics.Matrix,android.os.Handler,org.webrtc.YuvConverter,org.webrtc.TextureBufferImpl$RefCountMonitor)
org.webrtc.Camera2Session$CameraCaptureCallback: void onCaptureFailed(android.hardware.camera2.CameraCaptureSession,android.hardware.camera2.CaptureRequest,android.hardware.camera2.CaptureFailure)
androidx.window.layout.ExtensionInterfaceCompat: void setExtensionCallback(androidx.window.layout.ExtensionInterfaceCompat$ExtensionCallbackInterface)
org.webrtc.PeerConnection$Observer: void onAddTrack(org.webrtc.RtpReceiver,org.webrtc.MediaStream[])
org.webrtc.FrameCryptorKeyProvider: byte[] exportKey(java.lang.String,int)
org.webrtc.PeerConnection$TlsCertPolicy: PeerConnection$TlsCertPolicy(java.lang.String,int)
com.cloudwebrtc.webrtc.DataChannelObserver: void onStateChange()
org.webrtc.FileVideoCapturer: FileVideoCapturer(java.lang.String)
androidx.window.layout.WindowInfoTrackerDecorator: androidx.window.layout.WindowInfoTracker decorate(androidx.window.layout.WindowInfoTracker)
org.webrtc.PeerConnection: org.webrtc.PeerConnection$IceGatheringState nativeIceGatheringState()
org.webrtc.PeerConnection$TcpCandidatePolicy: org.webrtc.PeerConnection$TcpCandidatePolicy[] values()
org.webrtc.PeerConnection: void getStats(org.webrtc.RtpSender,org.webrtc.RTCStatsCollectorCallback)
org.webrtc.YuvHelper: void nativeI420Rotate(java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,int,int,int)
org.webrtc.CallSessionFileRotatingLogSink: byte[] getLogData(java.lang.String)
org.webrtc.AudioTrack: void setVolume(double)
org.webrtc.PeerConnection$KeyType: org.webrtc.PeerConnection$KeyType valueOf(java.lang.String)
org.webrtc.EglBase10Impl$1FakeSurfaceHolder: void setFormat(int)
org.webrtc.RtcCertificatePem: java.lang.String getCertificate()
org.webrtc.voiceengine.WebRtcAudioRecord: boolean enableBuiltInNS(boolean)
com.google.common.collect.Maps$EntryFunction: com.google.common.collect.Maps$EntryFunction valueOf(java.lang.String)
org.webrtc.PeerConnection$Observer$-CC: void $default$onConnectionChange(org.webrtc.PeerConnection$Observer,org.webrtc.PeerConnection$PeerConnectionState)
androidx.window.layout.SidecarWindowBackend: void access$setGlobalInstance$cp(androidx.window.layout.SidecarWindowBackend)
org.webrtc.PeerConnection$IceServer: java.lang.String toString()
org.webrtc.PeerConnection$IceServer: PeerConnection$IceServer(java.lang.String,java.util.List,java.lang.String,java.lang.String,org.webrtc.PeerConnection$TlsCertPolicy,java.lang.String,java.util.List,java.util.List)
org.webrtc.FrameCryptor: void checkFrameCryptorExists()
org.webrtc.ContextUtils: android.content.Context getApplicationContext()
androidx.window.embedding.ActivityFilter: java.lang.String toString()
com.cloudwebrtc.webrtc.MethodCallHandlerImpl: org.webrtc.PeerConnectionFactory getPeerConnectionFactory()
org.webrtc.AndroidVideoDecoder: void onFrame(org.webrtc.VideoFrame)
com.google.firestore.v1.Cursor: Cursor()
com.google.firestore.admin.v1.Index: Index()
org.webrtc.SoftwareVideoDecoderFactory$1: long createNativeVideoDecoder()
org.webrtc.audio.WebRtcAudioTrack: android.media.AudioTrack createAudioTrackBeforeOreo(int,int,int,android.media.AudioAttributes)
org.webrtc.PeerConnection$TcpCandidatePolicy: org.webrtc.PeerConnection$TcpCandidatePolicy valueOf(java.lang.String)
org.webrtc.VideoEncoder$EncoderInfo: int getRequestedResolutionAlignment()
org.webrtc.SurfaceViewRenderer: void onLayout(boolean,int,int,int,int)
androidx.window.embedding.SplitInfo: androidx.window.embedding.ActivityStack getPrimaryActivityStack()
com.google.common.base.Platform: Platform()
org.webrtc.voiceengine.BuildInfo: java.lang.String getProduct()
com.cloudwebrtc.webrtc.utils.PermissionUtils$RequestPermissionsFragment: void finish()
io.flutter.embedding.android.KeyData$Type: io.flutter.embedding.android.KeyData$Type[] values()
io.flutter.embedding.engine.FlutterJNI: void cleanupMessageData(long)
com.cloudwebrtc.webrtc.audio.AudioDeviceKind: com.cloudwebrtc.webrtc.audio.AudioDeviceKind[] values()
androidx.window.embedding.SplitPairFilter: java.lang.String toString()
io.flutter.embedding.engine.systemchannels.SettingsChannel$PlatformBrightness: io.flutter.embedding.engine.systemchannels.SettingsChannel$PlatformBrightness valueOf(java.lang.String)
org.webrtc.YuvHelper: void I420Rotate(java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,java.nio.ByteBuffer,int,int,int,int)
io.grpc.InternalChannelz$ChannelTrace$Event$Severity: io.grpc.InternalChannelz$ChannelTrace$Event$Severity[] values()
org.webrtc.TimestampAligner: void dispose()
org.webrtc.HardwareVideoEncoder: HardwareVideoEncoder(org.webrtc.MediaCodecWrapperFactory,java.lang.String,org.webrtc.VideoCodecMimeType,java.lang.Integer,java.lang.Integer,java.util.Map,int,int,org.webrtc.BitrateAdjuster,org.webrtc.EglBase14$Context)
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor: org.webrtc.FrameCryptorAlgorithm frameCryptorAlgorithmFromInt(int)
org.webrtc.RtpCapabilities: java.util.List getCodecs()
androidx.window.layout.SidecarWindowBackend$WindowLayoutChangeCallbackWrapper: androidx.core.util.Consumer getCallback()
com.cloudwebrtc.webrtc.utils.MediaConstraintsUtils: MediaConstraintsUtils()
org.webrtc.NetworkMonitorAutoDetect$WifiManagerDelegate: NetworkMonitorAutoDetect$WifiManagerDelegate(android.content.Context)
com.cloudwebrtc.webrtc.FlutterRTCFrameCryptor: void frameCryptorSetEnabled(java.util.Map,io.flutter.plugin.common.MethodChannel$Result)
org.webrtc.PeerConnection$RTCConfiguration: boolean getEnableImplicitRollback()
org.webrtc.WrappedNativeVideoDecoder: org.webrtc.VideoCodecStatus release()
org.webrtc.NetworkMonitor$2: void onNetworkConnect(org.webrtc.NetworkChangeDetector$NetworkInformation)
org.webrtc.HardwareVideoEncoder: void deliverEncodedImage()
org.webrtc.FrameCryptor: void setEnabled(boolean)
org.webrtc.VideoEncoder$Callback: void onEncodedFrame(org.webrtc.EncodedImage,org.webrtc.VideoEncoder$CodecSpecificInfo)
org.webrtc.RTCStats: void appendValue(java.lang.StringBuilder,java.lang.Object)
org.webrtc.PeerConnection$RTCConfiguration: int getMaxIPv6Networks()
org.webrtc.RTCStatsReport: RTCStatsReport(long,java.util.Map)
kotlin.coroutines.jvm.internal.BaseContinuationImpl: kotlin.coroutines.jvm.internal.CoroutineStackFrame getCallerFrame()
org.webrtc.voiceengine.WebRtcAudioTrack: void setErrorCallback(org.webrtc.voiceengine.WebRtcAudioTrack$ErrorCallback)
org.webrtc.PeerConnection: org.webrtc.SessionDescription nativeGetRemoteDescription()
androidx.window.embedding.ExtensionEmbeddingBackend: void getSplitChangeCallbacks$annotations()
androidx.window.layout.WindowMetrics: WindowMetrics(androidx.window.core.Bounds)
org.webrtc.VideoProcessor$-CC: org.webrtc.VideoFrame applyFrameAdaptationParameters(org.webrtc.VideoFrame,org.webrtc.VideoProcessor$FrameAdaptationParameters)
com.cloudwebrtc.webrtc.utils.ConstraintsMap: void putLong(java.lang.String,long)
org.webrtc.voiceengine.WebRtcAudioUtils: java.lang.String modeToString(int)
org.webrtc.PeerConnection: boolean setConfiguration(org.webrtc.PeerConnection$RTCConfiguration)
com.cloudwebrtc.webrtc.PeerConnectionObserver: java.util.Map rtpReceiverToMap(org.webrtc.RtpReceiver)
org.webrtc.voiceengine.WebRtcAudioUtils: WebRtcAudioUtils()
org.webrtc.RtpTransceiver$RtpTransceiverDirection: org.webrtc.RtpTransceiver$RtpTransceiverDirection valueOf(java.lang.String)
org.webrtc.MediaStreamTrack: boolean setEnabled(boolean)
org.webrtc.MediaStreamTrack$State: MediaStreamTrack$State(java.lang.String,int)
org.webrtc.VideoEncoder: org.webrtc.VideoCodecStatus setRates(org.webrtc.VideoEncoder$RateControlParameters)
org.webrtc.HardwareVideoDecoderFactory: org.webrtc.VideoDecoder createDecoder(org.webrtc.VideoCodecInfo)
org.webrtc.VideoFileRenderer: void lambda$release$2(java.util.concurrent.CountDownLatch)
org.webrtc.EglBase$ConfigBuilder: EglBase$ConfigBuilder()
org.webrtc.VideoDecoderWrapper: void lambda$createDecoderCallback$0(long,org.webrtc.VideoFrame,java.lang.Integer,java.lang.Integer)
androidx.window.layout.SidecarWindowBackend: java.util.concurrent.locks.ReentrantLock access$getGlobalLock$cp()
org.webrtc.PeerConnection: org.webrtc.SessionDescription nativeGetLocalDescription()
com.cloudwebrtc.webrtc.PeerConnectionObserver: org.webrtc.MediaStreamTrack$MediaType stringToMediaType(java.lang.String)
com.google.firestore.v1.Value$ValueTypeCase: com.google.firestore.v1.Value$ValueTypeCase[] values()
org.webrtc.PeerConnectionFactory: void nativePrintStackTrace(int)
org.webrtc.audio.WebRtcAudioTrack: int channelCountToConfiguration(int)
kotlinx.coroutines.internal.AtomicOp: AtomicOp()
org.webrtc.ThreadUtils$4: java.lang.Void call()
io.flutter.embedding.engine.FlutterOverlaySurface: FlutterOverlaySurface(int,android.view.Surface)
com.cloudwebrtc.webrtc.PeerConnectionObserver: java.util.Map dtmfSenderToMap(org.webrtc.DtmfSender,java.lang.String)
androidx.core.view.ViewCompat$UnhandledKeyEventManager: ViewCompat$UnhandledKeyEventManager()
org.webrtc.voiceengine.WebRtcAudioManager: boolean isProAudioSupported()
com.google.type.LatLng: LatLng()
